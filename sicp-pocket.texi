\input texinfo
@comment  페이지 여백을 자르려면 (To crop page margins):
@comment  @input marginless  (marginless 입력)
@comment
@comment             **********************************************************
@setfilename         html
@settitle            컴퓨터 프로그램의 구조와 해석, 제2판
@documentlanguage    ko
@comment             비공식 텍스인포 형식 (Unofficial Texinfo Format)
@comment
@set utfversion      2.andresraba6.6
@set utfversiondate  September 16, 2015
@comment
@comment             이 파일은 크리에이티브 커먼즈
@comment             저작자표시-동일조건변경허락 4.0 국제 라이선스로 제공됨
@comment             (This file is licensed under a Creative Commons
@comment             Attribution-ShareAlike 4.0 International License)
@comment             http://creativecommons.org/licenses/by-sa/4.0/
@comment             
@comment             이 파일은 Texinfo 파일이다. Info 하이퍼텍스트 형식으로
@comment             변환하려면 GNU Texinfo 패키지의 `makeinfo' 프로그램이 필요하다.
@comment             PDF를 만들려면 texi2pdf를 사용한다.
@comment             이 파일에 대한 더 많은 정보는
@comment             아래 `@node UTF' 항목의 텍스트를 참조하라.
@comment             (This is a Texinfo file.  To convert it to Info hypertext
@comment             format, you will need the `makeinfo' program from the GNU
@comment             Texinfo package.  To produce a PDF, use texi2pdf.
@comment             For more information about this file,
@comment             see the text under `@node UTF' below.)
@comment             
@comment             다양한 sicp.texi 버전과 사전 생성된 sicp.info는
@comment             다음 웹페이지에서 찾을 수 있다:
@comment             (Various versions of sicp.texi and preformatted sicp.info
@comment             can be found at the following Web pages:)
@comment             
@comment                 http://www.neilvandyke.org/sicp-texi/
@comment                 http://sicpebook.wordpress.com/
@comment                 [여기에 추가] ([add your own here])
@comment             
@comment             **********************************************************

@comment 변경 이력 (HISTORY):
@comment
@comment * 버전 1 (2001년 4월) - Lytha Ayth. (Version 1 (April, 2001) by Lytha Ayth.)
@comment
@comment * 버전 2 (2001년 4월 20일) - Lytha Ayth. (Version 2 (April 20, 2001) by Lytha Ayth.)
@comment
@comment * 버전 2.nwv1 (2002년 3월 11일) - Neil W. Van Dyke.
@comment   Info 형식 머리말의 외형 변경 및 주석 변경.
@comment   (Version 2.nwv1 (March 11, 2002) by Neil W. Van Dyke.)
@comment   (Cosmetic change to heading in Info format, and comment changes.)
@comment 
@comment * 버전 2.neilvandyke1 (2003년 2월 10일) - Neil W. Van Dyke
@comment   연습문제 1.39의 공식 수정 (Steve VanDevender가 발견).
@comment   Abelson과 Sussman 강의 영상 URL 추가.
@comment   (Version 2.neilvandyke1 (February 10, 2003) by Neil W. Van Dyke)
@comment   (Correction to Exercise 1.39 formula, spotted by Steve VanDevender.)
@comment   (Added URL of Abelson and Sussman video lectures.)
@comment
@comment * 버전 2.neilvandyke2 (미공개) (Version 2.neilvandyke2 (unreleased))
@comment
@comment * 버전 2.neilvandyke3 (2006년 4월 20일) - Neil W. Van Dyke
@comment   누락된 Lisp 예제를 추가하는 Pedro Kr@"oger 패치.
@comment   (Version 2.neilvandyke3 (April 20, 2006) by Neil W. Van Dyke)
@comment   (Pedro Kr@"oger patch to add missing Lisp example.)
@comment
@comment * 버전 2.neilvandyke4 (2007년 1월 10일) - Neil W. Van Dyke
@comment   @code{@@dircategory} 및 @code{@@direntry}를 추가하는 Brad Walker 패치.
@comment   (Version 2.neilvandyke4 (January 10, 2007) by Neil W. Van Dyke)
@comment   (Brad Walker patch to add @code{@@dircategory} and @code{@@direntry}.)
@comment
@comment * 버전 2.andresraba1 (2011년 5월 23일) - Andres Raba.
@comment   수식 TeX 조판, 도형 벡터 그래픽 재작성,
@comment   서체 변경, 교차 참조 개선, 하이퍼링크 추가,
@comment   알려진 오류 및 오타 수정.
@comment   (Version 2.andresraba1 (May 23, 2011) by Andres Raba.)
@comment   (Mathematics typeset in TeX, figures redrawn in vector graphics,
@comment   typeface changed, cross-references improved, hyperlinks added,
@comment   known errors and typos corrected.)
@comment
@comment * 버전 2.andresraba2 (2011년 11월 21일) - Andres Raba.
@comment   도표 모양 소폭 변경, 페이지 레이아웃 조정.
@comment   일부 오타 수정. 라이선스 CC BY-NC에서 CC BY-SA로 변경.
@comment   (Version 2.andresraba2 (November 21, 2011) by Andres Raba.)
@comment   (Minor change to the appearance of diagrams. Adjusted page layout.
@comment   Fixed some typos. License changed from CC BY-NC to CC BY-SA.)
@comment
@comment * 버전 2.gavrie1 (2011년 11월 21일) - Gavrie Philipson.
@comment   @kindle 추가(texinfo.tex에 정의) 및 페이지 번호 제거.
@comment   페이지 레이아웃과 텍스트 크기를 킨들형 기기에 맞춤.
@comment   (Version 2.gavrie1 (November 21, 2011) by Gavrie Philipson.)
@comment   (Added @kindle (defined in texinfo.tex), and removed page numbers.
@comment   Page layout and text size adapted to Kindle-like devices.)
@comment
@comment * 버전 2.araba1p-a2.1 (2012년 3월 19일) - Andres Raba.
@comment   두 장을 포켓 형식으로 재서식화. 페이지 지오메트리는
@comment   texinfo.tex의 @pocket(이전 @kindle)로 정의됨.
@comment   (Version 2.araba1p-a2.1 (March 19, 2012) by Andres Raba.)
@comment   (Two chapters reformatted to pocket format. Page geometry
@comment   defined by @pocket (previously @kindle) in texinfo.tex.)
@comment
@comment * 버전 2.andresraba4 (2012년 11월 23일) - Andres Raba.
@comment   포켓 형식 변환 완료. 전체 책이 6인치 전자책 화면(PDF)에서
@comment   읽히도록 조판됨.
@comment   (Version 2.andresraba4 (November 23, 2012) by Andres Raba.)
@comment   (Conversion to pocket format completed. The whole book 
@comment   is now typeset to be read on 6-inch e-reader screen (PDF).)
@comment
@comment * (버전 2.andresraba5는 LaTeX 버전이며 sicp-pdf 저장소에 설명됨.)
@comment   (Version 2.andresraba5 is the LaTeX version, described in
@comment   sicp-pdf repository.)
@comment
@comment * 버전 2.andresraba6 (2014년 1월 7일) - Andres Raba.
@comment   책을 HTML5와 EPUB3로 변환. 수식은 MathML과 MathJax로 조판.
@comment   (Version 2.andresraba6 (January 7, 2014) by Andres Raba.)
@comment   (Book converted to HTML5 and EPUB3. Mathematics is typeset 
@comment   with MathML and MathJax.)
@comment
@comment * 버전 2.andresraba6.1 (2014년 2월 15일) - Andres Raba.
@comment   분할 임계값을 subsection에서 section으로 상향.
@comment   (Version 2.andresraba6.1 (February 15, 2014) by Andres Raba.)
@comment   (Raised the splitting threshold from subsection to section.)
@comment
@comment * 버전 2.andresraba6.2 (2014년 2월 23일) - Andres Raba.
@comment   epubcheck 검증을 통과하도록 SVG 파일 수정.
@comment   (Version 2.andresraba6.2 (February 23, 2014) by Andres Raba.)
@comment   (Fixed the SVG files to pass epubcheck validation.)
@comment
@comment * 버전 2.andresraba6.3 (2014년 6월 9일) - Andres Raba.
@comment   일부 Scheme 코드의 보기 좋은 출력 개선.
@comment   epub 기본 글꼴 크기를 170%에서 100%로 감소.
@comment   (Version 2.andresraba6.3 (June 9, 2014) by Andres Raba.)
@comment   (Improved the pretty-printing of some Scheme code.
@comment   Decreased the default font size of epub from 170% to 100%.)
@comment
@comment * 버전 2.andresraba6.4 (2014년 6월 24일) - Andres Raba.
@comment   모든 뷰포트에서 하이픈 분할 사용, 텍스트 열 폭 확대,
@comment   일부 Scheme 코드 재배치, Mathjax 프로토콜을
@comment   http에서 https로 변경.
@comment   (Version 2.andresraba6.4 (June 24, 2014) by Andres Raba.)
@comment   (Switched on hyphenation for all viewports, made text column
@comment   wider, re-arranged some Scheme code, changed Mathjax
@comment   protocol from http to https.)
@comment
@comment * 버전 2.andresraba6.5 (2015년 1월 29일) - Andres Raba.
@comment   라이선스에 비상업 조항 추가, 끊어진 링크 수정,
@comment   전체 텍스트 링크 추가, MathML의 고정폭 글꼴을 로만체로 교체
@comment   (Android 렌더링 버그), 수식 타이포그래피 조정.
@comment   (Version 2.andresraba6.5 (January 29, 2015) by Andres Raba.)
@comment   (Added noncommercial clause to license, fixed broken links,
@comment   added more fulltext links, replaced monospace with roman in
@comment   MathML (Android rendering bug), adjusted math typography.)
@comment
@comment * 버전 2.andresraba6.6 (2015년 9월 16일) - Andres Raba.
@comment   끊어진 링크 수정. 장/절 번호에 색상 적용.
@comment   라이선스를 CC BY-SA 4.0으로 업데이트.
@comment   (Version 2.andresraba6.6 (September 16, 2015) by Andres Raba.)
@comment   (Fixed broken links. Tinted chapter and section numbers.
@comment   License updated to CC BY-SA 4.0.)

@documentencoding UTF-8

@dircategory Rust 프로그래밍
@direntry
* SICP-Rust: (sicp). 컴퓨터 프로그램의 구조와 해석, Rust Edition
@end direntry

@macro newterm{term}
@cindex \term\
@dfn{\term\}
@end macro

@c @setshortcontentsaftertitlepage

@titlepage

@titlefont{컴퓨터 프로그램의 구조와 해석}

@subtitle @abbr{Rust Edition}@* 비공식 텍스인포 판 (Unofficial Texinfo Format) @value{utfversion}

@author 해럴드 에이벌슨 (Harold Abelson), 제럴드 제이 서스먼 (Gerald Jay Sussman), 줄리 서스먼 (Julie Sussman) 공저, 앨런 J. 펄리스 (Alan J. Perlis) 서문

@page
@vskip 0pt plus 1filll
@noindent
@copyright{}1996 매사추세츠 공과대학교 (The Massachusetts Institute of Technology)

@noindent
@image{fig/icons/cc, 6mm,,,.std.svg}
@image{fig/icons/by, 6mm,,,.std.svg}
@image{fig/icons/sa, 6mm,,,.std.svg}

@noindent
이 저작물은 크리에이티브 커먼즈 저작자표시-동일조건변경허락 4.0 국제 라이선스(@url{http://creativecommons.org/licenses/by-sa/4.0/, @abbr{CC BY-SA 4.0}})에 따라 이용할 수 있습니다.
@url{http://mitpress.mit.edu/sicp/, mitpress.mit.edu}의 저작물을 바탕으로 합니다.

@noindent
매사추세츠 공과대학교 출판부 (The @abbr{MIT} Press)@*
케임브리지, 매사추세츠 (Cambridge, Massachusetts)@*
런던, 잉글랜드 (London, England)

@noindent
맥그로힐 도서회사 (McGraw-Hill Book Company)@*
뉴욕, 세인트루이스, 샌프란시스코 (New York, St. Louis, San Francisco)@*
몬트리올, 토론토 (Montreal, Toronto)

@noindent
이 책은 매사추세츠 공과대학교(MIT) 전기공학 및 컴퓨터 과학과 (Department of Electrical Engineering and Computer Science) 교수진이 집필한 일련의 교재 중 하나입니다 (This book is one of a series of textbooks written by the faculty of the Department of Electrical Engineering and Computer Science at MIT).
맥그로힐 도서회사 (McGraw-Hill Book Company)와의 공동 제작 및 유통 협약 (joint production and distribution agreement)에 따라 매사추세츠 공과대학교 출판부 (The @abbr{MIT} Press)에서 편집 및 제작되었습니다 (edited and manufactured).

@noindent
비공식 텍스인포 판 (Unofficial Texinfo Format) @url{http://sicpebook.wordpress.com, @value{utfversion}} (@value{utfversiondate}),
@url{http://www.neilvandyke.org/sicp-texi/, 2.neilvandyke4} (2007년 1월 10일) 기반.

@end titlepage

@shortcontents

@contents

@headings off

@finalout

@node Top, UTF, (dir), (dir)

@ifinfo

@heading 컴퓨터 프로그램의 구조와 해석 (Structure and Interpretation of Computer Programs)

@noindent
제2판 (Second Edition)@*
해럴드 에이벌슨, 제럴드 제이 서스먼 공저, 줄리 서스먼 기여@*
앨런 J. 펄리스 서문@*
@copyright{} 1996 매사추세츠 공과대학교 (Massachusetts Institute of Technology)

@noindent
비공식 텍스인포 판 (Unofficial Texinfo Format) 버전 @value{utfversion} (@value{utfversiondate})

@end ifinfo

@menu
* UTF::              비공식 텍스인포 판 (Unofficial Texinfo Format)
* Dedication::       헌사
* Foreword::         서문
* Preface::          제2판 머리말
* Preface 1e::       초판 머리말
* Acknowledgments::  감사의 글
* Chapter 1::        프로시저를 이용한 추상화 구축
* Chapter 2::        데이터를 이용한 추상화 구축
* Chapter 3::        모듈성, 객체, 그리고 상태
* Chapter 4::        메타언어적 추상화
* Chapter 5::        레지스터 기계를 이용한 계산
* References::       참고 문헌
* Exercises::        연습 문제 목록
* Figures::          그림 목록
* Term Index::       용어 색인
* Colophon::         판권란

@detailmenu
 --- 상세 노드 목록 (Detailed Node Listing) ---

Rust 프로그래밍 (Rust Programming)

* 1.1::              프로그래밍의 요소 (Elements of Programming)
* 1.2::              프로시저와 그들이 생성하는 프로세스 (Procedures and the Processes They Generate)
* 1.3::              고차 프로시저를 이용한 추상화의 정식화 (Formulating Abstractions with Higher-Order Procedures)

프로그래밍의 요소 (Elements of Programming)

* 1.1.1::            표현식 (Expressions)
* 1.1.2::            명명과 환경 (Naming and the Environment)
* 1.1.3::            조합의 평가 (The Evaluation of Combinations)
* 1.1.4::            복합 프로시저 (Compound Procedures)
* 1.1.5::            프로시저 적용의 치환 모델 (The Substitution Model for Procedure Application)
* 1.1.6::            조건식과 술어 (Conditionals and Predicates)
* 1.1.7::            예제: 뉴턴의 방법에 의한 제곱근 (Example: Square Roots by Newton's Method)
* 1.1.8::            블랙박스 추상화로서의 프로시저 (Procedures as Black-Box Abstractions)

프로시저와 그들이 생성하는 프로세스 (Procedures and the Processes They Generate)

* 1.2.1::            선형 재귀와 반복 (Linear Recursion and Iteration)
* 1.2.2::            트리 재귀 (Tree Recursion)
* 1.2.3::            증가 차수 (Orders of Growth)
* 1.2.4::            거듭제곱 (Exponentiation)
* 1.2.5::            최대공약수 (Greatest Common Divisors)
* 1.2.6::            예제: 소수성 판별 (Example: Testing for Primality)

고차 프로시저를 이용한 추상화의 정식화 (Formulating Abstractions with Higher-Order Procedures)

* 1.3.1::            인자로서의 프로시저 (Procedures as Arguments)
* 1.3.2::            클로저를 이용한 프로시저 구축 (Constructing Procedures Using Lambda)
* 1.3.3::            일반적 방법으로서의 프로시저 (Procedures as General Methods)
* 1.3.4::            반환값으로서의 프로시저 (Procedures as Returned Values)

데이터를 이용한 추상화 구축 (Building Abstractions with Data)

* 2.1::              데이터 추상화 소개 (Introduction to Data Abstraction)
* 2.2::              계층적 데이터와 클로저 속성 (Hierarchical Data and the Closure Property)
* 2.3::              기호 데이터 (Symbolic Data)
* 2.4::              추상 데이터의 다중 표현 (Multiple Representations for Abstract Data)
* 2.5::              제네릭 연산을 사용하는 시스템 (Systems with Generic Operations)

데이터 추상화 소개 (Introduction to Data Abstraction)

* 2.1.1::            예제: 유리수 산술 연산 (Example: Arithmetic Operations for Rational Numbers)
* 2.1.2::            추상화 장벽 (Abstraction Barriers)
* 2.1.3::            데이터란 무엇인가? (What Is Meant by Data?)
* 2.1.4::            심화 연습 문제: 구간 산술 (Extended Exercise: Interval Arithmetic)

계층적 데이터와 클로저 속성 (Hierarchical Data and the Closure Property)

* 2.2.1::            시퀀스 표현 (Representing Sequences)
* 2.2.2::            계층적 구조 (Hierarchical Structures)
* 2.2.3::            관습적인 인터페이스로서의 시퀀스 (Sequences as Conventional Interfaces)
* 2.2.4::            예제: 그림 언어 (Example: A Picture Language)

기호 데이터 (Symbolic Data)

* 2.3.1::            인용 (Quotation)
* 2.3.2::            예제: 기호 미분 (Example: Symbolic Differentiation)
* 2.3.3::            예제: 집합 표현 (Example: Representing Sets)
* 2.3.4::            예제: 허프만 인코딩 트리 (Example: Huffman Encoding Trees)

추상 데이터의 다중 표현 (Multiple Representations for Abstract Data)

* 2.4.1::            복소수 표현 (Representations for Complex Numbers)
* 2.4.2::            태그된 데이터 (Tagged Data)
* 2.4.3::            데이터 주도 프로그래밍과 가법성 (Data-Directed Programming and Additivity)

제네릭 연산을 사용하는 시스템 (Systems with Generic Operations)

* 2.5.1::            제네릭 산술 연산 (Generic Arithmetic Operations)
* 2.5.2::            서로 다른 타입의 데이터 결합 (Combining Data of Different Types)
* 2.5.3::            예제: 기호 대수 (Example: Symbolic Algebra)

모듈성, 객체, 그리고 상태 (Modularity, Objects, and State)

* 3.1::              할당과 지역 상태 (Assignment and Local State)
* 3.2::              평가의 환경 모델 (The Environment Model of Evaluation)
* 3.3::              가변 데이터를 이용한 모델링 (Modeling with Mutable Data)
* 3.4::              동시성: 시간은 본질적인 요소이다 (Concurrency: Time Is of the Essence)
* 3.5::              스트림 (Streams)

할당과 지역 상태 (Assignment and Local State)

* 3.1.1::            지역 상태 변수 (Local State Variables)
* 3.1.2::            할당 도입의 이점 (The Benefits of Introducing Assignment)
* 3.1.3::            할당 도입의 비용 (The Costs of Introducing Assignment)

평가의 환경 모델 (The Environment Model of Evaluation)

* 3.2.1::            평가 규칙 (The Evaluation Rule)
* 3.2.2::            단순 프로시저의 적용 (Applying Simple Procedures)
* 3.2.3::            지역 상태의 저장소로서의 프레임 (Frames as the Repository of Local State)
* 3.2.4::            내부 정의 (Internal Definitions)

가변 데이터를 이용한 모델링 (Modeling with Mutable Data)

* 3.3.1::            가변 리스트 구조 (Mutable List Structure)
* 3.3.2::            큐 표현 (Representing Queues)
* 3.3.3::            테이블 표현 (Representing Tables)
* 3.3.4::            디지털 회로 시뮬레이터 (A Simulator for Digital Circuits)
* 3.3.5::            제약 조건 전파 (Propagation of Constraints)

동시성: 시간은 본질적인 요소이다 (Concurrency: Time Is of the Essence)

* 3.4.1::            동시성 시스템에서 시간의 성질 (The Nature of Time in Concurrent Systems)
* 3.4.2::            동시성 제어 메커니즘 (Mechanisms for Controlling Concurrency)

스트림 (Streams)

* 3.5.1::            스트림은 지연 리스트이다 (Streams Are Delayed Lists)
* 3.5.2::            무한 스트림 (Infinite Streams)
* 3.5.3::            스트림 패러다임 활용 (Exploiting the Stream Paradigm)
* 3.5.4::            스트림과 지연 평가 (Streams and Delayed Evaluation)
* 3.5.5::            함수형 프로그램의 모듈성과 객체의 모듈성 (Modularity of Functional Programs and Modularity of Objects)

메타언어적 추상화

* 4.1::              메타순환적 평가기 (The Metacircular Evaluator)
* 4.2::              Scheme의 변형 -- 지연 평가 (Variations on a Scheme -- Lazy Evaluation)
* 4.3::              Scheme의 변형 -- 비결정론적 계산 (Variations on a Scheme -- Nondeterministic Computing)
* 4.4::              논리 프로그래밍 (Logic Programming)

메타순환적 평가기 (The Metacircular Evaluator)

* 4.1.1::            평가기의 핵심 (The Core of the Evaluator)
* 4.1.2::            표현식 표현 (Representing Expressions)
* 4.1.3::            평가기 데이터 구조 (Evaluator Data Structures)
* 4.1.4::            평가기를 프로그램으로 실행하기 (Running the Evaluator as a Program)
* 4.1.5::            프로그램으로서의 데이터 (Data as Programs)
* 4.1.6::            내부 정의 (Internal Definitions)
* 4.1.7::            실행에서 구문 분석 분리하기 (Separating Syntactic Analysis from Execution)

Scheme의 변형 -- 지연 평가 (Variations on a Scheme -- Lazy Evaluation)

* 4.2.1::            정규 순서와 적용 순서 (Normal Order and Applicative Order)
* 4.2.2::            지연 평가 인터프리터 (An Interpreter with Lazy Evaluation)
* 4.2.3::            지연 리스트로서의 스트림 (Streams as Lazy Lists)

Scheme의 변형 -- 비결정론적 계산 (Variations on a Scheme -- Nondeterministic Computing)

* 4.3.1::            Amb와 탐색 (Amb and Search)
* 4.3.2::            비결정론적 프로그램의 예 (Examples of Nondeterministic Programs)
* 4.3.3::            @code{Amb} 평가기 구현 (Implementing the @code{Amb} Evaluator)

논리 프로그래밍 (Logic Programming)

* 4.4.1::            연역적 정보 검색 (Deductive Information Retrieval)
* 4.4.2::            질의 시스템의 작동 원리 (How the Query System Works)
* 4.4.3::            논리 프로그래밍은 수리 논리학인가? (Is Logic Programming Mathematical Logic?)
* 4.4.4::            질의 시스템 구현 (Implementing the Query System)

질의 시스템 구현 (Implementing the Query System)

* 4.4.4.1::          드라이버 루프와 인스턴스화 (The Driver Loop and Instantiation)
* 4.4.4.2::          평가기 (The Evaluator)
* 4.4.4.3::          패턴 매칭에 의한 어설션 찾기 (Finding Assertions by Pattern Matching)
* 4.4.4.4::          규칙과 단일화 (Rules and Unification)
* 4.4.4.5::          데이터베이스 유지 관리 (Maintaining the Data Base)
* 4.4.4.6::          스트림 연산 (Stream Operations)
* 4.4.4.7::          질의 구문 프로시저 (Query Syntax Procedures)
* 4.4.4.8::          프레임과 바인딩 (Frames and Bindings)

레지스터 기계를 이용한 계산 (Computing with Register Machines)

* 5.1::              레지스터 기계 설계 (Designing Register Machines)
* 5.2::              레지스터 기계 시뮬레이터 (A Register-Machine Simulator)
* 5.3::              저장소 할당과 가비지 컬렉션 (Storage Allocation and Garbage Collection)
* 5.4::              명시적 제어 평가기 (The Explicit-Control Evaluator)
* 5.5::              컴파일 (Compilation)

레지스터 기계 설계 (Designing Register Machines)

* 5.1.1::            레지스터 기계 기술 언어 (A Language for Describing Register Machines)
* 5.1.2::            기계 설계의 추상화 (Abstraction in Machine Design)
* 5.1.3::            서브루틴 (Subroutines)
* 5.1.4::            스택을 이용한 재귀 구현 (Using a Stack to Implement Recursion)
* 5.1.5::            명령어 요약 (Instruction Summary)

레지스터 기계 시뮬레이터 (A Register-Machine Simulator)

* 5.2.1::            기계 모델 (The Machine Model)
* 5.2.2::            어셈블러 (The Assembler)
* 5.2.3::            명령어 실행 프로시저 생성 (Generating Execution Procedures for Instructions)
* 5.2.4::            기계 성능 모니터링 (Monitoring Machine Performance)

저장소 할당과 가비지 컬렉션 (Storage Allocation and Garbage Collection)

* 5.3.1::            벡터로서의 메모리 (Memory as Vectors)
* 5.3.2::            무한 메모리의 환상 유지하기 (Maintaining the Illusion of Infinite Memory)

레지스터와 연산 (Registers and Operations)

* 5.4.1::            명시적 제어 평가기의 핵심 (The Core of the Explicit-Control Evaluator)
* 5.4.2::            시퀀스 평가와 꼬리 재귀 (Sequence Evaluation and Tail Recursion)
* 5.4.3::            조건식, 할당, 그리고 정의 (Conditionals, Assignments, and Definitions)
* 5.4.4::            평가기 실행 (Running the Evaluator)

컴파일러 개요 (Compiler Overview)

* 5.5.1::            컴파일러의 구조 (Structure of the Compiler)
* 5.5.2::            표현식 컴파일 (Compiling Expressions)
* 5.5.3::            조합 컴파일 (Compiling Combinations)
* 5.5.4::            명령어 시퀀스 결합 (Combining Instruction Sequences)
* 5.5.5::            컴파일된 코드의 예 (An Example of Compiled Code)
* 5.5.6::            어휘적 주소 지정 (Lexical Addressing)
* 5.5.7::            컴파일된 코드를 평가기에 연결하기 (Interfacing Compiled Code to the Evaluator)

@end detailmenu
@end menu

@node    UTF, Dedication, Top, Top
@unnumbered 비공식 텍스인포 판 (Unofficial Texinfo Format)

이 책은 비공식 텍스인포 판 (Unofficial Texinfo Format) 기반의 @abbr{SICP} 제2판입니다.

아마도 여러분은 Emacs의 Info 모드와 같은 Info 하이퍼텍스트 브라우저에서 이 책을 읽고 있을 것입니다.
또는 화면이나 프린터에서 @TeX{} 형식으로 읽고 있을 수도 있지만, 그것은 조금 어리석은 일일 것입니다.
그리고 인쇄한다면 비용도 많이 들겠죠.

자유롭게 배포되는 공식 @abbr{HTML} 및 @abbr{GIF} 형식은 2001년 4월의 긴 Emacs 사랑 축제 주말 동안 Lytha Ayth에 의해 비공식 텍스인포 판(@abbr{UTF}) 버전 1로 처음 개인적으로 변환되었습니다.

@abbr{UTF}는 @abbr{HTML} 형식보다 검색하기 쉽습니다.
또한 기증받은 '386 기반 PC와 같은 사양이 낮은 컴퓨터를 사용하는 사람들에게 훨씬 더 접근하기 좋습니다.
386은 이론적으로 Linux, Emacs, 그리고 Scheme 인터프리터를 동시에 실행할 수 있지만, 대부분의 386은 자금이 부족한 신진 해커들에게 @newterm{스래싱(thrashing)}의 개념을 너무 일찍 소개하지 않고는 Netscape와 필요한 X Window System을 모두 실행할 수 없을 것입니다.
@abbr{UTF}는 1.44@abbr{MB} 플로피 디스크에 압축하지 않고도 들어갈 수 있으므로, 인터넷이나 @abbr{LAN} 접속이 안 되는 PC에 @abbr{UTF}를 설치할 때 유용할 수 있습니다.

Texinfo 변환은 가능한 한 직접적인 전사(transliteration)였습니다.
@TeX{}에서 @abbr{HTML}로의 변환과 마찬가지로, 이 과정에서도 약간의 깨짐이 도입되었습니다.
비공식 텍스인포 판의 경우, 그림들은 잃어버린 예술인 @abbr{ASCII} 아트의 아마추어적인 부활을 겪었습니다.
또한, 수많은 위첨자('^')와 아래첨자('_')를 변환하는 과정에서 일부 모호성 오류가 도입되었을 가능성이 큽니다.
@emph{어떤 것}이 그런지는 독자의 연습 문제로 남겨두었습니다.
하지만 적어도 우리는 @emph{크거나 같다} 기호를 @code{<u>&gt;</u>}로 인코딩하여 용감한 우주 비행사들을 위험에 빠뜨리지는 않았습니다.

오류를 수정하거나 @abbr{ASCII} 아트를 개선하기 위해 @file{sicp.texi}를 수정한다면, 변경 사항을 반영하기 위해 @code{@@set utfversion @value{utfversion}} 라인을 업데이트하십시오.
예를 들어, Lytha의 버전 @code{1}에서 시작했고 여러분의 이름이 Bob이라면, 후속 버전을 @code{1.bob1}, @code{1.bob2}, @dots{} @code{1.bob@i{n}}과 같이 이름을 붙일 수 있습니다.
또한 @code{utfversiondate}도 업데이트하십시오.
여러분의 버전을 웹에 배포하고 싶다면, 파일이나 웹 페이지 어딘가에 ``sicp.texi'' 문자열을 포함시키면 웹 검색 엔진으로 사람들이 더 쉽게 찾을 수 있습니다.

비공식 텍스인포 판은 우아하게 자유 배포되는 @abbr{HTML} 버전의 정신을 따르고 있다고 믿어집니다.
하지만 언젠가 누군가의 변호사 군단이 할 일이 필요해져서 사소한 일로 트집을 잡을지 모르니, 실명을 사용하거나 여러분의 계정이나 기계 이름이 포함될 수 있는 Info, @abbr{DVI}, PostScript, 또는 @abbr{PDF} 형식을 배포하기 전에 한 번 더 생각해보십시오.
@i{Lytha Ayth 드림}

@b{추가:} 에이벌슨과 서스먼의 @abbr{SICP} 비디오 강의도 참고하십시오:
@url{http://groups.csail.mit.edu/mac/classes/6.001/abelson-sussman-lectures/, @abbr{MIT CSAIL}} 또는 
@url{http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-001-structure-and-interpretation-of-computer-programs-spring-2005/video-lectures/, @abbr{MIT OCW}}.

@b{두 번째 추가:} 위 내용은 2001년의 원래 @abbr{UTF} 서문입니다.
10년 후, @abbr{UTF}는 변화했습니다: 수학 기호와 공식이 제대로 조판되었고, 그림은 벡터 그래픽으로 다시 그려졌습니다.
원래의 텍스트 공식과 @abbr{ASCII} 아트 그림은 여전히 Texinfo 소스에 남아 있지만, Info 출력으로 컴파일될 때만 표시됩니다.
전자책 리더기와 태블릿의 여명기에, 화면에서 @abbr{PDF}를 읽는 것은 공식적으로 더 이상 어리석은 일이 아닙니다. 즐기십시오!
@i{A.R, 2011년 5월}

@b{세 번째 추가:} 사물은 나선형으로 돌아갑니다. 우리는 @abbr{PDF} 책을 조판하기 위해 Texinfo와 LaTeX의 위력을 탐구했습니다.
이제 다시 @abbr{HTML}로 돌아올 때입니다. 이번에는 @abbr{HTML5}가 될 것입니다.
``그곳은 위험한 곳일 수 있지만, 평화를 위한 우리의 마지막이자 최고의 희망입니다.'' (싱클레어, @cite{@w{바빌론 5}}.)
브라우저 전쟁 이후에도 평화는 지속될까요? 어쨌든, 이 프로젝트의 목표는 @abbr{HTML5} 툴박스를 사용하여 LaTeX 출력의 품질에 접근하는 것입니다.
JavaScript, @abbr{CSS3}, @abbr{SVG}, MathJax, MathML, 그리고 웹 폰트가 여기에 사용되었습니다.
이 시도의 실험적인 성격 때문에 일부 브라우저에서는 글리치와 오류가 있을 것입니다.
기술적이고 예술적인 도움을 환영합니다. 그동안 책을 즐기시고, @abbr{REPL}을 실행하십시오!
@i{A.R, 2014년 1월}

@node    Dedication, Foreword, UTF, Top
@unnumbered 헌사 (Dedication)

이 책은 컴퓨터 안에 깃든 영혼에 존경과 경의를 표하며 그에게 바칩니다.

@quotation
``나는 컴퓨터 과학을 하는 우리가 컴퓨팅의 즐거움을 유지하는 것이 매우 중요하다고 생각합니다.
처음 시작할 때는 정말 즐거웠습니다. 물론 돈을 내는 고객들이 가끔 불만을 토로했고, 시간이 지나면서 우리는 그들의 불만을 진지하게 받아들이기 시작했습니다.
우리는 이 기계들의 성공적이고 오류 없는 완벽한 사용에 대해 정말로 책임이 있는 것처럼 느끼기 시작했습니다.
나는 우리가 그렇다고 생각하지 않습니다. 나는 우리의 책임이 그것들을 확장하고, 새로운 방향으로 이끌며, 집 안에 즐거움을 유지하는 것이라고 생각합니다.
컴퓨터 과학 분야가 그 즐거움을 잃지 않기를 바랍니다. 무엇보다도, 우리가 선교사가 되지 않기를 바랍니다.
성경 판매원처럼 느끼지 마십시오. 세상에는 이미 그런 사람들이 너무 많습니다. 여러분이 컴퓨팅에 대해 아는 것은 다른 사람들도 배울 것입니다.
성공적인 컴퓨팅의 열쇠가 오직 여러분의 손에만 있다고 느끼지 마십시오.
여러분의 손에 있는 것은, 내가 생각하고 희망하건대, 지성입니다: 기계를 처음 접했을 때보다 더 많은 것을 볼 수 있는 능력, 즉 여러분이 그것을 더 훌륭하게 만들 수 있다는 능력입니다.''

@noindent
---앨런 J. 펄리스 (1922년 4월 1일 -- 1990년 2월 7일)
@end quotation

@node    Foreword, Preface, Dedication, Top
@unnumbered 서문 (Foreword)

교육자, 장군, 영양사, 심리학자, 그리고 부모들이 프로그래밍을 합니다. 군대, 학생, 그리고 일부 사회가 프로그래밍됩니다.
거대한 문제에 대한 공격은 일련의 프로그램들을 고용하며, 그 대부분은 도중에 생겨납니다.
이러한 프로그램들은 당면한 문제에 특화된 것으로 보이는 문제들로 가득 차 있습니다.
프로그래밍을 그 자체로 지적인 활동으로 이해하려면 컴퓨터 프로그래밍으로 눈을 돌려야 합니다; 컴퓨터 프로그램을---그것도 많이---읽고 써야 합니다.
프로그램이 무엇에 관한 것인지, 어떤 응용 프로그램을 제공하는지는 크게 중요하지 않습니다.
중요한 것은 그것들이 얼마나 잘 수행되는지, 그리고 더 큰 프로그램을 만들기 위해 다른 프로그램들과 얼마나 매끄럽게 어우러지는지입니다.
프로그래머는 부분의 완벽함과 집합의 적절함을 모두 추구해야 합니다.
이 책에서 ``프로그램''의 사용은 디지털 컴퓨터에서 실행하기 위해 Lisp 방언으로 작성된 프로그램의 생성, 실행, 그리고 연구에 초점을 맞춥니다.
Lisp를 사용함으로써 우리는 우리가 프로그래밍할 수 있는 것을 제한하거나 한정하는 것이 아니라, 오직 프로그램 설명을 위한 표기법만을 제한합니다.

이 책의 주제에 대한 우리의 교류는 세 가지 현상의 초점과 관련이 있습니다: 인간의 마음, 컴퓨터 프로그램의 집합, 그리고 컴퓨터입니다.
모든 컴퓨터 프로그램은 실제 또는 정신적 과정에 대한, 마음속에서 부화한 모델입니다.
인간의 경험과 생각에서 비롯된 이러한 과정들은 그 수가 엄청나고, 세부 사항이 복잡하며, 언제나 부분적으로만 이해됩니다.
그것들은 우리의 컴퓨터 프로그램에 의해 영구적으로 만족스럽게 모델링되는 경우가 드뭅니다.
따라서 우리의 프로그램들이 신중하게 수작업으로 만든 개별적인 기호들의 집합, 서로 맞물린 함수들의 모자이크일지라도, 그것들은 끊임없이 진화합니다:
모델에 대한 우리의 인식이 깊어지고, 넓어지고, 일반화됨에 따라 우리는 그것들을 변경합니다. 모델이 궁극적으로 우리가 씨름하는 또 다른 모델 내에서 준안정적인 위치를 차지할 때까지 말이죠.
컴퓨터 프로그래밍과 관련된 환희의 원천은 프로그램으로 표현된 메커니즘이 마음속에서 그리고 컴퓨터 상에서 끊임없이 펼쳐지는 것과 그것들이 만들어내는 인식의 폭발입니다.
예술이 우리의 꿈을 해석한다면, 컴퓨터는 프로그램의 탈을 쓰고 그것들을 실행합니다!

그 모든 힘에도 불구하고, 컴퓨터는 가혹한 감독관입니다. 그것의 프로그램들은 정확해야 하며, 우리가 말하고자 하는 바는 모든 세부 사항에서 정확하게 말해져야 합니다.
다른 모든 상징적 활동에서와 마찬가지로, 우리는 논쟁을 통해 프로그램의 진실성을 확신하게 됩니다.
Lisp 자체에 의미론(그건 그렇고 또 다른 모델입니다)을 할당할 수 있으며, 프로그램의 함수가, 예를 들어, 술어 논리로 명시될 수 있다면, 논리학의 증명 방법을 사용하여 받아들일 수 있는 정확성 논쟁을 할 수 있습니다.
불행히도, 프로그램이 크고 복잡해짐에 따라(거의 항상 그렇듯이), 명세 자체의 적절성, 일관성, 그리고 정확성이 의심스러워지기 때문에, 완전한 형식적 정확성 논쟁이 대규모 프로그램에 동반되는 경우는 드뭅니다.
대규모 프로그램은 작은 프로그램에서 성장하기 때문에, 우리가 정확성을 확신하게 된 표준 프로그램 구조들의 무기고---우리는 그것들을 관용구라고 부릅니다---를 개발하고, 입증된 가치를 지닌 조직화 기술을 사용하여 그것들을 더 큰 구조로 결합하는 법을 배우는 것이 중요합니다.
이러한 기술들은 이 책에서 길게 다루어지며, 그것들을 이해하는 것은 프로그래밍이라 불리는 프로메테우스적 사업에 참여하는 데 필수적입니다.
무엇보다도, 강력한 조직화 기술의 발견과 숙달은 크고 의미 있는 프로그램을 만드는 우리의 능력을 가속화합니다.
반대로, 대규모 프로그램을 작성하는 것은 매우 힘든 일이기 때문에, 우리는 대규모 프로그램에 맞춰야 할 기능과 세부 사항의 덩어리를 줄이는 새로운 방법을 발명하도록 자극받습니다.

프로그램과 달리, 컴퓨터는 물리학의 법칙을 따ら야 합니다. 만약 그것들이 빠르게---상태 변화당 몇 나노초---수행하기를 원한다면, 전자들을 오직 작은 거리(기껏해야 @math{{1 {1\over2}}} 피트)만큼만 전송해야 합니다.
공간에 그렇게 집중된 거대한 수의 장치들에서 발생하는 열은 제거되어야 합니다.
기능의 다중성과 장치의 밀도 사이의 균형을 맞추는 정교한 공학 기술이 개발되었습니다.
어쨌든, 하드웨어는 항상 우리가 프로그래밍하고 싶어 하는 수준보다 더 원시적인 수준에서 작동합니다.
우리의 Lisp 프로그램을 ``기계'' 프로그램으로 변환하는 과정들 자체도 우리가 프로그래밍하는 추상 모델들입니다.
그것들의 연구와 생성은 임의의 모델을 프로그래밍하는 것과 관련된 조직화 프로그램들에 대한 많은 통찰력을 줍니다.
물론 컴퓨터 자체도 그렇게 모델링될 수 있습니다. 생각해보세요: 가장 작은 물리적 스위칭 요소의 동작은 미분 방정식으로 기술되는 양자 역학에 의해 모델링되며, 그 세부 동작은 @dots{}로 구성된 컴퓨터에서 실행되는 컴퓨터 프로그램으로 표현된 수치 근사에 의해 포착됩니다!

세 가지 초점을 별도로 식별하는 것은 단지 전술적 편의의 문제가 아닙니다.
사람들이 말하듯이, 모든 것이 머릿속에 있을지라도, 이 논리적 분리는 이들 초점 사이의 상징적 교류를 가속화하며, 그 풍요로움, 활력, 그리고 잠재력은 인간 경험에서 오직 생명의 진화 자체에 의해서만 능가됩니다.
기껏해야, 초점들 사이의 관계는 준안정적입니다. 컴퓨터는 결코 충분히 크거나 빠르지 않습니다.
하드웨어 기술의 각 돌파구는 더 거대한 프로그래밍 사업, 새로운 조직 원칙, 그리고 추상 모델의 풍요로움으로 이어집니다.
모든 독자는 주기적으로 자신에게 물어야 합니다 ``어떤 목적을 향해, 어떤 목적을 향해?''---하지만 너무 자주 묻지는 마십시오. 씁쓸한 철학의 변비를 위해 프로그래밍의 즐거움을 지나치지 않도록 말이죠.

우리가 작성하는 프로그램 중 일부는(하지만 결코 충분하지 않은) 숫자들의 수열에서 최댓값을 찾거나 정렬하는 것, 소수성 판별, 또는 제곱근 찾기와 같은 정밀한 수학적 함수를 수행합니다.
우리는 그런 프로그램들을 알고리즘이라고 부르며, 특히 실행 시간과 데이터 저장 요구 사항이라는 두 가지 중요한 매개변수와 관련하여 그것들의 최적 동작에 대해 많은 것이 알려져 있습니다.
프로그래머는 좋은 알고리즘과 관용구를 습득해야 합니다.
비록 어떤 프로그램들은 정밀한 명세에 저항할지라도, 그것들의 성능을 추정하고 항상 개선하려고 시도하는 것은 프로그래머의 책임입니다.

Lisp는 생존자로서, 약 4분의 1세기 동안 사용되어 왔습니다.
활발한 프로그래밍 언어들 중에서 오직 포트란만이 더 긴 수명을 가졌습니다.
두 언어 모두 중요한 응용 분야의 프로그래밍 요구를 지원해 왔습니다. 포트란은 과학 및 공학 계산을 위해, Lisp는 인공 지능을 위해서 말이죠.
이 두 분야는 계속해서 중요하며, 그 프로그래머들은 이 두 언어에 너무 헌신적이어서 Lisp와 포트란은 적어도 또 다른 4분의 1세기 동안 활발하게 사용될 것입니다.

Lisp는 변합니다. 이 책에서 사용된 Scheme 방언은 원래의 Lisp에서 진화했으며, 변수 바인딩을 위한 정적 스코핑과 함수를 값으로 산출하도록 허용하는 것을 포함하여 몇 가지 중요한 방식에서 후자와 다릅니다.
의미론적 구조에서 Scheme은 초기 Lisp들만큼이나 Algol 60과 밀접하게 관련되어 있습니다.
결코 다시는 활발한 언어가 되지 못할 Algol 60은 Scheme과 파스칼의 유전자 속에 살아 있습니다.
이 두 언어 주위에 모인 문화보다 더 다른 두 문화를 소통시키는 동전인 두 언어를 찾기는 어려울 것입니다.
파스칼은 피라미드를 짓기 위한 것입니다---무거운 블록을 제자리에 밀어 넣는 군대들에 의해 지어진 웅장하고, 숨 막히는, 정적인 구조물들 말이죠.
Lisp는 유기체를 만들기 위한 것입니다---변동하는 무수히 많은 더 단순한 유기체들을 제자리에 끼워 맞추는 분대들에 의해 지어진 웅장하고, 숨 막히는, 동적인 구조물들 말이죠.
사용된 조직 원칙들은 한 가지 매우 중요한 차이점을 제외하고는 두 경우 모두 동일합니다: 개별 Lisp 프로그래머에게 맡겨진 재량적이고 수출 가능한 기능성은 파스칼 사업 내에서 발견되는 것보다 한 자릿수 이상 큽니다.
Lisp 프로그램들은 그것들을 생산한 응용 프로그램을 초월하는 효용을 가진 함수들로 라이브러리를 부풀립니다.
Lisp의 고유 데이터 구조인 리스트는 그러한 효용의 성장에 크게 책임이 있습니다.
리스트의 단순한 구조와 자연스러운 적용 가능성은 놀랍도록 특이하지 않은 함수들에 반영되어 있습니다.
파스칼에서는 선언 가능한 데이터 구조의 과잉이 함수 내의 전문화를 유도하여 우연한 협력을 억제하고 불이익을 줍니다.
10개의 함수가 10개의 데이터 구조에서 작동하게 하는 것보다 100개의 함수가 하나의 데이터 구조에서 작동하게 하는 것이 더 낫습니다.
그 결과 피라미드는 천 년 동안 변함없이 서 있어야 합니다; 유기체는 진화하거나 소멸해야 합니다.

이 차이를 설명하기 위해, 이 책의 자료와 연습 문제의 처리를 파스칼을 사용하는 어떤 입문서의 그것과 비교해 보십시오.
이것이 오직 @abbr{MIT}에서만 소화 가능한, 그곳에서 발견되는 종족에게만 특유한 텍스트라는 환상 아래서 애쓰지 마십시오.
이것은 학생이 누구이든 또는 어디서 사용되든 간에, Lisp 프로그래밍에 관한 진지한 책이라면 정확히 갖추어야 할 모습입니다.

이것은 대부분의 Lisp 책들이 인공 지능 분야의 작업을 위한 준비로 사용되는 것과는 달리, 프로그래밍에 관한 텍스트라는 점을 주목하십시오.
결국, 소프트웨어 공학의 중요한 프로그래밍 관심사와 인공 지능의 관심사는 조사 중인 시스템이 더 커짐에 따라 합쳐지는 경향이 있습니다.
이것은 왜 인공 지능 외부에서 Lisp에 대한 관심이 그렇게 커지고 있는지를 설명합니다.

그 목표에서 예상할 수 있듯이, 인공 지능 연구는 많은 중요한 프로그래밍 문제들을 생성합니다.
다른 프로그래밍 문화에서는 이러한 문제의 홍수가 새로운 언어를 낳습니다.
실제로, 어떤 매우 큰 프로그래밍 작업에서든 유용한 조직 원칙은 언어의 발명을 통해 작업 모듈 내의 트래픽을 제어하고 격리하는 것입니다.
이러한 언어들은 우리가 가장 자주 상호 작용하는 시스템의 경계에 접근할수록 덜 원시적인 경향이 있습니다.
그 결과, 그러한 시스템들은 여러 번 복제된 복잡한 언어 처리 함수들을 포함합니다.
Lisp는 구문 분석이 기초적인 작업으로 취급될 수 있을 만큼 단순한 문법과 의미론을 가지고 있습니다.
따라서 구문 분석 기술은 Lisp 프로그램에서 거의 아무런 역할을 하지 않으며, 언어 처리기의 구축은 대규모 Lisp 시스템의 성장과 변화 속도에 거의 장애물이 되지 않습니다.
마지막으로, 모든 Lisp 프로그래머가 짊어진 짐과 자유에 책임이 있는 것은 바로 이 문법과 의미론의 단순함입니다.
몇 줄을 넘어서는 어떤 크기의 Lisp 프로그램도 재량적 함수들로 포화되지 않고는 작성될 수 없습니다.
발명하고 맞추십시오; 발작을 일으키고 다시 발명하십시오! 우리는 괄호의 둥지 안에 자신의 생각을 가두는 Lisp 프로그래머를 위해 건배합니다.

@noindent
앨런 J. 펄리스@*
코네티컷주 뉴헤이븐

@node    Preface, Preface 1e, Foreword, Top
@unnumbered 제2판 머리말 (Preface to the Second Edition)

@quotation
소프트웨어는 다른 어떤 것과도 같지 않으며, 버려지기 위해 만들어진다는 것이 가능한가: 요점은 항상 그것을 비눗방울로 보는 것인가?

---앨런 J. 펄리스
@end quotation


@noindent
이 책의 자료는 1980년부터 @abbr{MIT}의 입문 레벨 컴퓨터 과학 과목의 기초가 되어 왔습니다.
초판이 출판되었을 때 우리는 이 자료를 4년 동안 가르치고 있었고, 이 제2판이 나올 때까지 12년이 더 흘렀습니다.
우리는 우리의 작업이 널리 채택되고 다른 텍스트에 통합된 것을 기쁘게 생각합니다.
우리는 학생들이 이 책의 아이디어와 프로그램을 가져다가 새로운 컴퓨터 시스템과 언어의 핵심으로 구축하는 것을 보았습니다.
고대 탈무드의 말장난을 문자 그대로 실현하듯, 우리의 학생들은 우리의 건축가가 되었습니다.
우리는 그렇게 유능한 학생들과 훌륭한 건축가들을 갖게 되어 행운입니다.

이 판을 준비하면서, 우리는 우리 자신의 교육 경험과 @abbr{MIT} 및 다른 곳의 동료들의 코멘트에서 제안된 수백 가지의 명확한 설명을 통합했습니다.
우리는 일반 산술 시스템, 인터프리터, 레지스터 기계 시뮬레이터, 그리고 컴파일러를 포함하여 책의 주요 프로그래밍 시스템 대부분을 재설계했습니다;
그리고 @abbr{IEEE} Scheme 표준(@ref{IEEE 1990})을 준수하는 어떤 Scheme 구현체라도 코드를 실행할 수 있도록 모든 프로그램 예제를 다시 작성했습니다.

이 판은 몇 가지 새로운 주제를 강조합니다. 이것들 중 가장 중요한 것은 계산 모델에서 시간을 다루는 다양한 접근 방식이 수행하는 중심적인 역할입니다:
상태를 가진 객체, 동시성 프로그래밍, 함수형 프로그래밍, 지연 평가, 그리고 비결정론적 프로그래밍.
우리는 동시성과 비결정론에 대한 새로운 섹션을 포함했으며, 이 주제를 책 전체에 통합하려고 노력했습니다.

이 책의 초판은 @abbr{MIT} 한 학기 과목의 강의 계획서를 밀접하게 따랐습니다.
제2판의 모든 새로운 자료로 인해, 한 학기에 모든 것을 다루는 것은 불가능할 것이므로, 강사는 선택하고 골라야 할 것입니다.
우리 자신의 강의에서, 우리는 때때로 논리 프로그래밍에 대한 섹션(@ref{4.4})을 건너뛰고, 학생들이 레지스터 기계 시뮬레이터를 사용하게 하지만 그 구현(@ref{5.2})은 다루지 않으며, 컴파일러(@ref{5.5})에 대해서는 대략적인 개요만 제공합니다.
그렇더라도, 이것은 여전히 강도 높은 과정입니다. 어떤 강사들은 처음 3~4개의 챕터만 다루고 다른 자료는 후속 과정을 위해 남겨두기를 원할 수도 있습니다.

월드 와이드 웹 사이트 @url{http://mitpress.mit.edu/sicp}는 이 책의 사용자들을 위한 지원을 제공합니다.
여기에는 책의 프로그램, 샘플 프로그래밍 과제, 보충 자료, 그리고 다운로드 가능한 Lisp의 Scheme 방언 구현체가 포함됩니다.

@node    Preface 1e, Acknowledgments, Preface, Top
@unnumbered 초판 머리말 (Preface to the First Edition)

@quotation
컴퓨터는 바이올린과 같습니다. 초보자가 축음기를 먼저 시도해보고 나서 바이올린을 시도해보는 것을 상상할 수 있습니다.
후자는 끔찍한 소리가 난다고 그는 말합니다. 그것이 우리가 인문학자들과 대부분의 컴퓨터 과학자들에게서 들은 주장입니다.
컴퓨터 프로그램은 특정 목적에는 좋지만 유연하지 않다고 그들은 말합니다. 바이올린도, 타자기들도, 당신이 그것을 사용하는 법을 배울 때까지는 유연하지 않습니다.

---마빈 민스키, @cite{이해가 부족하고 조잡하게 정식화된 아이디어를 표현하기 위한 좋은 매체로서의 프로그래밍 (Why Programming Is a Good Medium for Expressing
Poorly-Understood and Sloppily-Formulated Ideas)}
@end quotation


@noindent
``컴퓨터 프로그램의 구조와 해석''은 매사추세츠 공과대학교(@abbr{MIT})의 컴퓨터 과학 입문 과목입니다.
이것은 회로와 선형 시스템에 관한 두 과목과 디지털 시스템 설계에 관한 과목을 포함하는 ``공통 핵심 커리큘럼''의 4분의 1로서, 전기 공학이나 컴퓨터 과학을 전공하는 @abbr{MIT}의 모든 학생들에게 필수입니다.
우리는 1978년부터 이 과목의 개발에 참여해 왔으며, 1980년 가을부터 매년 600명에서 700명 사이의 학생들에게 현재의 형태로 이 자료를 가르쳐 왔습니다.
이 학생들의 대부분은 이전에 계산에 대한 정식 훈련을 거의 또는 전혀 받지 않았지만, 많은 학생들이 컴퓨터를 조금 다뤄보았고 소수는 광범위한 프로그래밍 또는 하드웨어 설계 경험을 가지고 있습니다.

이 입문 컴퓨터 과학 과목에 대한 우리의 설계는 두 가지 주요 관심사를 반영합니다.
첫째, 우리는 컴퓨터 언어가 단지 컴퓨터가 연산을 수행하게 하는 방법이 아니라 방법론에 대한 아이디어를 표현하는 새로운 형식적 매체라는 아이디어를 확립하고 싶습니다.
따라서, 프로그램은 사람이 읽기 위해 작성되어야 하며, 기계가 실행하는 것은 부차적인 일입니다.
둘째, 우리는 이 수준의 과목에서 다루어야 할 필수 자료가 특정 프로그래밍 언어 구조의 문법이나 특정 함수를 효율적으로 계산하기 위한 영리한 알고리즘, 또는 알고리즘의 수학적 분석과 계산의 기초가 아니라, 대규모 소프트웨어 시스템의 지적 복잡성을 제어하는 데 사용되는 기술이라고 믿습니다.

우리의 목표는 이 과목을 마친 학생들이 프로그래밍의 스타일 요소와 미학에 대해 좋은 느낌을 갖는 것입니다.
그들은 대규모 시스템에서 복잡성을 제어하는 주요 기술을 지휘할 수 있어야 합니다.
그들은 모범적인 스타일로 작성되었다면 50페이지짜리 프로그램을 읽을 수 있어야 합니다.
그들은 무엇을 읽지 말아야 할지, 그리고 어떤 순간에 무엇을 이해할 필요가 없는지 알아야 합니다.
그들은 원래 저자의 정신과 스타일을 유지하면서 프로그램을 수정하는 데 대해 안심해야 합니다.

이러한 기술들은 결코 컴퓨터 프로그래밍에만 고유한 것이 아닙니다.
우리가 가르치고 활용하는 기술들은 모든 공학 설계에 공통적입니다.
우리는 적절할 때 세부 사항을 숨기는 추상화를 구축함으로써 복잡성을 제어합니다.
우리는 표준적이고 잘 이해된 조각들을 ``믹스 앤 매치'' 방식으로 결합하여 시스템을 구축할 수 있게 해주는 관습적인 인터페이스를 확립함으로써 복잡성을 제어합니다.
우리는 설계를 설명하기 위한 새로운 언어를 확립함으로써 복잡성을 제어합니다. 각각의 언어는 설계의 특정 측면을 강조하고 다른 측면을 경시합니다.

이 과목에 대한 우리의 접근 방식의 밑바탕에는 ``컴퓨터 과학''이 과학이 아니며 그 중요성이 컴퓨터와 거의 관련이 없다는 우리의 확신이 깔려 있습니다.
컴퓨터 혁명은 우리가 생각하는 방식과 우리가 생각하는 것을 표현하는 방식의 혁명입니다.
이 변화의 본질은 고전 수학 과목들이 취하는 더 선언적인 관점과 대조되는, 명령형 관점에서의 지식 구조에 대한 연구인 @newterm{절차적 인식론(procedural epistemology)}이라고 가장 잘 불릴 수 있는 것의 출현입니다.
수학은 ``무엇인가''의 개념을 정확하게 다루기 위한 프레임워크를 제공합니다.
계산은 ``어떻게 하는가''의 개념을 정확하게 다루기 위한 프레임워크를 제공합니다.

자료를 가르칠 때 우리는 프로그래밍 언어 Lisp의 방언을 사용합니다.
우리는 결코 언어를 공식적으로 가르치지 않습니다. 왜냐하면 그럴 필요가 없기 때문입니다.
우리는 단지 그것을 사용하고, 학생들은 며칠 만에 그것을 익힙니다.
이것은 Lisp 같은 언어들의 큰 장점 중 하나입니다: 그것들은 복합 표현식을 형성하는 방법이 매우 적고, 문법 구조가 거의 없습니다.
모든 형식적 속성은 체스의 규칙처럼 한 시간 안에 다룰 수 있습니다.
짧은 시간 후에 우리는 언어의 문법적 세부 사항을 잊어버리고(없기 때문에) 진짜 문제들---우리가 무엇을 계산하고 싶은지, 문제를 어떻게 관리 가능한 부분으로 분해할지, 그리고 그 부분들에 대해 어떻게 작업할지 파악하는 것---로 나아갑니다.
Lisp의 또 다른 장점은 우리가 아는 어떤 다른 언어보다 더 많은 대규모 프로그램 모듈 분해 전략을 지원한다(강제하지는 않지만)는 것입니다.
우리는 절차적 추상화와 데이터 추상화를 만들 수 있고, 일반적인 사용 패턴을 포착하기 위해 고차 함수를 사용할 수 있으며, 할당과 데이터 변경을 사용하여 지역 상태를 모델링할 수 있고, 스트림과 지연 평가로 프로그램의 부분들을 연결할 수 있으며, 내장 언어를 쉽게 구현할 수 있습니다.
이 모든 것은 점진적인 프로그램 설계, 구축, 테스트, 그리고 디버깅을 위한 훌륭한 지원을 갖춘 대화형 환경에 내장되어 있습니다.
우리는 전례 없는 힘과 우아함을 지닌 훌륭한 도구를 만들어낸 존 매카시를 시작으로 모든 세대의 Lisp 마법사들에게 감사합니다.

우리가 사용하는 Lisp의 방언인 Scheme은 Lisp와 Algol의 힘과 우아함을 함께 가져오려는 시도입니다.
Lisp로부터 우리는 단순한 문법, 프로그램의 데이터 객체로서의 균일한 표현, 그리고 가비지 컬렉션되는 힙 할당 데이터에서 파생되는 메타언어적 힘을 가져옵니다.
Algol로부터 우리는 어휘적 스코핑과 블록 구조를 가져오는데, 이것들은 Algol 위원회에 있었던 프로그래밍 언어 설계의 선구자들로부터 받은 선물입니다.
우리는 프로그래밍 언어의 구조와 처치(Church)의 λ-계산법 사이의 관계에 대한 통찰력을 준 존 레이놀즈와 피터 랜딘을 인용하고 싶습니다.
우리는 또한 컴퓨터가 등장하기 수십 년 전에 이 영역을 정찰한 수학자들에게 빚을 지고 있음을 인식합니다.
이 선구자들에는 알론조 처치, 바클리 로서, 스티븐 클리니, 그리고 하스켈 커리가 포함됩니다.

@node       Acknowledgments, Chapter 1, Preface 1e, Top
@unnumbered 감사의 글 (Acknowledgments)

우리는 이 책과 이 커리큘럼을 개발하는 데 도움을 준 많은 분들에게 감사하고 싶습니다.

우리의 과목은 1960년대 후반 @abbr{MIT}에서 잭 워젠크래프트와 아서 에반스 주니어가 가르친 프로그래밍 언어학과 λ-계산법에 관한 훌륭한 과목인 ``6.231''의 명확한 지적 후손입니다.

우리는 공학 설계의 원칙을 강조하기 위해 @abbr{MIT}의 전기 공학 및 컴퓨터 과학 입문 커리큘럼을 개편한 로버트 파노에게 큰 빚을 지고 있습니다. 그는 우리가 이 사업을 시작하도록 이끌었고 이 책이 발전한 첫 번째 과목 노트 세트를 썼습니다.

우리가 가르치려고 하는 프로그래밍의 스타일과 미학의 대부분은 제럴드 제이 서스먼과 함께 Scheme 언어의 초기 개발에 협력했던 가이 루이스 스틸 주니어와 함께 개발되었습니다.
또한, 데이비드 터너, 피터 헨더슨, 댄 프리드먼, 데이비드 와이즈, 그리고 윌 클링거는 이 책에 등장하는 함수형 프로그래밍 커뮤니티의 많은 기술을 우리에게 가르쳐 주었습니다.

조엘 모세스는 대규모 시스템을 구조화하는 것에 대해 우리에게 가르쳐 주었습니다.
기호 계산을 위한 Macsyma 시스템에 대한 그의 경험은 제어의 복잡성을 피하고 모델링되는 세계의 실제 구조를 반영하도록 데이터를 조직하는 데 집중해야 한다는 통찰력을 제공했습니다.

마빈 민스키와 시모어 페퍼트는 프로그래밍과 그것이 우리의 지적 생활에서 차지하는 위치에 대한 우리의 태도 중 많은 부분을 형성했습니다.
우리는 그들에게 계산이 복잡해서 정확하게 다루기 어려운 아이디어들을 탐구하기 위한 표현 수단을 제공한다는 이해를 빚지고 있습니다.
그들은 프로그램을 작성하고 수정하는 학생의 능력이 탐구가 자연스러운 활동이 되는 강력한 매체를 제공한다고 강조합니다.

우리는 또한 프로그래밍은 매우 재미있으며 프로그래밍의 즐거움을 지원하도록 주의해야 한다는 앨런 펄리스의 말에 강력히 동의합니다.
이 즐거움의 일부는 위대한 거장들이 일하는 것을 관찰하는 것에서 나옵니다.
우리는 운 좋게도 빌 고스퍼와 리처드 그린블랫의 발치에서 견습 프로그래머가 될 수 있었습니다.

우리의 커리큘럼 개발에 기여한 모든 사람들을 식별하기는 어렵습니다.
지난 15년 동안 우리와 함께 일해왔고 우리 과목에 많은 추가 시간을 투입한 모든 강사, 낭송 강사, 그리고 튜터들, 특히 빌 시버트, 앨버트 메이어, 조 스토이, 랜디 데이비스, 루이스 브라이다, 에릭 그림슨, 로드 브룩스, 린 스타인, 그리고 피터 졸로비츠에게 감사합니다.
우리는 특히 현재 웰즐리에 있는 프랭클린 터박의 뛰어난 교육 기여를 인정하고 싶습니다; 학부 교육에서 그의 작업은 우리 모두가 열망할 수 있는 기준을 세웠습니다.
우리는 동시성의 신비를 해결하는 데 도움을 준 제리 솔처와 짐 밀러에게, 그리고 @ref{Chapter 4,,Chapter 4}의 비결정론적 평가에 대한 설명에 기여한 피터 졸로비츠와 데이비드 맥앨리스터에게 감사합니다.

많은 사람들이 다른 대학에서 이 자료를 발표하는 데 상당한 노력을 기울였습니다.
우리와 긴밀히 협력한 사람들 중 일부는 테크니온의 제이콥 카젠엘슨, 어바인 캘리포니아 대학의 하디 메이어, 옥스퍼드의 조 스토이, 퍼듀의 엘리샤 삭스, 그리고 노르웨이 과학 기술 대학의 얀 코모로프스키입니다.
우리는 예일의 케네스 입, 버클리 캘리포니아 대학의 브라이언 하비, 그리고 코넬의 댄 후텐로처를 포함하여 다른 대학에서 이 과목을 각색하여 주요 교육상을 수상한 동료들을 매우 자랑스럽게 생각합니다.

알 모예는  Hewlett-Packard의 엔지니어들에게 이 자료를 가르치고 이 강의의 비디오테이프 제작을 주선했습니다.
우리는 재능 있는 강사들---특히 짐 밀러, 빌 시버트, 그리고 마이크 아이젠버그---에게 감사하고 싶습니다. 그들은 이 테이프들을 통합한 평생 교육 과정을 설계하고 전 세계의 대학과 산업체에서 가르쳤습니다.

다른 나라의 많은 교육자들이 초판을 번역하는 데 상당한 노력을 기울였습니다.
미셸 브리앙, 피에르 샤마르, 앙드레 픽은 프랑스어판을 제작했고; 수잔 다니엘스-헤롤드는 독일어판을; 그리고 후미오 모토요시는 일본어판을 제작했습니다.
우리는 누가 중국어판을 제작했는지 모르지만, ``무단'' 번역의 대상으로 선정된 것을 영광으로 생각합니다.

교육 목적으로 우리가 사용하는 Scheme 시스템의 개발에 기술적 기여를 한 모든 사람들을 열거하기는 어렵습니다.
가이 스틸 외에도 주요 마법사들에는 크리스 핸슨, 조 보비어, 짐 밀러, 기예르모 로자스, 그리고 스티븐 아담스가 포함됩니다.
상당한 시간을 투자한 다른 사람들은 리처드 스톨만, 앨런 보든, 켄트 피트먼, 존 태프트, 닐 메일, 존 램핑, 귄 오스노스, 트레이시 라라비, 조지 카레트, 소마 차우두리, 빌 키아르키아로, 스티븐 커시, 리 클로츠, 웨인 노스, 토드 카스, 패트릭 오도넬, 케빈 테오발드, 다니엘 와이즈, 케네스 싱클레어, 앤서니 코트만슈, 헨리 M. 우, 앤드류 베를린, 그리고 루스 슈입니다.

@abbr{MIT} 구현을 넘어, 우리는 R⁴RS를 편집한 윌리엄 클링거와 조나단 리스, 그리고 @abbr{IEEE} 표준을 준비한 크리스 헤인즈, 데이비드 바틀리, 크리스 핸슨, 짐 밀러를 포함하여 @abbr{IEEE} Scheme 표준 작업에 참여한 많은 분들에게 감사하고 싶습니다.

댄 프리드먼은 Scheme 커뮤니티의 오랜 리더였습니다.
커뮤니티의 광범위한 작업은 언어 설계 문제를 넘어 Schemer's Inc.의 EdScheme에 기반한 고등학교 커리큘럼, 그리고 마이크 아이젠버그와 브라이언 하비 및 매슈 라이트의 멋진 책들과 같은 중요한 교육적 혁신을 아우릅니다.

우리는 이것을 진짜 책으로 만드는 데 기여한 사람들, 특히 @abbr{MIT} Press의 테리 엘링, 래리 코헨, 그리고 폴 베스지에게 감사합니다.
엘라 마젤은 멋진 표지 이미지를 찾았습니다.
제2판을 위해 우리는 책 디자인에 도움을 준 버나드와 엘라 마젤, 그리고 @TeX{} 마법사 데이비드 존스에게 특히 감사합니다.
우리는 또한 새로운 초안에 대해 날카로운 코멘트를 해준 독자들에게 빚을 지고 있습니다: 제이콥 카젠엘슨, 하디 메이어, 짐 밀러, 그리고 특히 줄리가 그의 책 @cite{Simply Scheme}에 했던 것처럼 이 책에 해준 브라이언 하비에게 감사합니다.

마지막으로, 우리는 수년간 이 작업을 격려해 준 조직들의 지원, 특히 아이라 골드스타인과 조엘 번바움이 가능하게 한 Hewlett-Packard의 지원과 밥 칸이 가능하게 한 @abbr{DARPA}의 지원에 감사하고 싶습니다.

@node    Chapter 1, 1.1, Acknowledgments, Top
@chapter 프로시저를 이용한 추상화 구축 (Building Abstractions with Procedures)

@quotation
마음이 단순한 아이디어들에 대해 힘을 발휘하는 행위들은 주로 다음 세 가지입니다:
@w{1. 여러} 단순한 아이디어들을 하나의 복합적인 것으로 결합하는 것, 그리고 이렇게 해서 모든 복잡한 아이디어들이 만들어집니다.
@w{2. 두 번째는} 단순하든 복합적이든 두 아이디어를 가져와서, 그것들을 하나로 통합하지 않고 서로 나란히 놓아 한 번에 보는 것입니다. 이것에 의해 마음은 관계에 대한 모든 아이디어들을 얻습니다.
@w{3. 세 번째는} 그것들을 실제 존재에 동반되는 다른 모든 아이디어들과 분리하는 것입니다: 이것을 추상화라고 부르며, 이렇게 해서 모든 일반적인 아이디어들이 만들어집니다.

---존 로크, @cite{An Essay Concerning Human Understanding} (1690)
@end quotation


@noindent
우리는 이제 @newterm{계산 프로세스(computational process)}라는 아이디어를 공부하려고 합니다.
계산 프로세스는 컴퓨터 안에 서식하는 추상적인 존재입니다.
프로세스는 진화하면서 @newterm{데이터(data)}라고 불리는 다른 추상적인 것들을 조작합니다.
프로세스의 진화는 @newterm{프로그램(program)}이라고 불리는 규칙들의 패턴에 의해 지시됩니다.
사람들은 프로세스를 지시하기 위해 프로그램을 만듭니다. 사실상, 우리는 주문을 외워 컴퓨터의 정령을 불러내는 것입니다.

계산 프로세스는 정말로 마법사의 정령 아이디어와 많이 닮았습니다.
그것은 보이거나 만질 수 없습니다. 그것은 물질로 구성되어 있지도 않습니다.
하지만, 그것은 매우 실제적입니다. 그것은 지적인 작업을 수행할 수 있습니다. 질문에 답할 수 있습니다.
은행에서 돈을 지불하거나 공장에서 로봇 팔을 제어함으로써 세상에 영향을 미칠 수 있습니다.
우리가 프로세스를 불러내기 위해 사용하는 프로그램은 마법사의 주문과 같습니다.
그것들은 우리가 프로세스가 수행하기를 원하는 작업을 규정하는 불가사의하고 난해한 @newterm{프로그래밍 언어(programming languages)}의 기호 표현식들로 신중하게 구성됩니다.

올바르게 작동하는 컴퓨터에서 계산 프로세스는 프로그램을 정밀하고 정확하게 실행합니다.
따라서, 마법사의 제자처럼, 초보 프로그래머들은 그들의 주문이 가져올 결과를 이해하고 예상하는 법을 배워야 합니다.
프로그램의 작은 오류(보통 @newterm{버그(bugs)} 또는 @newterm{글리치(glitches)}라고 불리는)조차 복잡하고 예상치 못한 결과를 초래할 수 있습니다.

다행히도, 프로그래밍을 배우는 것은 마법을 배우는 것보다 훨씬 덜 위험합니다. 왜냐하면 우리가 다루는 정령들은 안전한 방식으로 편리하게 격리되어 있기 때문입니다.
하지만 실제 세계의 프로그래밍은 주의와 전문 지식, 그리고 지혜를 요구합니다.
예를 들어, 컴퓨터 지원 설계(CAD) 프로그램의 작은 버그는 비행기나 댐의 재앙적인 붕괴 또는 산업 로봇의 자폭으로 이어질 수 있습니다.

숙련된 소프트웨어 엔지니어들은 결과 프로세스가 의도한 작업을 수행할 것이라고 합리적으로 확신할 수 있도록 프로그램을 조직하는 능력을 가지고 있습니다.
그들은 시스템의 동작을 미리 시각화할 수 있습니다.
그들은 예상치 못한 문제가 재앙적인 결과로 이어지지 않도록 프로그램을 구조화하는 법을 알고 있으며, 문제가 발생했을 때 프로그램을 @newterm{디버그(debug)}할 수 있습니다.
자동차나 원자로처럼 잘 설계된 계산 시스템은 모듈식으로 설계되어 있어, 부품들을 개별적으로 구축하고, 교체하고, 디버그할 수 있습니다.

@subsubheading Programming in Rust

우리는 프로세스를 기술하기 위한 적절한 언어가 필요하며, 이 목적을 위해 프로그래밍 언어 Rust를 사용할 것입니다.
우리의 일상적인 생각이 보통 자연어(영어, 프랑스어, 또는 일본어 등)로 표현되고, 양적 현상에 대한 설명이 수학적 표기법으로 표현되는 것처럼, 우리의 절차적 생각은 Rust로 표현될 것입니다.

Rust는 안전성, 속도, 그리고 동시성에 초점을 맞춘 현대적인 시스템 프로그래밍 언어입니다.
이 책의 원판은 이러한 개념을 설명하기 위해 Lisp(구체적으로는 Scheme)를 사용했지만, 우리는 Rust의 렌즈를 통해 그것들을 탐구할 것입니다.
이것은 추상화에 대한 현대적인 관점을 제공합니다: Lisp가 동적 타입이고 가비지 컬렉션을 사용하는 반면, Rust는 정적 타입이며 가비지 컬렉터 없이 메모리를 관리하기 위해 독특한 소유권 모델을 사용합니다.
이러한 차이에도 불구하고, 추상화와 모듈화의 핵심 원칙은 보편적으로 유지됩니다.

Rust는 안전하면서도 빠른 언어를 만들겠다는 비전으로 Mozilla Research에서 탄생했습니다.
2015년에 버전 1.0에 도달했으며, 컴파일 타임에 전체 클래스의 버그(널 포인터 역참조나 데이터 레이스 같은)를 방지하는 능력 덕분에 널리 채택되었습니다.

왜 우리는 프로그래밍에 대한 논의의 프레임워크로 Rust를 사용할까요?
그것이 우리에게 데이터의 소유권과 수명에 대해 명확하게 생각하도록 강요하기 때문이며, 이것들은 현대 소프트웨어 공학에서 중요한 개념입니다.
Lisp가 균일한 구조를 통해 데이터와 코드 사이의 구분을 모호하게 하는 반면, Rust는 트레이트 시스템과 제로 비용 추상화를 통해 강력한 추상화를 달성합니다.
이를 통해 우리는 효율적인 기계 명령어로 컴파일되는 고수준 코드를 작성할 수 있습니다.

이 연습 문제들을 위해 Rust를 사용하는 것은 동적 언어들이 하지 않는 방식으로 타입과 메모리에 대해 생각하도록 여러분에게 도전할 것이며, 컴퓨터 시스템이 실제로 어떻게 작동하는지 이해하기 위한 엄격한 기초를 제공할 것입니다.

@menu
* 1.1::              The Elements of Programming
* 1.2::              Procedures and the Processes They Generate
* 1.3::              Formulating Abstractions with Higher-Order Procedures
@end menu

@node	1.1, 1.2, Chapter 1, Chapter 1
@section 프로그래밍의 요소 (The Elements of Programming)

강력한 프로그래밍 언어는 단지 컴퓨터에게 작업을 수행하도록 지시하는 수단 그 이상입니다.
언어는 또한 우리가 프로세스에 대한 아이디어를 조직하는 프레임워크 역할을 합니다.
따라서, 언어를 설명할 때, 우리는 그 언어가 단순한 아이디어들을 결합하여 더 복잡한 아이디어를 형성하기 위해 제공하는 수단에 특별한 주의를 기울여야 합니다.
모든 강력한 언어는 이것을 달성하기 위한 세 가지 메커니즘을 가지고 있습니다:

@itemize @bullet

@item @b{원시 표현식(primitive expressions)},
언어가 다루는 가장 단순한 개체들을 나타냅니다.

@item @b{조합 수단(means of combination)},
더 단순한 요소들로부터 복합 요소들이 만들어지는 방법입니다.

@item @b{추상화 수단(means of abstraction)},
복합 요소들이 이름을 부여받고 하나의 단위로서 조작될 수 있게 하는 방법입니다.

@end itemize

@noindent
프로그래밍에서 우리는 두 종류의 요소, 즉 프로시저와 데이터를 다룹니다. (나중에 우리는 그것들이 실제로 그렇게 뚜렷하게 구분되지 않는다는 것을 발견할 것입니다.)
비공식적으로, 데이터는 우리가 조작하고자 하는 ``재료''이고, 프로시저는 데이터를 조작하는 규칙에 대한 설명입니다.
따라서, 어떤 강력한 프로그래밍 언어라도 원시 데이터와 원시 프로시저를 설명할 수 있어야 하고, 프로시저와 데이터를 결합하고 추상화하는 방법을 가지고 있어야 합니다.

이 장에서 우리는 프로시저를 구축하는 규칙에 집중할 수 있도록 단순한 수치 데이터만 다룰 것입니다.@footnote{숫자를 ``단순 데이터''라고 특징짓는 것은 뻔뻔한 허풍입니다. 사실, 숫자의 처리는 모든 프로그래밍 언어에서 가장 까다롭고 혼란스러운 측면 중 하나입니다. 관련된 몇 가지 전형적인 문제는 다음과 같습니다: 일부 컴퓨터 시스템은 2와 같은 @newterm{정수(integers)}와 2.71과 같은 @newterm{실수(real numbers)}를 구별합니다. 실수 2.00은 정수 2와 다를까요? 정수에 사용되는 산술 연산은 실수에 사용되는 연산과 같을까요? 6을 2로 나누면 3이 나올까요, 아니면 3.0이 나올까요? 얼마나 큰 수를 표현할 수 있을까요? 소수점 몇 자리까지 정확도를 표현할 수 있을까요? 정수의 범위는 실수의 범위와 같을까요? 물론 이 질문들 너머에는 반올림과 잘림 오차에 관한 문제들의 집합---수치 해석학이라는 전체 과학---이 놓여 있습니다. 이 책에서 우리의 초점은 수치 기법보다는 대규모 프로그램 설계에 있기 때문에, 우리는 이 문제들을 무시할 것입니다. 이 장의 수치 예제들은 정수가 아닌 연산에서 제한된 소수점 자리수의 정확도를 보존하는 산술 연산을 사용할 때 관찰되는 일반적인 반올림 동작을 보여줄 것입니다.}
이후의 장에서 우리는 이 동일한 규칙들이 복합 데이터를 조작하는 프로시저를 구축하는 데에도 사용될 수 있음을 보게 될 것입니다.

@menu
* 1.1.1::            Expressions
* 1.1.2::            Naming and the Environment
* 1.1.3::            Evaluating Combinations
* 1.1.4::            Compound Procedures
* 1.1.5::            The Substitution Model for Procedure Application
* 1.1.6::            Conditional Expressions and Predicates
* 1.1.7::            Example: Square Roots by Newton's Method
* 1.1.8::            Procedures as Black-Box Abstractions
@end menu

@node	1.1.1, 1.1.2, 1.1, 1.1
@subsection 표현식 (Expressions)

프로그래밍을 시작하는 쉬운 방법 중 하나는 Rust REPL(Read-Eval-Print Loop, 읽기-평가-출력 루프)과의 전형적인 상호작용을 살펴보는 것입니다.
여러분이 컴퓨터 터미널 앞에 앉아 있다고 상상해 보십시오. 여러분이 @newterm{표현식(expression)}을 타이핑하면, 인터프리터는 그 표현식을 @newterm{평가(evaluating)}한 결과를 표시하여 응답합니다.

여러분이 타이핑할 수 있는 원시 표현식의 한 종류는 숫자입니다. (더 정확하게는, 여러분이 타이핑하는 표현식은 10진수로 숫자를 나타내는 숫자들로 구성됩니다.)
만약 여러분이 Rust에게 숫자를 제시하면

@example
486
@end example

@noindent
인터프리터는 그것을 출력함으로써 응답할 것입니다.@footnote{이 책 전체에서, 사용자가 입력한 것과 인터프리터가 출력한 응답 사이의 구분을 강조하고 싶을 때, 후자를 기울임꼴 문자로 표시할 것입니다.}

@example
@i{486}
@end example

@noindent
숫자를 나타내는 표현식들은 연산자(@code{+} 또는 @code{*}와 같은)와 결합되어 그 숫자들에 연산자를 적용한 것을 나타내는 복합 표현식을 형성할 수 있습니다. 예를 들어:

@example
137 + 349
// => 486

1000 - 334
// => 666

5 * 99
// => 495

10 / 5
// => 2

2.7 + 10.0
// => 12.7
@end example

@noindent
이와 같이 연산자와 피연산자를 결합한 표현식을 @newterm{복합 표현식(compound expressions)}이라고 부릅니다.
Rust는 표준 수학적 @newterm{중위 표기법(infix notation)}을 사용하는데, 여기서 연산자는 피연산자 사이에 나타납니다.
복합 표현식의 값은 피연산자의 값인 @newterm{인자(arguments)}에 연산자를 적용하여 얻습니다.

피연산자 사이에 연산자를 배치하는 이 관습은 @newterm{중위 표기법}으로 알려져 있으며, 관습적인 수학적 표기법을 따릅니다.
중위 표기법은 이항 연산자와 자연스럽게 작동하며, 다음 예제와 같이 체이닝을 통해 여러 피연산자를 처리하도록 확장될 수 있습니다:

@example
21 + 35 + 12 + 7
// => 75

25 * 4 * 12
// => 1200
@end example

@noindent
모호함은 발생하지 않습니다. 왜냐하면 Rust는 표준 연산자 우선순위 규칙(덧셈과 뺄셈보다 곱셈과 나눗셈을 먼저)을 따르며, 괄호를 사용하여 기본 우선순위를 재정의할 수 있기 때문입니다.

중위 표기법은 표현식이 @i{중첩(nested)}될 수 있도록 자연스럽게 확장됩니다. 즉, 피연산자 자체가 복합 표현식인 복합 표현식을 가질 수 있습니다:

@example
(3 * 5) + (10 - 6)
// => 19
@end example

@noindent
원칙적으로 이러한 중첩의 깊이와 Rust가 평가할 수 있는 표현식의 전체적인 복잡성에는 제한이 없습니다.
다음과 같은 여전히 비교적 단순한 표현식에 혼란스러워하는 것은 우리 인간들입니다.

@example
(3 * ((2 * 4) + (3 + 5))) + ((10 - 7) + 6)
@end example

@noindent
인터프리터는 이것을 57로 쉽게 평가할 것입니다.
우리는 그러한 표현식을 다음과 같은 형태로 작성함으로써 스스로를 도울 수 있습니다.

@example
(3 * ((2 * 4) +
      (3 + 5))) +
((10 - 7) + 6)
@end example

@noindent
이것은 @newterm{프리티 프린팅(pretty-printing)}이라고 알려진 서식 지정 관습을 따른 것으로, 긴 표현식은 피연산자들이 수직으로 정렬되도록 작성됩니다.
결과적인 들여쓰기는 표현식의 구조를 명확하게 보여줍니다.@footnote{Rust 개발 도구들은 일반적으로 사용자가 표현식의 서식을 지정하는 것을 돕는 기능을 제공합니다. 특히 유용한 두 가지 기능은 @code{rustfmt}와 같은 도구를 사용한 자동 서식 지정과, 일치하는 괄호로 복잡한 중첩 표현식을 시각적으로 파싱하는 데 도움을 주는 구문 강조(syntax highlighting)입니다.}

복잡한 표현식이라도 인터프리터는 항상 동일한 기본 주기로 작동합니다: 터미널에서 표현식을 읽고, 표현식을 평가하고, 결과를 출력합니다.
이러한 작동 모드는 종종 인터프리터가 @newterm{읽기-평가-출력 루프(read-eval-print loop)}에서 실행된다고 말함으로써 표현됩니다.
특히 표현식의 값을 출력하도록 인터프리터에게 명시적으로 지시할 필요가 없다는 점을 관찰하십시오.@footnote{Rust는 모든 표현식이 값을 갖는다는 관습을 따릅니다. 이것은 Rust 설계의 근본적인 원칙으로, 블록, @code{if} 문, @code{match} 표현식을 포함하여 거의 모든 것이 값으로 평가되는 표현식입니다.}

@node   1.1.2, 1.1.3, 1.1.1, 1.1

@subsection 명명과 환경 (Naming and the Environment)



프로그래밍 언어의 중요한 측면 중 하나는 계산 객체를 참조하기 위해 이름을 사용하는 수단을 제공하는 것입니다. 우리는 그 이름 이 객체를 값으로 갖는 @newterm{변수(variable)}를 식별한다고 말합니다.



Rust에서는 @code{let} 바인딩을 사용하여 사물에 이름을 붙입니다. 다음과 같이 입력하면



@example

let size = 2;

@end example



@noindent

인터프리터는 2라는 값을 @code{size}라는 이름과 연관시킵니다.@footnote{이 책에서는 정의를 평가할 때 인터프리터의 응답을 보여주지 않는데, 이는 구현에 따라 크게 달라지기 때문입니다.} @code{size}라는 이름이 숫자 2와 연관되면, 우리는 그 이름을 통해 값 2를 참조할 수 있습니다:



@example

size

// => 2



5 * size

// => 10

@end example



@noindent

다음은 @code{let}을 사용하는 추가 예제들입니다:



@example

let pi = 3.14159;

let radius = 10.0;



pi * (radius * radius)

// => 314.159



let circumference = 2.0 * pi * radius;



circumference

// => 62.8318

@end example



@noindent

@code{let} 바인딩은 우리 언어의 가장 단순한 추상화 수단입니다. 왜냐하면 위에서 계산된 @code{circumference}와 같이 복합 연산의 결과에 간단한 이름을 사용하여 참조할 수 있게 해주기 때문입니다. 일반적으로 계산 객체는 매우 복잡한 구조를 가질 수 있으며, 그것들을 사용하고 싶을 때마다 매번 세부 사항을 기억하고 반복하는 것은 매우 불편할 것입니다. 실제로 복잡한 프로그램은 점점 더 복잡해지는 계산 객체들을 단계별로 구축함으로써 만들어집니다. REPL(Read-Eval-Print Loop)은 이름-객체 연관이 연속적인 상 호작용에서 점진적으로 생성될 수 있기 때문에 이러한 단계별 프로그램 구축을 특히 편리하게 만듭니다. 이 기능은 프로그램의 점진적인 개발과 테스트를 장려하며, Rust 프로그램이 대개 수많은 비교적 단순한 함수들로 구성되는 주된 이유이기도 합니다.



값들을 기호와 연관시키고 나중에 그것들을 다시 가져올 수 있다는 것은 인터프리터가 이름-객체 쌍을 추적하는 일종의 메모리를 유 지해야 함을 의미합니다. 이 메모리를 @newterm{환경(environment)}(더 정확하게는 @newterm{전역 환경(global environment)})이라 고 부릅니다. 나중에 우리는 계산이 여러 다른 환경을 포함할 수 있음을 보게 될 것이기 때문입니다.@footnote{@ref{Chapter 3}에서는 이 환경의 개념이 인터프리터가 작동하는 방식을 이해하고 인터프리터를 구현하는 데 모두 중요하다는 것을 보여줄 것입니다.}



@node   1.1.3, 1.1.4, 1.1.2, 1.1

@subsection 조합의 평가 (Evaluating Combinations)



이 장의 우리의 목표 중 하나는 절차적으로 생각하는 것에 관한 이슈들을 분리하는 것입니다. 그 예로, 조합을 평가할 때 인터프 리터 자체가 하나의 프로시저를 따르고 있다는 점을 고려해 봅시다.

@quotation
조합(combination)을 평가하려면, 다음을 수행한다:

@enumerate 1

@item
조합의 부분표현식(subexpressions)을 평가한다.

@item
연산자(operator) 부분표현식의 값인 프로시저를 피연산자(operand) 부분표현식의 값인 인자(arguments)에 적용한다.

@end enumerate
@end quotation

@noindent
이 간단한 규칙조차 프로세스 일반에 관한 몇 가지 중요한 점을 보여준다.
먼저, 첫 번째 단계는 조합의 평가 프로세스를 수행하기 위해 조합의 각 요소에 대해 평가 프로세스를 먼저 수행해야 한다고 지시한다는 점을 관찰하자.
따라서 평가 규칙은 본질적으로 @newterm{재귀적(recursive)}이다. 즉, 그 단계 중 하나로서 규칙 자체를 호출해야 할 필요성을 포함한다.@footnote{평가 규칙의 첫 단계에서 조합의 가장 왼쪽 요소를 평가해야 한다고 말하는 것이 이상해 보일 수 있다. 왜냐하면 이 시점에서 그것은 덧셈이나 곱셈과 같은 내장 원시 프로시저를 나타내는 @code{+}나 @code{*}와 같은 연산자일 뿐이기 때문이다. 우리는 나중에 연산자 자체가 복합 표현식인 조합을 다룰 수 있는 것이 유용하다는 것을 보게 될 것이다.}

깊게 중첩된 조합의 경우 꽤 복잡한 프로세스로 보일 수 있는 것을 표현하기 위해 재귀의 아이디어가 얼마나 간결하게 사용될 수 있는지 주목하라.
예를 들어, 다음을 평가하려면

@example
(2 + (4 * 6)) * (3 + 5 + 7)
@end example

@noindent
평가 규칙을 네 개의 서로 다른 조합에 적용해야 한다.
@ref{Figure 1.1}에 나타난 것처럼 조합을 트리 형태로 표현함으로써 이 프로세스의 그림을 얻을 수 있다.
각 조합은 연산자와 그 조합의 피연산자에 해당하는 가지들이 뻗어 나오는 노드로 표현된다.
터미널 노드(즉, 뻗어 나오는 가지가 없는 노드)는 연산자나 숫자를 나타낸다.
트리 관점에서 평가를 보면, 피연산자의 값들이 터미널 노드에서 시작하여 위쪽으로 스며 올라가(percolate) 점점 더 높은 수준에서 결합한다고 상상할 수 있다.
일반적으로, 우리는 재귀가 계층적인 트리 모양의 객체를 다루는 데 매우 강력한 기술임을 보게 될 것이다.
사실, 평가 규칙의 ``값들이 위로 스며 올라가는'' 형태는 @newterm{트리 누산(tree accumulation)}이라고 알려진 일반적인 종류의 프로세스의 한 예이다.

@float
@anchor{Figure 1.1}
@ifinfo
@strong{Figure 1.1:} 트리 표현, 각 하위 조합의 값을 보여준다.

@example
   390
   /|\____________
  / |             \
 *  26            15
    /|\           /|\
   / | \         // \\
  +  2  24      / | | \
        /|\    +  3 5  7
       / | \
      *  4  6
@end example
@end ifinfo
@iftex
@image{fig/chap1/Fig1.1g,,58mm,,.std.svg}
@caption{@strong{Figure 1.1:} 트리 표현, 각 하위 조합의 값을 보여준다.}
@end iftex
@end float

@noindent
다음으로, 첫 번째 단계를 반복적으로 적용하면 조합이 아니라 숫자, 내장 연산자, 또는 다른 이름과 같은 원시 표현식을 평가해야 하는 시점에 도달한다는 것을 관찰하자.
우리는 다음을 규정함으로써 원시적인 경우들을 처리한다:

@itemize @bullet

@item
숫자의 값은 그것이 이름 붙인 수이다.

@item
내장 연산자의 값은 해당 연산을 수행하는 기계 명령어 시퀀스이다.

@item
다른 이름의 값은 환경에서 그 이름과 연관된 객체이다.

@end itemize

@noindent
우리는 @code{+}나 @code{*}와 같은 기호들도 전역 환경에 포함되어 있으며, 그것들의 ``값''인 기계 명령어 시퀀스와 연관되어 있다고 규정함으로써 두 번째 규칙을 세 번째 규칙의 특수한 경우로 간주할 수 있다.
주목해야 할 핵심 사항은 표현식 내 기호의 의미를 결정하는 데 있어 환경의 역할이다.
Lisp와 같은 대화형 언어에서는 기호 @code{x}(또는 심지어 기호 @code{+}에 대해서도)에 의미를 제공하는 환경에 대한 정보 없이는 @code{(+ x 1)}과 같은 표현식의 값에 대해 말하는 것이 무의미하다.
@ref{Chapter 3}에서 보게 되겠지만, 평가가 일어나는 컨텍스트를 제공하는 것으로서의 환경이라는 일반적인 개념은 프로그램 실행에 대한 우리의 이해에 중요한 역할을 할 것이다.

위에서 제시된 평가 규칙은 정의(definitions)를 다루지 않는다는 점에 주목하라.
예를 들어, @code{let x = 3;}을 실행하는 것은 함수를 인자에 적용하지 않는다.
@code{let} 문의 목적은 정확히 @code{x}를 어떤 값과 연관시키는 것이다.

Rust에서 우리는 값으로 평가되는 @newterm{표현식(expressions)}과, 동작(변수 바인딩 같은)을 수행하지만 값을 반환하지 않는(또는 유닛 타입 @code{()}을 반환하는) @newterm{문(statements)}을 구별한다. @code{let} 바인딩은 문이다.
이 구별은 중요하다. 왜냐하면 값이 예상되는 곳(수학 연산 내부 같은)에는 표현식만 사용될 수 있기 때문이다.

이 구조는 모든 것이 리스트이지만 일부 리스트가 특별한 평가 규칙을 갖는 Lisp의 @newterm{특수 형태(special forms)} 개념과는 다르다.
Rust는 제어 흐름과 정의를 위한 키워드와 특정 구조를 갖춘 더 풍부한 문법을 가지고 있다.
다양한 종류의 표현식과 문은 프로그래밍 언어의 문법(syntax)을 구성한다.
Rust의 문법은 Lisp보다 복잡하지만 서로 다른 구조에 대해 명확한 시각적 단서를 제공한다.@footnote{더 균일한 방식으로 작성될 수 있는 것들에 대해 단순히 편리한 대체 표면 구조인 특수 문법 형태들을 때로는 @newterm{문법적 설탕(syntactic sugar)}이라고 부르는데, 이는 피터 랜딘(Peter Landin)이 만든 용어이다.  Rust는 반복자 기반 루프를 위한 설탕인 @code{for} 루프와 같이, 일반적인 패턴을 더 쉽게 쓰고 읽을 수 있게 하기 위해 문법적 설탕을 사용한다.}

@node	1.1.4, 1.1.5, 1.1.3, 1.1
@subsection 복합 프로시저 (Compound Procedures)

우리는 Rust에서 어떤 강력한 프로그래밍 언어에든 등장해야 하는 요소들 중 일부를 확인했다:

@itemize @bullet

@item
숫자와 산술 연산은 원시 데이터이자 프로시저이다.

@item
조합의 중첩은 연산을 결합하는 수단을 제공한다.

@item
이름을 값과 연관시키는 정의는 제한적인 추상화 수단을 제공한다.

@end itemize

@noindent
이제 우리는 훨씬 더 강력한 추상화 기술인 @newterm{프로시저 정의(procedure definitions)}에 대해 배울 것이다. 이를 통해 복합 연산에 이름을 부여하고 하나의 단위로 참조할 수 있다.

우리는 ``제곱하기''라는 아이디어를 표현하는 방법을 조사하는 것으로 시작한다. 우리는 ``무언가를 제곱하려면, 그것을 자신과 곱하라''고 말할 수 있다. 이것은 우리 언어로 다음과 같이 표현된다:

@example
fn square(x: i64) -> i64 @{ x * x @}
@end example

@noindent
우리는 이것을 다음과 같은 방식으로 이해할 수 있다:

@example
fn square(x: i64) -> i64 @{ x   *   x @}
|    |    |         |      |   |   |
|    |    |         |       곱하기
|    |    |         반환 타입 (64비트 정수)
|    |    타입 주석이 있는 매개변수
|    함수 이름
함수 정의 키워드
@end example

@noindent
여기 @code{square}라는 이름이 부여된 @newterm{복합 프로시저(compound procedure)}가 있다.
이 프로시저는 무언가를 자신과 곱하는 연산을 나타낸다.
곱해질 대상에는 지역 이름 @code{x}가 주어지는데, 이는 자연어에서 대명사가 하는 것과 같은 역할을 한다.
정의를 평가하면 이 복합 프로시저가 생성되고 이름 @code{square}와 연관된다.@footnote{여기서 결합된 두 가지 서로 다른 연산이 있음을 관찰하라: 우리는 프로시저를 생성하고 있고, 그것에 @code{square}라는 이름을 부여하고 있다. 이 두 개념을 분리하는 것---이름 없이 프로시저를 생성하는 것과 이미 생성된 프로시저에 이름을 부여하는 것---은 가능하며, 실제로 중요하다. 우리는 @ref{1.3.2}에서 이를 수행하는 방법을 보게 될 것이다.}

프로시저 정의의 일반적인 형태는 다음과 같다:

@example
fn ⟨@var{name}⟩(⟨@var{formal parameters}⟩) -> ⟨@var{return type}⟩ @{ ⟨@var{body}⟩ @}
@end example

@noindent
@code{⟨}@var{name}@code{⟩}은 환경에서 프로시저 정의와 연관될 기호이다.@footnote{이 책 전체에서, 우리는 꺾쇠 괄호로 구분된 기울임꼴 기호---예: @code{⟨}@var{name}@code{⟩}---를 사용하여 표현식의 일반적인 구문을 설명할 것이다. 이는 해당 표현식이 실제로 사용될 때 채워져야 할 ``슬롯''을 나타낸다.}
@code{⟨}@var{@w{formal} @w{parameters}}@code{⟩}(형식 매개변수)는 프로시저 본문 내에서 해당 프로시저의 인자를 참조하는 데 사용되는 이름들이며, 각각 타입 주석을 갖는다.
@code{⟨}@var{@w{return} @w{type}}@code{⟩}(반환 타입)은 프로시저가 반환할 값의 타입을 지정한다.
@code{⟨}@var{body}@code{⟩}(본문)는 형식 매개변수가 프로시저가 적용되는 실제 인자로 대체될 때 프로시저 적용의 값을 산출할 표현식이다.@footnote{더 일반적으로, 프로시저의 본문은 표현식의 시퀀스일 수 있다. 이 경우 컴파일러는 시퀀스의 각 표현식을 차례로 평가하고 마지막 표현식의 값을 프로시저 적용의 값으로 반환한다.}
@code{⟨}@var{name}@code{⟩}과 @code{⟨}@var{formal parameters}@code{⟩}는 정의되는 프로시저에 대한 실제 호출에서와 마찬가지로 괄호 안에 그룹화된다.

@code{square}를 정의했으므로, 이제 우리는 그것을 사용할 수 있다:

@example
square(21)
@i{441}

square(2 + 5)
@i{49}

square(square(3))
@i{81}
@end example

@noindent
우리는 또한 다른 프로시저를 정의할 때 @code{square}를 구성 요소로 사용할 수 있다.
예를 들어, @math{x^2 + y^2}은 다음과 같이 표현될 수 있다.

@example
square(x) + square(y)
@end example

@noindent
우리는 두 개의 숫자를 인자로 받아 그 제곱의 합을 생성하는 프로시저 @code{sum_of_squares}를 쉽게 정의할 수 있다:

@example
fn sum_of_squares(x: i64, y: i64) -> i64 @{
    square(x) + square(y)
@}

sum_of_squares(3, 4)
@i{25}
@end example

@noindent
이제 우리는 더 많은 프로시저를 구축하는 데 @code{sum_of_squares}를 구성 요소로 사용할 수 있다:

@example
fn f(a: i64) -> i64 @{
    sum_of_squares(a + 1, a * 2)
@}

f(5)
@i{136}
@end example

@noindent
복합 프로시저는 원시 프로시저와 정확히 같은 방식으로 사용된다.
실제로, 위에서 주어진 @code{sum_of_squares}의 정의만 봐서는 @code{square}가 @code{+}나 @code{*}처럼 언어에 내장된 것인지 아니면 복합 프로시저로 정의된 것인지 알 수 없다.

@node	1.1.5, 1.1.6, 1.1.4, 1.1
@subsection 프로시저 적용의 치환 모델 (The Substitution Model for Procedure Application)

연산자가 복합 프로시저의 이름인 조합을 평가하기 위해, 인터프리터는 @ref{1.1.3}에서 설명했던, 연산자가 원시 프로시저의 이름인 조합의 경우와 거의 동일한 프로세스를 따른다.
즉, 인터프리터는 조합의 요소들을 평가하고 프로시저(조합의 연산자의 값)를 인자(조합의 피연산자의 값)에 적용한다.

우리는 원시 프로시저를 인자에 적용하는 메커니즘이 인터프리터에 내장되어 있다고 가정할 수 있다.
복합 프로시저의 경우, 적용 프로세스는 다음과 같다:

@quotation
복합 프로시저를 인자에 적용하려면, 각 형식 매개변수를 해당 인자에 바인딩한 상태에서 프로시저의 본문을 평가한다.
@end quotation

@noindent
이 프로세스를 설명하기 위해, 다음 조합을 평가해 보자.

@example
f(5)
@end example

@noindent
여기서 @code{f}는 @ref{1.1.4}에서 정의된 프로시저이다. 우리는 @code{f}의 본문을 가져오는 것으로 시작한다:

@example
sum_of_squares(a + 1, a * 2)
@end example

@noindent
그런 다음 형식 매개변수 @code{a}를 인자 5로 대체한다:

@example
sum_of_squares(5 + 1, 5 * 2)
@end example

@noindent
따라서 문제는 두 개의 피연산자와 연산자 @code{sum_of_squares}를 가진 조합의 평가로 축소된다.
이 조합을 평가하는 것은 세 가지 하위 문제를 포함한다.
우리는 적용될 프로시저를 얻기 위해 연산자를 평가해야 하고, 인자를 얻기 위해 피연산자를 평가해야 한다.
이제 @code{5 + 1}은 6을 생성하고 @code{5 * 2}는 10을 생성하므로, 우리는 @code{sum_of_squares} 프로시저를 6과 10에 적용해야 한다.
이 값들은 @code{sum_of_squares}의 본문에 있는 형식 매개변수 @code{x}와 @code{y}에 대해 치환되어 표현식을 다음과 같이 축소시킨다.

@example
square(6) + square(10)
@end example

@noindent
@code{square}의 정의를 사용하면, 이것은 다음과 같이 축소된다.

@example
(6 * 6) + (10 * 10)
@end example

@noindent
곱셈에 의해 다음과 같이 축소된다.

@example
36 + 100
@end example

@noindent
그리고 마지막으로

@example
136
@end example

@noindent
우리가 방금 설명한 프로세스를 프로시저 적용에 대한 @newterm{치환 모델(substitution model)}이라고 부른다.
이것은 이 장의 프로시저들에 관한 한 프로시저 적용의 ``의미''를 결정하는 모델로 받아들여질 수 있다.
그러나 강조해야 할 두 가지 점이 있다:

@itemize @bullet

@item
치환의 목적은 우리가 프로시저 적용에 대해 생각하는 것을 돕는 것이지, 인터프리터가 실제로 어떻게 작동하는지에 대한 설명을 제공하는 것이 아니다.
일반적인 인터프리터들은 형식 매개변수에 값을 치환하기 위해 프로시저의 텍스트를 조작함으로써 프로시저 적용을 평가하지 않는다.
실제로는 형식 매개변수에 대해 지역 환경을 사용함으로써 ``치환''이 달성된다.
우리는 @ref{Chapter 3}과 @ref{Chapter 4}에서 인터프리터의 구현을 자세히 조사할 때 이것을 더 완전하게 논의할 것이다.

@item
이 책의 과정 동안, 우리는 인터프리터가 어떻게 작동하는지에 대한 점점 더 정교해지는 일련의 모델들을 제시할 것이며, @ref{Chapter 5}에서 인터프리터와 컴파일러의 완전한 구현으로 정점을 찍을 것이다.
치환 모델은 이러한 모델들 중 첫 번째일 뿐이다---평가 프로세스에 대해 공식적으로 생각하기 시작하는 방법이다.
일반적으로 과학과 공학에서 현상을 모델링할 때, 우리는 단순화되고 불완전한 모델로 시작한다.
우리가 사물을 더 자세히 조사함에 따라, 이러한 단순한 모델들은 부적절해지고 더 정교한 모델로 대체되어야 한다.
치환 모델도 예외는 아니다.
특히 @ref{Chapter 3}에서 ``가변 데이터''를 가진 프로시저의 사용을 다룰 때, 우리는 치환 모델이 무너지고 프로시저 적용의 더 복잡한 모델로 대체되어야 함을 보게 될 것이다.

@end itemize

@subsubheading Applicative order versus normal order

@ref{1.1.3}에 주어진 평가에 대한 설명에 따르면, 인터프리터는 먼저 연산자와 피연산자를 평가한 다음 결과 프로시저를 결과 인자에 적용한다.
이것이 평가를 수행하는 유일한 방법은 아니다.
대안적인 평가 모델은 값이 필요할 때까지 피연산자를 평가하지 않을 것이다.
대신 원시 연산자만 포함하는 표현식을 얻을 때까지 피연산자 표현식을 매개변수에 치환한 다음 평가를 수행할 것이다.
만약 우리가 이 방법을 사용한다면, @code{f(5)}의 평가는 다음과 같은 확장 순서에 따라 진행될 것이다.

@example
sum_of_squares(5 + 1, 5 * 2)

square(5 + 1) + square(5 * 2)

(5 + 1) * (5 + 1) + (5 * 2) * (5 * 2)
@end example

@noindent
그 다음 축소가 뒤따른다.

@example
(6 * 6) + (10 * 10)

36 + 100

136
@end example

@noindent
이것은 우리의 이전 평가 모델과 같은 답을 주지만, 프로세스는 다르다.
특히 @code{5 + 1}과 @code{5 * 2}의 평가는 여기서 각각 두 번 수행되는데, 이는 @code{x}가 각각 @code{5 + 1}과 @code{5 * 2}로 대체된 상태에서 표현식 @code{x * x}의 축소에 해당한다.

이 대안적인 ``완전히 확장한 다음 축소하는'' 평가 방법은 @newterm{정규 순서 평가(normal-order evaluation)}로 알려져 있으며, 인터프리터가 실제로 사용하는 ``인자를 평가한 다음 적용하는'' 방법인 @newterm{적용 순서 평가(applicative-order evaluation)}와 대조된다.
치환을 사용하여 모델링할 수 있고(이 책의 처음 두 장에 있는 모든 프로시저를 포함하여) 합법적인 값을 산출하는 프로시저 적용에 대해, 정규 순서 평가와 적용 순서 평가는 동일한 값을 생성한다는 것을 보일 수 있다.
(정규 순서 평가와 적용 순서 평가가 동일한 결과를 주지 않는 ``불법적인'' 값의 예는 @ref{Exercise 1.5}를 참조하라.)

Rust는 적용 순서 평가를 사용한다. 이는 부분적으로 위에서 @code{5 + 1}과 @code{5 * 2}로 예시된 것과 같은 표현식의 다중 평가를 피함으로써 얻는 추가적인 효율성 때문이며, 더 중요하게는 치환에 의해 모델링될 수 있는 프로시저의 영역을 벗어날 때 정규 순서 평가를 다루기가 훨씬 더 복잡해지기 때문이다.
반면에 정규 순서 평가는 매우 가치 있는 도구가 될 수 있으며, 우리는 @ref{Chapter 3}과 @ref{Chapter 4}에서 그 의미 중 일부를 조사할 것이다.

@node	1.1.6, 1.1.7, 1.1.5, 1.1
@subsection 조건식과 술어 (Conditional Expressions and Predicates)

이 시점에서 우리가 정의할 수 있는 프로시저 클래스의 표현력은 매우 제한적이다.
왜냐하면 테스트를 만들고 테스트 결과에 따라 다른 작업을 수행할 방법이 없기 때문이다.
예를 들어, 숫자가 양수인지, 음수인지, 0인지 테스트하고 규칙에 따라 각 경우에 서로 다른 조치를 취함으로써 숫자의 절댓값을 계산하는 프로시저를 정의할 수 없다.
@ifinfo

@example
      /
      |   x  if x > 0
|x| = <   0  if x = 0
      |  -x  if x < 0
      \
@end example

@end ifinfo
@tex

\[ % :1:

\left|{x}\right| \; = \;
  \left\{ 
    \begin{array}{rll}	 	 
       x & \;\text{if} & x \gt 0, \\
       0 & \;\text{if} & x  =  0, \\
      -x & \;\text{if} & x \lt 0. 
    \end{array} 
  \right. 
\]

@end tex
이러한 구성을 @newterm{경우 분석(case analysis)}이라고 하며, Rust에는 그러한 경우 분석을 표기하기 위한 특별한 형태가 있다.
다음과 같이 @code{if/else if/else} 체인을 사용하여 표현할 수 있다:

@example
fn abs(x: i64) -> i64 @{
    if x > 0 @{
        x
    @} else if x == 0 @{
        0
    @} else @{
        -x
    @}
@}
@end example

@noindent
조건부 표현식의 일반적인 형태는 다음과 같다:

@example
if ⟨@var{p₁}⟩ @{
    ⟨@var{e₁}⟩
@} else if ⟨@var{p₂}⟩ @{
    ⟨@var{e₂}⟩
@}
@r{…}
else @{
    ⟨@var{eₙ}⟩
@}
@end example

@noindent
@code{if} 키워드와 조건, 블록이 뒤따르고, 선택적으로 @code{else if} 분기들과 마지막 @code{else} 분기가 뒤따르는 것으로 구성된다.
각 조건부 표현식은 @newterm{술어(predicate)}이다---즉, 그 값이 참(true) 또는 거짓(false)으로 해석되는 표현식이다.@footnote{``참 또는 거짓으로 해석된다''는 것은 다음을 의미한다: Rust에는 상수 @code{true}와 @code{false}로 표시되는 @code{bool} 타입의 구별된 두 값이 있다. 컴파일러가 술어의 값을 확인할 때, @code{false}는 거짓으로, @code{true}는 참으로 해석한다. Scheme과 달리, Rust는 술어가 명시적으로 @code{bool} 타입일 것을 요구하며 다른 값을 불리언으로 암시적으로 변환하지 않는다.}

조건부 표현식은 다음과 같이 평가된다.
먼저 술어 @math{{⟨p_1⟩}}이 평가된다.
그 값이 거짓이면 @math{{⟨p_2⟩}}가 평가된다.
@math{{⟨p_2⟩}}의 값도 거짓이면 @math{{⟨p_3⟩}}이 평가된다.
이 과정은 값이 참인 술어를 찾을 때까지 계속되며, 그 경우 인터프리터는 해당하는 @newterm{결과 표현식(consequent expression)} @math{{⟨e⟩}}의 값을 조건부 표현식의 값으로 반환한다.
만약 @math{{⟨p⟩}} 중 어느 것도 참이 아니고 마지막 @code{else} 분기가 있다면, 그 분기의 값이 반환된다.

@newterm{술어(predicate)}라는 단어는 참이나 거짓을 반환하는 함수뿐만 아니라 참이나 거짓으로 평가되는 표현식에도 사용된다.
절댓값 함수 @code{abs}는 원시 술어 @code{>}, @code{<}, 그리고 @code{==}를 사용한다.@footnote{@code{Abs}는 또한 ``마이너스'' 연산자 @code{-}를 사용하는데, 이것은 @code{-x}에서처럼 단항 접두사 연산자로 사용될 때 부정을 나타낸다.}
이것들은 두 숫자를 인자로 받아 첫 번째 숫자가 두 번째 숫자보다 각각 큰지, 작은지, 또는 같은지 테스트하고 그에 따라 참 또는 거짓을 반환한다.

절댓값 함수를 작성하는 또 다른 방법은 다음과 같다:

@example
fn abs(x: i64) -> i64 @{
    if x < 0 @{
        -x
    @} else @{
        x
    @}
@}
@end example

@noindent
이것은 영어로 ``만약 @math{x}가 0보다 작으면 @math{{-x}}를 반환하고, 그렇지 않으면 @math{x}를 반환하라''고 표현될 수 있다.
@code{else}는 조건문의 기본 분기를 제공하는 Rust의 키워드이다.
이것은 이전의 모든 조건이 거짓일 때 조건문이 @code{else} 블록의 값을 반환하게 한다.

여기 절댓값 함수를 작성하는 또 다른 방법이 있다:

@example
fn abs(x: i64) -> i64 @{
    if x < 0 @{ -x @} else @{ x @}
@}
@end example

@noindent
이것은 경우 분석에 정확히 두 가지 경우가 있을 때 사용할 수 있는 @code{if} 표현식을 사용한다.
@code{if} 표현식의 일반적인 형태는 다음과 같다:

@example
if ⟨@var{predicate}⟩ @{ ⟨@var{consequent}⟩ @} else @{ ⟨@var{alternative}⟩ @}
@end example

@noindent
@code{if} 표현식을 평가하기 위해, 인터프리터는 표현식의 @code{⟨}@var{predicate}@code{⟩}(술어) 부분을 평가하는 것으로 시작한다.
@code{⟨}@var{predicate}@code{⟩}가 참 값으로 평가되면, 인터프리터는 @code{⟨}@var{consequent}@code{⟩}(결과)를 평가하고 그 값을 반환한다.
그렇지 않으면 @code{⟨}@var{alternative}@code{⟩}(대안)를 평가하고 그 값을 반환한다.@footnote{Rust에서 @code{⟨}@var{consequent}@code{⟩}와 @code{⟨}@var{alternative}@code{⟩} 블록은 모두 문의 시퀀스를 포함할 수 있다. 블록이 여러 문을 포함하는 경우, 그것들은 순서대로 평가되며 블록 내의 마지막 표현식(세미콜론 없는)의 값이 블록의 값으로 반환된다.}

@code{<}, @code{==}, @code{>}와 같은 원시 술어 외에도, 복합 술어를 구성할 수 있게 해주는 논리 합성 연산이 있다.
가장 자주 사용되는 세 가지는 다음과 같다:

@itemize @bullet

@item
@code{⟨@var{e₁}⟩ && @r{…} && ⟨@var{eₙ}⟩}

인터프리터는 표현식 @code{⟨}@var{e}@code{⟩}를 왼쪽에서 오른쪽 순서로 한 번에 하나씩 평가한다.
어떤 @code{⟨}@var{e}@code{⟩}가 거짓으로 평가되면, @code{&&} 표현식의 값은 거짓이고, 나머지 @code{⟨}@var{e}@code{⟩}들은 평가되지 않는다.
모든 @code{⟨}@var{e}@code{⟩}가 참 값으로 평가되면, @code{&&} 표현식의 값은 참이다.

@item
@code{⟨@var{e₁}⟩ || @r{…} || ⟨@var{eₙ}⟩}

인터프리터는 표현식 @code{⟨}@var{e}@code{⟩}를 왼쪽에서 오른쪽 순서로 한 번에 하나씩 평가한다.
어떤 @code{⟨}@var{e}@code{⟩}가 참 값으로 평가되면, @code{||} 표현식의 값으로 참이 반환되고, 나머지 @code{⟨}@var{e}@code{⟩}들은 평가되지 않는다.
모든 @code{⟨}@var{e}@code{⟩}가 거짓으로 평가되면, @code{||} 표현식의 값은 거짓이다.

@item
@code{!⟨@var{e}⟩}

@code{!} 표현식의 값은 표현식 @code{⟨}@var{e}@code{⟩}가 거짓으로 평가되면 참이고, 그렇지 않으면 거짓이다.

@end itemize

@noindent
@code{&&}와 @code{||}는 단락 평가(short-circuit evaluation)를 사용한다는 점에 주목하라. 이는 부분표현식들이 반드시 모두 평가되지는 않음을 의미한다.
@code{!}는 항상 피연산자를 평가하는 일반 연산자이다.

이것들이 어떻게 사용되는지에 대한 예로, 숫자 @math{x}가 @math{5 < x < 10} 범위에 있다는 조건은 다음과 같이 표현될 수 있다:

@example
x > 5 && x < 10
@end example

@noindent
또 다른 예로, 어떤 숫자가 다른 숫자보다 크거나 같은지 테스트하는 술어를 다음과 같이 정의할 수 있다:

@example
fn gte(x: i64, y: i64) -> bool @{
    x > y || x == y
@}
@end example

@noindent
또는 대안적으로 다음과 같이:

@example
fn gte(x: i64, y: i64) -> bool @{
    !(x < y)
@}
@end example

@quotation
@strong{@anchor{Exercise 1.1}Exercise 1.1:} 아래는 표현식들의 시퀀스이다. 각 표현식에 대해 컴파일러가 출력하는 결과는 무엇인가?
시퀀스는 제시된 순서대로 평가된다고 가정하라.

@example
10
5 + 3 + 4
9 - 1
6 / 2
2 * 4 + (4 - 6)
let a = 3;
let b = a + 1;
a + b + a * b
a == b
if b > a && b < a * b @{
    b
@} else @{
    a
@}
if a == 4 @{
    6
@} else if b == 4 @{
    6 + 7 + a
@} else @{
    25
@}
2 + if b > a @{ b @} else @{ a @}
(if a > b @{
    a
@} else if a < b @{
    b
@} else @{
    -1
@}) * (a + 1)
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 1.2}Exercise 1.2:} 다음 표현식을 Rust로 번역하라:
@ifinfo

@example
5 + 4 + (2 - (3 - (6 + 4/5)))
-----------------------------
       3(6 - 2)(2 - 7)
@end example

@end ifinfo
@tex

\[ % :2:

{\frac{5 + 4 + (2 - (3 - (6 + \frac{4}{5})))}{3(6 - 2)(2 - 7)}.}
\]

@end tex
@end quotation

@quotation
@strong{@anchor{Exercise 1.3}Exercise 1.3:} 세 개의 숫자를 인자로 받아 더 큰 두 숫자의 제곱의 합을 반환하는 함수를 정의하라.
@end quotation

@quotation
@strong{@anchor{Exercise 1.4}Exercise 1.4:} 우리의 평가 모델이 조건에 따라 서로 다른 연산 중에서 선택하는 것을 허용한다는 점을 관찰하라.
이 관찰을 사용하여 다음 함수의 동작을 설명하라:

@example
fn a_plus_abs_b(a: i64, b: i64) -> i64 @{
    if b > 0 @{
        a + b
    @} else @{
        a - b
    @}
@}
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 1.5}Exercise 1.5:} Ben Bitdiddle은 그가 마주한 컴파일러가 적용 순서 평가를 사용하는지 정규 순서 평가를 사용하는지 결정하기 위한 테스트를 고안했다.
그는 다음 두 함수를 정의한다:

@example
fn p() -> i64 @{
    p()
@}

fn test(x: i64, y: i64) -> i64 @{
    if x == 0 @{
        0
    @} else @{
        y
    @}
@}
@end example

그리고 그는 다음 표현식을 평가한다.

@example
test(0, p())
@end example

적용 순서 평가를 사용하는 컴파일러에서 Ben은 어떤 동작을 관찰하게 될까?
정규 순서 평가를 사용하는 컴파일러에서 그는 어떤 동작을 관찰하게 될까?
답을 설명하라.
(컴파일러가 정규 순서를 사용하든 적용 순서를 사용하든 @code{if}에 대한 평가 규칙은 동일하다고 가정하라: 술어 표현식이 먼저 평가되고, 그 결과가 결과 표현식을 평가할지 대안 표현식을 평가할지 결정한다.)
@end quotation

@anchor{Sec.1.1.7}
@node	1.1.7, 1.1.8, 1.1.6, 1.1
@subsection 예제: 뉴턴의 방법에 의한 제곱근 (Example: Square Roots by Newton's Method)

위에서 소개된 프로시저들은 일반적인 수학 함수와 매우 비슷하다.
그것들은 하나 이상의 매개변수에 의해 결정되는 값을 명시한다.
그러나 수학 함수와 컴퓨터 프로시저 사이에는 중요한 차이점이 있다.
프로시저는 효율적(effective)이어야 한다.

적절한 사례로, 제곱근을 계산하는 문제를 고려해 보자.
우리는 제곱근 함수를 다음과 같이 정의할 수 있다:
@ifinfo

@example
sqrt(x) = the y such that y >= 0 and y^2 = x
@end example

@end ifinfo
@tex

\[ % :3:

\sqrt{x} \;\; = \;\; {\text{the} \;\; y} \;\;
{\text{such that}} \;\; {y \ge 0} \;\; {\text{and} \;\; y^2 = x.}
\]

@end tex
이것은 완벽하게 합법적인 수학 함수를 기술한다.
우리는 이것을 사용하여 어떤 숫자가 다른 숫자의 제곱근인지 인식하거나, 일반적으로 제곱근에 대한 사실을 도출할 수 있다.
반면에, 이 정의는 프로시저를 기술하지 않는다.
실제로, 이것은 주어진 숫자의 제곱근을 실제로 찾는 방법에 대해 거의 아무것도 말해주지 않는다.
이 정의를 의사 Rust(pseudo-Rust)로 바꿔 쓰는 것은 문제에 도움이 되지 않는다:

@example
fn sqrt(x: f64) -> f64 @{
    // the y such that y >= 0.0 && square(y) == x
    unimplemented!()
@}
@end example

@noindent
이것은 질문을 회피할 뿐이다.

함수와 프로시저의 대조는 사물의 속성을 기술하는 것과 사물을 어떻게 하는지를 기술하는 것 사이의 일반적인 구별, 또는 때때로 언급되듯이 선언적 지식(declarative knowledge)과 명령적 지식(imperative knowledge) 사이의 구별을 반영한다.
수학에서 우리는 대개 선언적(무엇인가) 설명에 관심을 갖는 반면, 컴퓨터 과학에서 우리는 대개 명령적(어떻게 하는가) 설명에 관심을 갖는다.@footnote{선언적 설명과 명령적 설명은 수학과 컴퓨터 과학이 그렇듯이 밀접하게 관련되어 있다. 예를 들어, 프로그램이 생성한 답이 ``정확하다''고 말하는 것은 프로그램에 대한 선언적 진술을 하는 것이다. 프로그램이 정확하다는 것을 증명하기 위한 기술을 확립하려는 많은 연구가 있으며, 이 주제의 기술적 어려움 중 상당 부분은 명령적 진술(프로그램이 구성되는)과 선언적 진술(무언가를 추론하는 데 사용될 수 있는) 사이의 전환을 협상하는 것과 관련이 있다. 관련된 맥락에서, 프로그래밍 언어 설계의 중요한 현재 영역은 소위 초고수준 언어(very high-level languages)의 탐구인데, 여기서는 실제로 선언적 진술을 사용하여 프로그래밍한다. 아이디어는 인터프리터를 충분히 정교하게 만들어서, 프로그래머가 지정한 ``무엇인가''에 대한 지식이 주어지면 ``어떻게 하는가''에 대한 지식을 자동으로 생성할 수 있게 하는 것이다. 이것은 일반적으로 수행될 수 없지만, 진전이 이루어진 중요한 영역들이 있다. 우리는 @ref{Chapter 4}에서 이 아이디어를 다시 방문할 것이다.}

제곱근은 어떻게 계산하는가?
가장 일반적인 방법은 뉴턴의 연속 근사법(method of successive approximations)을 사용하는 것이다. 이 방법은 숫자 @math{x}의 제곱근 값에 대한 추측값 @math{y}가 있을 때마다, @math{y}와 @math{{x / y}}의 평균을 구함으로써 더 나은 추측값(실제 제곱근에 더 가까운 값)을 얻기 위해 간단한 조작을 수행할 수 있다고 말한다.@footnote{이 제곱근 알고리즘은 사실 방정식의 근을 찾는 일반적인 기술인 뉴턴 방법(Newton's method)의 특수한 경우이다. 제곱근 알고리즘 자체는 서기 1세기에 알렉산드리아의 헤론(Heron of Alexandria)에 의해 개발되었다. 우리는 @ref{1.3.4}에서 일반적인 뉴턴 방법을 Rust 프로시저로 표현하는 방법을 보게 될 것이다.}
예를 들어, 우리는 다음과 같이 2의 제곱근을 계산할 수 있다.
초기 추측값이 1이라고 가정하자:

@example
Guess     Quotient      Average

1         (2/1)  = 2    ((2 + 1)/2)  = 1.5

1.5       (2/1.5)       ((1.3333 + 1.5)/2)
            = 1.3333      = 1.4167

1.4167    (2/1.4167)    ((1.4167 + 1.4118)/2) 
            = 1.4118      = 1.4142  

1.4142    ...           ...
@end example

@noindent
이 과정을 계속하면, 우리는 제곱근에 대한 점점 더 나은 근사값을 얻는다.

이제 프로시저 관점에서 이 프로세스를 공식화해 보자.
우리는 피제곱근수(radicand, 제곱근을 구하려는 숫자)에 대한 값과 추측값에 대한 값으로 시작한다.
만약 추측값이 우리의 목적에 충분히 좋다면, 완료된 것이다. 그렇지 않다면, 개선된 추측값으로 프로세스를 반복해야 한다.
우리는 이 기본 전략을 프로시저로 작성한다:

@example
fn sqrt_iter(guess: f64, x: f64) -> f64 @{
    if good_enough(guess, x) @{
        guess
    @} else @{
        sqrt_iter(improve(guess, x), x)
    @}
@}
@end example

@noindent
추측값은 피제곱근수와 이전 추측값의 몫과의 평균을 구함으로써 개선된다:

@example
fn improve(guess: f64, x: f64) -> f64 @{
    average(guess, x / guess)
@}
@end example

@noindent
여기서

@example
fn average(x: f64, y: f64) -> f64 @{
    (x + y) / 2.0
@}
@end example

@noindent
우리는 또한 ``충분히 좋다(good enough)''는 것이 무엇을 의미하는지 말해야 한다.
다음은 예시를 위해서는 충분하겠지만, 실제로는 그다지 좋은 테스트가 아니다. (@ref{Exercise 1.7}을 참조하라.)
아이디어는 답의 제곱이 피제곱근수와 미리 정해진 허용 오차(여기서는 0.001)보다 적게 차이 날 때까지 답을 개선하는 것이다:@footnote{Lisp에서는 술어에 물음표로 끝나는 이름(예: @code{good_enough?})을 붙이는 것이 일반적이다. Rust에서는 @code{is_}와 같은 동사 접두사를 사용하거나 불리언 반환 값을 암시하는 서술적인 이름을 사용하는 것이 관례이다. 물음표는 Rust 식별자에서 허용되지 않는다. 그것들은 @code{?} 연산자를 위해 예약되어 있다.}

@example
fn good_enough(guess: f64, x: f64) -> bool @{
    (guess.powi(2) - x).abs() < 0.001
@}
@end example

@noindent
마지막으로, 시작할 방법이 필요하다.
예를 들어, 우리는 항상 어떤 숫자의 제곱근도 1.0이라고 추측할 수 있다:@footnote{우리의 초기 추측값을 1이 아닌 1.0으로 표현했다는 점을 관찰하라. Rust에서 이 구별은 중요하다. 왜냐하면 @code{1}은 정수(@code{i32})이고 @code{1.0}은 부동 소수점 숫자(@code{f64})이기 때문이다. Rust는 정수와 실수 사이의 암시적 형 변환(coercion)을 지원하지 않는다. 만약 우리가 @code{1}을 사용했다면, @code{f64}를 기대하는 함수에서 그것을 사용하려고 할 때 컴파일 오류가 발생했을 것이다. Scheme에서 이 구별은 종종 정확한 유리수 산술 대 부정확한 소수 산술로 이어졌다.}

@example
fn sqrt(x: f64) -> f64 @{
    sqrt_iter(1.0, x)
@}
@end example

@noindent
이 정의들을 인터프리터에 입력하면, 우리는 다른 어떤 프로시저를 사용하는 것과 마찬가지로 @code{sqrt}를 사용할 수 있다:

@example
sqrt(9.0)
// => 3.00009155413138

sqrt(100.0 + 37.0)
// => 11.704699917758145

sqrt(sqrt(2.0) + sqrt(3.0))
// => 1.7739279023207892

square(sqrt(1000.0))
// => 1000.000369924366
@end example

@noindent
@code{sqrt} 프로그램은 또한 우리가 지금까지 소개한 간단한 절차적 언어가 C나 Pascal 같은 언어로 작성할 수 있는 순수 수치 프로그램을 작성하기에 충분하다는 것을 보여준다.
우리가 컴퓨터에게 무언가를 반복해서 하도록 지시하는 어떤 반복(루프) 구조도 언어에 포함시키지 않았기 때문에 이것은 놀라워 보일 수 있다.
반면에 @code{Sqrt-iter}는 프로시저를 호출하는 일반적인 능력 외에 다른 특별한 구조를 사용하지 않고도 반복이 어떻게 달성될 수 있는지를 보여준다.@footnote{반복을 구현하기 위해 프로시저 호출을 사용하는 것과 관련된 효율성 문제를 걱정하는 독자들은 @ref{1.2.1}의 ``꼬리 재귀(tail recursion)''에 대한 언급을 주목해야 한다.}

@quotation
@strong{@anchor{Exercise 1.6}Exercise 1.6:} Alyssa P. Hacker는 왜 @code{if}가 특수 형태로 제공되어야 하는지 이해하지 못한다.
그녀는 ``그냥 @code{cond}를 사용해서 일반 프로시저로 정의하면 안 되나요?''라고 묻는다.
Alyssa의 친구 Eva Lu Ator는 이것이 실제로 가능하다고 주장하며, @code{if}의 새로운 버전을 정의한다:

@example
fn new_if(predicate: bool, then_clause: f64, else_clause: f64) -> f64 @{
    if predicate @{
        then_clause
    @} else @{
        else_clause
    @}
@}
@end example

Eva는 Alyssa를 위해 프로그램을 시연한다:

@example
new_if(2 == 3, 0.0, 5.0)
// => 5.0

new_if(1 == 1, 0.0, 5.0)
// => 0.0
@end example

Delighted, Alyssa uses @code{new_if} to rewrite the square-root program:

@example
fn sqrt_iter(guess: f64, x: f64) -> f64 @{
    new_if(good_enough(guess, x),
           guess,
           sqrt_iter(improve(guess, x), x))
@}
@end example

Alyssa가 이것을 사용하여 제곱근을 계산하려고 시도하면 어떤 일이 발생하는가?
설명하라.
@end quotation

@quotation
@strong{@anchor{Exercise 1.7}Exercise 1.7:} 제곱근을 계산하는 데 사용된 @code{good_enough} 테스트는 매우 작은 숫자의 제곱근을 찾는 데는 별로 효과적이지 않을 것이다.
또한, 실제 컴퓨터에서 산술 연산은 거의 항상 제한된 정밀도로 수행된다.
이것은 우리의 테스트를 매우 큰 숫자에 대해 부적절하게 만든다.
작은 숫자와 큰 숫자에 대해 테스트가 어떻게 실패하는지 보여주는 예제를 들어 이 진술들을 설명하라.
@code{good_enough}를 구현하는 대안적인 전략은 @code{guess}가 한 반복에서 다음 반복으로 어떻게 변하는지 지켜보고, 그 변화가 추측값의 매우 작은 비율일 때 멈추는 것이다.
이런 종류의 종료 테스트를 사용하는 제곱근 프로시저를 설계하라.
이것이 작은 숫자와 큰 숫자에 대해 더 잘 작동하는가?
@end quotation

@quotation
@strong{@anchor{Exercise 1.8}Exercise 1.8:} 세제곱근에 대한 뉴턴 방법은 @math{y}가 @math{x}의 세제곱근에 대한 근사값이라면 더 나은 근사값은 다음 값으로 주어진다는 사실에 기초한다.
@ifinfo

@example
x/y^2 + 2y
----------
    3
@end example

@end ifinfo
@tex

\[ % :4:
 
{\frac{{x / y^2} + 2y}{3}.}
\]

@end tex
@noindent
이 공식을 사용하여 제곱근 프로시저와 유사한 세제곱근 프로시저를 구현하라.
(@ref{1.3.4}에서 우리는 이 제곱근 및 세제곱근 프로시저의 추상화로서 뉴턴 방법을 일반적으로 구현하는 방법을 보게 될 것이다.)
@end quotation

@node	1.1.8, 1.2, Chapter 1, 1.1
@subsection 블랙박스 추상화로서의 프로시저 (Procedures as Black-Box Abstractions)

@code{Sqrt}는 상호 정의된 프로시저들의 집합에 의해 정의된 프로세스의 첫 번째 예제이다.
@code{sqrt_iter} 정의가 @newterm{재귀적(recursive)}이라는 점에 주목하라. 즉, 프로시저가 자기 자신을 통해 정의된다.
프로시저를 자기 자신을 통해 정의할 수 있다는 아이디어는 혼란스러울 수 있다. 그러한 ``순환적'' 정의가 어떻게 말이 되는지, 하물며 컴퓨터가 수행할 잘 정의된 프로세스를 어떻게 명시할 수 있는지는 불분명해 보일 수 있다.
이 문제는 @ref{1.2}에서 더 주의 깊게 다루어질 것이다.
하지만 먼저 @code{sqrt} 예제에서 보여주는 몇 가지 다른 중요한 점들을 고려해 보자.

제곱근을 계산하는 문제는 자연스럽게 여러 하위 문제들로 나뉜다는 것을 관찰하라: 추측값이 충분히 좋은지 구별하는 방법, 추측값을 개선하는 방법 등.
이 작업들 각각은 별도의 프로시저에 의해 수행된다.
전체 @code{sqrt} 프로그램은 문제를 하위 문제로 분해한 것을 반영하는 프로시저들의 클러스터(@ref{Figure 1.2}에 표시됨)로 볼 수 있다.

@float
@anchor{Figure 1.2}
@ifinfo
@strong{Figure 1.2:} Procedural decomposition of the @code{sqrt} program.

@example
                 sqrt
                  |
              sqrt-iter
              /       \
        good-enough   improve
        /         \         \
   square         abs       average
@end example
@end ifinfo
@iftex
@image{fig/chap1/Fig1.2,,38mm,,.std.svg}
@caption{@strong{Figure 1.2:} @code{sqrt} 프로그램의 절차적 분해.}
@end iftex
@end float

@noindent
이 분해 전략의 중요성은 단순히 프로그램을 부분으로 나누는 것에 있지 않다.
결국, 우리는 어떤 큰 프로그램이라도 부분들로 나눌 수 있다---처음 10줄, 다음 10줄, 그다음 10줄, 등등으로.
오히려, 각 프로시저가 다른 프로시저를 정의할 때 모듈로서 사용될 수 있는 식별 가능한 작업을 수행하는 것이 중요하다.
예를 들어, 우리가 @code{square}를 사용하여 @code{good_enough} 프로시저를 정의할 때, 우리는 @code{square} 프로시저를 ``블랙박스''로 간주할 수 있다.
우리는 그 순간 프로시저가 결과를 @emph{어떻게} 계산하는지에는 관심이 없고, 그것이 제곱을 계산한다는 @emph{사실}에만 관심이 있다.
제곱이 계산되는 방법에 대한 세부 사항은 억제(suppressed)될 수 있으며, 나중에 고려될 수 있다.
실제로, @code{good_enough} 프로시저에 관한 한, @code{square}는 프로시저라기보다는 오히려 프로시저의 추상화, 소위 @newterm{절차적 추상화(procedural abstraction)}이다.
이 추상화 수준에서는 제곱을 계산하는 어떤 프로시저라도 똑같이 훌륭하다.

따라서 반환하는 값만 고려할 때, 숫자를 제곱하는 다음 두 프로시저는 구별할 수 없어야 한다.
각각은 숫자 인자를 받아 그 숫자의 제곱을 값으로 생성한다.@footnote{이 프로시저들 중 어느 것이 더 효율적인 구현인지조차 명확하지 않다. 이것은 사용 가능한 하드웨어에 따라 다르다. ``명백한'' 구현이 덜 효율적인 기계들도 있다. 로그와 역로그의 광범위한 테이블이 매우 효율적인 방식으로 저장된 기계를 고려해 보라.}

@example
fn square(x: f64) -> f64 @{ x * x @}

fn square(x: f64) -> f64 @{
    (x.ln() * 2.0).exp()
@}

fn double(x: f64) -> f64 @{ x + x @}
@end example

@noindent
따라서 프로시저 정의는 세부 사항을 억제할 수 있어야 한다.
프로시저의 사용자는 프로시저를 직접 작성하지 않았을 수도 있고, 다른 프로그래머로부터 블랙박스로서 얻었을 수도 있다.
사용자는 프로시저를 사용하기 위해 그것이 어떻게 구현되었는지 알 필요가 없어야 한다.

@subsubheading Local names

프로시저의 사용자에게 중요하지 않아야 할 프로시저 구현의 세부 사항 중 하나는 구현자가 프로시저의 형식 매개변수에 대해 선택한 이름이다.
따라서 다음 프로시저들은 구별할 수 없어야 한다:

@example
fn square(x: i64) -> i64 @{
    x * x
@}

fn square(y: i64) -> i64 @{
    y * y
@}
@end example

@noindent
프로시저의 의미가 작성자가 사용한 매개변수 이름과 독립적이어야 한다는 이 원칙은 표면적으로는 자명해 보이지만, 그 결과는 심오하다.
가장 간단한 결과는 프로시저의 매개변수 이름이 프로시저 본문에 국한(local)되어야 한다는 것이다.
예를 들어, 우리는 제곱근 프로시저의 @code{good_enough} 정의에서 @code{square}를 사용했다:

@example
fn good_enough(guess: f64, x: f64) -> bool @{
    (guess.powi(2) - x).abs() < 0.001
@}
@end example

@noindent
@code{good_enough} 작성자의 의도는 첫 번째 인자의 제곱이 두 번째 인자의 주어진 허용 오차 내에 있는지 결정하는 것이다.
우리는 @code{good_enough}의 작성자가 첫 번째 인자를 가리키기 위해 @code{guess}라는 이름을, 두 번째 인자를 가리키기 위해 @code{x}라는 이름을 사용했음을 본다.
@code{square}의 인자는 @code{guess}이다.
만약 @code{square}의 작성자가 그 인자를 가리키기 위해 (위에서처럼) @code{x}를 사용했다면, @code{good_enough}의 @code{x}는 @code{square}의 @code{x}와 다른 @code{x}여야 함을 알 수 있다.
@code{square} 프로시저를 실행하는 것은 @code{good_enough}가 사용하는 @code{x}의 값에 영향을 미쳐서는 안 된다. 왜냐하면 @code{good_enough}는 @code{square}가 계산을 마친 후에도 @code{x}의 값을 필요로 할 수 있기 때문이다.

만약 매개변수들이 각 프로시저의 본문에 국한되지 않는다면, @code{square}의 매개변수 @code{x}는 @code{good_enough}의 매개변수 @code{x}와 혼동될 수 있고, @code{good_enough}의 동작은 우리가 어떤 버전의 @code{square}를 사용하느냐에 따라 달라질 것이다.
따라서 @code{square}는 우리가 원했던 블랙박스가 아닐 것이다.

프로시저의 형식 매개변수는 프로시저 정의에서 매우 특별한 역할을 한다. 즉, 형식 매개변수가 어떤 이름을 갖는지는 중요하지 않다.
그러한 이름을 @newterm{바인딩된 변수(bound variable)}라고 하며, 우리는 프로시저 정의가 그 형식 매개변수를 @newterm{바인딩(binds)}한다고 말한다.
바인딩된 변수가 정의 전체에서 일관되게 이름이 변경된다면 프로시저 정의의 의미는 변하지 않는다.@footnote{일관된 이름 변경(consistent renaming)의 개념은 사실 미묘하고 공식적으로 정의하기 어렵다. 유명한 논리학자들도 여기서 당황스러운 실수를 저질렀다.}
변수가 바인딩되지 않았다면, 우리는 그것이 @newterm{자유(free)}라고 말한다.
바인딩이 이름을 정의하는 표현식의 집합을 그 이름의 @newterm{스코프(scope, 유효 범위)}라고 부른다.
프로시저 정의에서, 프로시저의 형식 매개변수로 선언된 바인딩된 변수들은 프로시저의 본문을 자신의 스코프로 갖는다.

위의 @code{good_enough} 정의에서, @code{guess}와 @code{x}는 바인딩된 변수이지만 @code{<}, @code{-}, @code{abs}, 그리고 @code{square}는 자유 변수이다.
@code{good_enough}의 의미는 우리가 @code{guess}와 @code{x}에 대해 선택한 이름이 서로 구별되고 @code{<}, @code{-}, @code{abs}, 그리고 @code{square}와 다르기만 하다면, 그 이름들과 독립적이어야 한다.
(만약 우리가 @code{guess}를 @code{abs}로 이름을 바꾼다면 변수 @code{abs}를 @newterm{포획(capturing)}함으로써 버그를 도입하게 될 것이다.
그것은 자유 변수에서 바인딩된 변수로 바뀌었을 것이다.)
하지만 @code{good_enough}의 의미는 자유 변수의 이름과 독립적이지 않다.
그것은 확실히 기호 @code{abs}가 숫자의 절댓값을 계산하는 프로시저의 이름이라는 (이 정의 외부의) 사실에 의존한다.
만약 우리가 정의에서 @code{abs} 대신 @code{cos}를 치환한다면 @code{Good-enough?}는 다른 함수를 계산할 것이다.

@subsubheading Internal definitions and block structure

우리는 지금까지 한 가지 종류의 이름 격리(name isolation)를 사용할 수 있었다: 프로시저의 형식 매개변수는 프로시저의 본문에 국한된다.
제곱근 프로그램은 우리가 이름 사용을 제어하고 싶은 또 다른 방법을 보여준다.
기존 프로그램은 별도의 프로시저들로 구성되어 있다:

@example
fn sqrt(x: f64) -> f64 @{
    sqrt_iter(1.0, x)
@}

fn sqrt_iter(guess: f64, x: f64) -> f64 @{
    if good_enough(guess, x) @{
        guess
    @} else @{
        sqrt_iter(improve(guess, x), x)
    @}
@}

fn good_enough(guess: f64, x: f64) -> bool @{
    (guess.powi(2) - x).abs() < 0.001
@}

fn improve(guess: f64, x: f64) -> f64 @{
    average(guess, x / guess)
@}
@end example

@noindent
이 프로그램의 문제는 @code{sqrt} 사용자에게 중요한 유일한 프로시저는 @code{sqrt}라는 것이다.
다른 프로시저들(@code{sqrt-iter}, @code{good_enough}, 그리고 @code{improve})은 그들의 마음을 어지럽힐 뿐이다.
그들은 제곱근 프로그램과 함께 작동하는 다른 프로그램의 일부로 @code{good_enough}라고 불리는 다른 어떤 프로시저도 정의할 수 없을지 모른다. 왜냐하면 @code{sqrt}가 그것을 필요로 하기 때문이다.
이 문제는 많은 별도의 프로그래머들이 대규모 시스템을 구축할 때 특히 심각하다.
예를 들어, 수치 프로시저의 대규모 라이브러리를 구축할 때, 많은 수치 함수들이 연속 근사법으로 계산되므로 보조 프로시저로 @code{good_enough}와 @code{improve}라는 이름의 프로시저를 가질 수 있다.
우리는 하위 프로시저들을 국한시켜서 @code{sqrt} 내부에 숨기고, @code{sqrt}가 각각 자신만의 비공개 @code{good_enough} 프로시저를 가진 다른 연속 근사법들과 공존할 수 있게 하고 싶다.
이것을 가능하게 하기 위해, 우리는 프로시저가 그 프로시저에 국한된 내부 정의를 가질 수 있도록 허용한다.
예를 들어, 제곱근 문제에서 우리는 다음과 같이 쓸 수 있다:

@example
fn sqrt(x: f64) -> f64 @{
    fn good_enough(guess: f64, x: f64) -> bool @{
        (guess.powi(2) - x).abs() < 0.001
    @}
    fn improve(guess: f64, x: f64) -> f64 @{
        average(guess, x / guess)
    @}
    fn sqrt_iter(guess: f64, x: f64) -> f64 @{
        if good_enough(guess, x) @{
            guess
        @} else @{
            sqrt_iter(improve(guess, x), x)
        @}
    @}
    sqrt_iter(1.0, x)
@}
@end example

@noindent
@newterm{블록 구조(block structure)}라고 불리는 이러한 정의의 중첩은 기본적으로 가장 간단한 이름 패키징 문제에 대한 올바른 해결책이다.
하지만 여기에 더 좋은 아이디어가 숨어 있다.
보조 프로시저의 정의를 내면화하는 것 외에도, 우리는 그것들을 단순화할 수 있다.
@code{x}는 @code{sqrt}의 정의에서 바인딩되어 있으므로, @code{sqrt} 내부에서 정의된 프로시저 @code{good_enough}, @code{improve}, 그리고 @code{sqrt_iter}는 @code{x}의 스코프 안에 있다.
따라서 @code{x}를 이 프로시저들 각각에 명시적으로 전달할 필요가 없다.
대신, 아래에 보이는 것처럼 우리는 @code{x}가 내부 정의에서 자유 변수가 되도록 허용한다.
그러면 @code{x}는 감싸고 있는 프로시저 @code{sqrt}가 호출될 때의 인자로부터 값을 얻는다.
이 규율을 @newterm{어휘적 스코핑(lexical scoping)}이라고 부른다.@footnote{어휘적 스코핑은 프로시저 내의 자유 변수가 감싸고 있는 프로시저 정의에 의해 만들어진 바인딩을 참조하도록 규정한다. 즉, 그것들은 프로시저가 정의된 환경에서 조회된다. 우리는 @ref{Chapter 3}에서 이것이 인터프리터를 구현하는 방법에 큰 영향을 미친다는 것을 보게 될 것이다.}

@example
fn sqrt(x: f64) -> f64 @{
    let good_enough = |guess: f64| @{
        (guess.powi(2) - x).abs() < 0.001
    @};
    let improve = |guess: f64| @{
        (guess + x / guess) / 2.0
    @};
    let mut guess = 1.0;
    while !good_enough(guess) @{
        guess = improve(guess);
    @}
    guess
@}
@end example

@noindent
우리는 대규모 프로그램을 다루기 쉬운 조각들로 나누는 것을 돕기 위해 블록 구조를 광범위하게 사용할 것이다.@footnote{임베디드 정의(Embedded definitions)는 프로시저 본문에서 가장 먼저 나와야 한다. 정의와 사용을 뒤섞는 프로그램을 실행한 결과에 대해서는 경영진이 책임지지 않는다.}
블록 구조의 아이디어는 프로그래밍 언어 Algol 60에서 유래했다.
그것은 대부분의 고급 프로그래밍 언어에 나타나며 대규모 프로그램의 구축을 조직하는 데 도움을 주는 중요한 도구이다.

@node   1.2, 1.3, 1.1, Chapter 1

@section 프로시저와 그들이 생성하는 프로세스 (Procedures and the Processes They Generate)



우리는 이제 프로그래밍의 요소들을 고려했다: 원시 산술 연산들을 사용했고, 이 연산들을 결합했으며, 이 복합 연산들을 복합 프로시저로 정의함으로써 추상화했다.

하지만 그것만으로는 우리가 프로그래밍하는 법을 안다고 말하기에 충분하지 않다.

우리의 상황은 체스에서 말들이 어떻게 움직이는지에 대한 규칙은 배웠지만 전형적인 오프닝, 전술, 또는 전략에 대해서는 아무것도 모르는 사람의 상황과 비슷하다.

초보 체스 선수처럼, 우리는 아직 그 도메인에서의 일반적인 사용 패턴을 모른다.

우리는 어떤 수가 둘 만한 가치가 있는지(어떤 프로시저가 정의할 가치가 있는지)에 대한 지식이 부족하다.

우리는 수를 두는 것(프로시저를 실행하는 것)의 결과를 예측할 경험이 부족하다.



고려 중인 행동의 결과를 시각화하는 능력은 전문가 프로그래머가 되는 데 결정적이며, 이는 어떤 합성적이고 창조적인 활동에서든 마찬가지이다.

예를 들어, 전문 사진작가가 되려면 장면을 보고 노출 및 현상 조건의 각 가능한 선택에 대해 인화지에서 각 영역이 얼마나 어둡게 나타날지 알아야 한다.

그래야만 역으로 추론하여 원하는 효과를 얻기 위해 프레이밍, 조명, 노출, 그리고 현상을 계획할 수 있다.

프로그래밍에서도 마찬가지이다. 우리는 프로세스가 취할 행동 과정을 계획하고 프로그램에 의해 프로세스를 제어한다.

전문가가 되기 위해, 우리는 다양한 종류의 프로시저에 의해 생성되는 프로세스를 시각화하는 법을 배워야 한다.

우리가 그러한 기술을 개발한 후에야 원하는 동작을 보이는 프로그램을 안정적으로 구축하는 법을 배울 수 있다.



프로시저는 계산 프로세스의 @newterm{지역적 진화(local evolution)}를 위한 패턴이다.

그것은 프로세스의 각 단계가 이전 단계 위에 어떻게 구축되는지 명시한다.

우리는 지역적 진화가 프로시저에 의해 명시된 프로세스의 전반적인, 또는 @newterm{전역적(global)} 행동에 대해 진술할 수 있기를 원한다.

이것은 일반적으로 매우 어려운 일이지만, 우리는 적어도 프로세스 진화의 몇 가지 전형적인 패턴을 기술하려고 시도할 수 있다.



이 절에서 우리는 간단한 프로시저에 의해 생성되는 프로세스의 몇 가지 일반적인 ``모양''을 조사할 것이다.

우리는 또한 이러한 프로세스들이 시간과 공간이라는 중요한 계산 자원을 소비하는 속도를 조사할 것이다.

우리가 고려할 프로시저들은 매우 간단하다.

그것들의 역할은 사진학에서 테스트 패턴이 하는 역할과 같다: 그 자체로 실용적인 예제라기보다는 지나치게 단순화된 원형적 패턴으로서의 역할이다.



@menu

* 1.2.1::            Linear Recursion and Iteration

* 1.2.2::            Tree Recursion

* 1.2.3::            Orders of Growth

* 1.2.4::            Exponentiation

* 1.2.4a::           Const Evaluation and Compile-Time Computation

* 1.2.5::            Greatest Common Divisors

* 1.2.6::            Example: Testing for Primality

@end menu

@node   1.2.1, 1.2.2, 1.2, 1.2

@subsection 선형 재귀와 반복 (Linear Recursion and Iteration)



우리는 팩토리얼 함수를 고려하는 것으로 시작한다. 다음과 같이 정의된다:

@ifinfo



@example

n! = n * (n - 1) * (n - 2) ... 3 * 2 * 1

@end example



@end ifinfo

@tex



\[ % :5:

 

n! \,=\, {n \cdot (n - 1)} \cdot {(n - 2)} \cdots {3 \cdot 2 \cdot 1.}

\]



@end tex

팩토리얼을 계산하는 데에는 많은 방법이 있다.

한 가지 방법은 어떤 양의 정수 @math{n}에 대해서도 @math{{n!}}이 @math{n} 곱하기 @math{{(n - 1)!}}과 같다는 관찰을 이용하는 것이다:

@ifinfo



@example

n! = n * [(n - 1) * (n - 2) ... 3 * 2 * 1] = n * (n - 1)!

@end example



@end ifinfo

@tex



\[ % :6:

 

n! \,=\, {n \cdot [(n - 1)} \cdot {(n - 2)} \cdots {3 \cdot 2 \cdot 1]} \,=\, {n \cdot (n - 1)!.}
\]

@end tex
따라서, 우리는 @math{{(n - 1)!}}을 계산하고 그 결과에 @math{n}을 곱함으로써 @math{{n!}}을 계산할 수 있다.
만약 우리가 1!이 1과 같다는 규정을 추가한다면, 이 관찰은 프로시저로 바로 번역된다:

@example
fn factorial(n: u64) -> u64 @{
    if n == 1 @{
        1
    @} else @{
        n * factorial(n - 1)
    @}
@}
@end example

@noindent
우리는 @ref{1.1.5}의 치환 모델을 사용하여 @code{6!}을 계산할 때 이 프로시저가 어떻게 동작하는지 볼 수 있다. (@ref{Figure 1.3}을 보라.)

@float
@anchor{Figure 1.3}
@ifinfo
@quotation
@strong{Figure 1.3:} @math{6!}을 계산하기 위한 선형 재귀적 프로세스.

@example
(factorial 6)        ----------------
(* 6 (factorial 5))                   \
(* 6 (* 5 (factorial 4)))               \
(* 6 (* 5 (* 4 (factorial 3))))           \
(* 6 (* 5 (* 4 (* 3 (factorial 2)))))       \
(* 6 (* 5 (* 4 (* 3 (* 2 (factorial 1))))))  |
(* 6 (* 5 (* 4 (* 3 (* 2 1)))))             /
(* 6 (* 5 (* 4 (* 3 2))))                 /
(* 6 (* 5 (* 4 6)))                     /
(* 6 (* 5 24))                        /
(* 6 120)                           /
720          <---------------------
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap1/Fig1.3d,139mm,,,.std.svg}
@caption{@strong{Figure 1.3:} @math{6!}을 계산하기 위한 선형 재귀적 프로세스.}
@end iftex
@end float

@noindent
이제 팩토리얼을 계산하는 두 번째 관점을 취해보자.
우리는 @math{n!}을 1부터 시작하여 @math{n}까지의 정수를 차례로 곱한 것으로 설명할 수 있다.
일반적으로, 우리는 현재 곱한 값 @math{product}와 1부터 @math{n}까지 세는 @math{counter}를 유지하면서 곱셈을 해 나갈 수 있다.
우리는 @math{counter}와 @math{product}가 한 단계에서 다음 단계로 변하는 규칙을 다음과 같이 기술할 수 있다:

@example
product ← counter * product
counter ← counter + 1
@end example

@noindent
그리고 @math{n!}은 @math{counter}가 @math{n}을 초과할 때의 @math{product}의 값임을 규정한다.

우리는 이 프로세스를 다음과 같이 프로시저로 재구성할 수 있다:@footnote{실제 프로그램에서 우리는 아마도 @ref{1.1.8}에서 소개한 블록 구조를 사용하여 @code{fact_iter}의 정의를 숨길 것이다:



@example

fn factorial(n: u64) -> u64 @{

    fn iter(product: u64, counter: u64, max_count: u64) -> u64 @{

        if counter > max_count @{

            product

        @} else @{

            iter(counter * product, counter + 1, max_count)

        @}

    @}

    iter(1, 1, n)

@}

@end example



우리는 한 번에 생각해야 할 것들의 수를 최소화하기 위해 여기서는 이렇게 하지 않았다.}

@example
fn factorial(n: u64) -> u64 @{
    fact_iter(1, 1, n)
@}

fn fact_iter(product: u64, counter: u64, max_count: u64) -> u64 @{
    if counter > max_count @{
        product
    @} else @{
        fact_iter(counter * product, counter + 1, max_count)
    @}
@}
@end example

@noindent
이전과 마찬가지로 치환 모델을 사용하여 @code{6!}을 계산하는 과정을 시각화할 수 있다. (@ref{Figure 1.4}를 보라.)

@float
@anchor{Figure 1.4}
@ifinfo
@quotation
@strong{Figure 1.4:} @math{6!}을 계산하기 위한 선형 반복적 프로세스.

@example
factorial(6)        -----.
fact_iter(1, 1, 6)       |
fact_iter(1, 2, 6)       |
fact_iter(2, 3, 6)       |
fact_iter(6, 4, 6)       |
fact_iter(24, 5, 6)      |
fact_iter(120, 6, 6)     |
fact_iter(720, 7, 6)     V
720
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap1/Fig1.4d,,62mm,,.std.svg}
@caption{@strong{Figure 1.4:} @math{6!}을 계산하기 위한 선형 반복적 프로세스.}
@end iftex
@end float

@noindent
두 프로세스를 비교해 보자.
한 가지 관점에서 보면, 그것들은 거의 같다. 둘 다 동일한 정의역의 동일한 수학적 함수를 계산하고, 둘 다 @math{{n!}}을 계산하기 위해 @math{n}에 비례하는 수의 단계가 필요하다.
실제로 두 프로세스는 동일한 곱셈 시퀀스를 수행하여 동일한 부분 곱 시퀀스를 얻는다.
반면에, 두 프로세스의 ``모양''을 시각화할 때 우리는 그것들이 상당히 다르게 진화한다는 것을 알 수 있다.

첫 번째 프로세스를 고려해 보자. 치환 모델은 @ref{Figure 1.3}의 화살표로 표시된 것처럼 팽창했다가 수축하는 모양을 보여준다.
팽창은 프로세스가 @newterm{지연된 연산(deferred operations)}(이 경우 지연된 곱셈)의 체인을 구축할 때 발생한다.
수축은 연산이 실제로 수행될 때 발생한다.
이러한 종류의 프로세스, 즉 지연된 연산의 체인으로 특징지어지는 프로세스를 @newterm{재귀적 프로세스(recursive process)}라고 부른다.
이 프로세스를 수행하려면 인터프리터는 나중에 수행될 연산을 추적해야 한다.
@math{{n!}}을 계산할 때 지연된 곱셈 체인의 길이는, 그리고 따라서 그것을 추적하는 데 필요한 정보의 양은 @math{n}에 비례하여(선형적으로) 증가한다.
그러한 프로세스를 @newterm{선형 재귀적 프로세스(linear recursive process)}라고 부른다.

대조적으로, 두 번째 프로세스는 팽창하고 수축하지 않는다.
어느 단계에서든, 임의의 @math{n}에 대해 프로세스의 상태를 추적하기 위해 우리가 알아야 할 것은 변수 @code{product}, @code{counter}, 그리고 @code{max_count}의 값뿐이다.
우리는 이 프로세스를 @newterm{반복적 프로세스(iterative process)}라고 부른다.
일반적으로 반복적 프로세스는 계산이 진행됨에 따라 수정되는 고정된 수의 @newterm{상태 변수(state variables)}와, 상태 변수가 한 상태에서 다음 상태로 이동할 때 업데이트되는 방법을 명시하는 고정된 규칙, 그리고 프로세스가 종료되어야 하는 조건을 명시하는 (선택적인) 종료 테스트로 상태를 요약할 수 있는 프로세스이다.
@math{{n!}}을 계산할 때 필요한 단계의 수는 @math{n}에 비례하여 증가한다.
그러한 프로세스를 @newterm{선형 반복적 프로세스(linear iterative process)}라고 부른다.

두 프로세스의 대조는 다른 관점에서도 볼 수 있다.
반복적인 경우, 어느 시점에서든 프로그램 변수는 프로세스의 상태에 대한 완전한 설명을 제공한다.
만약 우리가 단계 사이에서 계산을 멈춘다면, 계산을 재개하기 위해 필요한 것은 인터프리터에게 세 프로그램 변수의 값을 제공하는 것뿐이다.
재귀적 프로세스는 그렇지 않다.
이 경우 프로그램 변수에 포함되지 않은, 인터프리터에 의해 유지되는 ``숨겨진'' 추가 정보가 있으며, 이것은 지연된 연산의 체인을 협상하는 데 있어 ``프로세스가 어디에 있는지''를 나타낸다.
체인이 길수록 더 많은 정보가 유지되어야 한다.@footnote{@ref{Chapter 5}에서 레지스터 기계에서의 프로시저 구현을 논의할 때, 우리는 어떤 반복적 프로세스도 고정된 수의 레지스터를 갖고 보조 메모리가 없는 기계로서 ``하드웨어로'' 실현될 수 있음을 보게 될 것이다. 대조적으로, 재귀적 프로세스를 실현하려면 @newterm{스택(stack)}이라고 알려진 보조 데이터 구조를 사용하는 기계가 필요하다.}

반복과 재귀를 대조할 때, 우리는 재귀적 @newterm{프로세스(process)}의 개념과 재귀적 @newterm{프로시저(procedure)}의 개념을 혼동하지 않도록 주의해야 한다.
우리가 프로시저를 재귀적이라고 설명할 때, 우리는 프로시저 정의가 (직접적으로든 간접적으로든) 프로시저 자체를 참조한다는 문법적 사실을 언급하는 것이다.
하지만 우리가 프로세스가 예를 들어 선형 재귀적 패턴을 따른다고 설명할 때, 우리는 프로시저가 어떻게 작성되었는지에 대한 문법이 아니라 프로세스가 어떻게 진화하는지에 대해 말하는 것이다.
@code{fact_iter}와 같은 재귀적 프로시저를 반복적 프로세스를 생성하는 것으로 언급하는 것이 불편해 보일 수 있다.
그러나 그 프로세스는 정말로 반복적이다: 그 상태는 세 개의 상태 변수에 의해 완전히 포착되며, 인터프리터는 프로세스를 실행하기 위해 세 개의 변수만 추적하면 된다.

프로세스와 프로시저의 구별이 혼란스러운 한 가지 이유는 일반적인 언어들(Ada, Pascal, C, 그리고 Rust 포함)의 대부분의 구현이 원칙적으로는 반복적인 프로세스라 할지라도 재귀적 프로시저의 해석이 프로시저 호출 수에 비례하여 증가하는 메모리를 소비하도록 설계되었기 때문이다.
그 결과, 이러한 언어들은 @code{do}, @code{repeat}, @code{until}, @code{for}, 그리고 @code{while}과 같은 특수 목적의 ``반복 구조(looping constructs)''에 의존해서만 반복적 프로세스를 설명할 수 있다.
Rust에서, LLVM 컴파일러 백엔드가 경우에 따라 꼬리 호출(tail calls)을 최적화할 수 있지만, 꼬리 호출 최적화는 언어 명세에 의해 보장되지 않는다.
따라서 진정으로 상수 공간 반복 프로세스를 위해, Rust 프로그래머들은 일반적으로 재귀적 함수 호출에 의존하기보다는 @code{loop}, @code{while}, 또는 @code{for} 구조를 사용한다.
@ref{Chapter 5}에서 우리가 고려할 Scheme 구현체는 이러한 결함을 공유하지 않는다.
그것은 반복적 프로세스가 재귀적 프로시저에 의해 설명되더라도 상수 공간에서 실행할 것이다.
이러한 속성을 가진 구현을 @newterm{꼬리 재귀적(tail-recursive)}이라고 부른다.
꼬리 재귀적 구현에서는 반복이 일반적인 프로시저 호출 메커니즘을 사용하여 표현될 수 있으므로, 특별한 반복 구조는 문법적 설탕으로서만 유용하다.@footnote{꼬리 재귀는 오랫동안 컴파일러 최적화 기술로 알려져 왔다. 꼬리 재귀에 대한 일관된 의미론적 기초는 Carl @ref{Hewitt (1977)}에 의해 제공되었으며, 그는 우리가 @ref{Chapter 3}에서 논의할 계산의 ``메시지 전달'' 모델 측면에서 이를 설명했다. 이에 영감을 받아 Gerald Jay Sussman과 Guy Lewis Steele Jr.(see @ref{Steele and Sussman 1975})는 Scheme을 위한 꼬리 재귀적 인터프리터를 구축했다. Steele은 나중에 꼬리 재귀가 프로시저 호출을 컴파일하는 자연스러운 방법의 결과임을 보여주었다(@ref{Steele 1977}). Scheme에 대한 @abbr{IEEE} 표준은 Scheme 구현체가 꼬리 재귀적일 것을 요구한다.}

@quotation
@strong{@anchor{Exercise 1.9}Exercise 1.9:} 다음 두 프로시저는 각각 인자를 1만큼 증가시키는 프로시저 @code{inc}와 인자를 1만큼 감소시키는 프로시저 @code{dec}를 사용하여 두 양의 정수를 더하는 방법을 정의한다.

@example
fn add(a: u64, b: u64) -> u64 @{
    if a == 0 @{
        b
    @} else @{
        inc(add(dec(a), b))
    @}
@}

fn add(a: u64, b: u64) -> u64 @{
    if a == 0 @{
        b
    @} else @{
        add(dec(a), inc(b))
    @}
@}
@end example

치환 모델을 사용하여, @code{add(4, 5)}를 평가할 때 각 프로시저에 의해 생성되는 프로세스를 설명하라. 이 프로세스들은 반복적인가 재귀적인가?
@end quotation

@quotation
@strong{@anchor{Exercise 1.10}Exercise 1.10:} 다음 프로시저는 아커만 함수(Ackermann's function)라는 수학 함수를 계산한다.

@example
fn a(x: u64, y: u64) -> u64 @{
    if y == 0 @{
        0
    @} else if x == 0 @{
        2 * y
    @} else if y == 1 @{
        2
    @} else @{
        a(x - 1, a(x, y - 1))
    @}
@}
@end example

다음 표현식들의 값은 무엇인가?

@example
a(1, 10)
a(2, 4)
a(3, 3)
@end example

다음 프로시저들을 고려하라. 여기서 @code{a}는 위에서 정의된 프로시저이다:

@example
fn f(n: u64) -> u64 @{ a(0, n) @}
fn g(n: u64) -> u64 @{ a(1, n) @}
fn h(n: u64) -> u64 @{ a(2, n) @}
fn k(n: u64) -> u64 @{ 5 * n * n @}
@end example

양의 정수 값 @math{n}에 대해 프로시저 @code{f}, @code{g}, 그리고 @code{h}에 의해 계산되는 함수들에 대한 간결한 수학적 정의를 제시하라. 예를 들어, @code{k(n)}은 @math{{5n^2}}을 계산한다.
@end quotation

@node   1.2.2, 1.2.3, 1.2.1, 1.2

@subsection 트리 재귀 (Tree Recursion)



계산의 또 다른 일반적인 패턴은 @newterm{트리 재귀(tree recursion)}라고 불린다.

예를 들어, 피보나치 수열을 계산하는 것을 고려해 보자. 여기서 각 숫자는 앞의 두 숫자의 합이다:



@center 0, 1, 1, 2, 3, 5, 8, 13, 21, @dots{}.



@noindent

일반적으로, 피보나치 수는 다음 규칙에 의해 정의될 수 있다:

@ifinfo



@example

         /

         |  0                        if n = 0

Fib(n) = <  1                        if n = 1

         |  Fib(n - 1) + Fib(n - 2)  otherwise

         \

@end example



@end ifinfo

@tex



\[ % :7:

  

\text{Fib}(n) \; = \;

  \left\{ 

    \begin{array}{ll}            

      0 & \;\text{if} \;\; n = 0, \\

      1 & \;\text{if} \;\; n = 1, \\

      \text{Fib}(n-1) + \text{Fib}(n-2) & \;\text{otherwise}. 

    \end{array} 

  \right. 

\]



@end tex

우리는 이 정의를 피보나치 수를 계산하기 위한 재귀적 프로시저로 즉시 번역할 수 있다:



@example

fn fib(n: u64) -> u64 @{

    if n == 0 @{

        0

    @} else if n == 1 @{

        1

    @} else @{

        fib(n - 1) + fib(n - 2)

    @}

@}

@end example



@noindent

이 계산의 패턴을 고려해 보자. @code{fib(5)}를 계산하기 위해, 우리는 @code{fib(4)}와 @code{fib(3)}을 계산한다.

@code{fib(4)}를 계산하기 위해, 우리는 @code{fib(3)}과 @code{fib(2)}를 계산한다.

일반적으로, 진화된 프로세스는 @ref{Figure 1.5}에 보이는 것처럼 트리 모양을 한다.

각 레벨에서(맨 아래를 제외하고) 가지가 두 갈래로 갈라지는 것에 주목하라; 이것은 @code{fib} 프로시저가 호출될 때마다 자기 자신을 두 번 호출한다는 사실을 반영한다.



@float

@anchor{Figure 1.5}

@ifinfo

@strong{Figure 1.5:} @code{fib(5)}를 계산할 때 생성된 트리 재귀적 프로세스.



@example



                   ..<............ fib5   <.......... 

                ...     ___________/  \___________   .  

             ...       /       . .....            \    . 

           ..       fib4     .        . . . .     fib3  .  

         ..     ____/. \____  ..             .  __/  \__  .  

       ..      /  . .  ..   \    .        ..   /  . .   \   . 

     ..     fib3 .       .  fib2 .        . fib2 .   .  fib1 .

   ..      / . \  .     .   /  \  .      .  /  \ ...  .  |  .

 ..       / . . \   .  .   /  . \   .  .   / .  \   .  . 1 .

.      fib2 . . fib1.  .fib1 .  fib0 . .fib1. . fib0 .  .  .

.      /  \  . . |  .  . |  .  . |   . . |   . . |   .   .>

V     /  . \   . 1  .  . 1  .  . 0  .  . 1  .  . 0  ..

.  fib1 .. fib0..  .   .   .   .   .   V   .   ..  . 

.   |  .  . |  . .>     .>.     . .    ..>.      .>

.   1 .   . 0  .      

 .   .     .  .       

  .>.       ..        



@end example

@end ifinfo

@iftex

@image{fig/chap1/Fig1.5d,147mm,,,.std.svg}

@caption{@strong{Figure 1.5:} @code{fib(5)}를 계산할 때 생성된 트리 재귀적 프로세스.}
@end iftex
@end float

@noindent
이 프로시저는 전형적인 트리 재귀로서 교육적이지만, 너무 많은 중복 계산을 수행하기 때문에 피보나치 수를 계산하는 방법으로는 끔찍하다.
@ref{Figure 1.5}에서 @code{fib(3)} 전체 계산---거의 절반의 작업---이 중복되는 것에 주목하라.
사실, 이 프로시저가 @code{fib(1)} 또는 @code{fib(0)}을 계산하는 횟수(일반적으로 위 트리의 잎 노드 수)가 정확히 @math{{\text{Fib}(n+1)}}임을 보이기란 어렵지 않다.
이것이 얼마나 나쁜지 감을 잡기 위해, @math{{\text{Fib}(n)}}의 값이 @math{n}에 따라 기하급수적으로 증가함을 보일 수 있다.
더 정확하게는(@ref{Exercise 1.13} 참조), @math{{\text{Fib}(n)}}은 @math{{\varphi^n / \sqrt{5}}}에 가장 가까운 정수이다. 여기서
@ifinfo

@example
[phi] = (1 + [sqrt]5)/2 ~= 1.6180
@end example

@end ifinfo
@tex

\[ % :8:

\varphi \,=\, \frac{1 + \sqrt{5}}{2} \,\approx\, 1.6180
\]

@end tex
@noindent
는 @newterm{황금비(golden ratio)}이며, 다음 방정식을 만족한다.
@ifinfo

@example
[phi]^2 = [phi] + 1
@end example

@end ifinfo
@tex

\[ % :9:
 
\varphi^2 \,=\, {\varphi + 1.}
\]

@end tex
따라서 이 프로세스는 입력에 따라 기하급수적으로 증가하는 수의 단계를 사용한다.
반면에 필요한 공간은 입력에 따라 선형적으로만 증가하는데, 이는 계산의 어느 시점에서든 트리의 우리 위에 어떤 노드들이 있는지만 추적하면 되기 때문이다.
일반적으로, 트리 재귀적 프로세스에 필요한 단계의 수는 트리의 노드 수에 비례하는 반면, 필요한 공간은 트리의 최대 깊이에 비례한다.

우리는 또한 피보나치 수를 계산하기 위한 반복적 프로세스를 공식화할 수 있다.
아이디어는 정수 쌍 @math{a}와 @math{b}를 사용하여 @math{{\text{Fib(1) = 1}}}과 @math{{\text{Fib(0) = 0}}}으로 초기화하고, 다음과 같은 동시 변환을 반복적으로 적용하는 것이다.

@ifinfo

@example
a <- a + b
b <- a
@end example

@end ifinfo
@tex

\[ % :10:
 
\begin{array}{l}
  a \;\leftarrow\; a + b, \\ 
  b \;\leftarrow\; a. 
\end{array}
\]

@end tex
@noindent
이 변환을 @math{n}번 적용한 후, @math{a}와 @math{b}가 각각 @math{{\text{Fib}(n+1)}}과 @math{{\text{Fib}(n)}}과 같아질 것임을 보이기란 어렵지 않다.
따라서 우리는 다음 프로시저를 사용하여 피보나치 수를 반복적으로 계산할 수 있다.

@example
fn fib(n: u64) -> u64 @{
    fib_iter(1, 0, n)
@}

fn fib_iter(a: u64, b: u64, count: u64) -> u64 @{
    if count == 0 @{
        b
    @} else @{
        fib_iter(a + b, a, count - 1)
    @}
@}
@end example

@noindent
@math{{\text{Fib}(n)}}을 계산하는 이 두 번째 방법은 선형 반복이다.
두 방법 사이에 필요한 단계 수의 차이---하나는 @math{n}에 선형적이고, 하나는 @math{{\text{Fib}(n)}} 자체만큼 빠르게 증가함---는 작은 입력에 대해서도 엄청나다.

이로부터 트리 재귀적 프로세스가 쓸모없다고 결론지어서는 안 된다.
숫자가 아니라 계층적으로 구조화된 데이터에서 작동하는 프로세스를 고려할 때, 우리는 트리 재귀가 자연스럽고 강력한 도구임을 알게 될 것이다.@footnote{이것의 한 예가 @ref{1.1.3}에서 암시되었다. 인터프리터 자체가 트리 재귀적 프로세스를 사용하여 표현식을 평가한다.}
하지만 수치 연산에서도 트리 재귀적 프로세스는 우리가 프로그램을 이해하고 설계하는 데 도움이 될 수 있다.
예를 들어, 첫 번째 @code{fib} 프로시저는 두 번째 것보다 훨씬 덜 효율적이지만, 피보나치 수열의 정의를 리스프로 거의 그대로 번역한 것이어서 더 직관적이다.
반복적 알고리즘을 공식화하려면 계산을 세 개의 상태 변수를 가진 반복으로 재구성할 수 있다는 점을 알아차려야 했다.

@subsubheading Example: Counting change

반복적인 피보나치 알고리즘을 생각해내는 데는 약간의 기발함만 있으면 된다.
대조적으로 다음 문제를 고려해 보자: 50센트, 25센트, 10센트, 5센트, 그리고 1센트 동전이 주어졌을 때, 1달러를 거슬러 줄 수 있는 방법은 몇 가지인가?
더 일반적으로, 임의의 금액에 대해 거스름돈을 만드는 방법의 수를 계산하는 프로시저를 작성할 수 있을까?

이 문제는 재귀적 프로시저로서 간단한 해결책이 있다.
우리가 사용할 수 있는 동전의 종류가 어떤 순서로 배열되어 있다고 가정하자.
그러면 다음과 같은 관계가 성립한다:

금액 @math{a}를 @math{n}종류의 동전으로 거슬러 주는 방법의 수는 다음과 같은 두 종류의 방법의 합과 같다:

@itemize @bullet

@item
첫 번째 종류의 동전을 전혀 사용하지 않고 금액 @math{a}를 거슬러 주는 방법의 수.
플러스

@item
금액 @math{{a - d}}를 @math{n}종류의 모든 동전으로 거슬러 주는 방법의 수. 여기서 @math{d}는 첫 번째 종류 동전의 액면가이다.

@end itemize

@noindent
이것이 왜 사실인지 보려면, 거스름돈을 만드는 방법들이 두 그룹으로 나뉠 수 있다는 점을 관찰하라: 첫 번째 종류의 동전을 전혀 사용하지 않는 방법들과 사용하는 방법들.
따라서 어떤 금액에 대해 거스름돈을 만드는 전체 방법의 수는 첫 번째 동전을 사용하지 않고 그 금액을 만드는 방법의 수에, 적어도 하나의 첫 번째 동전을 사용한다고 가정하고 만드는 방법의 수를 더한 것과 같다.
그런데 후자의 수는 첫 번째 종류의 동전을 하나 사용한 후 남은 금액에 대해 거스름돈을 만드는 방법의 수와 같다.

따라서 우리는 거스름돈 만들기 문제를 더 적은 금액이나 더 적은 종류의 동전을 거슬러 주는 문제로 재귀적으로 축소할 수 있다.
이 축소 규칙을 주의 깊게 살펴보고, 다음과 같은 퇴화된 사례(degenerate cases)를 지정하면 알고리즘을 기술하는 데 사용할 수 있다는 것을 스스로 확신해 보라:@footnote{예를 들어, 축소 규칙이 10센트를 5센트와 1센트 동전으로 거슬러 주는 문제에 어떻게 적용되는지 자세히 살펴보라.}

@itemize @bullet

@item
@math{a}가 정확히 0이면, 거스름돈을 만드는 방법을 1가지로 센다.

@item
@math{a}가 0보다 작으면, 거스름돈을 만드는 방법을 0가지로 센다.

@item
@math{n}이 0이면, 거스름돈을 만드는 방법을 0가지로 센다.

@end itemize

@noindent
이 설명은 쉽게 재귀 프로시저로 옮길 수 있다:

@example
fn count_change(amount: i64) -> u64 @{
    cc(amount, 5)
@}

fn cc(amount: i64, kinds_of_coins: u64) -> u64 @{
    if amount == 0 @{
        1
    @} else if amount < 0 || kinds_of_coins == 0 @{
        0
    @} else @{
        cc(amount, kinds_of_coins - 1) +
        cc(amount - first_denomination(kinds_of_coins), kinds_of_coins)
    @}
@}

fn first_denomination(kinds_of_coins: u64) -> i64 @{

    match kinds_of_coins @{

        1 => 1,

        2 => 5,

        3 => 10,

        4 => 25,

        5 => 50,

        _ => 0,

    @}

@}

@end example



@noindent

(@code{first_denomination} 프로시저는 사용할 수 있는 동전의 종류를 입력으로 받아 첫 번째 동전의 액면가를 반환한다. 여기서는 동전들이 큰 것부터 작은 것 순으로 나열되어 있다고 가정했지만 어떤 순서라도 상관없다.)

우리는 이제 1달러를 거슬러 주는 방법의 수에 대한 원래 질문에 답할 수 있다:



@example

count_change(100)

@i{292}

@end example



@noindent

@code{count_change}는 @code{fib}의 첫 번째 구현과 유사한 중복을 가진 트리 재귀적 프로세스를 생성한다. (결과값 292를 계산하는 데 꽤 오랜 시간이 걸릴 것이다.)

반면에, 결과를 계산하기 위한 더 나은 알고리즘을 설계하는 것은 명확하지 않으며, 이 문제를 도전 과제로 남겨둔다.

트리 재귀적 프로세스가 매우 비효율적일 수 있지만 종종 명시하고 이해하기 쉽다는 관찰은, 트리 재귀적 프로시저를 동일한 결과를 계산하는 더 효율적인 프로시저로 변환할 수 있는 ``스마트 컴파일러''를 설계함으로써 두 세계의 장점을 모두 얻을 수 있다는 제안으로 이어졌다.@footnote{중복 계산에 대처하는 한 가지 방법은 값이 계산될 때 자동으로 테이블을 구성하도록 하는 것이다. 프로시저를 어떤 인자에 적용하라는 요청을 받을 때마다, 먼저 그 값이 이미 테이블에 저장되어 있는지 확인하고, 그렇다면 중복 계산을 피한다. @newterm{도표화(tabulation)} 또는 @newterm{메모이제이션(memoization)}이라고 알려진 이 전략은 간단한 방법으로 구현될 수 있다. 도표화는 때때로 기하급수적인 수의 단계가 필요한 프로세스(@code{count_change}와 같은)를 공간과 시간 요구 사항이 입력에 따라 선형적으로 증가하는 프로세스로 변환하는 데 사용될 수 있다. @ref{Exercise 3.27}을 참조하라.}



@quotation

@strong{@anchor{Exercise 1.11}Exercise 1.11:} 함수 @math{f}는 다음 규칙에 의해 정의된다: @math{{n < 3}}이면 @math{{f(n) = n}}이고, @math{{n \ge 3}}이면 @math{{f(n)} = {f(n-1)} + {2f(n-2)} + {3f(n-3)}}이다.

재귀적 프로세스에 의해 @math{f}를 계산하는 프로시저를 작성하라. 반복적 프로세스에 의해 @math{f}를 계산하는 프로시저를 작성하라.

@end quotation



@quotation

@strong{@anchor{Exercise 1.12}Exercise 1.12:} 다음은 @newterm{파스칼의 삼각형(Pascal's triangle)}이라고 불리는 숫자들의 배열이다.



@example

         1

       1   1

     1   2   1

   1   3   3   1

 1   4   6   4   1

       . . .

@end example



삼각형의 양 끝에 있는 숫자는 모두 1이다. 삼각형 내부의 각 숫자는 그 바로 위에 있는 두 숫자의 합이다.@footnote{파스칼 삼각형의 요소를 @newterm{이항 계수(binomial coefficients)}라고 부르는데, 이는 @math{{n^{\text{th}}}} 행이 @math{{(x + y)^n}} 전개식의 항들의 계수로 구성되기 때문이다. 계수를 계산하는 이 패턴은 블레즈 파스칼(Blaise Pascal)의 1653년 확률론에 관한 독창적인 저작인 @cite{Trait@'e du triangle arithm@'etique}에 등장했다. @ref{Knuth (1973)}에 따르면, 동일한 패턴이 1303년 중국 수학자 주세걸(Chu Shih-chieh)이 발표한 @cite{사원옥감(Szu-yuen Y@"u-chien, ``The Precious Mirror of the Four Elements'')}, 12세기 페르시아 시인이자 수학자인 오마르 하이얌(Omar Khayyam)의 저작, 그리고 12세기 힌두 수학자 바스카라 아차리야(Bh@'ascara @'Ach@'arya)의 저작에도 나타난다.}

재귀적 프로세스에 의해 파스칼 삼각형의 요소를 계산하는 프로시저를 작성하라.

@end quotation



@quotation

@strong{@anchor{Exercise 1.13}Exercise 1.13:} @math{{\text{Fib}(n)}}이 @math{{\varphi^n / \sqrt{5}}}에 가장 가까운 정수임을 증명하라. 여기서 @math{\varphi = {(1 + \sqrt{5}) / 2}}이다.

힌트: @math{\psi = {(1 - \sqrt{5}) / 2}}라고 하자. 수학적 귀납법과 피보나치 수의 정의(@ref{1.2.2} 참조)를 사용하여 @math{{\text{Fib}(n)} = {(\varphi^n - \psi^n) / \sqrt{5}}}임을 증명하라.

@end quotation



@node   1.2.3, 1.2.4, 1.2.2, 1.2

@subsection 증가 차수 (Orders of Growth)



이전 예제들은 서로 다른 프로세스가 계산 자원을 소비하는 속도에 큰 차이가 있을 수 있음을 보여주었다.

이러한 차이를 기술하는 데 사용되는 편리한 척도가 @newterm{증가 차수(order of growth)}라는 개념이다. 증가 차수는 입력이 커짐에 따라 프로세스에 필요한 자원의 양에 대한 거친 척도를 제공한다.



@math{n}을 문제의 크기를 나타내는 매개변수라고 하고, @math{{R(n)}}을 문제 크기가 @math{n}일 때 프로세스에 필요한 자원의 양이라고 하자.

우리의 이전 예제들에서 우리는 @math{n}을 주어진 함수가 계산될 대상인 숫자로 잡았지만, 다른 가능성들도 있다. 예를 들어, 숫자의 제곱근 근사값을 구하는 것이 목표라면, 필요한 정확도(자리수)를 @math{n}으로 잡을 수 있을 것이다.
행렬 곱셈의 경우 행렬의 행 수를 @math{n}으로 잡을 수 있다.
일반적으로 주어진 프로세스를 분석하는 데 바람직한 문제의 여러 속성이 있을 수 있다.
마찬가지로, @math{{R(n)}}은 사용된 내부 저장 레지스터의 수, 수행된 기본 기계 명령어의 수 등을 측정할 수 있다.
컴퓨터에서 한 번에 고정된 수의 연산만 수행할 수 있는 경우, 필요한 시간은 수행된 기본 기계 명령어의 수에 비례할 것이다.

우리는 충분히 큰 @math{n}에 대해 @math{{R(n)}}이 @math{{k_1 f(n)}}과 @math{{k_2 f(n)}} 사이에 있도록 하는, @math{n}과 독립적인 양의 상수 @math{k_1}과 @math{k_2}가 존재한다면, @math{{R(n)}}이 @math{{\Theta(f(n))}}의 증가 차수를 갖는다고 말한다. (``@math{{f(n)}}의 세타''라고 읽는다.)

예를 들어, @ref{1.2.1}에서 설명한 팩토리얼을 계산하기 위한 선형 재귀적 프로세스의 경우, 단계의 수는 입력 @math{n}에 비례하여 증가한다. 따라서 이 프로세스에 필요한 단계는 @math{{\Theta(n)}}으로 증가한다. 우리는 또한 공간 요구 사항도 @math{{\Theta(n)}}으로 증가함을 보았다.
반복적 팩토리얼의 경우, 단계의 수는 여전히 @math{{\Theta(n)}}이지만 공간은 @math{{\Theta(1)}}---즉, 상수이다.@footnote{이러한 진술들은 상당한 지나친 단순화를 감추고 있다. 예를 들어, 프로세스 단계를 ``기계 연산''으로 센다면 우리는 곱셈을 수행하는 데 필요한 기계 연산의 수가 곱해지는 숫자의 크기와 독립적이라는 가정을 하고 있는 것인데, 이는 숫자가 충분히 크면 거짓이다. 공간 추정치에 대해서도 비슷한 언급이 성립한다. 프로세스의 설계 및 기술과 마찬가지로, 프로세스의 분석도 다양한 추상화 수준에서 수행될 수 있다.}
트리 재귀적 피보나치 계산은 @math{{\Theta(\varphi^n)}} 단계와 @math{{\Theta(n)}} 공간이 필요하다. 여기서 @math{\varphi}는 @ref{1.2.2}에서 설명한 황금비이다.

증가 차수는 프로세스의 행동에 대한 거친 설명만을 제공한다.
예를 들어, @math{n^2} 단계가 필요한 프로세스와 @math{{1000n^2}} 단계가 필요한 프로세스, 그리고 @math{{3n^2} + {10n} + 17} 단계가 필요한 프로세스는 모두 @math{{\Theta(n^2)}}의 증가 차수를 갖는다.
반면에 증가 차수는 문제의 크기가 변함에 따라 프로세스의 행동이 어떻게 변할지 예측하는 데 유용한 가이드를 제공한다.
@math{{\Theta(n)}} (선형) 프로세스의 경우, 크기를 두 배로 늘리면 자원 사용량도 대략 두 배가 된다.
지수적 프로세스의 경우, 문제 크기가 조금만 커져도 자원 사용량이 급격히 증가한다.
@ref{1.2}의 나머지 부분에서 우리는 증가 차수가 로그형(logarithmic)인 두 알고리즘을 조사할 것인데, 이 경우 문제 크기를 두 배로 늘려도 자원 요구 사항은 일정한 양만큼만 증가한다.

@quotation
@strong{@anchor{Exercise 1.14}Exercise 1.14:} @ref{1.2.2}의 @code{count_change} 프로시저가 11센트를 거슬러 줄 때 생성하는 프로세스를 보여주는 트리를 그려라.
거슬러 줄 금액이 증가함에 따라 이 프로세스에 사용되는 공간과 단계 수의 증가 차수는 각각 어떻게 되는가?
@end quotation

@quotation
@strong{@anchor{Exercise 1.15}Exercise 1.15:} 각도가 충분히 작을 때(라디안 단위), 각도 @math{x}의 사인(sine) 값은 @math{{\sin x  \approx x}}로 근사될 수 있으며, 삼각 항등식
@ifinfo

@example
               x             x
sin x = 3 sin --- - 4 sin^3 ---
               3             3
@end example

@end ifinfo
@tex

\[ % :12:
 
{\sin x} \,=\, {3\sin \frac{x}{3}} \,-\, {4\sin^3 \frac{x}{3}}
\]

@end tex
@noindent
를 사용하여 사인 인자의 크기를 줄일 수 있다. (이 연습 문제를 위해 각도의 절댓값이 0.1 라디안보다 크지 않으면 ``충분히 작은'' 것으로 간주한다.) 이 아이디어들은 다음 프로시저들에 구현되어 있다:

@example
fn cube(x: f64) -> f64 @{ x * x * x @}
fn p(x: f64) -> f64 @{ 3.0 * x - 4.0 * cube(x) @}
fn sine(angle: f64) -> f64 @{
    if angle.abs() <= 0.1 @{
        angle
    @} else @{
        p(sine(angle / 3.0))
    @}
@}
@end example

@enumerate a

@item
@code{sine(12.15)}를 평가할 때 프로시저 @code{p}는 몇 번 호출되는가?

@item
@code{sine(a)}를 평가할 때 프로세스에 의해 사용되는 공간과 단계 수(의 증가 차수)를 @math{a}의 함수로 나타내면 무엇인가?

@end enumerate
@end quotation

@node   1.2.4, 1.2.4a, 1.2.3, 1.2

@subsection 거듭제곱 (Exponentiation)



주어진 숫자의 거듭제곱을 계산하는 문제를 고려해 보자.

우리는 밑 @math{b}와 양의 정수 지수 @math{n}을 인자로 받아 @math{b^n}을 계산하는 프로시저를 원한다.

이를 수행하는 한 가지 방법은 다음과 같은 재귀적 정의를 이용하는 것이다.

@ifinfo



@example

b^n = b * b^(n - 1)

b^0 = 1

@end example



@end ifinfo

@tex



\[ % :13:

 

\begin{array}{l}

  b^n \,=\, b\cdot b^{n-1}, \\ 

  b^0 \,=\, 1, 

\end{array}

\]



@end tex

이것은 다음 프로시저로 바로 번역된다:



@example

fn expt(b: u64, n: u64) -> u64 @{

    if n == 0 @{

        1

    @} else @{

        b * expt(b, n - 1)

    @}

@}

@end example



@noindent

이것은 선형 재귀적 프로세스로, @math{{\Theta(n)}} 단계와 @math{{\Theta(n)}} 공간이 필요하다.

팩토리얼과 마찬가지로, 우리는 이에 상응하는 선형 반복을 손쉽게 공식화할 수 있다:



@example

fn expt(b: u64, n: u64) -> u64 @{

    expt_iter(b, n, 1)

@}



fn expt_iter(b: u64, counter: u64, product: u64) -> u64 @{

    if counter == 0 @{

        product

    @} else @{

        expt_iter(b, counter - 1, b * product)

    @}

@}

@end example



@noindent

이 버전은 @math{{\Theta(n)}} 단계와 @math{{\Theta(1)}} 공간이 필요하다.



우리는 연속적인 제곱(successive squaring)을 사용하여 더 적은 단계로 거듭제곱을 계산할 수 있다. 예를 들어, @math{b^8}을 다음과 같이 계산하는 대신
@ifinfo

@example
b * (b * (b * (b * (b * (b * (b * b))))))
@end example

@end ifinfo
@tex

\[ % :14:
  
{b\cdot (b\cdot (b}\cdot {(b\cdot (b\cdot (b}\cdot {(b\cdot b)))))),}
\]

@end tex
우리는 세 번의 곱셈을 사용하여 그것을 계산할 수 있다:
@ifinfo

@example
b^2 = b * b
b^4 = b^2 * b^2
b^8 = b^4 * b^4
@end example

@end ifinfo
@tex

\[ % :15:
 
\begin{array}{l}
  b^2 \,=\, b\cdot b, \\ 
  b^4 \,=\, b^2\cdot b^2, \\
  b^8 \,=\, b^4\cdot b^4.
\end{array}
\]

@end tex
이 방법은 지수가 2의 거듭제곱일 때 잘 작동한다.
우리는 다음 규칙을 사용하면 일반적으로 거듭제곱을 계산하는 데 있어 연속적인 제곱의 이점을 누릴 수 있다.
@ifinfo

@example
b^n = (b^(n/2))^2    n이 짝수이면
b^n = b * b^(n - 1)  n이 홀수이면
@end example

@end ifinfo
@tex

\[ % :16:
 
\begin{array}{ll}
  b^n \,=\, (b^{n / 2})^2   & \text{n이 짝수이면}, \\
  b^n \,=\, b\cdot b^{n-1}  & \text{n이 홀수이면}.
\end{array}
\]

@end tex
우리는 이 방법을 프로시저로 표현할 수 있다:

@example
fn fast_expt(b: u64, n: u64) -> u64 @{
    if n == 0 @{
        1
    @} else if n % 2 == 0 @{
        let half = fast_expt(b, n / 2);
        half * half
    @} else @{
        b * fast_expt(b, n - 1)
    @}
@}
@end example

@noindent
여기서 정수가 짝수인지 테스트하는 술어는 원시 연산자 @code{%}를 사용하여 다음과 같이 정의된다:

@example
fn is_even(n: u64) -> bool @{
    n % 2 == 0
@}
@end example

@noindent
@code{fast_expt}에 의해 진화된 프로세스는 공간과 단계 수 모두에서 @math{n}에 대해 로그형으로 증가한다.
이를 보려면, @code{fast_expt}를 사용하여 @math{b^{2n}}을 계산하는 것이 @math{b^n}을 계산하는 것보다 단 한 번의 곱셈만 더 필요하다는 점을 관찰하라.
따라서 우리가 계산할 수 있는 지수의 크기는 우리가 허용하는 각 새로운 곱셈에 대해 (대략) 두 배가 된다.
결과적으로 지수 @math{n}에 대해 필요한 곱셈의 수는 2를 밑으로 하는 @math{n}의 로그만큼 빠르게 증가한다.
이 프로세스는 @math{{\Theta(\log n)}}의 증가율을 갖는다.@footnote{더 정확하게는, 필요한 곱셈의 수는 @math{n}의 이진수 표현에서의 비트 수와 @math{n}의 이진수 표현에서의 1의 개수의 합에서 1을 뺀 것과 같다. 이 합계는 항상 @math{n}의 이진 로그의 두 배보다 작다. 증가 차수 표기법의 정의에서 임의의 상수 @math{k_1}과 @math{k_2}는 로그형 프로세스의 경우 로그의 밑이 무엇인지는 중요하지 않음을 의미하므로, 그러한 모든 프로세스는 @math{{\Theta(\log n)}}으로 기술된다.}

@math{{\Theta(\log n)}} 증가율과 @math{{\Theta(n)}} 증가율 사이의 차이는 @math{n}이 커짐에 따라 매우 두드러지게 된다.
예를 들어, @math{n = 1000}일 때 @code{fast_expt}는 단지 14번의 곱셈만 필요하다.@footnote{누군가 왜 숫자를 1000제곱하는 것에 관심을 가질지 궁금할 수 있다. @ref{1.2.6}을 보라.}
또한 연속적인 제곱의 아이디어를 사용하여 로그형의 단계 수로 거듭제곱을 계산하는 반복적 알고리즘을 고안하는 것도 가능하다(@ref{Exercise 1.16} 참조). 비록 반복적 알고리즘의 경우 대개 그렇듯이 재귀적 알고리즘만큼 직관적으로 작성되지는 않지만 말이다.@footnote{이 반복적 알고리즘은 고대부터 전해 내려온다. 그것은 기원전 200년 이전에 쓰여진 핑갈라 아차리야(Pingala @'Ach@'arya)의 @cite{Chandah-sutra}에 나타난다. 이 방법과 다른 거듭제곱 방법에 대한 전체적인 논의와 분석은 @ref{Knuth 1981}, 섹션 4.6.3을 참조하라.}

@quotation
@strong{@anchor{Exercise 1.16}Exercise 1.16:} @code{fast_expt}와 마찬가지로 연속적인 제곱을 사용하고 로그형의 단계 수를 사용하는 반복적 거듭제곱 프로세스를 진화시키는 프로시저를 설계하라. (힌트: @math{{(b^{n / 2})^2} = {(b^2)^{n / 2}}}라는 관찰을 사용하여, 지수 @math{n}과 밑 @math{b}와 함께 추가적인 상태 변수 @math{a}를 유지하고, 곱 @math{{ab^n}}이 한 상태에서 다음 상태로 바뀔 때 변하지 않도록 상태 변환을 정의하라. 프로세스 시작 시 @math{a}는 1로 잡고, 답은 프로세스 종료 시 @math{a}의 값으로 주어진다. 일반적으로 상태 간에 변하지 않고 유지되는 @newterm{불변량(invariant quantity)}을 정의하는 기술은 반복적 알고리즘의 설계를 생각하는 강력한 방법이다.)
@end quotation

@quotation
@strong{@anchor{Exercise 1.17}Exercise 1.17:} 이 절의 거듭제곱 알고리즘들은 반복적인 곱셈을 통해 거듭제곱을 수행하는 것에 기초한다.
비슷한 방식으로, 반복적인 덧셈을 통해 정수 곱셈을 수행할 수 있다.
다음 곱셈 프로시저(우리의 언어가 곱셈은 못 하고 더하기만 할 수 있다고 가정한다)는 @code{expt} 프로시저와 유사하다:

@example
fn multiply(a: u64, b: u64) -> u64 @{
    if b == 0 @{
        0
    @} else @{
        a + multiply(a, b - 1)
    @}
@}
@end example

이 알고리즘은 @code{b}에 선형적인 수의 단계를 필요로 한다.
이제 덧셈과 함께, 정수를 두 배로 만드는 @code{double} 연산과, (짝수) 정수를 2로 나누는 @code{halve} 연산이 포함되어 있다고 가정하자. 이것들을 사용하여 @code{fast-expt}와 유사하게 로그형 단계 수를 사용하는 곱셈 프로시저를 설계하라.
@end quotation

@quotation
@strong{@anchor{Exercise 1.18}연습문제 1.18:} @ref{Exercise 1.16}과 @ref{Exercise 1.17}의 결과를 사용하여, 더하기, 두 배, 절반 연산으로 두 정수를 곱하는 반복적 프로세스를 생성하고 로그형 단계 수를 사용하는 프로시저를 고안하라.@footnote{이 알고리즘은 때때로 ``러시아 농부 곱셈법''으로 알려져 있으며 매우 오래되었다. 그 사용 예는 가장 오래된 수학 문서 두 개 중 하나인 라인드 파피루스(Rhind Papyrus)에서 발견된다. 이 문서는 기원전 (B.C.) 약 1700년에 이집트 서기관 아흐모세(A'h-mose)가 (더 오래된 문서에서 베껴) 작성했다.}
@end quotation

@quotation
@strong{@anchor{Exercise 1.19}연습문제 1.19:} 피보나치 수를 로그형 단계 수로 계산하는 영리한 알고리즘이 있다. @ref{1.2.2}의 @code{fib-iter} 프로세스에서 상태 변수 @math{a}와 @math{b}의 변환을 떠올려 보라: @math{a \gets a + b}, @math{b \gets a}이다.
이 변환을 @math{T}라고 하자. 1과 0에서 시작하여 @math{T}를 @math{n}번 반복 적용하면 @math{{\text{Fib}(n+1)}}과 @math{{\text{Fib}(n)}}의 쌍이 생성됨을 관찰하라. 즉, 피보나치 수는 변환 @math{T}의 @math{n^{\text{th}}} 거듭제곱 @math{T^n}을 (1, 0) 쌍에 적용함으로써 생성된다.
이제 변환 족 @math{T_{pq}}에서 @math{p=0}, @math{q=1}인 특별한 경우로서 @math{T}를 생각하라. 여기서 @math{T_{pq}}는 쌍 @math{{(a, b)}}를 @math{a \gets {bq} + {aq} + {ap}}, @math{b \gets {bp} + {aq}}에 따라 변환한다.
이러한 변환 @math{T_{pq}}를 두 번 적용하는 효과가 동일한 형태의 단일 변환 @math{T_{p'q'}}를 사용하는 것과 같음을 보이고, @math{p'}와 @math{q'}를 @math{p}와 @math{q}에 대한 식으로 계산하라. 이것은 이러한 변환들을 제곱하는 명시적인 방법을 제공하며, 따라서 우리는 @code{fast-expt} 프로시저에서와 같이 연속적인 제곱을 사용하여 @math{T^n}을 계산할 수 있다. 이 모든 것을 종합하여 로그형의 단계 수로 실행되는 다음 프로시저를 완성하라:@footnote{이 연습 문제는 @ref{Kaldewaij 1990}의 예제를 바탕으로 Joe Stoy가 제안했다.}

@example
fn fib(n: u64) -> u64 @{
    fib_iter(1, 0, 0, 1, n)
@}

fn fib_iter(a: u64, b: u64, p: u64, q: u64, count: u64) -> u64 @{
    if count == 0 @{
        b
    @} else if count % 2 == 0 @{
        fib_iter(a,
                 b,
                 ⟨??⟩,  // p' 계산
                 ⟨??⟩,  // q' 계산
                 count / 2)
    @} else @{
        fib_iter(b * q + a * q + a * p,
                 b * p + a * q,
                 p,
                 q,
                 count - 1)
    @}
@}
@end example
@end quotation

@node 1.2.4a, 1.2.5, 1.2.4, 1.2
@subsection 상수 평가 (Const Evaluation)

제로 비용 추상화(zero-cost abstraction)를 달성하기 위한 Rust의 가장 강력한 특징 중 하나는 @newterm{상수 평가(const evaluation)}를 통한 @newterm{컴파일 타임 계산(compile-time computation)}이다. 지금까지 본 프로시저들은 런타임에 평가되지만, Rust는 특정 계산을 컴파일 중에 수행할 수 있게 하여 해당 연산에 대한 모든 런타임 오버헤드를 제거한다.

@ref{1.2.1}의 팩토리얼 함수를 고려해 보자. @code{factorial(5)}라고 작성하면, 계산은 프로그램이 실행될 때 일어난다. 하지만 인자를 컴파일 타임에 알고 있다면, 왜 프로그램이 실행될 때마다 이 계산 비용을 지불해야 할까? Rust의 @code{const fn} 기능을 사용하면 컴파일러가 그러한 계산을 컴파일 타임에 한 번만 수행할 수 있다.

@example
const fn factorial(n: u64) -> u64 @{
    if n == 0 @{
        1
    @} else @{
        n * factorial(n - 1)
    @}
@}

const FACT_5: u64 = factorial(5);  // Computed at compile time
const FACT_10: u64 = factorial(10); // Also at compile time
@end example

@noindent
@code{FACT_5}를 선언하면 컴파일러는 컴파일 중에 @code{factorial(5)}를 평가하고 생성된 코드에서 @code{FACT_5}를 리터럴 값 @code{120}으로 치환한다. 런타임에는 함수 호출도, 스택 프레임도, 계산도 없다---결과 값만 남는다. 이것이 우리가 @newterm{제로-비용 추상화(zero-cost abstraction)}라고 말하는 것이다: 우리는 높은 수준의 코드(팩토리얼 함수)를 작성하지만 그 추상화에 대해 런타임 비용을 지불하지 않는다.

@code{fn} 앞의 @code{const} 키워드는 이 함수가 컴파일 타임에 평가될 수 있음을 나타낸다. 그러나 이는 몇 가지 제약을 부과한다: const 함수는 임의의 연산을 수행할 수 없다. 그것들은 오직 인자에만 의존하고 부수 효과가 없는 @newterm{순수 함수(pure functions)}여야 한다. 힙 메모리를 할당하거나 I/O를 수행하거나 const가 아닌 함수를 호출할 수 없다.

@ref{1.2.2}의 피보나치 수열을 고려하여 컴파일 타임 평가와 런타임 평가의 차이를 좀 더 자세히 살펴보자:

@example
const fn fib(n: u64) -> u64 @{
    if n < 2 @{
        n
    @} else @{
        fib(n - 1) + fib(n - 2)
    @}
@}

// 컴파일 타임 평가
const FIB_10: u64 = fib(10);

// 런타임 평가
fn compute_fib_at_runtime(n: u64) -> u64 @{
    fib(n)  // 프로그램 실행 시 계산됨
@}
@end example

@noindent
@code{const FIB_10 = fib(10)}을 작성하면 컴파일러는 프로그램이 실행되기 전에 그 값을 알아야 한다. 컴파일 중에 재귀 호출을 평가하여 @code{55}를 얻고, 컴파일된 프로그램에는 이 리터럴 값만 들어간다. 반대로 @code{compute_fib_at_runtime(10)}은 인자가 같더라도 호출될 때마다 계산을 수행한다.

이 차이는 성능에 민감한 코드에서 중요해진다. 예를 들어 2의 거듭제곱을 조회 테이블로 계산해 보자:

@example
const fn pow2(n: u32) -> u64 @{
    1 << n
@}

const POWERS_OF_TWO: [u64; 64] = @{
    let mut arr = [0; 64];
    let mut i = 0;
    while i < 64 @{
        arr[i] = pow2(i as u32);
        i += 1;
    @}
    arr
@};
@end example

@noindent
이 예제는 @newterm{const 블록(const blocks)}---컴파일 타임에 실행되는 코드 블록---을 소개한다. @code{const} 문맥에서는 (블록 안에서) 명령형 루프와 가변 바인딩을 사용할 수 있지만, 모든 계산은 컴파일 중에 일어난다. 결과 배열 @code{POWERS_OF_TWO}는 모든 64개 값이 미리 계산된 채로 프로그램의 데이터 섹션에 직접 포함된다.

컴파일러의 const 평가 엔진은 꽤 정교하다. 다음을 처리할 수 있다:

@itemize @bullet
@item 산술 연산과 비트 연산
@item 조건식 (@code{if} 표현식)
@item 루프 (@code{while}와 @code{loop}; 모든 문맥에서 @code{for}는 아님)
@item 패턴 매칭
@item 다른 const 함수 호출
@item 튜플과 배열 연산
@end itemize

@noindent
그러나 컴파일러는 평가가 언제 끝나는지 결정할 수 있어야 한다. const 문맥에서 무한 루프나 무한 재귀는 컴파일 실패를 일으킨다:

@example
const fn infinite() -> u64 @{
    infinite()  // 컴파일 오류: 무한 재귀
@}
@end example

@subheading 상수 제네릭 (Const Generics)

const 평가는 @newterm{상수 제네릭(const generics)}---타입이 아니라 값인 제네릭 매개변수---과 결합되면 더욱 강력해진다. 이를 통해 특정 상수 값에 특화된 함수를 컴파일 타임에 만들 수 있다.

@example
fn create_array<const N: usize>() -> [u64; N] @{
    let mut arr = [0; N];
    let mut i = 0;
    while i < N @{
        arr[i] = (i * i) as u64;
        i += 1;
    @}
    arr
@}

const SQUARES_5: [u64; 5] = create_array::<5>();
const SQUARES_100: [u64; 100] = create_array::<100>();
@end example

@noindent
Here, @code{N} is a const generic parameter---a compile-time constant value.
The compiler generates specialized versions of @code{create_array} for each
value of @code{N} we use, and if called in a const context, it evaluates the
entire function at compile time.

This feature is particularly valuable for fixed-size data structures.  The
fast exponentiation algorithm from @ref{1.2.4} can be adapted to create
compile-time lookup tables:

@example
const fn fast_expt(b: u64, n: u64) -> u64 @{
    if n == 0 @{
        1
    @} else if n % 2 == 0 @{
        let half = fast_expt(b, n / 2);
        half * half
    @} else @{
        b * fast_expt(b, n - 1)
    @}
@}

const fn create_power_table<const BASE: u64, const SIZE: usize>()
    -> [u64; SIZE]
@{
    let mut table = [0; SIZE];
    let mut i = 0;
    while i < SIZE @{
        table[i] = fast_expt(BASE, i as u64);
        i += 1;
    @}
    table
@}

// 2^0부터 2^10까지의 2의 거듭제곱을 미리 계산
const POWERS_OF_2: [u64; 11] = create_power_table::<2, 11>();

// 3^0부터 3^10까지의 3의 거듭제곱을 미리 계산
const POWERS_OF_3: [u64; 11] = create_power_table::<3, 11>();
@end example

@noindent
컴파일러는 각 밑에 대해 11개의 거듭제곱을 컴파일 타임에 생성한다. 런타임에서 @code{POWERS_OF_2[5]}를 조회하는 것은 단순한 배열 인덱싱 연산일 뿐이며, 거듭제곱 계산은 발생하지 않는다.

@subheading 컴파일러는 언제 평가하는가? (When Does the Compiler Evaluate?)

효율적인 코드를 작성하려면, 컴파일러가 const 평가를 수행할지 아니면 런타임으로 미룰지를 언제 선택하는지 이해하는 것이 중요하다. 규칙은 다음과 같다:

@enumerate
@item
@strong{반드시 평가:} const 문맥(@code{const} 항목, 배열 길이, 상수 제네릭 인자)에서는 컴파일러가 표현식을 컴파일 타임에 평가해야 한다. 불가능하면 컴파일이 실패한다.

@item
@strong{선택적 평가:} const 함수가 비-const 문맥에서 상수 인자로 호출되면, 컴파일러는 최적화로 컴파일 타임에 평가할 수도 있지만 반드시 그럴 필요는 없다.

@item
@strong{평가 불가:} const 함수가 런타임 값으로 호출되면, 평가는 반드시 런타임에 일어난다.
@end enumerate

@example
const fn square(x: u64) -> u64 @{
    x * x
@}

const A: u64 = square(5);           // 컴파일 타임에 반드시 평가

fn example() @{
    let b = square(5);              // 컴파일 타임에 평가될 수도 있음
    let n = read_input();           // 런타임 값
    let c = square(n);              // 런타임에 반드시 평가
@}
@end example

@noindent
이 예에서 @code{A}는 런타임 계산 없이 @code{25} 값을 포함함이 보장된다. @code{b}의 값은 컴파일 타임에 계산될 수도 있지만(최적화), @code{n}은 프로그램이 실행되기 전에는 알 수 없으므로 @code{c}는 런타임에 계산되어야 한다.

현대 Rust 컴파일러는 가능할 때 컴파일 타임 평가에 매우 공격적이다. 리터럴 인자로 호출된 단순한 const 함수는 비-const 문맥에서도 거의 항상 컴파일 타임에 평가된다. 이는 제로-비용 추상화의 철학과 맞닿아 있다: 추상화는 런타임 페널티를 부과하지 않아야 한다.

@subheading const 평가의 한계 (Limits of Const Evaluation)

강력하지만 const 평가는 정지 문제에서 비롯되는 한계를 가진다. 컴파일러는 평가가 완료되는지 판단해야 하는데, 일반적으로는 결정 불가능하다. 따라서 Rust는 실용적인 제한을 둔다:

@itemize @bullet
@item
@strong{Recursion depth:} There's a limit on how deeply recursive calls can
nest during const evaluation (typically around 128 levels, but
implementation-specific).

@item
@strong{Instruction count:} The compiler limits the total number of
instructions executed during const evaluation to prevent compilation from
hanging on infinite loops.

@item
@strong{Available operations:} Only a subset of Rust's operations are
permitted in const contexts.  For example, heap allocation through @code{Box}
or @code{Vec} is not allowed in const functions (as of Rust 1.83).
@end itemize

@noindent
이러한 제한을 넘어서면 const 평가가 실패했음을 알리는 컴파일 오류가 발생한다. 보통 해결책은 계산의 복잡도를 줄이거나 런타임에 수행하는 것이다.

@subheading 제로-비용 추상화의 철학 (The Philosophy of Zero-Cost Abstraction)

const 평가는 Rust의 제로-비용 추상화에 대한 헌신을 잘 보여준다. 우리는 재귀 함수, 루프, 복잡한 데이터 구조 같은 표현력 높은 고수준 코드를 작성하면서도 손으로 최적화한 기계 코드의 성능을 유지할 수 있다. 추상화 비용은 런타임이 아니라 컴파일 타임에 지불된다.

이 철학은 Rust 설계 전반에 스며들어 있다. 뒤에서 반복자(@ref{1.3.5}), 제네릭 함수, 트레이트 구현으로 어떻게 확장되는지 보게 될 것이다. 각 경우의 목표는 같다: 이해하고 유지보수하기 쉬운 코드를 작성하면서도 손으로 저수준 최적화를 한 것만큼 효율적인 기계 코드를 생성하는 것.

핵심 통찰은 많은 프로그램이 입력이 컴파일 타임에 알려진 계산을 포함한다는 점이다. 구성 값, 수학 상수, 조회 테이블 등은 실행 때마다 다시 계산하는 대신 컴파일 중 한 번 미리 계산할 수 있다. const 평가는 이 최적화를 자동적이고 투명하게 만든다.

@quotation
@strong{@anchor{Exercise 1.24a}연습문제 1.24a:} @ref{1.2.1}의 반복적 팩토리얼도 const로 만들 수 있다. 반복 팩토리얼 프로시저의 const 버전을 정의하라. 그런 다음 0부터 12까지의 팩토리얼을 담는 const 배열을 만들라. (주의: 13!은 @code{u64::MAX}를 넘으므로 12에서 멈춘다.)

@code{FACTORIALS[5]}가 120이고 @code{FACTORIALS[12]}가 479001600인지 확인하여 배열이 올바른지 검증하라.
@end quotation

@quotation
@strong{@anchor{Exercise 1.24b}연습문제 1.24b:} @ref{1.2.4}의 @code{fast_expt} 프로시저를 생각해 보라. 이를 const 함수로 만든 뒤 컴파일 타임에 @math{2^{64} - 1}을 계산하라 (이는 @code{u64}가 표현할 수 있는 최대 값이며 @code{u64::MAX}로도 제공된다).

@code{const MAX: u64 = fast_expt(2, 64);}가 왜 컴파일 오류를 일으키는지(힌트: 오버플로) 설명하고, const 평가로 @math{2^{64} - 1}을 올바르게 계산하는 방법을 보여라.

이제 생각해 보자: 일반 함수 본문(const 문맥이 아님)에서 @code{fast_expt(2, 10)}을 호출하면 컴파일 타임에 평가된다고 보장할 수 있는가? 왜 그런가, 또는 왜 아닌가?
@end quotation

@node	1.2.5, 1.2.6, 1.2.4a, 1.2
@subsection 최대공약수 (Greatest Common Divisors)

두 정수 @math{a}와 @math{b}의 최대공약수(@abbr{GCD})는 @math{a}와 @math{b}를 나눌 때 나머지가 0이 되도록 하는 가장 큰 정수로 정의된다. 예를 들어 16과 28의 @abbr{GCD}는 4이다. @ref{Chapter 2}에서 유리수 산술을 구현하는 방법을 조사할 때 유리수를 기약분수로 만들기 위해 @abbr{GCD}를 계산할 수 있어야 한다. (유리수를 기약분수로 만들려면 분자와 분모를 @abbr{GCD}로 나눠야 한다. 예를 들어 16/28은 4/7로 줄어든다.) 두 정수의 @abbr{GCD}를 찾는 한 가지 방법은 인수분해 후 공통 인수를 찾는 것이지만, 훨씬 효율적인 유명한 알고리즘이 있다.

이 알고리즘의 아이디어는 다음 관찰에 기반한다: @math{r}이 @math{a}를 @math{b}로 나눈 나머지라면, @math{a}와 @math{b}의 공약수는 @math{b}와 @math{r}의 공약수와 정확히 같다. 따라서 다음 식을 사용할 수 있다:

@example
GCD(a,b) = GCD(b,r)
@end example

@noindent
이를 사용하여 @abbr{GCD} 계산 문제를 점점 더 작은 정수 쌍의 @abbr{GCD}를 계산하는 문제로 연속적으로 축소할 수 있다. 예를 들어,

@example
GCD(206,40) = GCD(40,6)
            = GCD(6,4)
            = GCD(4,2)
            = GCD(2,0) = 2
@end example

@noindent
reduces @abbr{GCD}(206, 40) to @abbr{GCD}(2, 0), which is 2.  It is
possible to show that starting with any two positive integers and performing
repeated reductions will always eventually produce a pair where the second
number is 0.  Then the @abbr{GCD} is the other number in the pair.  This
method for computing the @abbr{GCD} is known as 
@newterm{Euclid's Algorithm}.@footnote{Euclid's Algorithm is so called because 
이는 유클리드의 @cite{Elements} (제7권, 기원전 (B.C.) 약 300년)에도 등장한다.
@ref{Knuth (1973)}에 따르면, 이는 알려진 비자명 알고리즘 중 가장 오래된 것으로 볼 수 있다.
고대 이집트의 곱셈 방법(@ref{Exercise 1.18})이 더 오래되었을 가능성이 높지만, Knuth가 설명하듯이 유클리드 알고리즘은 예시의 모음이 아니라 일반 알고리즘으로 제시된 것 중 가장 오래된 것으로 알려져 있다.}

유클리드 알고리즘은 함수로 쉽게 표현할 수 있다:

@example
fn gcd(a: u64, b: u64) -> u64 @{
    if b == 0 @{
        a
    @} else @{
        gcd(b, a % b)
    @}
@}
@end example

@noindent
이는 반복적 프로세스를 생성하며, 단계 수는 관련된 수의 로그에 비례해 증가한다.

유클리드 알고리즘에 필요한 단계 수가 로그형으로 증가한다는 사실은 피보나치 수와 흥미로운 관련이 있다:

@quotation
@strong{라메 정리(Lam@'e's Theorem):} 유클리드 알고리즘이 어떤 쌍의 @abbr{GCD}를 계산하는 데 @math{k}단계를 필요로 한다면, 그 쌍에서 더 작은 수는 @math{k^{\text{th}}} 피보나치 수보다 크거나 같다.@footnote{이 정리는 프랑스의 수학자이자 공학자인 가브리엘 라메(Gabriel Lam@'e)가 1845년에 증명했으며, 그는 수리 물리학에 대한 기여로 널리 알려져 있다. 정리를 증명하기 위해, 유클리드 알고리즘이 @math{k}단계에서 끝나는 @math{{(a_k, b_k)}} 쌍(@math{{a_k \ge b_k}})을 고려한다. 증명은 다음 주장에 기반한다: 축소 과정에서 @math{{(a_{k+1}, b_{k+1})} \to {(a_k, b_k)} \to {(a_{k-1}, b_{k-1})}}가 연속한 세 쌍이라면, @math{b_{k+1} \ge b_k + b_{k-1}}가 성립한다. 이 주장을 확인하려면, 축소 단계가 변환 @math{{a_{k-1} = b_k}}, @math{{b_{k-1} =}} (@math{a_k}를 @math{b_k}로 나눈 나머지)로 정의됨을 고려하라. 두 번째 식은 어떤 양의 정수 @math{q}에 대해 @math{a_k = {qb_k} + {b_{k-1}}}임을 뜻한다. @math{q}는 최소 1이므로 @math{a_k = {qb_k} + b_{k-1} \ge b_k + b_{k-1}}가 된다. 그런데 이전 축소 단계에서 @math{b_{k+1} = a_k}이므로, @math{b_{k+1} = a_k \ge b_k + b_{k-1}}이다. 이는 주장을 확인한다. 이제 알고리즘이 종료하는 데 필요한 단계 수 @math{k}에 대해 귀납법으로 정리를 증명할 수 있다. 결과는 @math{{k = 1}}에서 참인데, 이는 @math{b}가 @math{{\text{Fib}(1) = 1}} 이상이면 충분하기 때문이다. 이제 @math{k} 이하의 모든 정수에 대해 결과가 참이라고 가정하고 @math{{k + 1}}에 대해 성립함을 보이자. 축소 과정에서 연속한 쌍 @math{{(a_{k+1}, b_{k+1})} \to {(a_k, b_k)} \to {(a_{k-1}, b_{k-1})}}를 취하라. 귀납 가정에 의해 @math{b_{k-1} \ge {\text{Fib}(k - 1)}}이고 @math{b_k \ge {\text{Fib}(k)}}이다. 따라서 방금 증명한 주장과 피보나치 수의 정의를 함께 적용하면 @math{b_{k+1} \ge b_k + b_{k-1} \ge {\text{Fib}(k)} + {\text{Fib}(k-1)} = {\text{Fib}(k+1)}}가 된다. 이것으로 라메 정리의 증명이 완성된다.}
@end quotation

@noindent
이 정리를 사용하면 유클리드 알고리즘의 증가 차수를 추정할 수 있다. @math{n}을 두 입력 중 작은 수라고 하자. 프로세스가 @math{k}단계를 필요로 한다면 @math{n \ge {\text{Fib}(k)} \approx {\varphi^k / \sqrt{5}}}여야 한다. 따라서 단계 수 @math{k}는 @math{n}의 로그(@math{\varphi}를 밑으로)로 증가한다. 그러므로 증가 차수는 @math{{\Theta(\log n)}}이다.

@quotation
@strong{@anchor{Exercise 1.20}연습문제 1.20:} 프로시저가 생성하는 프로세스는 물론 인터프리터가 사용하는 규칙에 의존한다. 예로, 위의 반복적 @code{gcd} 프로시저를 생각하라. @ref{1.1.5}에서 논의한 정규 순서 평가로 이 프로시저를 해석한다고 가정하자. (@code{if}에 대한 정규 순서 평가 규칙은 @ref{Exercise 1.5}에 설명되어 있다.) 치환 방법(정규 순서용)을 사용하여 @code{gcd(206, 40)}을 평가할 때 생성되는 프로세스를 보여주고, 실제로 수행되는 @code{remainder} 연산을 표시하라. 정규 순서 평가에서 @code{gcd(206, 40)}을 계산할 때 실제로 수행되는 @code{remainder} 연산은 몇 번인가? 적용 순서 평가에서는?
@end quotation

@node	1.2.6, 1.3, 1.1, 1.2
@subsection 예제: 소수성 판별 (Example: Testing for Primality)

이 절은 정수 @math{n}의 소수성을 확인하는 두 가지 방법을 설명한다. 하나는 증가 차수가 @math{{\Theta(\sqrt{n})}}이고, 다른 하나는 증가 차수가 @math{{\Theta(\log n)}}인 ``확률적'' 알고리즘이다. 이 절 끝의 연습 문제들은 이러한 알고리즘을 바탕으로 한 프로그래밍 프로젝트를 제안한다.

@subsubheading 약수 찾기 (Searching for divisors)

고대부터 수학자들은 소수에 관한 문제에 매혹되어 왔고, 많은 사람들이 수가 소수인지 검사하는 방법을 찾는 문제에 몰두해 왔다. 어떤 수가 소수인지 시험하는 한 가지 방법은 그 수의 약수를 찾는 것이다. 다음 프로그램은 주어진 수 @math{n}의 (1보다 큰) 가장 작은 정수 약수를 찾는다. 2부터 시작하여 연속된 정수로 @math{n}이 나누어지는지 검사하는 단순한 방법을 사용한다.

@example
fn smallest_divisor(n: u64) -> u64 @{
    find_divisor(n, 2)
@}

fn find_divisor(n: u64, test_divisor: u64) -> u64 @{
    if square(test_divisor) > n @{
        n
    @} else if divides(test_divisor, n) @{
        test_divisor
    @} else @{
        find_divisor(n, test_divisor + 1)
    @}
@}

fn divides(a: u64, b: u64) -> bool @{
    b % a == 0
@}
@end example

@noindent
We can test whether a number is prime as follows: @math{n} is prime if and only if
@math{n} is its own smallest divisor.

@example
fn is_prime(n: u64) -> bool @{
    n == smallest_divisor(n)
@}
@end example

@noindent
The end test for @code{find_divisor} is based on the fact that if @math{n} is not
prime it must have a divisor less than or equal to
@math{\sqrt{n}}.@footnote{If @math{d} is a divisor of @math{n}, then so is
@math{{n \,/\, d}}.  But @math{d} and @math{{n \,/\, d}} cannot both be greater than
@math{\sqrt{n}}.}  This means that the algorithm need only test divisors
between 1 and @math{\sqrt{n}}.  Consequently, the number of steps required
to identify @math{n} as prime will have order of growth
@math{{\Theta(\sqrt{n})}}.

@subsubheading The Fermat test

The @math{{\Theta(\log n)}} primality test is based on a result from
number theory known as Fermat's Little Theorem.@footnote{Pierre de Fermat
(1601-1665) is considered to be the founder of modern number theory.  He
obtained many important number-theoretic results, but he usually announced just
the results, without providing his proofs.  Fermat's Little Theorem was stated
in a letter he wrote in 1640.  The first published proof was given by Euler in
1736 (and an earlier, identical proof was discovered in the unpublished
manuscripts of Leibniz).  The most famous of Fermat's results---known as
Fermat's Last Theorem---was jotted down in 1637 in his copy of the book
@cite{Arithmetic} (by the third-century Greek mathematician Diophantus) with
the remark ``I have discovered a truly remarkable proof, but this margin is too
small to contain it.''  Finding a proof of Fermat's Last Theorem became one of
the most famous challenges in number theory.  A complete solution was finally
given in 1995 by Andrew Wiles of Princeton University.}

@quotation
@strong{Fermat's Little Theorem:} If @math{n} is a prime number and @math{a} is any
positive integer less than @math{n}, then @math{a} raised to the @math{n^{\text{th}}} power is
congruent to @math{a} modulo @math{n}.
@end quotation

@noindent
(두 수가 @math{n}으로 나누었을 때 같은 나머지를 가지면 @math{n}에 대해 @newterm{모듈러 합동(congruent modulo)}이라고 한다. 수 @math{a}를 @math{n}으로 나눈 나머지는 @math{a}의 @newterm{모듈러 나머지(remainder of)} @math{n}이라고도 부르며, 간단히 @math{a} @newterm{모듈러(modulo)} @math{n}이라고도 한다.)

@math{n}이 소수가 아니면, 일반적으로 @math{{a < n}}인 대부분의 수는 위의 관계를 만족하지 않는다. 이는 다음과 같은 소수성 판별 알고리즘으로 이어진다: 수 @math{n}이 주어지면 @math{{a < n}}인 임의의 수 @math{a}를 고르고, @math{a^n}을 @math{n}으로 나눈 나머지를 계산한다. 결과가 @math{a}와 다르면 @math{n}은 확실히 소수가 아니다. 결과가 @math{a}라면 @math{n}이 소수일 가능성이 높다. 이제 다른 임의의 @math{a}를 골라 같은 방법으로 시험하라. 역시 식을 만족하면 @math{n}이 소수일 것이라는 신뢰도가 더 높아진다. 더 많은 @math{a} 값을 시험할수록 결과에 대한 신뢰는 증가한다. 이 알고리즘은 페르마 테스트(Fermat test)로 알려져 있다.

페르마 테스트를 구현하려면 어떤 수의 거듭제곱을 다른 수로 모듈러 계산하는 프로시저가 필요하다:

@example
fn expmod(base: u64, exp: u64, m: u64) -> u64 @{
    if exp == 0 @{
        1
    @} else if is_even(exp) @{
        square(expmod(base, exp / 2, m)) % m
    @} else @{
        (base * expmod(base, exp - 1, m)) % m
    @}
@}
@end example

@noindent
이는 @ref{1.2.4}의 @code{fast-expt} 프로시저와 매우 유사하다. 연속적인 제곱을 사용하므로 단계 수는 지수에 대해 로그형으로 증가한다.@footnote{지수 @math{e}가 1보다 큰 경우의 축소 단계는 다음 사실에 기반한다: 임의의 정수 @math{x}, @math{y}, @math{m}에 대해 @math{x}와 @math{y}를 각각 @math{m}으로 나눈 나머지를 구하고 이를 곱한 뒤, 그 결과를 다시 @math{m}으로 나눈 나머지를 취하면 @math{x}와 @math{y}를 곱한 값을 @math{m}으로 나눈 나머지를 얻을 수 있다. 예를 들어 @math{e}가 짝수인 경우, @math{b^{e / 2}}를 @math{m}으로 나눈 나머지를 계산하고 이를 제곱한 뒤, 다시 @math{m}으로 나눈 나머지를 취한다. 이 기법은 @math{m}보다 훨씬 큰 수를 다루지 않고도 계산을 수행할 수 있게 해 주므로 유용하다. (@ref{Exercise 1.25} 참조.)}

페르마 테스트는 1과 @math{{n-1}} 사이의 임의의 수 @math{a}를 선택한 다음, @math{a}의 @math{n^{\text{th}}} 거듭제곱을 @math{n}으로 나눈 나머지가 @math{a}와 같은지 확인하는 방식으로 수행된다. 임의의 수 @math{a}는 환경에 제공되는 @code{random} 프로시저로 선택한다고 가정한다( Rust에서는 보통 @code{rand} 크레이트에서 제공한다).
@code{Random}은 입력 정수보다 작은 음이 아닌 정수를 반환한다. 따라서 1과 @math{{n-1}} 사이의 임의의 수를 얻기 위해 @code{random}에 @math{{n-1}}을 입력하고 결과에 1을 더한다:

@example
fn fermat_test(n: u64) -> bool @{
    fn try_it(a: u64, n: u64) -> bool @{
        expmod(a, n, n) == a
    @}
    // 참고: rand 크레이트의 random() 함수 사용
    // Rust: use rand::Rng; let a = rand::thread_rng().gen_range(1..n);
    let a = 1 + (rand::random::<u64>() % (n - 1));
    try_it(a, n)
@}
@end example

@noindent
다음 프로시저는 매개변수로 지정된 횟수만큼 테스트를 수행한다. 매번 테스트가 성공하면 true이고, 그렇지 않으면 false이다.

@example
fn fast_prime(n: u64, times: u64) -> bool @{
    if times == 0 @{
        true
    @} else if fermat_test(n) @{
        fast_prime(n, times - 1)
    @} else @{
        false
    @}
@}
@end example

@subsubheading 확률적 방법 (Probabilistic methods)

페르마 테스트는 정답을 보장하는 계산을 수행하는 대부분의 익숙한 알고리즘들과 성격이 다르다.
여기서 얻은 답은 단지 확률적으로만 옳다.
더 정확히 말하면, 만약 @math{n}이 페르마 테스트를 통과하지 못하면 @math{n}은 확실히 소수가 아니다.
하지만 @math{n}이 테스트를 통과한다는 사실은 매우 강력한 징후이긴 하지만 여전히 @math{n}이 소수라는 보장은 아니다.
우리가 말하고 싶은 것은 어떤 수 @math{n}에 대해, 만약 우리가 충분히 여러 번 테스트를 수행하여 @math{n}이 항상 테스트를 통과한다면, 우리의 소수성 판별에서 오류 확률을 우리가 원하는 만큼 작게 만들 수 있다는 것이다.

불행히도, 이 주장은 완전히 옳지는 않다.
페르마 테스트를 속이는 수들이 존재한다: 소수가 아니면서도 모든 정수 @math{{a < n}}에 대해 @math{a^n}이 @math{n}에 대해 @math{a}와 합동이라는 성질을 갖는 수 @math{n}이 있다.
그러한 수는 극히 드물기 때문에 페르마 테스트는 실제로는 꽤 신뢰할 만하다.@footnote{@anchor{Footnote 47} 페르마 테스트를 속이는 수를 @newterm{카마이클 수(Carmichael numbers)}라고 부르며, 극히 드물다는 것 외에는 알려진 바가 거의 없다.
100,000,000 미만에는 255개의 카마이클 수가 있다.
가장 작은 몇 개는 561, 1105, 1729, 2465, 2821, 그리고 6601이다.
무작위로 선택된 매우 큰 수의 소수성을 검사할 때, 페르마 테스트를 속이는 값을 우연히 만날 확률은 ``정확한'' 알고리즘을 수행하는 중에 우주 방사선이 컴퓨터에 오류를 일으킬 확률보다 낮다.
첫 번째 이유로는 알고리즘이 부적절하다고 간주하지만 두 번째 이유로는 그렇지 않다고 간주하는 것은 수학과 공학의 차이를 보여준다.}

속일 수 없는 페르마 테스트의 변형들이 있다.
이러한 테스트에서는 페르마 방법과 마찬가지로 정수 @math{n}의 소수성을 테스트하기 위해
@math{{a < n}}인 임의의 정수를 선택하고 @math{n}과 @math{a}에 의존하는 어떤 조건을 검사한다. (그런 테스트의 예는 @ref{Exercise 1.28}을 보라.)
반면 페르마 테스트와 달리, 어떤 @math{n}에 대해서도 @math{n}이 소수가 아니면 @math{{a < n}}인 대부분의 정수는 그 조건을 만족하지 않음을 증명할 수 있다. 따라서 임의의 @math{a} 선택에서 @math{n}이 테스트를 통과하면, @math{n}이 소수일 가능성은 절반보다 높다. 임의의 @math{a} 두 번의 선택에서 테스트를 통과하면, @math{n}이 소수일 가능성은 4분의 3보다 높다. 더 많은 임의의 @math{a} 값으로 테스트를 반복할수록 오류 확률을 원하는 만큼 작게 만들 수 있다.

오류 확률이 임의로 작아짐을 증명할 수 있는 테스트의 존재는 이러한 유형의 알고리즘에 대한 관심을 불러일으켰고, 이들은 @newterm{확률적 알고리즘(probabilistic algorithms)}으로 알려지게 되었다. 이 분야에는 많은 연구가 진행되고 있으며, 확률적 알고리즘은 여러 분야에 유익하게 적용되어 왔다.@footnote{확률적 소수 판별의 가장 인상적인 응용 중 하나는 암호학이다. 임의의 200자리 수를 인수분해하는 것은 이제 계산적으로 불가능하지만, 그 수의 소수성은 페르마 테스트로 몇 초 만에 확인할 수 있다. 이 사실은 @ref{Rivest et al. (1977)}이 제안한 ``깨지지 않는 코드''를 구성하는 기법의 기반을 이룬다. 그 결과인 @newterm{RSA 알고리즘(RSA algorithm)}은 전자 통신 보안을 강화하는 데 널리 사용되는 기법이 되었다. 이와 관련된 발전 때문에, 한때 ``순수'' 수학에서 그 자체로만 연구되는 주제의 전형으로 여겨졌던 소수 연구가 이제 암호학, 전자 자금 이체, 정보 검색에 중요한 실용적 응용을 갖는 것으로 드러났다.}

@quotation
@strong{@anchor{Exercise 1.21}연습문제 1.21:} @code{smallest_divisor} 프로시저를 사용하여 다음 수들의 가장 작은 약수를 찾아라: 199, 1999, 19999.
@end quotation

@quotation
@strong{@anchor{Exercise 1.22}연습문제 1.22:} 대부분의 Lisp 구현은 @code{runtime}이라는 기본 프로시저를 포함하고 있는데, 이는 시스템이 실행된 시간을 나타내는 정수를 반환한다(예: 마이크로초 단위). 다음 @code{timed_prime_test} 프로시저는 정수 @math{n}으로 호출되면 @math{n}을 출력하고 @math{n}이 소수인지 검사한다. @math{n}이 소수라면 프로시저는 별표 세 개와 테스트에 사용된 시간을 출력한다.

@example
fn timed_prime_test(n: u64) @{
    println!();
    print!("@{@}", n);
    start_prime_test(n, Instant::now());
@}
@end example

@example
fn start_prime_test(n: u64, start_time: Instant) @{
    if is_prime(n) @{
        report_prime(start_time.elapsed());
    @}
@}
@end example

@example
fn report_prime(elapsed_time: Duration) @{
    print!(" *** ");
    print!("@{:?@}", elapsed_time);
@}
@end example

이 프로시저를 사용하여 지정된 범위의 연속된 홀수를 검사하는 @code{search_for_primes} 프로시저를 작성하라. 이 프로시저로 1000보다 큰 가장 작은 소수 3개, 10,000보다 큰 가장 작은 소수 3개, 100,000보다 큰 가장 작은 소수 3개, 1,000,000보다 큰 가장 작은 소수 3개를 찾아라. 각 소수를 테스트하는 데 걸리는 시간을 기록하라. 테스트 알고리즘의 증가 차수는 @math{{\Theta(\sqrt{n})}}이므로, 10,000 근처의 소수를 검사하는 데 걸리는 시간은 1000 근처를 검사하는 시간의 약 @math{\sqrt{10}}배가 될 것으로 예상해야 한다. 시간 측정 데이터가 이를 뒷받침하는가? 100,000과 1,000,000에 대한 데이터는 @math{{\Theta(\sqrt{n})}} 예측을 얼마나 잘 지지하는가? 여러분의 결과는 여러분의 기계에서 프로그램이 계산에 필요한 단계 수에 비례하는 시간에 실행된다는 관념과 양립하는가?
@end quotation

@quotation
@strong{@anchor{Exercise 1.23}연습문제 1.23:} 이 절의 시작에서 보인 @code{smallest_divisor} 프로시저는 불필요한 테스트를 많이 수행한다:
일단 수가 2로 나누어지는지 확인한 후에는 더 큰 짝수로 나누어지는지 확인할 필요가 없다.
이는 @code{test-divisor}에 사용되는 값이 2, 3, 4, 5, 6, @dots{}이 아니라 2, 3, 5, 7, 9, @dots{}가 되어야 함을 시사한다.
이 변경을 구현하기 위해, 입력이 2와 같으면 3을 반환하고 그렇지 않으면 입력 더하기 2를 반환하는 프로시저 @code{next}를 정의하라.
@code{smallest_divisor} 프로시저가 @code{(+ test-divisor 1)} 대신 @code{(next test-divisor)}를 사용하도록 수정하라.
@code{smallest_divisor}의 이 수정된 버전을 포함하는 @code{timed_prime_test}로 @ref{Exercise 1.22}에서 찾은 12개의 소수 각각에 대해 테스트를 실행하라.
이 수정은 테스트 단계의 수를 절반으로 줄이므로, 약 두 배 더 빠르게 실행될 것으로 예상해야 한다.
이 예상이 확인되었는가? 만약 그렇지 않다면, 두 알고리즘의 속도 비율은 얼마로 관찰되었으며, 그것이 2와 다르다는 사실을 어떻게 설명하겠는가?
@end quotation

@quotation
@strong{@anchor{Exercise 1.24}연습문제 1.24:} @ref{Exercise 1.22}의 @code{timed_prime_test} 프로시저를 @code{fast_prime} (페르마 방법)을 사용하도록 수정하고, 그 연습 문제에서 찾은 12개의 소수 각각을 테스트하라.
페르마 테스트는 @math{{\Theta(\log n)}}의 증가 차수를 가지므로, 1,000,000 근처의 소수를 테스트하는 시간이 1000 근처의 소수를 테스트하는 시간과 비교하여 어떨 것으로 예상하는가?
여러분의 데이터가 이를 뒷받침하는가? 발견된 불일치가 있다면 설명할 수 있는가?
@end quotation

@quotation
@strong{@anchor{Exercise 1.25}연습문제 1.25:} Alyssa P. Hacker는 우리가 @code{expmod}를 작성하는 데 너무 많은 추가 작업을 했다고 불평한다.
그녀의 말에 따르면, 우리는 이미 거듭제곱을 계산하는 방법을 알고 있으므로, 다음과 같이 간단히 쓸 수 있었다는 것이다:

@example
fn expmod(base: u64, exp: u64, m: u64) -> u64 @{
    fast_expt(base, exp) % m
@}
@end example

그녀가 옳은가? 이 프로시저가 우리의 빠른 소수 테스터로서도 잘 작동할까? 설명하라.
@end quotation

@quotation
@strong{@anchor{Exercise 1.26}연습문제 1.26:} 루이스 리즈너(Louis Reasoner)는 @ref{Exercise 1.24}를 하는 데 큰 어려움을 겪고 있다. 그의 @code{fast_prime} 테스트가 @code{is_prime} 테스트보다 더 느리게 실행되는 것처럼 보인다. 루이스는 친구 에바 루 에이터(Eva Lu Ator)를 불러 도움을 청한다. 두 사람이 루이스의 코드를 살펴보니, 그는 @code{square}를 호출하는 대신 명시적인 곱셈을 사용하도록 @code{expmod} 프로시저를 다시 작성했다:

@example
fn expmod(base: u64, exp: u64, m: u64) -> u64 @{
    if exp == 0 @{
        1
    @} else if is_even(exp) @{
        (expmod(base, exp / 2, m) * expmod(base, exp / 2, m)) % m
    @} else @{
        (base * expmod(base, exp - 1, m)) % m
    @}
@}
@end example

``그게 무슨 차이를 만들지 모르겠어.''라고 루이스가 말한다. @w{``난 알아.''}라고 에바가 말한다. ``그렇게 프로시저를 작성하면 @math{{\Theta(\log n)}} 프로세스를 @math{{\Theta(n)}} 프로세스로 바꿔버린 거야.'' 설명하라.
@end quotation

@quotation
@strong{@anchor{Exercise 1.27}연습문제 1.27:} @ref{Footnote 47}에 나열된 카마이클 수(Carmichael numbers)가 실제로 페르마 테스트를 속인다는 것을 보여라. 즉, 정수 @math{n}을 입력으로 받아 모든 @math{{a < n}}에 대해 @math{a^n}이 @math{a}와 @math{n}에 대해 합동인지 검사하는 프로시저를 작성하고, 주어진 카마이클 수에 대해 그 프로시저를 실행해 보라.
@end quotation

@quotation
@strong{@anchor{Exercise 1.28}연습문제 1.28:} 페르마 테스트의 변형 중 속일 수 없는 것으로 알려진 것이 @newterm{밀러-라빈 테스트(Miller-Rabin test)}이다(@ref{Miller 1976}; @ref{Rabin 1980}). 이는 페르마의 소정리의 다른 형태에서 시작한다. 즉, @math{n}이 소수이고 @math{a}가 @math{n}보다 작은 양의 정수라면, @math{a}의 @math{{(n-1)}}제곱은 @math{n}에 대해 1과 합동이라는 것이다. 밀러-라빈 테스트로 @math{n}의 소수성을 검사하려면 @math{{a < n}}인 임의의 수를 고르고 @code{expmod} 프로시저로 @math{a}의 @math{{(n-1)}}제곱을 @math{n}으로 모듈러 계산한다. 그런데 @code{expmod}에서 제곱 단계마다 ``@math{n}에 대한 1의 비자명한 제곱근''을 발견했는지 확인한다. 즉, 1이나 @math{{n-1}}이 아니면서 제곱이 @math{n}에 대해 1과 합동인 수다. 이런 비자명한 제곱근이 존재하면 @math{n}은 소수가 아님을 증명할 수 있다. 또한 @math{n}이 홀수이면서 소수가 아니라면, 적어도 절반의 @math{{a < n}}에 대해 이 방법으로 @math{a^{n-1}}을 계산하면 @math{n}에 대한 1의 비자명한 제곱근이 드러난다는 것도 증명할 수 있다. (이 때문에 밀러-라빈 테스트는 속일 수 없다.) @code{expmod} 프로시저를 수정하여 비자명한 제곱근을 발견하면 신호하도록 만들고, 이를 사용해 @code{fermat-test}와 유사한 프로시저로 밀러-라빈 테스트를 구현하라. 알려진 소수와 합성수에 대해 테스트하여 프로시저를 확인하라. 힌트: @code{expmod}가 신호를 보내게 하는 편리한 방법 중 하나는 0을 반환하게 만드는 것이다.
@end quotation

@node	1.3, Chapter 2, 1.2, Chapter 1
@section 고차 프로시저를 이용한 추상화의 정식화 (Formulating Abstractions with Higher-Order Procedures)

우리는 프로시저가 실제로 특정 숫자와는 독립적으로 숫자에 대한 복합 연산을 설명하는 추상화임을 보았다. 예를 들어, 우리가 다음과 같이 쓸 때

@example
fn cube(x: i64) -> i64 @{
    x * x * x
@}
@end example

@noindent
우리는 특정한 수의 세제곱을 말하는 것이 아니라, 어떤 수든 세제곱을 구하는 방법을 말하고 있다. 물론 이 프로시저를 정의하지 않고도 다음과 같은 표현식을 매번 직접 써서 지낼 수도 있다:

@example
3 * 3 * 3
x * x * x
y * y * y
@end example

@noindent
그리고 @code{cube}를 명시적으로 언급하지 않을 수도 있다.
이것은 우리를 심각한 불이익에 빠뜨릴 것인데, 왜냐하면 우리가 더 높은 수준의 연산 관점에서 일하는 대신 언어의 원시 연산(이 경우 곱셈) 수준에서 항상 일하도록 강요하기 때문이다.
우리의 프로그램은 세제곱을 계산할 수 있겠지만, 우리 언어는 세제곱하기라는 개념을 표현할 능력이 부족할 것이다.
우리가 강력한 프로그래밍 언어에 요구해야 할 것 중 하나는 공통 패턴에 이름을 부여하여 추상화를 구축하고, 그 추상화 관점에서 직접 작업할 수 있는 능력이다.
프로시저는 이 능력을 제공한다.
이것이 가장 원시적인 프로그래밍 언어를 제외한 모든 언어가 프로시저 정의 메커니즘을 포함하는 이유이다.

그러나 수치 처리에서조차, 만약 우리가 매개변수가 숫자여야만 하는 프로시저로 제한된다면 추상화를 생성하는 능력에 심각한 제약을 받을 것이다.
종종 동일한 프로그래밍 패턴이 여러 다른 프로시저와 함께 사용된다.
그러한 패턴을 개념으로 표현하기 위해, 우리는 프로시저를 인자로 받거나 프로시저를 값으로 반환할 수 있는 프로시저를 구축할 필요가 있다.
프로시저를 조작하는 프로시저를 @newterm{고차 프로시저(higher-order procedures)}라고 부른다.
이 절은 고차 프로시저가 어떻게 강력한 추상화 메커니즘으로 작용하여 우리 언어의 표현력을 크게 향상할 수 있는지 보여준다.

@menu
* 1.3.1::            Procedures as Arguments
* 1.3.2::            Constructing Procedures Using Closures
* 1.3.3::            Procedures as General Methods
* 1.3.4::            Procedures as Returned Values
* 1.3.5::            Iterator Combinators and Zero-Cost Abstraction
@end menu

@node	1.3.1, 1.3.2, 1.3, 1.3
@subsection 인자로서의 프로시저 (Procedures as Arguments)

다음 세 가지 프로시저를 고려해 보자. 첫 번째는 @code{a}부터 @code{b}까지의 정수 합을 계산한다:

@example
fn sum_integers(a: i64, b: i64) -> i64 @{
    if a > b @{
        0
    @} else @{
        a + sum_integers(a + 1, b)
    @}
@}
@end example

@noindent
두 번째는 주어진 범위의 정수 세제곱의 합을 계산한다:

@example
fn sum_cubes(a: i64, b: i64) -> i64 @{
    if a > b @{
        0
    @} else @{
        cube(a) + sum_cubes(a + 1, b)
    @}
@}
@end example

@noindent
세 번째는 다음 급수의 항들의 합을 계산한다:
@ifinfo

@example
  1       1       1
----- + ----- + ------ + ...
1 * 3   5 * 7   9 * 11
@end example

@end ifinfo
@tex

\[ % :17:
  
\frac{1}{1\cdot 3} +  \frac{1}{5\cdot 7} + \frac{1}{9\cdot 11} + {\dots,}
\]

@end tex
@noindent
이 급수는 @math{{\pi / 8}}로 (매우 느리게) 수렴한다:@footnote{이 급수는 보통 동치 형태인 
@math{{\pi\over4} = {1 - {1\over3} + {1\over5}} - {{1\over7} + \dots}}로 쓰이며, 라이프니츠(Leibniz)가 제안했다. @ref{3.5.3}에서 이를 바탕으로 한 흥미로운 수치 기법을 보게 될 것이다.}

@example
fn pi_sum(a: i64, b: i64) -> f64 @{
    if a > b @{
        0.0
    @} else @{
        1.0 / (a as f64 * (a as f64 + 2.0)) + pi_sum(a + 4, b)
    @}
@}
@end example

@noindent
이 세 프로시저는 공통된 바탕 패턴을 분명히 공유한다. 대부분이 동일하며, 프로시저의 이름, 더할 항을 계산하는 @code{a}의 함수, 그리고 다음 @code{a} 값을 제공하는 함수만 다르다. 같은 템플릿의 빈칸을 채우면 각각의 프로시저를 생성할 수 있다:

@example
fn ⟨@var{name}⟩(a: i64, b: i64) -> i64 @{
    if a > b @{
        0
    @} else @{
        ⟨@var{term}⟩(a) + ⟨@var{name}⟩(⟨@var{next}⟩(a), b)
    @}
@}
@end example

@noindent
이러한 공통 패턴의 존재는 유용한 추상화가 표면 위로 드러나기를 기다리고 있다는 강력한 증거다. 실제로 수학자들은 오래전에 @newterm{급수의 합(summation of a series)}이라는 추상화를 식별하고 ``시그마 표기법(sigma notation)''을 고안했다. 예를 들어:
@ifinfo

@example
  b
 ---
 >    f(n) = f(a) + ... + f(b)
 ---
 n=a
@end example

@end ifinfo
@tex

\[ % :18:
 
{\sum_{n = a}^b f(n)} \,=\, {f(a)} + \dots + {f(b),}
\]

@end tex
@noindent
이 개념을 표현하기 위해.
시그마 표기법의 힘은 수학자들이 특정한 합뿐만 아니라 합(summation)이라는 개념 자체를 다룰 수 있게 한다는 점이다---예를 들어, 더해지는 특정 급수와 무관하게 합에 대한 일반적인 결과를 공식화할 수 있다.

마찬가지로, 프로그램 설계자로서 우리는 우리 언어가 특정 합을 계산하는 프로시저뿐만 아니라 합이라는 개념 자체를 표현하는 프로시저를 작성할 수 있을 만큼 강력하기를 원한다.
우리는 위에서 보인 공통 템플릿을 가져와서 ``슬롯''을 형식 매개변수로 변환함으로써 우리 절차적 언어에서 이를 쉽게 수행할 수 있다:

@example
fn sum<F, N>(term: F, a: i64, next: N, b: i64) -> i64
where
    F: Fn(i64) -> i64,
    N: Fn(i64) -> i64,
@{
    if a > b @{
        0
    @} else @{
        term(a) + sum(term, next(a), next, b)
    @}
@}
@end example

@noindent
@code{sum}이 하한과 상한 @code{a}와 @code{b}를 프로시저 @code{term} 및 @code{next}와 함께 인자로 받는다는 점에 주목하라.
Rust에서 우리는 제네릭 타입 매개변수 @code{F}와 @code{N}에 트레이트 바운드 @code{Fn(i64) -> i64}를 사용하여 이 매개변수들이 @code{i64}를 받아 @code{i64}를 반환하는 함수임을 명시한다. @code{Fn} 트레이트는 자신을 소비하지 않고 여러 번 호출될 수 있는 함수와 클로저를 나타낸다.
우리는 다른 프로시저와 마찬가지로 @code{sum}을 사용할 수 있다. 예를 들어, (인자를 1만큼 증가시키는 프로시저 @code{inc}와 함께) 이것을 사용하여 @code{sum_cubes}를 정의할 수 있다:

@example
fn inc(n: i64) -> i64 @{
    n + 1
@}

fn sum_cubes(a: i64, b: i64) -> i64 @{
    sum(cube, a, inc, b)
@}
@end example

@noindent
이것을 사용하여 우리는 1부터 10까지 정수의 세제곱 합을 계산할 수 있다:

@example
sum_cubes(1, 10)
// => 3025
@end example

@noindent
항을 계산하는 항등(identity) 프로시저의 도움을 받아, 우리는 @code{sum}으로 @code{sum_integers}를 정의할 수 있다:

@example
fn identity(x: i64) -> i64 @{
    x
@}

fn sum_integers(a: i64, b: i64) -> i64 @{
    sum(identity, a, inc, b)
@}
@end example

@noindent
그러면 우리는 1부터 10까지의 정수를 더할 수 있다:

@example
sum_integers(1, 10)
// => 55
@end example

@noindent
우리는 또한 @code{pi_sum}을 같은 방식으로 정의할 수 있다:@footnote{@code{pi_next}와 @code{pi_term}이 다른 목적으로 유용할 가능성이 낮기 때문에 블록 구조(@ref{1.1.8})를 사용하여 그 정의를 @code{pi_sum} 내부에 포함시킨 것에 주목하라. Rust에서는 이것들을 외부 함수 내의 지역 함수로 정의한다. 우리는 @ref{1.3.2}에서 클로저를 사용하여 이것들을 완전히 제거하는 방법을 보게 될 것이다.}

@example
fn pi_sum(a: i64, b: i64) -> f64 @{
    fn pi_term(x: i64) -> f64 @{
        1.0 / (x as f64 * (x as f64 + 2.0))
    @}
    fn pi_next(x: i64) -> i64 @{
        x + 4
    @}
    sum(pi_term, a, pi_next, b) as f64
@}
@end example

@noindent
이 프로시저들을 사용하여 우리는 @math{\pi}에 대한 근사값을 계산할 수 있다:

@example
8.0 * pi_sum(1, 1000)
// => 3.139592655589783
@end example

@noindent
일단 @code{sum}이 있으면, 우리는 이것을 더 많은 개념을 공식화하는 구성 요소로 사용할 수 있다.
예를 들어, 함수 @math{f}의 범위 @math{a}와 @math{b} 사이의 정적분은 다음 공식을 사용하여 수치적으로 근사할 수 있다.
@ifinfo

@example
/b     /  /     dx \    /          dx \    /           dx \      \
|  f = | f| a + -- | + f| a + dx + -- | + f| a + 2dx + -- | + ...| dx
/a     \  \     2  /    \          2  /    \           2  /      /
@end example

@end ifinfo
@tex

\[ % :19:
 
{\int_a^b \kern-0.3em f}
  \;=\; {\left[\;f\left(a + \frac{d x}{2}\right)\right.}
  \,+\, {f\left(a + dx + \frac{dx}{2}\right)}
  \,+\, {\left. f\left(a + 2dx + \frac{dx}{2}\right)
  \,+\, \dots \;\right] dx}
\]

@end tex
@noindent
여기서 @math{{dx}}는 작은 값이다. 우리는 이것을 프로시저로 직접 표현할 수 있다:

@example
fn integral<F>(f: F, a: f64, b: f64, dx: f64) -> f64
where
    F: Fn(f64) -> f64,
@{
    fn sum_f64<F, N>(term: F, a: f64, next: N, b: f64) -> f64
    where
        F: Fn(f64) -> f64,
        N: Fn(f64) -> f64,
    @{
        if a > b @{
            0.0
        @} else @{
            term(a) + sum_f64(term, next(a), next, b)
        @}
    @}

    let add_dx = |x| x + dx;
    sum_f64(f, a + dx / 2.0, add_dx, b) * dx
@}

integral(|x| x * x * x, 0.0, 1.0, 0.01)
// => 0.24998750000000042

integral(|x| x * x * x, 0.0, 1.0, 0.001)
// => 0.249999875000001
@end example

@noindent
(0과 1 사이의 @code{cube} 적분의 정확한 값은 1/4이다.)

@code{integral} 함수에서 @code{add_dx}를 정의하기 위해 Rust의 클로저 구문을 사용했다는 점에 주목하라: 표현식 @code{|x| x + dx}는 감싸고 있는 스코프에서 @code{dx} 변수를 캡처하는 클로저를 생성한다.
세로 막대 @code{|...|}는 매개변수 목록을 감싸며, 그 뒤의 표현식은 클로저 본문이다.
우리는 또한 @code{|x| x * x * x} 클로저를 @code{integral}의 인자로 직접 전달했는데, 이는 클로저의 이름을 짓지 않고도 인라인으로 생성할 수 있음을 보여준다.

@quotation
@strong{@anchor{Exercise 1.29}연습문제 1.29:} 심슨의 규칙(Simpson's Rule)은 위에서 예시된 방법보다 더 정확한 수치 적분 방법이다.
심슨의 규칙을 사용하면, @math{a}와 @math{b} 사이의 함수 @math{f}의 적분은 다음과 같이 근사된다.
@ifinfo

@example
h
- (y_0 + 4y_1 + 2y_2 + 4y_3 + 2y_4 + ... + 2y_(n-2) + 4y_(n-1) + y_n)
3
@end example

@end ifinfo
@tex

\[ % :20:
  
\frac{h}{3}(y_0 + {4y_1} + {2y_2} + {4y_3} + {2y_4} + \dots + {2y_{n-2}} + {4y_{n-1} + y_n),}
\]

@end tex
@noindent
여기서 @math{{h = (b - a)/n}}이고 @math{n}은 짝수이며, @math{y_k = {f(a + kh)}}이다. (@math{n}을 늘리면 근사값의 정확도가 증가한다.)
@math{f}, @math{a}, @math{b}, 그리고 @math{n}을 인자로 받아 심슨의 규칙을 사용하여 계산된 적분 값을 반환하는 프로시저를 정의하라.
여러분의 프로시저를 사용하여 0과 1 사이의 @code{cube}를 적분하고(@math{{n = 100}}과 @math{{n = 1000}}으로), 결과를 위에 나온 @code{integral} 프로시저의 결과와 비교하라.
@end quotation

@quotation
@strong{@anchor{Exercise 1.30}연습문제 1.30:} 위의 @code{sum} 프로시저는 선형 재귀를 생성한다.
이 프로시저는 합을 반복적으로 수행하도록 다시 작성될 수 있다.
다음 정의에서 누락된 표현식을 채워서 이를 수행하는 방법을 보여라:

@example
fn sum<F, N>(term: F, a: i64, next: N, b: i64) -> i64
where
    F: Fn(i64) -> i64,
    N: Fn(i64) -> i64,
@{
    fn iter<F, N>(term: &F, next: &N, a: i64, b: i64, result: i64) -> i64
    where
        F: Fn(i64) -> i64,
        N: Fn(i64) -> i64,
    @{
        if ⟨??⟩ @{
            ⟨??⟩
        @} else @{
            iter(term, next, ⟨??⟩, b, ⟨??⟩)
        @}
    @}
    iter(&term, &next, ⟨??⟩, b, ⟨??⟩)
@}
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 1.31}연습문제 1.31:} 

@enumerate a

@item
@code{sum} 프로시저는 고차 프로시저로서 포착될 수 있는 수많은 유사한 추상화들 중 가장 단순한 것일 뿐이다.@footnote{@ref{Exercise 1.31}부터 @ref{Exercise 1.33}까지의 의도는 겉보기에 서로 다른 많은 연산들을 통합하기 위해 적절한 추상화를 사용함으로써 얻을 수 있는 표현력을 보여주는 것이다. 그러나 누산(accumulation)과 필터링(filtering)이 우아한 아이디어이긴 하지만, 이 시점에서는 이러한 추상화를 위한 적절한 조합 수단을 제공할 데이터 구조가 아직 없기 때문에 사용하는 데 다소 제약이 있다. 우리는 @ref{2.2.3}에서 필터와 누산기를 결합하여 훨씬 더 강력한 추상화를 구축하기 위한 인터페이스로 @newterm{시퀀스(sequences)}를 사용하는 방법을 보여줄 때 이 아이디어들을 다시 다룰 것이다. 우리는 거기서 이러한 방법들이 프로그램 설계를 위한 강력하고 우아한 접근 방식으로서 진정으로 빛을 발하는 것을 보게 될 것이다.}
주어진 범위의 점들에서 함수의 값들의 곱을 반환하는 @code{product}라는 유사한 프로시저를 작성하라.
@code{product}를 사용하여 @code{factorial}을 정의하는 방법을 보여라.
또한 @code{product}를 사용하여 다음 공식을 통해 @math{\pi}의 근사값을 계산하라.@footnote{이 공식은 17세기 영국 수학자 존 월리스(John Wallis)가 발견했다.}
@ifinfo

@example
pi   2 * 4 * 4 * 6 * 6 * 8 ...
-- = -------------------------
 4   3 * 3 * 5 * 5 * 7 * 7 ...
@end example

@end ifinfo
@tex

\[ % :21:
  
\frac{\pi}{4} \,=\, {\frac{2\cdot 4\cdot 4\cdot 6\cdot 6\cdot 8\cdot\cdots}
                     {3\cdot 3\cdot 5\cdot 5\cdot 7\cdot 7\cdot\cdots}.}
\]

@end tex
@item
여러분의 @code{product} 프로시저가 재귀적 프로세스를 생성한다면, 반복적 프로세스를 생성하는 것을 하나 작성하라.
반복적 프로세스를 생성한다면, 재귀적 프로세스를 생성하는 것을 하나 작성하라.

@end enumerate
@end quotation

@quotation
@strong{@anchor{Exercise 1.32}연습문제 1.32:} 

@enumerate a

@item
@code{sum}과 @code{product}(@ref{Exercise 1.31})가 둘 다 일반적인 누산 함수를 사용하여 항들의 컬렉션을 결합하는, @code{accumulate}라고 불리는 더 일반적인 개념의 특수한 경우임을 보여라:

@example
accumulate(combiner, null_value, term, a, next, b)
@end example

@code{Accumulate}는 @code{sum} 및 @code{product}와 동일한 항과 범위 명세를 인자로 받으며, 여기에 현재 항을 이전 항들의 누적과 결합하는 방법을 지정하는 (두 인자의) @code{combiner} 프로시저와 항이 소진되었을 때 사용할 기본값을 지정하는 @code{null-value}를 함께 받는다.
@code{accumulate}를 작성하고, @code{sum}과 @code{product}를 @code{accumulate}에 대한 단순한 호출로 정의할 수 있음을 보여라.

@item
여러분의 @code{accumulate} 프로시저가 재귀적 프로세스를 생성한다면, 반복적 프로세스를 생성하는 것을 하나 작성하라.
반복적 프로세스를 생성한다면, 재귀적 프로세스를 생성하는 것을 하나 작성하라.

@end enumerate
@end quotation

@quotation
@strong{@anchor{Exercise 1.33}연습문제 1.33:} 결합될 항들에 대한 @newterm{필터(filter)} 개념을 도입함으로써 @code{accumulate}(@ref{Exercise 1.32})의 훨씬 더 일반적인 버전을 얻을 수 있다.
즉, 범위 내의 값들로부터 파생된 항들 중에서 지정된 조건을 만족하는 것들만 결합하는 것이다.
결과적으로 얻어지는 @code{filtered_accumulate} 추상화는 accumulate와 동일한 인자들을 받으며, 여기에 필터를 지정하는 1인자 술어가 추가된다.
@code{filtered_accumulate}를 프로시저로 작성하라.
@code{filtered_accumulate}를 사용하여 다음을 표현하는 방법을 보여라:

@enumerate a

@item
구간 @math{a}에서 @math{b} 사이의 소수들의 제곱의 합 (이미 @code{is_prime} 술어가 작성되어 있다고 가정한다).

@item
@math{n}보다 작으면서 @math{n}과 서로소인 모든 양의 정수의 곱 (즉, @math{{\text{GCD}(i, n) = 1}}인 모든 양의 정수 @math{{i < n}}).

@end enumerate
@end quotation

@node	1.3.2, 1.3.3, 1.3.1, 1.3
@subsection 클로저를 이용한 프로시저 구축 (Constructing Procedures Using Closures)

@ref{1.3.1}에서처럼 @code{sum}을 사용할 때, 단지 고차 프로시저의 인자로 사용하기 위해 @code{pi_term}이나 @code{pi_next}와 같은 사소한 프로시저를 정의해야 하는 것은 몹시 어색해 보인다.
@code{pi_next}와 @code{pi_term}을 정의하는 대신, ``입력을 4만큼 증가시켜 반환하는 프로시저''와 ``입력에 2를 더한 것과 입력의 곱의 역수를 반환하는 프로시저''를 직접 명시하는 방법이 있다면 더 편리할 것이다.
우리는 익명 함수를 생성하는 Rust의 @newterm{클로저(closure)} 문법을 사용하여 이를 수행할 수 있다.
클로저를 사용하여 우리가 원하는 것을 다음과 같이 기술할 수 있다:

@example
|x| x + 4
@end example

@noindent
그리고

@example
|x| 1.0 / (x * (x + 2.0))
@end example

@noindent
그러면 우리의 @code{pi_sum} 프로시저는 어떤 보조 프로시저도 정의하지 않고 다음과 같이 표현될 수 있다:

@example
fn pi_sum(a: i32, b: i32) -> f64 @{
    sum(|x| 1.0 / (x as f64 * (x as f64 + 2.0)),
        a,
        |x| x + 4,
        b)
@}
@end example

@noindent
다시 클로저를 사용하여, 우리는 보조 프로시저 @code{add_dx}를 정의하지 않고도 @code{integral} 프로시저를 작성할 수 있다:

@example
fn integral<F>(f: F, a: f64, b: f64, dx: f64) -> f64
where
    F: Fn(f64) -> f64,
@{
    sum(f, a + dx / 2.0, |x| x + dx, b) * dx
@}
@end example

@noindent
일반적으로 클로저는 함수의 이름이 지정되지 않는다는 점을 제외하면 @code{fn}과 같은 방식으로 익명 함수를 생성하는 데 사용된다:

@example
|⟨@var{formal-parameters}⟩| ⟨@var{body}⟩
@end example

@noindent
결과로 생성되는 클로저는 @code{fn}을 사용하여 생성된 것과 똑같은 함수이다.
유일한 차이점은 환경의 어떤 이름과도 연관되지 않았다는 것이다.
사실,

@example
fn plus4(x: i32) -> i32 @{ x + 4 @}
@end example

@noindent
은 다음과 동등하다

@example
let plus4 = |x: i32| x + 4;
@end example

@noindent
우리는 클로저 표현식을 다음과 같이 읽을 수 있다:

@example
|       x       |       x   +     4
|       |       |       |   |     |
the function of an argument x that adds x and 4
@end example

@noindent
함수를 값으로 갖는 다른 표현식과 마찬가지로, 클로저 표현식은 다음과 같이 즉시 사용될 수 있다

@example
(|x, y, z| x + y + square(z))(1, 2, 3)
// => 12
@end example

@noindent
또는, 더 일반적으로, 우리가 함수 이름을 사용하는 어떤 맥락에서든 사용될 수 있다.@footnote{Rust의 클로저 문법은 Ruby나 Smalltalk 같은 언어에서 영감을 받았으며, 궁극적으로는 수리 논리학자 알론조 처치(Alonzo Church)가 소개한 수학적 형식주의인 λ-계산법(@ref{Church (1941)})으로 거슬러 올라간다.
처치는 함수와 함수 적용의 개념을 연구하기 위한 엄격한 기초를 제공하기 위해 λ-계산법을 개발했다.
λ-계산법은 프로그래밍 언어의 의미론에 대한 수학적 연구의 기본 도구가 되었다.
Rust 클로저의 중요한 특징은 감싸고 있는 환경의 변수를 @newterm{포획(capture)}하여 그 변수들에 대한 클로저를 생성할 수 있다는 것이다.}

@subsubheading @code{let}을 사용하여 지역 변수 생성하기 (Using @code{let} to create local variables)

Rust에서 @code{let} 키워드는 지역 변수를 생성하는 데 사용된다.
우리는 종종 형식 매개변수로 바인딩된 것 이외의 지역 변수를 프로시저 내에서 필요로 한다.
예를 들어, 우리가 다음 함수를 계산하고 싶다고 가정해 보자
@ifinfo

@example
f(x,y) = x(1 + xy)^2 + y(1 - y) + (1 + xy)(1 - y)
@end example

@end ifinfo
@tex

\[ % :22:
  
{f(x,y)} \,=\, {x(1 + xy)^2} + {y(1 - y)} + {(1 + xy)(1 - y),}
\]

@end tex
@noindent
이것은 다음과 같이 표현될 수도 있다
@ifinfo

@example
     a = 1 + xy
     b = 1 - y
f(x,y) = xa^2 + yb + ab
@end example

@end ifinfo
@tex

\[ % :23:
 
\begin{eqnarray}
  a                     &=&   {1 + xy,}  \\
  \hphantom{(x,y)} b    &=&   {1 - y,}   \\
  {f(x,y)}              &=&   {xa^2} + {yb} + {ab.}
\end{eqnarray}
\]

@end tex
@math{f}를 계산하는 프로시저를 작성할 때, 우리는 @math{x}와 @math{y}뿐만 아니라 @math{a}와 @math{b} 같은 중간 수량의 이름도 지역 변수로 포함하고 싶다.
이를 달성하는 한 가지 방법은 지역 변수를 바인딩하기 위해 보조 프로시저를 사용하는 것이다:

@example
fn f(x: f64, y: f64) -> f64 @{
    fn f_helper(x: f64, y: f64, a: f64, b: f64) -> f64 @{
        x * square(a) + y * b + a * b
    @}
    f_helper(x, y, 1.0 + x * y, 1.0 - y)
@}
@end example

@noindent
물론, 우리는 지역 변수를 바인딩하기 위해 익명 함수를 지정하는 클로저를 사용할 수도 있다.
그러면 @code{f}의 본문은 그 클로저에 대한 단일 호출이 된다:

@example
fn f(x: f64, y: f64) -> f64 @{
    (|a, b| x * square(a) + y * b + a * b)(1.0 + x * y, 1.0 - y)
@}
@end example

@noindent
Rust에서 @code{let} 바인딩은 지역 변수를 생성하는 자연스럽고 편리한 방법이다.
@code{let}을 사용하여 @code{f} 프로시저는 다음과 같이 작성될 수 있다

@example
fn f(x: f64, y: f64) -> f64 @{
    let a = 1.0 + x * y;
    let b = 1.0 - y;
    x * square(a) + y * b + a * b
@}
@end example

@noindent
Rust에서 @code{let} 바인딩의 일반적인 형태는 다음과 같다

@example
let ⟨@var{var₁}⟩ = ⟨@var{exp₁}⟩;
let ⟨@var{var₂}⟩ = ⟨@var{exp₂}⟩;
@r{…}
let ⟨@var{varₙ}⟩ = ⟨@var{expₙ}⟩;
⟨@var{body}⟩
@end example

@noindent
이것은 다음과 같이 말하는 것으로 생각할 수 있다

@example
let ⟨@var{var₁}⟩ @r{have the value} ⟨@var{exp₁}⟩ @r{and}
    ⟨@var{var₂}⟩ @r{have the value} ⟨@var{exp₂}⟩ @r{and}
    @r{…}
    ⟨@var{varₙ}⟩ @r{have the value} ⟨@var{expₙ}⟩
  @r{in} ⟨@var{body}⟩
@end example

@noindent
각 @code{let} 바인딩은 이름을 해당 표현식의 값과 연관시킨다.
함수의 본문은 이 이름들이 지역 변수로 바인딩된 상태에서 평가된다.
Rust에서 @code{let} 바인딩은 순차적으로 평가되며, 이는 각 바인딩은 이전 바인딩의 값을 사용할 수 있음을 의미한다.
이것은 즉시 실행되는 클로저를 사용하는 것과 유사하다:

@example
(|⟨@var{var₁}⟩, @r{…}, ⟨@var{varₙ}⟩| ⟨@var{body}⟩)(⟨@var{exp₁}⟩, @r{…}, ⟨@var{expₙ}⟩)
@end example

@noindent
Rust의 @code{let}은 문법적 설탕이 아니라 기본적인 언어 구조이지만, 클로저와의 개념적 관계는 지역 변수가 어떻게 스코프가 지정된 바인딩을 생성하는지 이해하는 데 도움이 된다.

@code{let} 바인딩에 의해 지정된 변수의 스코프는 바인딩 지점부터 감싸고 있는 블록의 끝까지이다. 이는 다음을 의미한다:

@itemize @bullet

@item
@code{Let}은 변수를 그것이 사용될 곳에 가능한 한 가깝게 바인딩할 수 있게 해준다.
예를 들어, @code{x}의 값이 5라면, 다음 표현식의 값은

@example
@{
    let inner_result = @{
        let x = 3;
        x + x * 10
    @};
    inner_result + x
@}
@end example

@noindent
38이다. 여기서 내부 블록의 @code{x}는 3이므로 내부 표현식의 값은 33이다. 반면에 가장 바깥쪽 @code{+}의 두 번째 인자인 @code{x}는 여전히 5이다.

@item
Rust에서 @code{let} 바인딩은 순차적으로 평가된다.
이것은 지역 변수의 값을 제공하는 표현식이 지역 변수 자체와 같은 이름을 가진 변수에 의존할 때 중요하다.
예를 들어, @code{x}의 값이 2라면, 다음 표현식은

@example
@{
    let x = 3;
    let y = x + 2;
    x * y
@}
@end example

@noindent
15라는 값을 갖는다. 왜냐하면 @code{y}는 @code{x}의 새로운 값(3)을 사용하므로 @code{y}는 5가 되고, @code{x} * @code{y} = 15가 되기 때문이다.
이것은 모든 바인딩이 어느 하나라도 바인딩되기 전에 평가되는 Scheme의 @code{let}과는 다르다.

@end itemize

@noindent
Rust에서 @code{let} 바인딩은 함수 내에서 지역 변수를 정의하는 자연스러운 방법이다.
예를 들어, 위의 @code{f} 프로시저는 다음과 같이 작성되었다

@example
fn f(x: f64, y: f64) -> f64 @{
    let a = 1.0 + x * y;
    let b = 1.0 - y;
    x * square(a) + y * b + a * b
@}
@end example

@noindent
우리는 지역 변수와 값에 대해 @code{let} 바인딩을 사용하는 반면, 내부 @code{fn} 정의는 내부 도우미 함수에 대해서만 사용한다.@footnote{Rust의 @code{let} 바인딩은 나타나는 순서대로 순차적으로 평가되므로 평가 모델이 직관적이다. 각 바인딩은 동일한 스코프 내의 모든 이전 바인딩을 포함하는 환경을 사용하여 평가된다.}

@quotation
@strong{@anchor{Exercise 1.34}연습문제 1.34:} 우리가 다음과 같은 함수를 정의한다고 가정하자

@example
fn f<F>(g: F) -> i32
where
    F: Fn(i32) -> i32,
@{
    g(2)
@}
@end example

그러면 우리는 다음을 갖는다

@example
f(square)
// => 4

f(|z| z * (z + 1))
// => 6
@end example

만약 우리가 (심술궂게) 컴파일러에게 @code{f(f)} 호출을 평가하도록 요청하면 어떤 일이 발생하는가? 설명하라.
@end quotation

@node	1.3.3, 1.3.4, 1.3.2, 1.3
@subsection 일반적 방법으로서의 프로시저 (Procedures as General Methods)

우리는 @ref{1.1.4}에서 복합 프로시저를 수치 연산의 패턴을 추상화하여 관련된 특정 숫자와 독립적으로 만드는 메커니즘으로 소개했다.
@ref{1.3.1}의 @code{integral} 프로시저와 같은 고차 프로시저를 통해, 우리는 더 강력한 종류의 추상화를 보기 시작했다: 관련된 특정 함수와 독립적으로 계산의 일반적인 방법을 표현하는 데 사용되는 프로시저들이다.
이 절에서 우리는 두 가지 더 정교한 예제---함수의 영점과 고정점을 찾는 일반적인 방법---를 논의하고, 이러한 방법들이 어떻게 프로시저로 직접 표현될 수 있는지 보여줄 것이다.

@subsubheading 반값 방법으로 방정식의 근 찾기 (Finding roots of equations by the half-interval method)

@newterm{반값 방법(half-interval method)}은 @math{f}가 연속 함수일 때 방정식 @math{{f(x) = 0}}의 근을 찾는 간단하지만 강력한 기술이다.
아이디어는 다음과 같다: 만약 @math{{f(a) < 0 < f(b)}}를 만족하는 점 @math{a}와 @math{b}가 주어진다면, @math{f}는 @math{a}와 @math{b} 사이에 적어도 하나의 영점을 가져야 한다.
영점을 찾기 위해, @math{x}를 @math{a}와 @math{b}의 평균이라 하고 @math{{f(x)}}를 계산한다.
만약 @math{{f(x) > 0}}이면, @math{f}는 @math{a}와 @math{x} 사이에 영점을 가져야 한다.
만약 @math{{f(x) < 0}}이면, @math{f}는 @math{x}와 @math{b} 사이에 영점을 가져야 한다.
이런 식으로 계속하면, 우리는 @math{f}가 영점을 가져야만 하는 점점 더 작은 구간들을 식별할 수 있다.
구간이 충분히 작다고 간주할 수 있는 지점에 도달하면 프로세스는 멈춘다.
불확실성의 구간이 프로세스의 각 단계에서 절반으로 줄어들기 때문에, 필요한 단계의 수는 @math{{\Theta(\log(L\, /\, T))}}로 증가한다. 여기서 @math{L}은 원래 구간의 길이이고 @math{T}는 허용 오차(즉, 우리가 ``충분히 작다''고 간주할 구간의 크기)이다.
다음은 이 전략을 구현하는 프로시저이다:

@example
fn search<F>(f: F, neg_point: f64, pos_point: f64) -> f64
where
    F: Fn(f64) -> f64,
@{
    let midpoint = average(neg_point, pos_point);
    if close_enough(neg_point, pos_point) @{
        midpoint
    @} else @{
        let test_value = f(midpoint);
        if test_value > 0.0 @{
            search(f, neg_point, midpoint)
        @} else if test_value < 0.0 @{
            search(f, midpoint, pos_point)
        @} else @{
            midpoint
        @}
    @}
@}
@end example

@noindent
우리는 초기에 함수 @math{f}와 함께 그 값이 각각 음수와 양수인 점들이 주어진다고 가정한다.
우리는 먼저 두 주어진 점의 중점을 계산한다.
다음으로 주어진 구간이 충분히 작은지 확인하고, 그렇다면 중점을 답으로 반환한다.
그렇지 않다면, 테스트 값으로 중점에서의 @math{f} 값을 계산한다.
만약 테스트 값이 양수이면, 우리는 원래의 음수 점에서 중점까지 이어지는 새로운 구간으로 프로세스를 계속한다.
만약 테스트 값이 음수이면, 우리는 중점에서 양수 점까지의 구간으로 계속한다.
마지막으로 테스트 값이 0일 가능성이 있는데, 이 경우 중점 자체가 우리가 찾는 근이다.

끝점들이 ``충분히 가까운지'' 테스트하기 위해 우리는 @ref{1.1.7}에서 제곱근을 계산하는 데 사용한 것과 유사한 프로시저를 사용할 수 있다:@footnote{우리는 0.001을 계산에서 허용 가능한 오차에 대한 허용치를 나타내는 대표적인 ``작은'' 숫자로 사용했다.
실제 계산에 적합한 허용 오차는 해결해야 할 문제와 컴퓨터 및 알고리즘의 한계에 따라 다르다.
이것은 종종 수치 해석가나 다른 종류의 마법사의 도움을 필요로 하는 매우 미묘한 고려 사항이다.}

@example
fn close_enough(x: f64, y: f64) -> bool @{
    (x - y).abs() < 0.001
@}
@end example

@noindent
@code{search}를 직접 사용하는 것은 까다로운데, 실수로 @math{f}의 값이 요구되는 부호를 갖지 않는 점들을 줄 수 있고, 그 경우 잘못된 답을 얻게 되기 때문이다.
대신 우리는 다음 프로시저를 통해 @code{search}를 사용할 것이다. 이 프로시저는 끝점 중 어느 것이 음의 함수 값을 갖고 어느 것이 양의 값을 갖는지 확인하고 그에 따라 @code{search} 프로시저를 호출한다.
두 주어진 점이 같은 부호의 함수 값을 갖는다면 반값 방법을 사용할 수 없으며, 이 경우 프로시저는 오류를 알린다.@footnote{이는 오류 메시지로 출력되는 여러 항목을 인자로 받는 @code{error}를 사용하여 달성할 수 있다.}

@example
fn half_interval_method<F>(f: F, a: f64, b: f64) -> f64
where
    F: Fn(f64) -> f64,
@{
    let a_value = f(a);
    let b_value = f(b);
    if a_value < 0.0 && b_value > 0.0 @{
        search(f, a, b)
    @} else if b_value < 0.0 && a_value > 0.0 @{
        search(f, b, a)
    @} else @{
        panic!("Values are not of opposite sign @{@} @{@}", a, b)
    @}
@}
@end example

@noindent
다음 예제는 반값 방법을 사용하여 @math{{\sin x = 0}}의 2와 4 사이의 근인 @math{\pi}를 근사한다:

@example
half_interval_method(f64::sin, 2.0, 4.0)
// => 3.14111328125
@end example

@noindent
여기 또 다른 예제가 있다. 반값 방법을 사용하여 1과 2 사이에서 방정식 @math{{x^3 - 2x - 3 = 0}}의 근을 찾는다:

@example
half_interval_method(
    |x| x * x * x - 2.0 * x - 3.0,
    1.0,
    2.0
)
// => 1.89306640625
@end example

@subsubheading 함수의 고정점 찾기 (Finding fixed points of functions)

수 @math{x}가 방정식 @math{{f(x) = x}}를 만족하면, @math{x}를 함수 @math{f}의 @newterm{고정점(fixed point)}이라고 부른다.
어떤 함수 @math{f}에 대해서는 초기 추측값으로 시작하여 @math{f}를 반복적으로 적용함으로써 고정점을 찾을 수 있다.
@ifinfo

@example
f(x), f(f(x)), f(f(f(x))), ...
@end example

@end ifinfo
@tex

\[ % :24:
  
{f(x),}\quad {f(f(x)),}\quad {f(f(f(x))),} \quad{\dots,}
\]

@end tex
@noindent
값이 크게 변하지 않을 때까지.
이 아이디어를 사용하여, 함수와 초기 추측값을 입력으로 받아 함수의 고정점에 대한 근사값을 생성하는 프로시저 @code{fixed_point}를 고안할 수 있다.
우리는 규정된 허용 오차보다 적은 차이를 가진 두 개의 연속된 값을 찾을 때까지 함수를 반복적으로 적용한다:

@example
const TOLERANCE: f64 = 0.00001;

fn fixed_point<F>(f: F, first_guess: f64) -> f64
where
    F: Fn(f64) -> f64,
@{
    fn close_enough(v1: f64, v2: f64) -> bool @{
        (v1 - v2).abs() < TOLERANCE
    @}
    fn try_guess<F>(f: &F, guess: f64) -> f64
    where
        F: Fn(f64) -> f64,
    @{
        let next = f(guess);
        if close_enough(guess, next) @{
            next
        @} else @{
            try_guess(f, next)
        @}
    @}
    try_guess(&f, first_guess)
@}
@end example

@noindent
예를 들어, 우리는 이 방법을 사용하여 1을 초기 추측값으로 시작하여 코사인 함수의 고정점을 근사할 수 있다:@footnote{지루한 강의 시간에 이것을 시도해 보라: 계산기를 라디안 모드로 설정하고 고정점을 얻을 때까지 @code{cos} 버튼을 반복해서 눌러라.}

@example
fixed_point(f64::cos, 1.0)
// => 0.7390822985224023
@end example

@noindent
마찬가지로, 우리는 방정식 @math{{y = \sin y + \cos y}}에 대한 해를 찾을 수 있다:

@example
fixed_point(|y| y.sin() + y.cos(), 1.0)
// => 1.2587315962971173
@end example

@noindent
고정점 프로세스는 우리가 @ref{1.1.7}에서 제곱근을 찾기 위해 사용했던 프로세스를 상기시킨다.
둘 다 결과가 어떤 기준을 만족할 때까지 추측값을 반복적으로 개선한다는 아이디어에 기반한다.
사실, 우리는 제곱근 계산을 고정점 탐색으로 쉽게 공식화할 수 있다.
어떤 수 @math{x}의 제곱근을 계산하는 것은 @math{{y^2 = x}}가 되는 @math{y}를 찾는 것을 요구한다.
이 방정식을 동등한 형태인 @math{{y = x / y}}로 바꾸면, 우리는 함수 @math{{y \mapsto x / y}}의 고정점을 찾고 있음을 인식하게 되며,@footnote{@math{\mapsto}(``maps to''라고 읽음)는 함수를 쓰는 수학자의 방식이다. @math{{y \mapsto x / y}}는 @code{|y| x / y}, 즉 @math{y}에서의 값이 @math{{x / y}}인 함수를 의미한다.}
따라서 다음과 같이 제곱근 계산을 시도할 수 있다.

@example
fn sqrt(x: f64) -> f64 @{
    fixed_point(|y| x / y, 1.0)
@}
@end example

@noindent
불행히도, 이 고정점 탐색은 수렴하지 않는다.
초기 추측값 @math{y_1}을 고려해 보자.
다음 추측값은 @math{{y_2 = x / y_1}}이고 그 다음 추측값은 @math{y_3 = {x / y_2} = {x / (x / y_1)} = y_1}이다.
이것은 두 추측값 @math{y_1}과 @math{y_2}가 계속 반복되는 무한 루프를 초래하며, 답 주위에서 진동한다.

그러한 진동을 제어하는 한 가지 방법은 추측값이 너무 많이 변하는 것을 방지하는 것이다.
답은 항상 우리의 추측값 @math{y}와 @math{{x / y}} 사이에 있으므로, @math{y}와 @math{{x / y}}의 평균을 구함으로써 @math{{x / y}}만큼 @math{y}에서 멀지 않은 새로운 추측값을 만들 수 있다.
따라서 @math{y} 다음의 추측값은 @math{{x / y}} 대신 @math{{{1\over2}(y + x / y)}}가 된다.
그러한 추측값의 시퀀스를 만드는 프로세스는 단순히 @math{y \mapsto {{1\over2}(y + x / y)}}의 고정점을 찾는 프로세스이다:

@example
fn sqrt(x: f64) -> f64 @{
    fixed_point(|y| average(y, x / y), 1.0)
@}
@end example

@noindent
(@math{y = {{1\over2}(y + x / y)}}는 방정식 @math{{y = x / y}}의 단순한 변형임을 주목하라; 이를 유도하려면 방정식의 양변에 @math{y}를 더하고 2로 나누면 된다.)

이 수정으로 제곱근 프로시저는 작동한다.
사실, 정의들을 풀어보면, 여기서 생성된 제곱근에 대한 근사값의 시퀀스가 @ref{1.1.7}의 원래 제곱근 프로시저에 의해 생성된 것과 정확히 동일함을 알 수 있다.
연속적인 근사값들을 평균하여 해를 구하는 이 접근 방식은 우리가 @newterm{평균 댐핑(average damping)}이라고 부르는 기술로, 종종 고정점 탐색의 수렴을 돕는다.

@quotation
@strong{@anchor{Exercise 1.35}연습문제 1.35:} 황금비 @math{\varphi}(@ref{1.2.2})가 변환 @math{{x \mapsto 1 + 1 / x}}의 고정점임을 보이고, 이 사실을 사용하여 @code{fixed_point} 프로시저로 @math{\varphi}를 계산하라.
@end quotation

@quotation
@strong{@anchor{Exercise 1.36}연습문제 1.36:} @code{fixed_point}를 수정하여 @ref{Exercise 1.22}에 나온 @code{newline}과 @code{display} 원시 프로시저를 사용하여 생성되는 근사값의 시퀀스를 출력하도록 하라.
그 다음 @math{x \mapsto {\log(1000) / \log(x)}}의 고정점을 찾음으로써 @math{{x^x = 1000}}의 해를 찾아라. (자연 로그를 계산하는 Scheme의 원시 프로시저 @code{log}를 사용하라.)
평균 댐핑을 사용했을 때와 사용하지 않았을 때 걸리는 단계 수를 비교하라. (@math{{\log(1) = 0}}으로 인해 0으로 나누기가 발생하므로 @code{fixed_point}를 추측값 1로 시작할 수 없음에 유의하라.)
@end quotation

@quotation
@strong{@anchor{Exercise 1.37}연습문제 1.37:} 

@enumerate a

@item
무한 @newterm{연분수(continued fraction)}는 다음과 같은 형태의 표현식이다.
@ifinfo

@example
           N_1
f = ---------------------
               N_2
    D_1 + ---------------
                   N_3
          D_2 + ---------
                D_3 + ...
@end example

@end ifinfo
@tex

\[ % :25:
  
f \,=\, {\frac{N_1}{D_1 + \frac{N_2}{D_2 + \frac{N_3}{D_3 + \dots}}}.}
\]

@end tex
예를 들어, @math{N_i}와 @math{D_i}가 모두 1인 무한 연분수 전개는 @math{{1 / \varphi}}를 생성함을 보일 수 있다. 여기서 @math{\varphi}는 황금비이다(@ref{1.2.2}에서 설명됨).
무한 연분수를 근사하는 한 가지 방법은 주어진 항의 개수 후에 전개를 잘라내는 것이다.
그러한 잘라냄---소위 @newterm{@i{k}-항 유한 연분수}---는 다음과 같은 형태를 갖는다.
@ifinfo

@example
       N_1
-----------------
          N_2
D_1 + -----------
      ...    N_K
          + -----
             D_K
@end example

@end ifinfo
@tex

\[ % :26:
  
{\frac{N_1}{D_1 + \frac{N_2}{\ddots + \frac{N_k}{D_k}}}.}
\]

@end tex
@code{n}과 @code{d}가 (연분수의 항의 인덱스 @math{i}인) 인자 하나를 받아 연분수 항의 @math{N_i}와 @math{D_i}를 반환하는 프로시저라고 가정하자.
@code{cont_frac} 프로시저를 정의하여 @code{(cont-frac n d k)}를 평가하면 @math{k}-항 유한 연분수의 값을 계산하도록 하라.
다음을 사용하여 @math{{1 / \varphi}}를 근사함으로써 프로시저를 확인하라.

@example
cont_frac(|_i| 1.0, |_i| 1.0, k)
@end example

@noindent
연속적인 @code{k} 값에 대해. 소수점 4자리까지 정확한 근사값을 얻으려면 @code{k}를 얼마나 크게 만들어야 하는가?

@item
여러분의 @code{cont_frac} 프로시저가 재귀적 프로세스를 생성한다면, 반복적 프로세스를 생성하는 것을 하나 작성하라.
반복적 프로세스를 생성한다면, 재귀적 프로세스를 생성하는 것을 하나 작성하라.

@end enumerate
@end quotation

@quotation
@strong{@anchor{Exercise 1.38}연습문제 1.38:} 1737년, 스위스 수학자 레온하르트 오일러(Leonhard Euler)는 @cite{De Fractionibus Continuis}라는 논문을 발표했는데, 여기에는 @math{{e - 2}}에 대한 연분수 전개가 포함되어 있다. 여기서 @math{e}는 자연 로그의 밑이다.
이 분수에서 @math{N_i}는 모두 1이고, @math{D_i}는 차례로 1, 2, 1, 1, 4, 1, 1, 6, 1, 1, 8, @dots{}이다.
@ref{Exercise 1.37}의 @code{cont_frac} 프로시저를 사용하여 오일러의 전개를 바탕으로 @math{e}를 근사하는 프로그램을 작성하라.
@end quotation

@quotation
@strong{@anchor{Exercise 1.39}연습문제 1.39:} 탄젠트 함수의 연분수 표현은 1770년 독일 수학자 J.H. 람베르트(J.H. Lambert)에 의해 발표되었다:
@ifinfo

@example
              x
tan x = ---------------
                x^2
        1 - -----------
                  x^2
            3 - -------
                5 - ...
@end example

@end ifinfo
@tex

\[ % :27:
  
{\tan x} \,=\, {\frac{x}{1 - \frac{x^2}{3 - \frac{x^2}{5 - \dots}}}\,,}
\]

@end tex
@noindent
여기서 @math{x}는 라디안이다. 람베르트의 공식을 바탕으로 탄젠트 함수의 근사값을 계산하는 프로시저 @code{(tan_cf x k)}를 정의하라.
@code{k}는 @ref{Exercise 1.37}에서처럼 계산할 항의 수를 지정한다.
@end quotation

@node	1.3.4, 1.3.5, 1.2, 1.3
@subsection 반환값으로서의 프로시저 (Procedures as Returned Values)

위의 예제들은 프로시저를 인자로 전달하는 능력이 프로그래밍 언어의 표현력을 얼마나 크게 향상시키는지를 보여주었다.
우리는 반환값이 그 자체로 프로시저인 프로시저를 생성함으로써 훨씬 더 큰 표현력을 얻을 수 있다.

우리는 @ref{1.3.3} 끝부분에서 설명한 고정점 예제를 다시 살펴봄으로써 이 아이디어를 설명할 수 있다.
우리는 @math{\sqrt{x}}가 함수 @math{{y \mapsto x / y}}의 고정점이라는 관찰에서 시작하여, 제곱근 프로시저의 새로운 버전을 고정점 탐색으로 공식화했다.
그런 다음 근사값이 수렴하도록 만들기 위해 평균 댐핑을 사용했다.
평균 댐핑은 그 자체로 유용한 일반적인 기술이다.
즉, 함수 @math{f}가 주어지면, @math{x}에서의 값이 @math{x}와 @math{{f(x)}}의 평균인 함수를 고려한다.

우리는 다음 프로시저를 통해 평균 댐핑이라는 아이디어를 표현할 수 있다:

@example
fn average_damp<F>(f: F) -> impl Fn(f64) -> f64
where
    F: Fn(f64) -> f64 + 'static,
@{
    move |x| average(x, f(x))
@}
@end example

@noindent
Rust에서 클로저를 반환하려면 반환 타입으로 @code{impl Fn}을 사용해야 한다.
@code{move} 키워드는 @code{f}를 값으로 캡처하여 소유권을 반환되는 클로저로 이전한다. 이는 클로저가 함수 스코프보다 오래 지속되기 때문에 필요하다. @code{'static} 수명 바운드는 @code{f}가 제한된 수명을 가진 참조를 포함하지 않음을 보장한다.

@noindent
@code{Average-damp}는 프로시저 @code{f}를 인자로 받아서, 숫자 @code{x}에 적용될 때 @code{x}와 @code{f(x)}의 평균을 생성하는 프로시저(클로저에 의해 생성된)를 값으로 반환하는 프로시저이다.
예를 들어, @code{average_damp}를 @code{square} 프로시저에 적용하면 어떤 수 @math{x}에서의 값이 @math{x}와 @math{x^2}의 평균인 프로시저가 생성된다.
이 결과 프로시저를 10에 적용하면 10과 100의 평균, 즉 55를 반환한다:@footnote{이것은 연산자 자체가 조합인 조합임을 관찰하라. @ref{Exercise 1.4}는 이미 그러한 조합을 형성하는 능력을 보여주었지만, 그것은 단지 장난감 예제였다. 여기서 우리는 고차 프로시저에 의해 반환된 값으로 얻어진 프로시저를 적용할 때 그러한 조합에 대한 진짜 필요성을 보기 시작한다.}

@example
average_damp(square)(10.0)
// => 55.0
@end example

@noindent
@code{average_damp}를 사용하여 제곱근 프로시저를 다음과 같이 재구성할 수 있다:

@example
fn sqrt(x: f64) -> f64 @{
    fixed_point(
        average_damp(move |y| x / y),
        1.0,
    )
@}
@end example

@noindent
이 공식이 방법의 세 가지 아이디어, 즉 고정점 탐색, 평균 댐핑, 그리고 함수 @math{{y \mapsto x / y}}를 얼마나 명시적으로 만드는지 주목하라.
제곱근 방법의 이 공식을 @ref{1.1.7}에 주어진 원래 버전과 비교해 보는 것은 유익하다.
이 프로시저들이 동일한 프로세스를 표현한다는 점을 염두에 두고, 우리가 프로세스를 이러한 추상화 관점에서 표현할 때 아이디어가 얼마나 더 명확해지는지 주목하라.
일반적으로 프로세스를 프로시저로 공식화하는 방법은 많이 있다.
숙련된 프로그래머는 특히 명료하고, 프로세스의 유용한 요소들이 다른 응용 프로그램에서 재사용될 수 있는 별도의 개체로 노출되는 절차적 공식을 선택할 줄 안다.
재사용의 간단한 예로, @math{x}의 세제곱근은 함수 @math{{y \mapsto x / y^2}}의 고정점이라는 사실을 주목하라. 따라서 우리는 즉시 제곱근 프로시저를 일반화하여 세제곱근을 추출하는 프로시저를 만들 수 있다:@footnote{@ref{Exercise 1.45}에서 추가적인 일반화를 참조하라.}

@example
fn cube_root(x: f64) -> f64 @{
    fixed_point(
        average_damp(move |y| x / square(y)),
        1.0,
    )
@}
@end example

@subsubheading 뉴턴의 방법 (Newton's method)

@ref{1.1.7}에서 제곱근 프로시저를 처음 소개했을 때, 우리는 이것이 @newterm{뉴턴의 방법(Newton's method)}의 특수한 경우라고 언급했다.
만약 @math{{x \mapsto g(x)}}가 미분 가능한 함수라면, 방정식 @math{{g(x) = 0}}의 해는 함수 @math{{x \mapsto f(x)}}의 고정점이다. 여기서
@ifinfo

@example
           g(x)
f(x) = x - -----
           Dg(x)
@end example

@end ifinfo
@tex

\[ % :28:
  
{f(x)} \,=\, x - \frac{g(x)}{D g(x)}
\]

@end tex
@noindent
이고 @math{{Dg(x)}}는 @math{x}에서 평가된 @math{g}의 도함수(derivative)이다. 뉴턴의 방법은 우리가 위에서 본 고정점 방법을 사용하여 함수 @math{{f}}의 고정점을 찾음으로써 방정식의 해를 근사하는 것이다.@footnote{초급 미적분학 책들은 보통 뉴턴의 방법을 근사값의 시퀀스 @math{x_{n+1} = x_n - {g(x_n)\,/ Dg(x_n)}}의 관점에서 설명한다.
프로세스에 대해 이야기할 수 있는 언어를 갖고 고정점의 아이디어를 사용하는 것은 방법의 설명을 단순화한다.}

많은 함수 @math{g}와 충분히 좋은 초기 추측값 @math{x}에 대해, 뉴턴의 방법은 @math{{g(x) = 0}}의 해로 매우 빠르게 수렴한다.@footnote{뉴턴의 방법이 항상 답으로 수렴하는 것은 아니지만, 유리한 경우에는 각 반복이 해에 대한 근사값의 유효 자릿수를 두 배로 늘린다는 것을 보일 수 있다. 그러한 경우, 뉴턴의 방법은 반값 방법보다 훨씬 더 빠르게 수렴할 것이다.}

뉴턴의 방법을 프로시저로 구현하기 위해, 우리는 먼저 도함수의 개념을 표현해야 한다.
``도함수''는 평균 댐핑처럼 함수를 다른 함수로 변환하는 것이라는 점에 주목하라.
예를 들어, 함수 @math{{x \mapsto x^3}}의 도함수는 함수 @math{{x \mapsto 3x^2}}이다.
일반적으로, 만약 @math{g}가 함수이고 @math{{dx}}가 작은 수라면, @math{g}의 도함수 @math{{Dg}}는 임의의 수 @math{x}에서의 값이 (작은 @math{{dx}}의 극한에서) 다음과 같이 주어지는 함수이다.
@ifinfo

@example
        g(x + dx) - g(x)
Dg(x) = ----------------
               dx
@end example

@end ifinfo
@tex

\[ % :29:
  
Dg(x) \,=\, {\frac{g(x + dx) - g(x)}{dx}.}
\]

@end tex
@noindent
따라서 우리는 도함수의 아이디어를 (@math{{dx}}를 예를 들어 0.00001로 잡고) 다음과 같은 프로시저로 표현할 수 있다.

@example
const DX: f64 = 0.00001;

fn deriv<G>(g: G) -> impl Fn(f64) -> f64
where
    G: Fn(f64) -> f64 + 'static,
@{
    move |x| (g(x + DX) - g(x)) / DX
@}
@end example

@noindent
@code{average_damp}와 마찬가지로, @code{deriv}는 프로시저를 인자로 받아 프로시저를 값으로 반환하는 프로시저이다.
예를 들어, 5에서 @math{{x \mapsto x^3}}의 도함수(정확한 값은 75)를 근사하기 위해 우리는 다음을 평가할 수 있다

@example
fn cube(x: f64) -> f64 @{
    x * x * x
@}

deriv(cube)(5.0)
// => 75.00014999664018
@end example

@noindent
@code{deriv}의 도움으로, 우리는 뉴턴의 방법을 고정점 프로세스로 표현할 수 있다:

@example
fn newton_transform<G>(g: G) -> impl Fn(f64) -> f64
where
    G: Fn(f64) -> f64 + Clone + 'static,
@{
    let g_clone = g.clone();
    move |x| x - (g(x) / deriv(g_clone.clone())(x))
@}

fn newtons_method<G>(g: G, guess: f64) -> f64
where
    G: Fn(f64) -> f64 + Clone + 'static,
@{
    fixed_point(newton_transform(g), guess)
@}
@end example

@noindent
여기서 @code{newton_transform}은 @code{G: Clone}을 요구하는데, 왜냐하면 @code{g}를 직접 사용하기도 하고 @code{deriv}에 전달하기도 해야 하기 때문이다. Rust의 소유권 규칙을 만족시키기 위해 @code{g}를 복제한다.

@noindent
@code{newton_transform} 프로시저는 이 절의 시작 부분에 있는 공식을 표현하며, @code{newtons_method}는 이것을 사용하여 쉽게 정의된다.
이것은 우리가 영점을 찾고자 하는 함수를 계산하는 프로시저와 초기 추측값을 인자로 받는다.
예를 들어, @math{x}의 제곱근을 찾기 위해, 우리는 초기 추측값 1로 시작하여 함수 @math{{y \mapsto y^2 - x}}의 영점을 찾기 위해 뉴턴의 방법을 사용할 수 있다.@footnote{제곱근을 찾을 때, 뉴턴의 방법은 어떤 시작점에서도 정답으로 빠르게 수렴한다.}

이것은 제곱근 프로시저의 또 다른 형태를 제공한다:

@example
fn sqrt(x: f64) -> f64 @{
    newtons_method(move |y| square(y) - x, 1.0)
@}
@end example

@subsubheading 추상화와 일급 프로시저 (Abstractions and first-class procedures)

우리는 제곱근 계산을 더 일반적인 방법의 인스턴스로 표현하는 두 가지 방법을 보았다. 한 번은 고정점 탐색으로, 한 번은 뉴턴의 방법을 사용하여.
뉴턴의 방법 자체가 고정점 프로세스로 표현되었으므로, 우리는 사실상 제곱근을 고정점으로 계산하는 두 가지 방법을 본 셈이다.
각 방법은 함수로 시작하여 함수의 어떤 변환의 고정점을 찾는다.
우리는 이 일반적인 아이디어 자체를 프로시저로 표현할 수 있다:

@example
fn fixed_point_of_transform<G, T, F>(g: G, transform: T, guess: f64) -> f64
where
    G: Fn(f64) -> f64 + 'static,
    T: Fn(G) -> F,
    F: Fn(f64) -> f64,
@{
    fixed_point(transform(g), guess)
@}
@end example

@noindent
이 함수는 함수 @code{g}, 한 함수를 다른 함수로 변환하는 @code{transform}, 그리고 초기 @code{guess}를 받는다. 제네릭 매개변수 @code{G}, @code{T}, 그리고 @code{F}는 다양한 함수 변환의 유연한 구성을 허용한다.

@noindent
이 매우 일반적인 프로시저는 어떤 함수를 계산하는 프로시저 @code{g}, @code{g}를 변환하는 프로시저, 그리고 초기 추측값을 인자로 받는다.
반환된 결과는 변환된 함수의 고정점이다.

이 추상화를 사용하여, 우리는 이 절의 첫 번째 제곱근 계산(@math{{y \mapsto x / y}}의 평균 댐핑된 버전의 고정점을 찾는)을 이 일반적인 방법의 인스턴스로 재구성할 수 있다:

@example
fn sqrt(x: f64) -> f64 @{
    fixed_point_of_transform(move |y| x / y, average_damp, 1.0)
@}
@end example

@noindent
마찬가지로, 우리는 이 절의 두 번째 제곱근 계산(뉴턴의 방법의 인스턴스로, @math{{y \mapsto y^2 - x}}의 뉴턴 변환의 고정점을 찾는)을 다음과 같이 표현할 수 있다.

@example
fn sqrt(x: f64) -> f64 @{
    fixed_point_of_transform(move |y| square(y) - x, newton_transform, 1.0)
@}
@end example

@noindent
우리는 복합 프로시저가 계산의 일반적인 방법을 우리 프로그래밍 언어의 명시적인 요소로 표현할 수 있게 해주기 때문에 중요한 추상화 메커니즘이라는 관찰로 @ref{1.3} 절을 시작했다.
이제 우리는 고차 프로시저가 이러한 일반적인 방법들을 조작하여 더 높은 추상화를 생성할 수 있게 해준다는 것을 보았다.

프로그래머로서, 우리는 우리 프로그램에 내재된 추상화를 식별하고 그 위에 구축하며 그것들을 일반화하여 더 강력한 추상화를 만들 기회에 주의를 기울여야 한다.
이것은 항상 가장 추상적인 방식으로 프로그램을 작성해야 한다는 말은 아니다; 숙련된 프로그래머는 자신의 작업에 적합한 추상화 수준을 선택할 줄 안다.
하지만 이러한 추상화 관점에서 생각할 수 있어서 새로운 맥락에서 그것들을 적용할 준비가 되어 있는 것은 중요하다.
고차 프로시저의 중요성은 그것들이 우리 프로그래밍 언어의 요소로서 이러한 추상화를 명시적으로 표현할 수 있게 해주어, 다른 계산 요소들처럼 다룰 수 있게 해준다는 점에 있다.

일반적으로 프로그래밍 언어는 계산 요소들이 조작될 수 있는 방식에 제한을 둔다.
제한이 가장 적은 요소들은 @newterm{일급(first-class)} 지위를 갖는다고 말한다.
일급 요소들의 ``권리와 특권'' 중 일부는 다음과 같다:@footnote{프로그래밍 언어 요소의 일급 지위 개념은 영국 컴퓨터 과학자 크리스토퍼 스트래치(Christopher Strachey, 1916-1975)에 의한 것이다.}

@itemize @bullet

@item
변수로 이름 붙일 수 있다.

@item
프로시저에 인자로 전달될 수 있다.

@item
프로시저의 결과로 반환될 수 있다.

@item
데이터 구조에 포함될 수 있다.@footnote{우리는 @ref{Chapter 2}에서 데이터 구조를 소개한 후 이에 대한 예를 보게 될 것이다.}

@end itemize

@noindent
Lisp는 다른 일반적인 프로그래밍 언어들과 달리 프로시저에 완전한 일급 지위를 부여한다.
이것은 효율적인 구현에 도전을 제기하지만, 그로 인한 표현력의 이득은 엄청나다.@footnote{일급 프로시저의 주요 구현 비용은 프로시저가 값으로 반환되도록 허용하면 프로시저가 실행되지 않을 때에도 프로시저의 자유 변수를 위한 저장소를 예약해야 한다는 것이다. 우리가 @ref{4.1}에서 공부할 Scheme 구현에서는 이러한 변수들이 프로시저의 환경에 저장된다.}

@quotation
@strong{@anchor{Exercise 1.40}연습문제 1.40:} 삼차 방정식 @math{{x^3 + ax^2 + bx + c}}의 영점을 근사하기 위해 다음과 같은 형태의 표현식에서 @code{newtons_method} 프로시저와 함께 사용될 수 있는 @code{cubic} 프로시저를 정의하라.

@example
newtons_method(cubic(a, b, c), 1.0)
@end example

@example
fn cubic(a: f64, b: f64, c: f64) -> impl Fn(f64) -> f64 @{
    move |x| x.powi(3) + a * x.powi(2) + b * x + c
@}
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 1.41}연습문제 1.41:} 인자 하나를 받는 프로시저를 인자로 받아 원래 프로시저를 두 번 적용하는 프로시저를 반환하는 @code{double} 프로시저를 정의하라.
예를 들어, @code{inc}가 인자에 1을 더하는 프로시저라면, @code{double(inc)}는 2를 더하는 프로시저여야 한다. 다음 반환값은 무엇인가?

@example
double(double(double))(inc)(5)
@end example

@example
fn double<F, T>(f: F) -> impl Fn(T) -> T
where
    F: Fn(T) -> T + Clone + 'static,
    T: 'static,
@{
    move |x| f(f(x))
@}
@end example

@noindent
Rust에서 @code{double}은 타입 @code{T}에 대해 다형적이어서 어떤 타입과도 작동할 수 있다. @code{f}를 두 번 적용하므로 @code{Clone} 바운드가 필요하다.
@end quotation

@quotation
@strong{@anchor{Exercise 1.42}연습문제 1.42:} @math{f}와 @math{g}를 1인자 함수라고 하자. @math{g} 다음 @math{f}의 @newterm{합성(composition)}은 함수 @math{{x \mapsto f(g(x))}}로 정의된다.
합성을 구현하는 프로시저 @code{compose}를 정의하라. 예를 들어, @code{inc}가 인자에 1을 더하는 프로시저라면,

@example
compose(square, inc)(6)
// => 49
@end example

@example
fn compose<F, G, T, U, V>(f: F, g: G) -> impl Fn(T) -> V
where
    F: Fn(U) -> V + 'static,
    G: Fn(T) -> U + 'static,
    T: 'static,
    U: 'static,
    V: 'static,
@{
    move |x| f(g(x))
@}
@end example

@noindent
Rust에서의 함수 합성은 세 개의 타입 매개변수를 필요로 한다: @code{T} (입력 타입), @code{U} (중간 타입), 그리고 @code{V} (출력 타입). 이를 통해 서로 다른 입력 및 출력 타입을 가진 함수들을 합성할 수 있다.
@end quotation

@quotation
@strong{@anchor{Exercise 1.43}연습문제 1.43:} @math{f}가 수치 함수이고 @math{n}이 양의 정수라면, 우리는 @math{f}의 @math{n^{\text{th}}} 반복 적용을 형성할 수 있다. 이는 @math{x}에서의 값이 @math{{f(f(\dots (f(x))\dots ))}}인 함수로 정의된다.
예를 들어, @math{f}가 함수 @math{{x \mapsto x + 1}}이라면, @math{f}의 @math{n^{\text{th}}} 반복 적용은 함수 @math{{x \mapsto x + n}}이다.
@math{f}가 숫자를 제곱하는 연산이라면, @math{f}의 @math{n^{\text{th}}} 반복 적용은 인자를 @math{{2^n\text{-th}}} 제곱하는 함수이다.
@math{f}를 계산하는 프로시저와 양의 정수 @math{n}을 입력으로 받아 @math{f}의 @math{n^{\text{th}}} 반복 적용을 계산하는 프로시저를 반환하는 프로시저를 작성하라.
여러분의 프로시저는 다음과 같이 사용될 수 있어야 한다:

@example
repeated(square, 2)(5.0)
// => 625.0
@end example

힌트: @ref{Exercise 1.42}의 @code{compose}를 사용하는 것이 편리할 수 있다.

@example
fn repeated<F, T>(f: F, n: usize) -> impl Fn(T) -> T
where
    F: Fn(T) -> T + Clone + 'static,
    T: Clone + 'static,
@{
    move |x| @{
        let mut result = x;
        for _ in 0..n @{
            result = f(result);
        @}
        result
    @}
@}
@end example

@noindent
@code{repeated} 함수는 입력에 @code{f}를 정확히 @code{n}번 적용한다.
다중 적용을 허용하기 위해 @code{F}와 @code{T} 모두 @code{Clone}을 요구한다.
@end quotation

@quotation
@strong{@anchor{Exercise 1.44}연습문제 1.44:} 함수를 @newterm{평활화(smoothing)}한다는 아이디어는 신호 처리에서 중요한 개념이다.
@math{f}가 함수이고 @math{{dx}}가 어떤 작은 수라면, @math{f}의 평활화된 버전은 점 @math{x}에서의 값이 @math{{f(x - dx)}}, @math{{f(x)}}, 그리고 @math{{f(x + dx)}}의 평균인 함수이다.
@math{f}를 계산하는 프로시저를 입력으로 받아 평활화된 @math{f}를 계산하는 프로시저를 반환하는 프로시저 @code{smooth}를 작성하라.
때로는 함수를 반복적으로 평활화(즉, 평활화된 함수를 평활화하고, 등등)하여 @newterm{@i{n}-겹 평활화된 함수(@i{n}-fold smoothed function)}를 얻는 것이 가치 있다.
@code{smooth}와 @ref{Exercise 1.43}의 @code{repeated}를 사용하여 주어진 함수의 @i{n}-겹 평활화된 함수를 생성하는 방법을 보여라.
@end quotation

@quotation
@strong{@anchor{Exercise 1.45}연습문제 1.45:} 우리는 @ref{1.3.3}에서 @math{{y \mapsto x / y}}의 고정점을 순진하게 찾으려 하면 제곱근 계산이 수렴하지 않으며, 이것이 평균 댐핑으로 해결될 수 있음을 보았다.
같은 방법이 @math{{y \mapsto x / y^2}}의 평균 댐핑된 고정점으로서 세제곱근을 찾는 데에도 효과가 있다.
불행히도, 이 프로세스는 네제곱근에 대해서는 작동하지 않는다---한 번의 평균 댐핑은 @math{{y \mapsto x / y^3}}에 대한 고정점 탐색을 수렴하게 하기에 충분하지 않다.
반면에, 만약 우리가 두 번 평균 댐핑을 하면(즉, 평균 댐핑의 평균 댐핑을 사용하면) @math{{y \mapsto x / y^3}}에 대한 고정점 탐색은 수렴한다.
@math{{y \mapsto x / y^{\kern0.1em n-1}}}의 반복된 평균 댐핑을 기반으로 한 고정점 탐색으로서 @math{n^{\text{th}}} 제곱근을 계산하기 위해 얼마나 많은 평균 댐핑이 필요한지 결정하기 위해 실험을 해보라.
이것을 사용하여 @code{fixed_point}, @code{average_damp}, 그리고 @ref{Exercise 1.43}의 @code{repeated} 프로시저를 사용하여 @math{n^{\text{th}}} 제곱근을 계산하는 간단한 프로시저를 구현하라.
필요한 산술 연산은 원시 연산으로 사용 가능하다고 가정하라.
@end quotation

@quotation
@strong{@anchor{Exercise 1.46}연습문제 1.46:} 이 장에서 설명된 여러 수치 방법들은 @newterm{반복적 개선(iterative improvement)}이라고 알려진 매우 일반적인 계산 전략의 인스턴스들이다.
반복적 개선은 무언가를 계산하기 위해 답에 대한 초기 추측값으로 시작해서, 추측값이 충분히 좋은지 테스트하고, 그렇지 않으면 추측값을 개선하고 개선된 추측값을 새로운 추측값으로 사용하여 프로세스를 계속한다는 것이다.
두 프로시저를 인자로 받는 프로시저 @code{iterative_improve}를 작성하라: 추측값이 충분히 좋은지 말해주는 방법과 추측값을 개선하는 방법.
@code{Iterative-improve}는 추측값을 인자로 받아 충분히 좋아질 때까지 계속 추측값을 개선하는 프로시저를 값으로 반환해야 한다.
@ref{1.1.7}의 @code{sqrt} 프로시저와 @ref{1.3.3}의 @code{fixed_point} 프로시저를 @code{iterative_improve} 관점에서 다시 작성하라.
@end quotation

@node 1.3.5, Chapter 2, 1.3.4, 1.3
@subsection 반복자 콤비네이터 (Iterator Combinators)

이 장 전체에 걸쳐, 우리는 다른 프로시저에 작용하는 프로시저---계산의 공통 패턴을 추상화하는 고차 프로시저---를 탐구했다.
우리는 반복적 조합의 본질을 포착하는 방법으로 @code{sum}, @code{product}, 그리고 @code{accumulate}를 보았다.
Rust는 이 아이디어를 @newterm{반복자(iterators)}로 더 발전시켰다---이는 고차 함수의 우아함과 직접 작성한 루프의 성능을 결합한 순차적 데이터 처리를 위한 제로 비용 추상화(zero-cost abstraction)이다.

@subheading Iterator 트레이트 (The Iterator Trait)

반복자는 @code{Iterator} 트레이트를 구현하는 모든 타입이며, 이 트레이트는 단 하나의 메서드를 요구한다:

@example
pub trait Iterator @{
    type Item;

    fn next(&mut self) -> Option<Self::Item>;
@}
@end example

@noindent
@code{next} 메서드는 시퀀스의 각 요소에 대해 @code{Some(value)}를 반환하고, 시퀀스가 소진되면 @code{None}을 반환한다.
이 간단한 인터페이스는 강력한 구성 패턴을 가능하게 한다.

1부터 5까지 세는 것을 고려해 보자. 우리는 범위(range)에서 반복자를 생성할 수 있다:

@example
let range = 1..=5;
let mut iter = range.into_iter();

assert_eq!(iter.next(), Some(1));
assert_eq!(iter.next(), Some(2));
assert_eq!(iter.next(), Some(3));
assert_eq!(iter.next(), Some(4));
assert_eq!(iter.next(), Some(5));
assert_eq!(iter.next(), None);
@end example

@noindent
@code{into_iter} 메서드는 @code{IntoIterator} 트레이트에서 오는데, 타입들은 자신을 반복자로 변환하기 위해 이를 구현한다.
배열, 벡터, 그리고 범위와 같은 컬렉션들은 모두 @code{IntoIterator}를 구현하여, @code{for} 루프나 반복자 메서드와 함께 사용될 수 있게 한다.

@subheading Map, Filter, 그리고 고차 연산 (Map, Filter, and Higher-Order Operations)

범위에 걸쳐 값을 누산하는 패턴을 추상화했던 @ref{1.3.1}의 @code{sum} 프로시저를 떠올려 보라.
반복자를 사용하면, 우리는 값의 @emph{생성(generating)}, 값의 @emph{변환(transforming)}, 그리고 값의 @emph{결합(combining)}에 대한 관심사를 분리할 수 있다:

@example
// 1부터 10까지 제곱의 합
let sum_of_squares: i32 = (1..=10)
    .map(|x| x * x)
    .sum();

assert_eq!(sum_of_squares, 385);
@end example

@noindent
여기서 @code{map}은 @newterm{반복자 콤비네이터(iterator combinator)}---한 반복자를 다른 반복자로 변환하는 메서드---이다.
이것은 클로저를 받아서 각 요소에 클로저를 적용하는 새로운 반복자를 생성한다.
@code{sum} 메서드는 @newterm{소비자(consumer)}---반복자를 소비하여 최종 값을 생성한다.

이것을 @ref{1.3.1}의 초기 @code{sum_integers}와 비교해 보라:

@example
fn sum<F>(term: F, a: i32, next: fn(i32) -> i32, b: i32) -> i32
where
    F: Fn(i32) -> i32,
@{
    if a > b @{
        0
    @} else @{
        term(a) + sum(term, next(a), next, b)
    @}
@}

fn sum_cubes(a: i32, b: i32) -> i32 @{
    sum(|x| x * x * x, a, |x| x + 1, b)
@}
@end example

@noindent
반복자를 사용하면, 이것은 다음과 같이 된다:

@example
fn sum_cubes(a: i32, b: i32) -> i32 @{
    (a..=b).map(|x| x * x * x).sum()
@}
@end example

@noindent
반복자 버전은 더 간결하면서도 동등하게 표현적이다.
@code{map} 연산은 우리의 @code{term} 매개변수에 해당하고, 범위 @code{a..=b}는 반복을 처리하며, @code{sum}은 누산을 수행한다.

@code{filter} 콤비네이터는 술어에 기초하여 요소를 선택하는데, 이는 조건부 누산의 우아한 표현을 가능하게 한다.
@ref{Exercise 1.33}에서, 우리는 조건을 만족하는 요소만 합하거나 곱하기 위해 @code{filtered_accumulate}를 구현했다.
반복자를 사용하면:

@example
// 1부터 10까지 홀수의 제곱의 합
let sum: i32 = (1..=10)
    .filter(|x| x % 2 == 1)
    .map(|x| x * x)
    .sum();

assert_eq!(sum, 165);  // 1 + 9 + 25 + 49 + 81
@end example

@noindent
@code{filter} 콤비네이터는 술어가 @code{true}를 반환하는 값만 산출하는 반복자를 생성한다.
우리는 여러 변환을 체이닝하여 간단한 연산들로 복잡한 파이프라인을 구축할 수 있다.

@subheading 지연 평가와 제로 비용 추상화 (Lazy Evaluation and Zero-Cost Abstraction)

반복자 콤비네이터의 중요한 속성은 @newterm{지연 평가(lazy evaluation)}이다---소비자가 값을 요구할 때까지 아무런 계산도 일어나지 않는다.
우리가 다음과 같이 쓸 때:

@example
let iter = (1..=1000000)
    .map(|x| x * x)
    .filter(|x| x % 2 == 0);
@end example

@noindent
이것은 반복자 파이프라인을 생성하지만 아무런 계산도 수행하지 않는다.
배열도 할당되지 않고, 제곱도 계산되지 않으며, 필터링도 일어나지 않는다.
반복자는 값이 아니라 값을 생산하는 @emph{방법}을 기술하는 경량 상태 기계이다.

계산은 우리가 반복자를 소비할 때만 일어난다:

@example
let first_five: Vec<i32> = iter.take(5).collect();
@end example

@noindent
@code{take} 콤비네이터는 최대 5개의 요소를 산출하는 반복자를 생성하고, @code{collect}는 반복자를 소비하여 벡터를 생성한다.
오직 그때만 값이 계산되며---실제로 필요한 값만 계산된다.
우리는 백만 개가 아니라 5개의 제곱을 계산하고 5번의 나머지 연산을 수행한다.

이 게으름(laziness)은 효율적인 체이닝을 가능하게 한다. 다음을 고려해 보자:

@example
let sum: i32 = (1..=1000)
    .map(|x| x * 2)
    .filter(|x| x % 3 == 0)
    .map(|x| x * x)
    .sum();
@end example

@noindent
순진한 구현은 세 개의 중간 컬렉션을 생성할 것이다: 하나는 두 배 된 값을 위해, 하나는 필터링된 값을 위해, 그리고 하나는 제곱된 값을 위해.
대신, Rust 컴파일러는 이러한 연산들을 할당 없는 단일 루프로 융합(fuse)한다:

@example
// 직접 작성한 것과 동등함:
let mut sum = 0;
for x in 1..=1000 @{
    let doubled = x * 2;
    if doubled % 3 == 0 @{
        let squared = doubled * doubled;
        sum += squared;
    @}
@}
@end example

@noindent
이것이 제로 비용 추상화이다: 반복자 버전은 수동 루프와 동일하게 효율적인 기계 코드로 컴파일되지만, 계산을 더 선언적으로 표현한다.

@subheading Fold 콤비네이터 (The Fold Combinator)

@code{sum}과 @code{product} 메서드는 더 일반적인 패턴인 폴딩(folding, 접기)의 특수한 경우이다.
@code{fold} 콤비네이터는 @ref{Exercise 1.32}의 @code{accumulate}에 직접적으로 대응한다:

@example
fn accumulate<T, F, C>(
    combiner: C,
    null_value: T,
    term: F,
    a: i32,
    next: fn(i32) -> i32,
    b: i32,
) -> T
where
    F: Fn(i32) -> T,
    C: Fn(T, T) -> T,
    T: Copy,
@{
    if a > b @{
        null_value
    @} else @{
        combiner(
            term(a),
            accumulate(combiner, null_value, term, next(a), next, b),
        )
    @}
@}
@end example

@noindent
@code{fold}를 사용하면:

@example
let result = (a..=b)
    .map(term)
    .fold(null_value, combiner);
@end example

@noindent
@code{fold} 메서드는 초기 값과 이항 함수를 받아, 누산기와 각 요소에 차례로 함수를 적용한다.
예를 들어, 팩토리얼은 다음과 같이 표현될 수 있다:

@example
fn factorial(n: u64) -> u64 @{
    (1..=n).fold(1, |acc, x| acc * x)
@}
@end example

@noindent
이것은 @ref{1.2.1}의 의미에서 반복적인 프로세스이다---누산기는 완전한 상태를 보유하며, 계산은 범위를 통해 선형적으로 진행된다.

@subheading 풍부한 콤비네이터 라이브러리 (Rich Combinator Library)

Rust의 표준 라이브러리는 수십 개의 반복자 콤비네이터를 제공하며, 각각은 공통 패턴을 포착한다.
필수적인 몇 가지는 다음과 같다:

@table @code
@item chain
두 반복자를 순차적으로 연결한다.

@example
let combined: Vec<i32> = (1..=3)
    .chain(10..=12)
    .collect();
assert_eq!(combined, vec![1, 2, 3, 10, 11, 12]);
@end example

@item zip
두 반복자의 요소를 쌍으로 묶는다.

@example
let pairs: Vec<(i32, char)> = (1..=3)
    .zip(['a', 'b', 'c'])
    .collect();
assert_eq!(pairs, vec![(1, 'a'), (2, 'b'), (3, 'c')]);
@end example

@item enumerate
반복자 요소에 인덱스를 추가한다.

@example
let indexed: Vec<(usize, char)> = ['a', 'b', 'c']
    .iter()
    .enumerate()
    .collect();
assert_eq!(indexed, vec![(0, 'a'), (1, 'b'), (2, 'c')]);
@end example

@item take
최대 @math{n}개의 요소를 산출한다.

@example
let first_three: Vec<i32> = (1..)  // 무한 반복자!
    .take(3)
    .collect();
assert_eq!(first_three, vec![1, 2, 3]);
@end example

@item skip
처음 @math{n}개의 요소를 건너뛴다.

@example
let after_skip: Vec<i32> = (1..=10)
    .skip(5)
    .collect();
assert_eq!(after_skip, vec![6, 7, 8, 9, 10]);
@end example
@end table

@noindent
이러한 콤비네이터들은 자유롭게 합성된다.
우리는 복잡한 질의를 간결하게 표현할 수 있다:

@example
// 처음 5개의 짝수 피보나치 수의 제곱의 합을 구하라
fn fib_iter() -> impl Iterator<Item = u64> @{
    let mut a = 0;
    let mut b = 1;
    std::iter::from_fn(move || @{
        let current = a;
        a = b;
        b = current + b;
        Some(current)
    @})
@}

let sum: u64 = fib_iter()
    .filter(|x| x % 2 == 0)
    .take(5)
    .map(|x| x * x)
    .sum();

assert_eq!(sum, 29480);  // 0 + 4 + 64 + 4624 + 24784
@end example

@noindent
이 파이프라인은: 피보나치 수의 무한 시퀀스를 생성하고, 짝수 값만 필터링하고, 처음 5개를 취하고, 각각을 제곱하고, 결과를 합산한다.
중간 컬렉션을 할당하지 않고, 모두 효율적인 기계 코드로 컴파일된다.

@subheading Collect와 타입 추론 (Collect and Type Inference)

@code{collect} 메서드는 특별한 주의를 기울일 가치가 있다.
이것은 반복자를 소비하여 컬렉션을 구축한다---하지만 어떤 컬렉션인가?
대상 타입은 타입 추론에 의해 결정된다:

@example
let v: Vec<i32> = (1..=5).collect();
let a: [i32; 5] = (1..=5).collect();  // 배열 (크기가 일치해야 함!)
@end example

@noindent
추론이 모호할 때, 우리는 ``터보피쉬(turbofish)'' 문법 @code{::<T>}를 사용한다:

@example
let v = (1..=5).collect::<Vec<i32>>();
@end example

@noindent
많은 컬렉션 타입들이 @code{IntoIterator}의 쌍대인 @code{FromIterator}를 구현한다.
이 트레이트는 반복자로부터 컬렉션을 구축하는 방법을 설명하여, @code{collect}가 벡터, 배열, 집합, 맵, 그리고 사용자 정의 컬렉션과 함께 작동할 수 있게 한다.

@subheading 재귀적 접근 방식과의 비교 (Comparison with Recursive Approaches)

1장 전체에 걸쳐, 우리는 재귀적 프로시저와 그것들이 생성하는 프로세스를 강조했다.
반복자는 상호 보완적인 관점을 제공한다: 데이터 변환 파이프라인으로서의 계산.
이전 절의 @code{sum_of_squares} 프로시저를 고려해 보자:

@example
// 재귀적 버전
fn sum_of_squares_rec(a: i32, b: i32) -> i32 @{
    if a > b @{
        0
    @} else @{
        (a * a) + sum_of_squares_rec(a + 1, b)
    @}
@}

// 반복적 버전 (꼬리 재귀)
fn sum_of_squares_iter(a: i32, b: i32) -> i32 @{
    fn iter(a: i32, b: i32, acc: i32) -> i32 @{
        if a > b @{
            acc
        @} else @{
            iter(a + 1, b, acc + (a * a))
        @}
    @}
    iter(a, b, 0)
@}

// 반복자 버전
fn sum_of_squares_range(a: i32, b: i32) -> i32 @{
    (a..=b).map(|x| x * x).sum()
@}
@end example

@noindent
세 가지 모두 수학적 의미에서 동등하며 컴파일된 성능에서도 동등하다(현대 Rust 컴파일러는 세 가지 모두 유사하게 최적화한다).
그들 사이의 선택은 스타일의 문제이며 문제의 구조에 따라 다르다.

재귀는 문제가 자연스러운 재귀적 구조(트리 순회, 분할 정복 알고리즘)를 가질 때 빛을 발한다.
반복은 변환 파이프라인이 명확한 순차적 처리에서 빛을 발한다.
Rust의 반복자는 우리에게 저수준 루프의 성능과 함께 고차 함수의 선언적 우아함을 제공한다.

@subheading 무한 반복자 (Infinite Iterators)

우리가 @ref{3.5.2}에서 탐구할 무한 스트림처럼, 반복자는 제한 없는 시퀀스를 표현할 수 있다.
범위 @code{1..}은 모든 양의 정수를 생성한다(오버플로가 발생할 때까지).
우리는 값을 지연 생성하는 무한 반복자를 만들 수 있다:

@example
// 모든 양의 정수
let naturals = 1..;

// 2의 모든 거듭제곱
let powers_of_2 = std::iter::successors(Some(1u64), |n| n.checked_mul(2));

// 모든 피보나치 수 (오버플로까지)
let fibs = std::iter::successors(Some((0u64, 1u64)), |(a, b)| @{
    Some((*b, a + b))
@}).map(|(a, _)| a);
@end example

@noindent
이 무한 반복자들은 반복이 지연되기 때문에 안전하다.
우리는 유한한 부분 시퀀스를 추출하기 위해 이것들을 @code{take}, @code{take_while}, 또는 유사한 콤비네이터와 결합해야 한다:

@example
let first_10_fibs: Vec<u64> = fibs.take(10).collect();
@end example

@noindent
이 패턴---지연 평가에 의해 실용적이 된 무한 데이터 구조---은 우리가 3장에서 공부할 스트림 처리를 예상하게 한다.

@quotation
@strong{@anchor{Exercise 1.42a}연습문제 1.42a:} @ref{Exercise 1.33}의 @code{sum_of_squares_of_odd} 프로시저는 반복자로 우아하게 표현될 수 있다.
범위 @math{[a, b]}에 있는 모든 홀수 정수의 제곱의 합을 계산하기 위해 @code{filter}, @code{map}, 그리고 @code{sum}을 사용하는 함수를 작성하라.

그런 다음 @ref{1.2.6}의 @code{is_prime} 술어를 사용하여 범위 내의 홀수 @emph{소수}의 제곱만 합하도록 해결책을 수정하라.
반복자 버전을 재귀적 구현과 비교해 보라---어느 것이 더 명확한가?
@end quotation

@quotation
@strong{@anchor{Exercise 1.42b}연습문제 1.42b:} 반복자 콤비네이터를 사용하여 범위 @math{[a, b]}에 있는 모든 짝수의 제곱의 곱을 계산하는 함수 @code{product_of_squares_of_evens(a: i32, b: i32) -> i32}를 구현하라.

이제 효율성을 고려해 보자: 만약 우리가 이 함수를 @code{a = 1}과 @code{b = 1000000}으로 호출한다면, Rust는 백만 개의 요소를 가진 배열을 할당하는가?
지연 평가를 언급하며, 왜 그런지 또는 왜 그렇지 않은지 설명하라.
그리고 마지막 @code{product()} 호출 전에 @code{.collect::<Vec<_>>()}를 추가하면 어떤 일이 발생하는지 설명하라.
@end quotation

@quotation
@strong{@anchor{Exercise 1.42c}연습문제 1.42c:} @ref{Exercise 1.32}의 @code{accumulate} 프로시저는 @code{combiner} 함수, @code{null_value}, 그리고 @code{term} 함수를 받는다.
@code{fold}를 사용하여 다음을 구현하라:

@enumerate a
@item
@code{sum_of_nth_powers(a: i32, b: i32, n: u32) -> i32}---@math{[a, b]}의 @math{i}에 대한 @math{i^n}의 합.

@item
@code{factorial(n: u64) -> u64}---1부터 @math{n}까지의 정수의 곱.

@item
@ref{Exercise 1.37}의 연분수, @math{1/\varphi}를 계산한다. 여기서 @math{\varphi}는 황금비이다.
연분수를 아래에서 위로 계산하기 위해 @code{fold}를 사용하라. (힌트: @code{N}과 @code{D} 값의 반복자에 대해 fold 하라.)
@end enumerate

(c) 부분의 경우, 오른쪽에서 왼쪽으로 접는 것과 왼쪽에서 오른쪽으로 접는 것에 대해 생각해야 할 것이다.
@code{rfold} 메서드(fold-right)를 조사하고 언제 @code{fold} 대신 이것이 필요한지 설명하라.
@end quotation

@node    Chapter 2, 2.1, 1.3.5, Top
@chapter 데이터를 이용한 추상화 구축 (Building Abstractions with Data)

@quotation
우리는 이제 수학적 추상화의 결정적인 단계에 도달했다: 우리는 기호가 무엇을 나타내는지 잊어버리는 것이다. @dots{} [수학자는] 게으를 필요가 없다; 기호가 나타내는 것을 쳐다보지 않고도 이 기호들을 가지고 수행할 수 있는 많은 연산들이 있다.

---헤르만 바일(Hermann Weyl), @cite{수학적 사고 방식 (The Mathematical Way of Thinking)}
@end quotation


@noindent
우리는 @ref{Chapter 1}에서 계산 프로세스와 프로그램 설계에서 프로시저의 역할에 집중했다.
우리는 원시 데이터(숫자)와 원시 연산(산술 연산)을 사용하는 방법, 합성과 조건문 및 매개변수 사용을 통해 프로시저를 결합하여 복합 프로시저를 형성하는 방법, 그리고 정의를 사용하여 프로시저를 추상화하는 방법을 보았다.
우리는 프로시저가 프로세스의 지역적 진화를 위한 패턴으로 간주될 수 있음을 보았고, 프로시저로 구현된 프로세스의 몇 가지 공통 패턴을 분류하고 추론하며 간단한 알고리즘 분석을 수행했다.
우리는 또한 고차 프로시저가 계산의 일반적인 방법을 조작하고 그 관점에서 추론할 수 있게 함으로써 우리 언어의 힘을 향상시킨다는 것을 보았다.
이것이 프로그래밍의 본질 중 상당 부분이다.

이 장에서 우리는 더 복잡한 데이터를 살펴볼 것이다.
1장의 모든 프로시저는 단순한 수치 데이터에 작용했지만, 단순 데이터는 우리가 계산을 사용하여 해결하고자 하는 많은 문제에 충분하지 않다.
프로그램은 일반적으로 복잡한 현상을 모델링하도록 설계되며, 종종 여러 측면을 가진 실제 세계의 현상을 모델링하기 위해 여러 부분으로 구성된 계산 객체를 구축해야 한다.
따라서 1장에서 우리의 초점이 프로시저를 결합하여 복합 프로시저를 형성함으로써 추상화를 구축하는 데 있었던 반면, 우리는 이 장에서 모든 프로그래밍 언어의 또 다른 핵심 측면으로 관심을 돌린다: 데이터 객체를 결합하여 @newterm{복합 데이터(compound data)}를 형성함으로써 추상화를 구축하기 위해 언어가 제공하는 수단이다.

왜 우리는 프로그래밍 언어에서 복합 데이터를 원하는가?
우리가 복합 프로시저를 원하는 것과 같은 이유에서다: 우리가 프로그램을 설계할 수 있는 개념적 수준을 높이고, 설계의 모듈성을 높이며, 우리 언어의 표현력을 향상시키기 위해서다.
프로시저를 정의하는 능력이 언어의 원시 연산보다 더 높은 개념적 수준에서 프로세스를 다룰 수 있게 해주는 것처럼, 복합 데이터 객체를 구축하는 능력은 언어의 원시 데이터 객체보다 더 높은 개념적 수준에서 데이터를 다룰 수 있게 해준다.

유리수 산술 연산을 수행하는 시스템을 설계하는 작업을 고려해 보자.
우리는 두 유리수를 받아 그 합을 생성하는 연산 @code{add_rat}을 상상할 수 있다.
단순 데이터 측면에서, 유리수는 두 개의 정수, 즉 분자와 분모로 생각할 수 있다.
따라서 우리는 각 유리수가 두 개의 정수(분자와 분모)로 표현되고 @code{add_rat}이 두 프로시저(하나는 합의 분자를 생성하고 하나는 분모를 생성하는)로 구현되는 프로그램을 설계할 수 있다.
하지만 이것은 어색할 것이다. 왜냐하면 우리는 어떤 분자가 어떤 분모에 대응하는지 명시적으로 추적해야 하기 때문이다.
많은 유리수에 대해 많은 연산을 수행하려는 시스템에서, 그러한 부기(bookkeeping) 세부 사항은 프로그램을 상당히 어수선하게 만들 것이며, 우리 마음을 혼란스럽게 할 것이다.
분자와 분모를 ``접착''하여 하나의 쌍---@newterm{복합 데이터 객체(compound data object)}---을 형성하고, 우리 프로그램이 유리수를 하나의 개념적 단위로 간주하는 것과 일관된 방식으로 조작할 수 있다면 훨씬 더 좋을 것이다.

복합 데이터의 사용은 또한 우리 프로그램의 모듈성을 높일 수 있게 해준다.
만약 우리가 유리수를 그 자체로 객체로서 직접 조작할 수 있다면, 우리는 유리수 자체를 다루는 프로그램 부분과 유리수가 정수 쌍으로 표현되는 방법에 대한 세부 사항을 분리할 수 있다.
데이터 객체가 어떻게 표현되는지 다루는 프로그램 부분과 데이터 객체가 어떻게 사용되는지 다루는 프로그램 부분을 격리하는 일반적인 기술은 @newterm{데이터 추상화(data abstraction)}라고 불리는 강력한 설계 방법론이다.
우리는 데이터 추상화가 어떻게 프로그램을 설계, 유지 보수, 그리고 수정하기 훨씬 더 쉽게 만드는지 보게 될 것이다.

복합 데이터의 사용은 우리 프로그래밍 언어의 표현력을 실질적으로 증가시킨다.
``선형 결합'' @math{{ax + by}}를 형성하는 아이디어를 고려해 보자.
우리는 @math{a}, @math{b}, @math{x}, 그리고 @math{y}를 인자로 받아 @math{{ax + by}}의 값을 반환하는 프로시저를 작성하고 싶을 수 있다.
만약 인자가 숫자라면 이것은 어려움이 없다. 왜냐하면 우리는 다음과 같이 함수를 쉽게 정의할 수 있기 때문이다.

@example
fn linear_combination(a: i64, b: i64, x: i64, y: i64) -> i64 @{
    a * x + b * y
@}
@end example

@noindent
하지만 우리가 숫자에만 관심이 있는 것이 아니라고 가정해 보자.
우리는 덧셈과 곱셈이 정의될 때마다---유리수, 복소수, 다항식, 또는 무엇이든---선형 결합을 형성할 수 있다는 아이디어를 절차적 용어로 표현하고 싶다고 가정해 보자.
우리는 이것을 트레이트 바운드를 사용하는 함수로 표현할 수 있다:

@example
use std::ops::@{Add, Mul@};

fn linear_combination<T>(a: T, b: T, x: T, y: T) -> T
where
    T: Add<Output = T> + Mul<Output = T> + Copy,
@{
    a * x + b * y
@}
@end example

@noindent
여기서 트레이트 바운드 @code{Add<Output = T> + Mul<Output = T>}는 @code{T}가 덧셈과 곱셈 연산을 지원해야 함을 명시한다. 핵심은 @code{linear_combination}이 @code{T}가 이 트레이트들을 구현한다는 것만 알면 된다는 것이다---이 함수는 정수, 부동 소수점 숫자, 유리수, 복소수, 또는 다항식이든 상관없이 그렇게 하는 모든 타입에 대해 작동한다.
함수의 관점에서 볼 때, @code{a}, @code{b}, @code{x}, 그리고 @code{y}가 무엇인지는 무관하며, 그것들이 더 원시적인 데이터로 어떻게 표현될 수 있는지는 더더욱 무관하다.
이 동일한 예제는 왜 우리 프로그래밍 언어가 복합 객체를 직접 조작할 수 있는 능력을 제공하는 것이 중요한지 보여준다: 이것 없이는 @code{linear_combination}과 같은 함수가 서로 다른 타입에 대해 일반적으로 작동하게 할 방법이 없다.@footnote{프로시저를 직접 조작하는 능력은 프로그래밍 언어의 표현력을 유사하게 증가시킨다. 예를 들어, @ref{1.3.1}에서 우리는 @code{term} 프로시저를 인자로 받아 지정된 구간에서 @code{term} 값들의 합을 계산하는 @code{sum} 프로시저를 소개했다. @code{sum}을 정의하기 위해, @code{term}과 같은 프로시저가 더 원시적인 연산으로 어떻게 표현될 수 있는지와 무관하게 그 자체로 하나의 개체로서 @code{term}에 대해 말할 수 있는 것이 중요하다. 실제로, 만약 우리에게 ``프로시저''라는 개념이 없었다면, @code{sum}과 같은 연산을 정의할 가능성을 생각조차 하지 못했을 것이다. 게다가, 합산 수행에 관한 한, @code{term}이 더 원시적인 연산으로부터 어떻게 구성될 수 있는지에 대한 세부 사항은 무관하다.}

우리는 위에서 언급한 유리수 산술 시스템을 구현함으로써 이 장을 시작한다.
이것은 복합 데이터와 데이터 추상화에 대한 우리 논의의 배경을 형성할 것이다.
복합 프로시저와 마찬가지로, 다루어야 할 주요 이슈는 복잡성에 대처하는 기술로서의 추상화이며, 우리는 데이터 추상화가 프로그램의 서로 다른 부분 사이에 적절한 @newterm{추상화 장벽(abstraction barriers)}을 세울 수 있게 해주는 방법을 보게 될 것이다.

우리는 복합 데이터를 형성하는 열쇠가 프로그래밍 언어가 데이터 객체들을 결합하여 더 복잡한 데이터 객체를 형성할 수 있도록 일종의 ``풀(glue)''을 제공해야 한다는 것임을 보게 될 것이다.
많은 가능한 종류의 풀이 있다.
실제로, 우리는 특별한 ``데이터'' 연산 없이 오직 프로시저만을 사용하여 복합 데이터를 형성하는 방법을 발견할 것이다.
이것은 1장의 끝부분에서 이미 희미해지고 있던 ``프로시저''와 ``데이터'' 사이의 구분을 더욱 모호하게 만들 것이다.
우리는 또한 시퀀스와 트리를 표현하기 위한 몇 가지 관습적인 기술을 탐구할 것이다.
복합 데이터를 다루는 데 있어 하나의 핵심 아이디어는 @newterm{폐포(closure, 클로저)} 개념이다---우리가 데이터 객체를 결합하는 데 사용하는 풀은 원시 데이터 객체뿐만 아니라 복합 데이터 객체도 결합할 수 있어야 한다는 것이다.
또 다른 핵심 아이디어는 복합 데이터 객체가 프로그램 모듈을 믹스 앤 매치 방식으로 결합하기 위한 @newterm{관습적인 인터페이스(conventional interfaces)} 역할을 할 수 있다는 것이다.
우리는 폐포를 생생한 방식으로 활용하는 간단한 그래픽 언어를 제시함으로써 이러한 아이디어 중 일부를 예시한다.

그런 다음 우리는 숫자뿐만 아니라 임의의 기호가 기본 부분이 될 수 있는 데이터인 @newterm{기호 표현식(symbolic expressions)}을 도입함으로써 우리 언어의 표현력을 증강할 것이다.
우리는 객체 집합을 표현하기 위한 다양한 대안을 탐구한다.
우리는 주어진 수치 함수가 많은 다른 계산 프로세스에 의해 계산될 수 있는 것처럼, 주어진 데이터 구조가 더 단순한 객체 측면에서 표현될 수 있는 많은 방법이 있으며, 표현의 선택이 데이터를 조작하는 프로세스의 시간 및 공간 요구 사항에 상당한 영향을 미칠 수 있음을 알게 될 것이다.
우리는 기호 미분, 집합 표현, 그리고 정보 인코딩의 맥락에서 이러한 아이디어들을 조사할 것이다.

다음으로 우리는 프로그램의 다른 부분에 의해 다르게 표현될 수 있는 데이터를 다루는 문제를 다룰 것이다.
이것은 많은 다른 유형의 데이터를 처리해야 하는 @newterm{제네릭 연산(generic operations)}을 구현할 필요성으로 이어진다.
제네릭 연산이 존재할 때 모듈성을 유지하려면 단순한 데이터 추상화만으로 세울 수 있는 것보다 더 강력한 추상화 장벽이 필요하다.
특히, 우리는 개별 데이터 표현이 격리되어 설계된 다음 @newterm{가법적으로(additively)} (즉, 수정 없이) 결합될 수 있게 하는 기술로서 @newterm{데이터 주도 프로그래밍(data-directed programming)}을 소개한다.
시스템 설계에 대한 이 접근 방식의 힘을 설명하기 위해, 우리는 다항식의 계수가 정수, 유리수, 복소수, 심지어 다른 다항식일 수도 있는 다항식에 대한 기호 산술을 수행하는 패키지의 구현에 배운 것을 적용함으로써 이 장을 마친다.

@menu
* 2.1::              Introduction to Data Abstraction
* 2.2::              Hierarchical Data and the Closure Property
* 2.3::              Symbolic Data
* 2.4::              Multiple Representations for Abstract Data
* 2.5::              Systems with Generic Operations
@end menu

@node	2.1, 2.2, Chapter 2, Chapter 2
@section 데이터 추상화 소개 (Introduction to Data Abstraction)

@ref{1.1.8}에서, 우리는 더 복잡한 프로시저를 생성하는 요소로 사용되는 프로시저가 특정 연산들의 집합일 뿐만 아니라 절차적 추상화로도 간주될 수 있다는 점에 주목했다.
즉, 프로시저가 어떻게 구현되었는지에 대한 세부 사항은 억제될 수 있으며, 특정 프로시저 자체는 동일한 전체적인 동작을 하는 다른 프로시저로 대체될 수 있다.
달리 말하면, 우리는 프로시저가 사용되는 방식과 프로시저가 더 원시적인 프로시저로 구현되는 방식의 세부 사항을 분리하는 추상화를 만들 수 있었다.
복합 데이터에 대한 유사한 개념을 @newterm{데이터 추상화(data abstraction)}라고 부른다.
데이터 추상화는 복합 데이터 객체가 어떻게 사용되는지와 그것이 더 원시적인 데이터 객체로부터 어떻게 구축되는지에 대한 세부 사항을 격리할 수 있게 해주는 방법론이다.

데이터 추상화의 기본 아이디어는 복합 데이터 객체를 사용하는 프로그램이 ``추상 데이터(abstract data)''에 대해 작동하도록 구조화하는 것이다.
즉, 우리 프로그램은 현재 작업을 수행하는 데 꼭 필요한 것 외에는 데이터에 대해 어떤 가정도 하지 않는 방식으로 데이터를 사용해야 한다.
동시에, 데이터를 사용하는 프로그램과 독립적으로 ``구체적인'' 데이터 표현이 정의된다.
우리 시스템의 이 두 부분 사이의 인터페이스는 구체적인 표현의 관점에서 추상 데이터를 구현하는 @newterm{선택자(selectors)}와 @newterm{생성자(constructors)}라고 불리는 프로시저 집합이 될 것이다.
이 기술을 설명하기 위해, 우리는 유리수를 조작하기 위한 프로시저 집합을 설계하는 방법을 고려할 것이다.

@menu
* 2.1.1::            Example: Arithmetic Operations for Rational Numbers
* 2.1.2::            Abstraction Barriers
* 2.1.3::            What Is Meant by Data?
* 2.1.4::            Extended Exercise: Interval Arithmetic
@end menu

@node	2.1.1, 2.1.2, 2.1, 2.1
@subsection 예제: 유리수 산술 연산 (Example: Arithmetic Operations for Rational Numbers)

우리가 유리수 산술 연산을 하고 싶다고 가정해 보자.
우리는 유리수를 더하고, 빼고, 곱하고, 나누고, 두 유리수가 같은지 테스트할 수 있기를 원한다.

먼저 분자와 분모로부터 유리수를 생성하는 방법이 이미 있다고 가정해 보자.
또한 유리수가 주어졌을 때, 그 분자와 분모를 추출(또는 선택)하는 방법이 있다고 가정하자.
생성자와 선택자가 다음과 같은 프로시저로 사용 가능하다고 더 가정해 보자:

@itemize @bullet

@item
@code{Rational::new(⟨@var{n}⟩, ⟨@var{d}⟩)}는 분자가 정수 @code{⟨@var{n}⟩}이고 분모가 정수 @code{⟨@var{d}⟩}인 유리수를 반환한다.

@item
@code{⟨@var{x}⟩.num()}은 유리수 @code{⟨@var{x}⟩}의 분자를 반환한다.

@item
@code{⟨@var{x}⟩.denom()}은 유리수 @code{⟨@var{x}⟩}의 분모를 반환한다.

@end itemize

@noindent
우리는 여기서 강력한 합성 전략을 사용하고 있다: @newterm{희망적 사고(wishful thinking)}.
우리는 아직 유리수가 어떻게 표현되는지, 또는 메서드 @code{num}, @code{denom}, 그리고 @code{new}가 어떻게 구현되어야 하는지 말하지 않았다.
그렇더라도, 만약 우리에게 이 세 가지 메서드가 있다면, 우리는 다음 관계식을 사용하여 덧셈, 뺄셈, 곱셈, 나눗셈, 그리고 등식 테스트를 수행할 수 있을 것이다:
@ifinfo

@example
n_1   n_2   n_1 d_2 + n_2 d_1
--- + --- = -----------------
d_1   d_2        d_1 d_2

n_1   n_2   n_1 d_2 - n_2 d_1
--- - --- = -----------------
d_1   d_2        d_1 d_2

n_1   n_2   n_1 n_2
--- * --- = -------
d_1   d_2   d_1 d_2

n_1 / d_1   n_1 d_2
--------- = -------
n_2 / d_2   d_1 n_2

n_1   n_2
--- = ---  if and only if n_1 d_2 = n_2 d_1
d_1   d_2
@end example

@end ifinfo
@tex
\[ % :30:
 
\begin{eqnarray}
{n_1 \over d_1} + {n_2 \over d_2}       &=& {n_1 d_2 + n_2 d_1 \over d_1 d_2}, \\
{n_1 \over d_1} - {n_2 \over d_2} 	&=& {n_1 d_2 - n_2 d_1 \over d_1 d_2}, \\
{n_1 \over d_1} \times {n_2 \over d_2} 	&=& {n_1 n_2 \over d_1 d_2}, \\
{n_1 \,/\, d_1} \over {n_2 \,/\, d_2} 	&=& {n_1 d_2 \over d_1 n_2}, \\
{n_1 \over d_1} 			&=& {n_2 \over d_2} \quad
						{\rm\ if\ and\ only\ if\quad} 
						n_1 d_2 = n_2 d_1. 
\end{eqnarray}
\]
@end tex
@noindent
우리는 이 규칙들을 함수로 표현할 수 있다:

@example
fn add_rat(x: &Rational, y: &Rational) -> Rational @{
    Rational::new(
        x.num() * y.denom() + y.num() * x.denom(),
        x.denom() * y.denom()
    )
@}

fn sub_rat(x: &Rational, y: &Rational) -> Rational @{
    Rational::new(
        x.num() * y.denom() - y.num() * x.denom(),
        x.denom() * y.denom()
    )
@}

fn mul_rat(x: &Rational, y: &Rational) -> Rational @{
    Rational::new(
        x.num() * y.num(),
        x.denom() * y.denom()
    )
@}

fn div_rat(x: &Rational, y: &Rational) -> Rational @{
    Rational::new(
        x.num() * y.denom(),
        x.denom() * y.num()
    )
@}

fn equal_rat(x: &Rational, y: &Rational) -> bool @{
    x.num() * y.denom() == y.num() * x.denom()
@}
@end example

@noindent
이제 우리는 선택자와 생성자 메서드 @code{num}, @code{denom}, 그리고 @code{new}의 관점에서 유리수 연산을 정의했다.
하지만 우리는 아직 이것들을 정의하지 않았다.
우리에게 필요한 것은 분자와 분모를 접착하여 유리수를 형성하는 어떤 방법이다.

@subsubheading 쌍 (Pairs)

우리가 데이터 추상화의 구체적인 수준을 구현할 수 있도록 하기 위해, Rust는 @newterm{튜플(tuple)}이라는 복합 구조를 제공하는데, 이는 괄호와 쉼표로 구분된 값을 사용하여 생성할 수 있다.
튜플은 두 개(또는 그 이상)의 값을 받아 그 값들을 부분으로 포함하는 복합 데이터 객체를 반환한다.
쌍(2-튜플)이 주어지면, 우리는 패턴 매칭이나 @code{.0}과 @code{.1}을 사용한 필드 접근으로 그 부분들을 추출할 수 있다.@footnote{Scheme과 Lisp에서 @code{cons}, @code{car}, 그리고 @code{cdr}라는 이름은 IBM 704에서의 Lisp의 원래 구현에서 유래했다.
그 기계는 메모리 위치의 ``주소(address)''와 ``감소(decrement)'' 부분을 참조할 수 있는 주소 지정 방식을 가지고 있었다.
@code{Car}는 ``레지스터의 주소 부분의 내용(Contents of Address part of Register)''을 의미하고 @code{cdr}(``쿠더''라고 발음함)는 ``레지스터의 감소 부분의 내용(Contents of Decrement part of Register)''을 의미한다. Rust는 대신 숫자 필드 접근이나 명명된 필드를 가진 튜플과 구조체를 사용한다.} 따라서 우리는 다음과 같이 튜플을 사용할 수 있다:

@example
let x = (1, 2);

x.0
// 1

x.1
// 2
@end example

@noindent
쌍은 원시 데이터 객체와 마찬가지로 이름을 부여하고 조작할 수 있는 데이터 객체라는 점에 주목하라.
게다가 튜플은 요소가 쌍인 쌍을 형성하는 데 사용될 수 있으며, 이런 식으로 계속될 수 있다:

@example
let x = (1, 2);
let y = (3, 4);
let z = (x, y);

z.0.0
// 1

z.1.0
// 3
@end example

@noindent
@ref{2.2}에서 우리는 쌍을 결합하는 이 능력이 튜플과 구조체가 모든 종류의 복잡한 데이터 구조를 생성하기 위한 범용 구성 요소로 사용될 수 있음을 의미한다는 것을 보게 될 것이다.
복합 데이터 기본 요소인 @newterm{튜플(tuples)}과 @newterm{구조체(structs)}는 우리에게 필요한 주요 도구이다.
이것들로부터 구성된 데이터 객체는 Rust 타입 시스템의 기초이며 @newterm{리스트 구조(list-structured)} 데이터를 표현할 수 있다.

@subsubheading 유리수 표현 (Representing rational numbers)

구조체(struct)는 유리수 시스템을 완성하는 자연스러운 방법을 제공한다.
간단히 유리수를 두 개의 정수 필드(분자와 분모)를 가진 구조체로 표현하면 된다.
그러면 @code{Rational::new}, @code{num}, 그리고 @code{denom}은 다음과 같이 쉽게 구현된다:@footnote{우리는 유리수를 표현하기 위해 간단한 튜플 @code{(i64, i64)}를 사용할 수도 있는데, 이는 더 가볍다:

@example
fn make_rat(n: i64, d: i64) -> (i64, i64) @{ (n, d) @}
fn numer(x: (i64, i64)) -> i64 @{ x.0 @}
fn denom(x: (i64, i64)) -> i64 @{ x.1 @}
@end example

하지만 명명된 구조체를 사용하는 것은 더 나은 타입 안전성과 더 명확한 의도를 제공한다.
Rust 타입 시스템은 우리가 실수로 (점과 같은) 다른 것을 나타내는 튜플을 유리수로 사용하는 것을 방지할 것이다.
명명된 구조체는 또한 더 나은 문서화를 제공하며 사용자 정의 동작을 위한 트레이트를 구현할 수 있다.}

@example
struct Rational @{
    num: i64,
    denom: i64,
@}

impl Rational @{
    fn new(n: i64, d: i64) -> Self @{
        Rational @{ num: n, denom: d @}
    @}

    fn num(&self) -> i64 @{
        self.num
    @}

    fn denom(&self) -> i64 @{
        self.denom
    @}
@}
@end example

@noindent
또한, 계산 결과를 표시하기 위해, 우리는 분자, 슬래시, 분모를 출력함으로써 유리수를 출력할 수 있다:@footnote{Rust에서 우리는 @code{Display} 트레이트를 구현하여 타입에 대한 사용자 정의 서식 지정을 제공한다. @code{println!} 매크로는 값을 출력하기 위해 이 트레이트를 사용한다. @code{Display} 구현은 유용한 값을 반환하지 않으므로(@code{Result<(), fmt::Error>}를 반환함), 아래의 출력 사용에서는 표현식이 평가되는 값이 아니라 출력되는 내용만 보여준다.}

@example
use std::fmt;

impl fmt::Display for Rational @{
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result @{
        write!(f, "@{@}/@{@}", self.num, self.denom)
    @}
@}
@end example

@noindent
이제 우리는 유리수 함수들을 시도해 볼 수 있다:

@example
let one_half = Rational::new(1, 2);
println!("@{@}", one_half);
// 1/2

let one_third = Rational::new(1, 3);
println!("@{@}", add_rat(&one_half, &one_third));
// 5/6

println!("@{@}", mul_rat(&one_half, &one_third));
// 1/6

println!("@{@}", add_rat(&one_third, &one_third));
// 6/9
@end example

@noindent
마지막 예제가 보여주듯이, 우리의 유리수 구현은 유리수를 기약분수로 만들지 않는다.
우리는 @code{new}를 변경하여 이 문제를 해결할 수 있다.
만약 우리에게 두 정수의 최대공약수를 생성하는 @ref{1.2.5}의 @code{gcd}와 같은 함수가 있다면, 우리는 값을 생성하기 전에 @code{gcd}를 사용하여 분자와 분모를 기약분수로 만들 수 있다:

@example
fn gcd(a: i64, b: i64) -> i64 @{
    if b == 0 @{
        a.abs()
    @} else @{
        gcd(b, a % b)
    @}
@}

impl Rational @{
    fn new(n: i64, d: i64) -> Self @{
        let g = gcd(n, d);
        Rational @{
            num: n / g,
            denom: d / g,
        @}
    @}
    // ... 다른 메서드들 ...
@}
@end example

@noindent
이제 우리는 다음을 얻는다

@example
println!("@{@}", add_rat(&one_third, &one_third));
// 2/3
@end example

@noindent
원하는 대로다. 이 수정은 실제 연산을 구현하는 함수들(@code{add_rat} 및 @code{mul_rat}과 같은)을 변경하지 않고 생성자 @code{new}를 변경함으로써 달성되었다.

@quotation
@strong{@anchor{Exercise 2.1}연습문제 2.1:} 양수와 음수 인자를 모두 처리하는 @code{Rational::new}의 더 나은 버전을 정의하라.
@code{new}는 부호를 정규화해서 유리수가 양수이면 분자와 분모가 모두 양수이고, 유리수가 음수이면 분자만 음수가 되도록 해야 한다.
@end quotation

@node	2.1.2, 2.1.3, 2.1.1, 2.1
@subsection 추상화 장벽 (Abstraction Barriers)

복합 데이터와 데이터 추상화에 대한 더 많은 예제를 계속하기 전에, 유리수 예제에서 제기된 몇 가지 문제를 고려해 보자.
우리는 생성자 @code{Rational::new}와 메서드 @code{num}, @code{denom}의 관점에서 유리수 연산을 정의했다.
일반적으로 데이터 추상화의 기본 아이디어는 각 데이터 객체 유형에 대해 해당 유형의 데이터 객체의 모든 조작이 표현될 기본 연산 집합을 식별한 다음, 데이터를 조작할 때 그 연산들만 사용하는 것이다.

우리는 유리수 시스템의 구조를 @ref{Figure 2.1}과 같이 시각화할 수 있다.
수평선은 시스템의 서로 다른 ``레벨''을 격리하는 @newterm{추상화 장벽(abstraction barriers)}을 나타낸다.
각 레벨에서, 장벽은 데이터 추상화를 사용하는 프로그램(위쪽)과 데이터 추상화를 구현하는 프로그램(아래쪽)을 분리한다.
유리수를 사용하는 프로그램은 유리수 모듈이 ``공개용으로'' 제공하는 함수들인 @code{add_rat}, @code{sub_rat}, @code{mul_rat}, @code{div_rat}, 그리고 @code{equal_rat}의 관점에서만 유리수를 조작한다.
이 함수들은 차례로 생성자와 메서드 @code{Rational::new}, @code{num}, 그리고 @code{denom}의 관점에서만 구현되며, 이들 자체는 구조체 필드를 사용하여 구현된다.
구조체가 어떻게 구현되었는지에 대한 세부 사항은 구조체가 공개 인터페이스를 통해 조작될 수 있는 한 유리수 모듈의 나머지 부분과 무관하다.
사실상, 각 레벨의 함수와 메서드는 추상화 장벽을 정의하고 서로 다른 레벨을 연결하는 인터페이스이다.

@float
@anchor{Figure 2.1}
@ifinfo
@quotation
@strong{Figure 2.1:} 유리수 패키지의 데이터 추상화 장벽.

@example
        +------------------------------------+
--------| Programs that use rational numbers |--------
        +------------------------------------+
          Rational numbers in problem domain
            +---------------------------+
------------|   add-rat  sub-rat  ...   |-------------
            +---------------------------+
   Rational numbers as numerators and denominators
              +------------------------+
--------------| make-rat  numer  denom |--------------
              +------------------------+
              Rational numbers as pairs
                  +----------------+
------------------| cons  car  cdr |------------------
                  +----------------+
            However pairs are implemented
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap2/Fig2.1d,125mm,,,.std.svg}
@caption{@strong{Figure 2.1:} 유리수 패키지의 데이터 추상화 장벽.}
@end iftex
@end float

@noindent
이 간단한 아이디어에는 많은 장점이 있다.
한 가지 장점은 프로그램을 유지 보수하고 수정하기 훨씬 쉽게 만든다는 것이다.
어떤 복잡한 데이터 구조라도 프로그래밍 언어가 제공하는 원시 데이터 구조를 사용하여 다양한 방식으로 표현될 수 있다.
물론, 표현의 선택은 그것에 작용하는 프로그램에 영향을 미친다. 따라서 표현이 나중에 변경된다면, 그러한 모든 프로그램도 그에 따라 수정되어야 할 수 있다.
표현에 대한 의존성이 설계에 의해 아주 소수의 프로그램 모듈에 국한되지 않는다면, 대규모 프로그램의 경우 이 작업은 시간 소모적이고 비용이 많이 들 수 있다.

예를 들어, 유리수를 기약분수로 만드는 문제를 해결하는 대안적인 방법은 유리수를 생성할 때가 아니라 유리수의 부분에 접근할 때마다 약분을 수행하는 것이다.
이것은 다른 생성자와 접근자 메서드로 이어진다:

@example
impl Rational @{
    fn new(n: i64, d: i64) -> Self @{
        Rational @{ num: n, denom: d @}
    @}

    fn num(&self) -> i64 @{
        let g = gcd(self.num, self.denom);
        self.num / g
    @}

    fn denom(&self) -> i64 @{
        let g = gcd(self.num, self.denom);
        self.denom / g
    @}
@}
@end example

@noindent
이 구현과 이전 구현의 차이점은 우리가 언제 @code{gcd}를 계산하느냐에 있다.
유리수의 전형적인 사용에서 우리가 동일한 유리수의 분자와 분모에 여러 번 접근한다면, 유리수가 생성될 때 @code{gcd}를 계산하는 것이 바람직할 것이다.
그렇지 않다면, 접근할 때까지 @code{gcd} 계산을 미루는 것이 더 나을 수 있다.
어쨌든, 우리가 한 표현에서 다른 표현으로 변경할 때, @code{add_rat}, @code{sub_rat} 등의 함수는 전혀 수정할 필요가 없다.

표현에 대한 의존성을 소수의 인터페이스 프로시저로 제한하는 것은 프로그램을 수정하는 것뿐만 아니라 설계하는 데에도 도움이 되는데, 이는 우리가 대안적인 구현을 고려할 수 있는 유연성을 유지할 수 있게 해주기 때문이다.
우리의 간단한 예제를 계속하자면, 우리가 유리수 패키지를 설계하고 있는데 처음에 @code{gcd}를 생성 시점에 수행할지 선택 시점에 수행할지 결정할 수 없다고 가정해 보자.
데이터 추상화 방법론은 시스템의 나머지 부분에 대한 진전을 잃지 않으면서 그 결정을 미룰 수 있는 방법을 제공한다.

@quotation
@strong{@anchor{Exercise 2.2}연습문제 2.2:} 평면상의 선분을 표현하는 문제를 고려해 보자.
각 선분은 점의 쌍, 즉 시작점과 끝점으로 표현된다.
선분을 점의 관점에서 표현하는 @code{Segment} 구조체와 메서드 @code{start} 및 @code{end}를 정의하라.
또한, 점은 두 개의 숫자, 즉 @math{x} 좌표와 @math{y} 좌표의 쌍으로 표현될 수 있다.
따라서 이 표현을 정의하는 필드 @code{x}와 @code{y}를 가진 @code{Point} 구조체를 정의하라.
마지막으로, 여러분의 구조체와 메서드를 사용하여 선분을 인자로 받아 그 중점(좌표가 끝점 좌표의 평균인 점)을 반환하는 함수 @code{midpoint_segment}를 정의하라.
구현을 시도해 보려면 점을 출력하는 방법이 필요할 것이다:

@example
use std::fmt;

impl fmt::Display for Point @{
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result @{
        write!(f, "(@{@}, @{@})", self.x, self.y)
    @}
@}
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 2.3}연습문제 2.3:} 평면상의 직사각형에 대한 표현을 구현하라. (힌트: @ref{Exercise 2.2}를 활용하고 싶을 수 있다.)
여러분의 구조체와 메서드의 관점에서, 주어진 직사각형의 둘레와 넓이를 계산하는 함수를 생성하라.
이제 직사각형에 대한 다른 표현을 구현하라(아마도 트레이트를 사용하여).
동일한 둘레 및 넓이 함수가 두 표현 모두와 작동하도록 적절한 추상화 장벽을 갖춘 시스템을 설계할 수 있는가?
@end quotation

@node	2.1.3, 2.1.4, 2.1.2, 2.1
@subsection 데이터란 무엇인가? (What Is Meant by Data?)

우리는 @ref{2.1.1}에서 유리수 연산 @code{add_rat}, @code{sub_rat} 등을 지정되지 않은 세 함수 @code{Rational::new}, @code{num}, 그리고 @code{denom}의 관점에서 구현함으로써 유리수 구현을 시작했다.
그 시점에서, 우리는 연산들이 데이터 객체---분자, 분모, 그리고 유리수---의 관점에서 정의되고 있으며, 이 객체들의 동작은 뒤의 세 함수에 의해 지정된다고 생각할 수 있었다.

하지만 @newterm{데이터(data)}란 정확히 무엇을 의미하는가?
``주어진 메서드와 생성자에 의해 구현된 것''이라고 말하는 것만으로는 충분하지 않다.
분명히 임의의 세 함수 집합이 모두 유리수 구현을 위한 적절한 기초가 될 수 있는 것은 아니다.
우리는 만약 정수 쌍 @code{n}과 @code{d}로부터 유리수 @code{x}를 생성한다면, @code{x}의 @code{num}과 @code{denom}을 추출하여 나누면 @code{n}을 @code{d}로 나눈 것과 같은 결과를 산출해야 한다는 것을 보장해야 한다.
다시 말해, @code{Rational::new}, @code{num}, 그리고 @code{denom}은 어떤 정수 @code{n}과 0이 아닌 어떤 정수 @code{d}에 대해서도, 만약 @code{x}가 @code{Rational::new(n, d)}라면 다음 조건을 만족해야 한다.
@ifinfo

@example
x.num()      n
--------- = ---
x.denom()    d
@end example

@end ifinfo
@tex
\[ % :31:
  {\text{x.num()} \over \text{x.denom()}} = {{\text{n} \over \text{d}}.}   \]
@end tex
사실, 이것이 @code{Rational::new}, @code{num}, 그리고 @code{denom}이 유리수 표현을 위한 적절한 기초를 형성하기 위해 충족해야 할 유일한 조건이다.
일반적으로, 우리는 데이터를 어떤 메서드와 생성자의 집합, 그리고 이 함수들이 유효한 표현이 되기 위해 충족해야 할 지정된 조건들로 정의된다고 생각할 수 있다.@footnote{놀랍게도, 이 아이디어를 엄밀하게 공식화하는 것은 매우 어렵다. 그러한 공식화를 제공하는 두 가지 접근 방식이 있다. 하나는 C. A. R. @ref{Hoare (1972)}가 개척한 것으로, @newterm{추상 모델(abstract models)} 방법이라고 알려져 있다.
이것은 위의 유리수 예제에서 개요를 설명한 것과 같은 ``프로시저 더하기 조건'' 명세를 공식화한다.
유리수 표현에 대한 조건이 정수에 대한 사실(등식과 나눗셈)의 관점에서 진술되었음에 주목하라.
일반적으로 추상 모델은 이전에 정의된 데이터 객체 타입의 관점에서 새로운 종류의 데이터 객체를 정의한다.
따라서 데이터 객체에 대한 주장은 이전에 정의된 데이터 객체에 대한 주장으로 환원됨으로써 확인될 수 있다.
Zilles(@abbr{MIT}), Goguen, Thatcher, Wagner, Wright(IBM, @ref{Thatcher et al. 1978} 참조), 그리고 Guttag(토론토, @ref{Guttag 1977} 참조)가 도입한 또 다른 접근 방식은 @newterm{대수적 명세(algebraic specification)}라고 불린다.
이것은 ``프로시저''를 추상 대수 시스템의 요소로 간주하며, 그 동작은 우리의 ``조건''에 해당하는 공리들에 의해 지정된다. 그리고 데이터 객체에 대한 주장을 확인하기 위해 추상 대수의 기술을 사용한다.
두 방법 모두 @ref{Liskov and Zilles (1975)}의 논문에서 조사되었다.}

이 관점은 유리수와 같은 ``고수준'' 데이터 객체뿐만 아니라 더 저수준 객체를 정의하는 데에도 사용될 수 있다.
우리가 유리수를 정의하기 위해 사용했던 쌍(pair)의 개념을 고려해 보자.
우리는 쌍이 무엇인지 실제로 말한 적이 없고, 단지 Rust가 쌍을 조작하기 위해 튜플과 구조체를 제공한다고만 했다.
하지만 우리가 쌍에 대해 알아야 할 유일한 것은 두 객체를 접착하면 나중에 그 객체들을 다시 가져올 수 있다는 것이다.
즉, 연산들은 어떤 객체 @code{x}와 @code{y}에 대해, 만약 @code{z}가 @code{(x, y)}라면 @code{z.0}은 @code{x}이고 @code{z.1}은 @code{y}라는 조건을 만족한다.
실제로 튜플은 Rust의 원시 요소이다.
그러나 위의 조건을 만족하는 어떤 구현이라도 쌍을 구현하는 기초로 사용될 수 있다.
이 점은 우리가 데이터 구조를 전혀 사용하지 않고 오직 클로저만을 사용하여 쌍 연산을 구현할 수 있다는 사실에 의해 놀랍게 예시된다.
정의는 다음과 같다:

@example
fn cons<T: 'static, U: 'static>(x: T, y: U) -> Box<dyn Fn(i32) -> Box<dyn std::any::Any>> @{
    Box::new(move |m| @{
        match m @{
            0 => Box::new(x.clone()) as Box<dyn std::any::Any>,
            1 => Box::new(y.clone()) as Box<dyn std::any::Any>,
            _ => panic!("Argument not 0 or 1: CONS"),
        @}
    @})
@}

fn car<T: 'static>(z: &dyn Fn(i32) -> Box<dyn std::any::Any>) -> T
where
    T: Clone + 'static,
@{
    *z(0).downcast::<T>().unwrap()
@}

fn cdr<U: 'static>(z: &dyn Fn(i32) -> Box<dyn std::any::Any>) -> U
where
    U: Clone + 'static,
@{
    *z(1).downcast::<U>().unwrap()
@}
@end example

@noindent
이러한 클로저의 사용은 데이터가 무엇이어야 하는지에 대한 우리의 직관적인 개념과는 전혀 다르다.
그럼에도 불구하고, 이것이 쌍을 표현하는 유효한 방법임을 보이기 위해 우리가 해야 할 일은 이 함수들이 위에서 주어진 조건을 만족함을 확인하는 것뿐이다.

주목해야 할 미묘한 점은 @code{cons(x, y)}에 의해 반환된 값이 클로저---즉 @code{x}와 @code{y}를 포획하고 인자 하나를 받아 인자가 0인지 1인지에 따라 @code{x} 또는 @code{y}를 반환하는 함수---라는 것이다.
이에 상응하여, @code{car(z)}는 @code{z}를 0에 적용하는 것으로 정의된다.
따라서 만약 @code{z}가 @code{cons(x, y)}에 의해 형성된 클로저라면, @code{z}를 0에 적용하면 @code{x}를 산출할 것이다.
따라서 우리는 원하는 대로 @code{car(cons(x, y))}가 @code{x}를 산출함을 보였다.
마찬가지로, @code{cdr(cons(x, y))}는 @code{cons(x, y)}가 반환한 클로저를 1에 적용하며, 이는 @code{y}를 반환한다.
따라서, 이 절차적 쌍 구현은 유효한 구현이며, 만약 우리가 @code{cons}, @code{car}, 그리고 @code{cdr}만을 사용하여 쌍에 접근한다면 이 구현을 튜플이나 구조체를 사용하는 것과 구별할 수 없다.

쌍의 절차적 표현을 보여주는 요점은 Rust가 이런 식으로 작동한다는 것(Rust는 효율성과 타입 안전성 때문에 튜플과 구조체를 직접 구현한다)이 아니라, 이런 식으로 작동할 수 있다는 것이다.
절차적 표현은 비록 모호하고 동적 타이핑을 필요로 하지만, 쌍이 충족해야 할 유일한 조건을 충족하므로 쌍을 표현하는 완벽하게 적절한 방법이다.
이 예제는 또한 클로저를 값으로 조작하는 능력이 복합 데이터를 표현하는 능력을 자동으로 제공함을 보여준다.
이것은 지금은 호기심거리처럼 보일지 모르지만, 데이터의 절차적 표현은 우리의 프로그래밍 레퍼토리에서 중심적인 역할을 할 것이다.
이런 스타일의 프로그래밍을 종종 @newterm{메시지 전달(message passing)}이라고 부르며, 우리는 @ref{Chapter 3}에서 모델링과 시뮬레이션의 문제를 다룰 때 이것을 기본 도구로 사용할 것이다.

@quotation
@strong{@anchor{Exercise 2.4}연습문제 2.4:} 다음은 클로저를 사용하는 쌍의 대안적인 절차적 표현이다. 이 표현에 대해, 임의의 객체 @code{x}와 @code{y}에 대해 @code{car(cons(x, y))}가 @code{x}를 산출함을 확인하라.

@example
// 제네릭과 클로저를 사용하는 단순화된 버전
type Pair<T> = Box<dyn Fn(Box<dyn Fn(T, T) -> T>) -> T>;

fn cons<T: Clone + 'static>(x: T, y: T) -> Pair<T> @{
    Box::new(move |m| m(x.clone(), y.clone()))
@}

fn car<T: Clone + 'static>(z: &Pair<T>) -> T @{
    z(Box::new(|p, _q| p))
@}
@end example

@code{cdr}의 해당 정의는 무엇인가? (힌트: 이것이 작동함을 확인하기 위해 @ref{1.1.5}의 치환 모델을 사용하라.)
@end quotation

@quotation
@strong{@anchor{Exercise 2.5}연습문제 2.5:} 쌍 @math{a}와 @math{b}를 @math{{2^a 3^b}}의 곱인 정수로 표현한다면, 숫자와 산술 연산만 사용하여 음이 아닌 정수의 쌍을 표현할 수 있음을 보여라.
프로시저 @code{cons}, @code{car}, 그리고 @code{cdr}의 해당 정의를 제시하라.
@end quotation

@quotation
@strong{@anchor{Exercise 2.6}연습문제 2.6:} 쌍을 클로저로 표현하는 것이 충분히 놀랍지 않다면, 클로저를 조작할 수 있는 언어에서는 0과 1을 더하는 연산을 다음과 같이 구현함으로써 숫자 없이도(적어도 음이 아닌 정수에 관해서는) 지낼 수 있다는 것을 고려해 보라.

@example
// Rust에서의 처치 숫자 (단순화됨)
type ChurchNum<T> = Box<dyn Fn(Box<dyn Fn(T) -> T>) -> Box<dyn Fn(T) -> T>>;

fn zero<T: 'static>() -> ChurchNum<T> @{
    Box::new(|_f| Box::new(|x| x))
@}

fn add_1<T: 'static>(n: ChurchNum<T>) -> ChurchNum<T> @{
    Box::new(move |f| @{
        let nf = n(f.clone());
        Box::new(move |x| f(nf(x)))
    @})
@}
@end example

이 표현은 발명자인 논리학자 알론조 처치(Alonzo Church, λ-계산법을 발명한 사람)의 이름을 따서 @newterm{처치 숫자(Church numerals)}라고 알려져 있다.

@code{one}과 @code{two}를 (@code{zero}와 @code{add_1}의 관점이 아니라) 직접 정의하라. (힌트: @code{add_1(zero())}를 평가하기 위해 치환을 사용하라).
덧셈 함수 @code{add}를 (@code{add_1}의 반복 적용의 관점이 아니라) 직접 정의하라.
@end quotation

@node	2.1.4, 2.2, Chapter 2, 2.1
@subsection 심화 연습 문제: 구간 산술 (Extended Exercise: Interval Arithmetic)

Alyssa P. Hacker는 사람들이 공학 문제를 해결하는 것을 돕기 위해 시스템을 설계하고 있다.
그녀가 시스템에 제공하고 싶은 한 가지 기능은 알려진 정밀도로 부정확한 수량(물리적 장치의 측정된 매개변수와 같은)을 조작하는 능력이다. 이를 통해 그러한 근사값으로 계산을 수행할 때 결과가 알려진 정밀도의 숫자가 되도록 하는 것이다.

전기 기술자들은 Alyssa의 시스템을 사용하여 전기량을 계산할 것이다.
그들은 때때로 공식
@ifinfo

@example
            1
R_p = -------------
      1/R_1 + 1/R_2
@end example

@end ifinfo
@tex
\[ % :32:
  R_p \,=\, {{1 \over 1 / R_1 + 1 / R_2}.}   \]
@end tex
을 사용하여 두 저항 @math{R_1}과 @math{R_2}의 병렬 등가 저항 @math{R_p}의 값을 계산해야 한다.
저항 값은 대개 저항 제조사가 보장하는 어떤 허용 오차(tolerance)까지만 알려져 있다.
예를 들어, ``10% 허용 오차를 가진 6.8옴''이라고 표시된 저항을 산다면, 저항이 6.8 @math{-} 0.68 = 6.12옴과 6.8 + 0.68 = 7.48옴 사이의 저항을 갖는다는 것만 확신할 수 있다.
따라서 만약 6.8옴 10% 저항을 4.7옴 5% 저항과 병렬로 연결하면, 조합의 저항은 약 2.58옴(두 저항이 하한에 있을 때)에서 약 2.97옴(두 저항이 상한에 있을 때)까지의 범위를 가질 수 있다.

Alyssa의 아이디어는 ``구간 산술(interval arithmetic)''을 ``구간(intervals)''(부정확한 수량의 가능한 값의 범위를 나타내는 객체)을 결합하기 위한 산술 연산 세트로 구현하는 것이다.
두 구간을 더하거나, 빼거나, 곱하거나, 나누는 결과는 그 자체로 결과의 범위를 나타내는 구간이다.

Alyssa는 하한(lower bound)과 상한(upper bound)이라는 두 끝점을 가진 ``구간''이라는 추상 객체의 존재를 가정한다.
그녀는 또한 구간의 끝점이 주어지면 데이터 생성자 @code{Interval::new}를 사용하여 구간을 생성할 수 있다고 가정한다.
Alyssa는 먼저 두 구간을 더하는 프로시저를 작성한다.
그녀는 합이 가질 수 있는 최솟값은 두 하한의 합이고 최댓값은 두 상한의 합이라고 추론한다:

@example
fn add_interval(x: &Interval, y: &Interval) -> Interval @{
    Interval::new(
        x.lower_bound() + y.lower_bound(),
        x.upper_bound() + y.upper_bound()
    )
@}
@end example

@noindent
Alyssa는 또한 경계들의 곱의 최솟값과 최댓값을 찾아 결과 구간의 경계로 사용함으로써 두 구간의 곱을 계산한다.
(@code{min}과 @code{max}는 임의의 수의 인자의 최솟값이나 최댓값을 찾는 원시 함수이다.)

@example
fn mul_interval(x: &Interval, y: &Interval) -> Interval @{
    let p1 = x.lower_bound() * y.lower_bound();
    let p2 = x.lower_bound() * y.upper_bound();
    let p3 = x.upper_bound() * y.lower_bound();
    let p4 = x.upper_bound() * y.upper_bound();
    Interval::new(
        p1.min(p2).min(p3).min(p4),
        p1.max(p2).max(p3).max(p4)
    )
@}
@end example

@noindent
두 구간을 나누기 위해, Alyssa는 첫 번째 구간에 두 번째 구간의 역수를 곱한다.
역수 구간의 경계는 상한의 역수와 하한의 역수 순서라는 점에 주목하라.

@example
fn div_interval(x: &Interval, y: &Interval) -> Interval @{
    mul_interval(
        x,
        &Interval::new(
            1.0 / y.upper_bound(),
            1.0 / y.lower_bound()
        )
    )
@}
@end example

@quotation
@strong{@anchor{Exercise 2.7}연습문제 2.7:} Alyssa의 프로그램은 불완전하다. 왜냐하면 그녀가 구간 추상화의 구현을 명시하지 않았기 때문이다.
여기 구간 생성자의 정의가 있다:

@example
struct Interval @{
    lower: f64,
    upper: f64,
@}

impl Interval @{
    fn new(a: f64, b: f64) -> Self @{
        Interval @{ lower: a, upper: b @}
    @}
@}
@end example

선택자 @code{upper_bound}와 @code{lower_bound}를 정의하여 구현을 완료하라.
@end quotation

@quotation
@strong{@anchor{Exercise 2.8}연습문제 2.8:} Alyssa와 유사한 추론을 사용하여, 두 구간의 차이를 어떻게 계산할 수 있는지 설명하라.
해당하는 뺄셈 프로시저 @code{sub_interval}을 정의하라.
@end quotation

@quotation
@strong{@anchor{Exercise 2.9}연습문제 2.9:} 구간의 @newterm{너비(width)}는 상한과 하한 차이의 절반이다.
너비는 구간에 의해 지정된 숫자의 불확실성에 대한 척도이다.
어떤 산술 연산의 경우 두 구간을 결합한 결과의 너비는 인자 구간들의 너비만의 함수인 반면, 다른 연산의 경우 결합의 너비는 인자 구간들의 너비만의 함수가 아니다.
두 구간의 합(또는 차)의 너비는 더해지는(또는 빼지는) 구간들의 너비만의 함수임을 보여라.
곱셈이나 나눗셈에 대해서는 이것이 사실이 아님을 보여주는 예제를 제시하라.
@end quotation

@quotation
@strong{@anchor{Exercise 2.10}연습문제 2.10:} 전문가 시스템 프로그래머인 Ben Bitdiddle은 Alyssa의 어깨너머로 보다가 0을 포함하는 구간으로 나누는 것이 무엇을 의미하는지 불분명하다고 논평한다.
Alyssa의 코드를 수정하여 이 조건을 확인하고 발생 시 오류를 신호하도록 하라.
@end quotation

@quotation
@strong{@anchor{Exercise 2.11}연습문제 2.11:} 지나가면서, Ben은 또한 아리송하게 논평한다: ``구간의 끝점들의 부호를 검사함으로써, @code{mul_interval}을 9가지 경우로 나눌 수 있는데, 그중 하나만이 두 번 이상의 곱셈을 필요로 한다.''
Ben의 제안을 사용하여 이 프로시저를 다시 작성하라.

프로그램을 디버깅한 후, Alyssa는 그것을 잠재적인 사용자에게 보여주었는데, 그는 그녀의 프로그램이 잘못된 문제를 해결한다고 불평한다.
그는 중심값과 가법적 허용 오차(additive tolerance)로 표현된 숫자를 다룰 수 있는 프로그램을 원한다; 예를 들어, [3.35, 3.65]보다는 3.5 @math{\pm} 0.15와 같은 구간으로 작업하고 싶어 한다.
Alyssa는 책상으로 돌아와 대안적인 생성자와 대안적인 선택자를 제공함으로써 이 문제를 해결한다:

@example
impl Interval @{
    fn from_center_width(c: f64, w: f64) -> Self @{
        Interval::new(c - w, c + w)
    @}

    fn center(&self) -> f64 @{
        (self.lower_bound() + self.upper_bound()) / 2.0
    @}

    fn width(&self) -> f64 @{
        (self.upper_bound() - self.lower_bound()) / 2.0
    @}
@}
@end example

불행히도, Alyssa의 사용자 대부분은 엔지니어이다.
실제 공학 상황은 대개 구간의 중점에 대한 구간 너비의 비율로 측정되는 작은 불확실성만을 가진 측정값을 포함한다.
엔지니어들은 대개 앞서 주어진 저항 사양에서처럼 장치의 매개변수에 대해 백분율 허용 오차를 지정한다.
@end quotation

@quotation
@strong{@anchor{Exercise 2.12}연습문제 2.12:} 중심과 백분율 허용 오차를 받아 원하는 구간을 생성하는 생성자 @code{make-center-percent}를 정의하라.
또한 주어진 구간에 대해 백분율 허용 오차를 생성하는 선택자 @code{percent}를 정의해야 한다.
@code{center} 선택자는 위에 표시된 것과 같다.
@end quotation

@quotation
@strong{@anchor{Exercise 2.13}연습문제 2.13:} 작은 백분율 허용 오차를 가정할 때, 두 구간의 곱의 백분율 허용 오차를 인자들의 허용 오차로 나타내는 간단한 공식이 있음을 보여라.
모든 숫자가 양수라고 가정하여 문제를 단순화할 수 있다.

상당한 작업 끝에, Alyssa P. Hacker는 완성된 시스템을 인도한다.
몇 년 후, 그녀가 그것에 대해 모두 잊어버린 뒤, 그녀는 화가 난 사용자 Lem E. Tweakit으로부터 광란의 전화를 받는다.
Lem은 병렬 저항 공식이 대수적으로 동등한 두 가지 방식으로 쓰일 수 있다는 것을 알아챈 것 같다:
@ifinfo

@example
 R_1 R_2
---------
R_1 + R_2
@end example

@end ifinfo
@tex
\[ % :33:
  {R_1 R_2 \over R_1 + R_2}  \]
@end tex
@noindent
그리고
@ifinfo

@example
      1
-------------
1/R_1 + 1/R_2
@end example

@end ifinfo
@tex
\[ % :34:
  {{1 \over 1 / R_1 + 1 / R_2}.}  \]
@end tex
그는 각각 병렬 저항 공식을 다르게 계산하는 다음 두 프로그램을 작성했다:

@example
fn par1(r1: &Interval, r2: &Interval) -> Interval @{
    div_interval(
        &mul_interval(r1, r2),
        &add_interval(r1, r2)
    )
@}

fn par2(r1: &Interval, r2: &Interval) -> Interval @{
    let one = Interval::new(1.0, 1.0);
    div_interval(
        &one,
        &add_interval(
            &div_interval(&one, r1),
            &div_interval(&one, r2)
        )
    )
@}
@end example

Lem은 Alyssa의 프로그램이 두 가지 계산 방식에 대해 다른 답을 준다고 불평한다. 이것은 심각한 불만이다.
@end quotation

@quotation
@strong{@anchor{Exercise 2.14}연습문제 2.14:} Lem이 옳음을 증명하라.
다양한 산술 표현식에 대해 시스템의 동작을 조사하라.
어떤 구간 @math{A}와 @math{B}를 만들고, 표현식 @math{{A / A}}와 @math{{A / B}}를 계산하는 데 그것들을 사용하라.
너비가 중심값의 작은 백분율인 구간을 사용하면 가장 많은 통찰력을 얻을 수 있다.
계산 결과를 중심-백분율 형태(@ref{Exercise 2.12} 참조)로 조사하라.
@end quotation

@quotation
@strong{@anchor{Exercise 2.15}연습문제 2.15:} 또 다른 사용자인 Eva Lu Ator 또한 대수적으로 동등하지만 다른 표현식에 의해 계산된 다른 구간들을 알아챘다.
그녀는 Alyssa의 시스템을 사용하여 구간을 계산하는 공식이, 불확실한 숫자를 나타내는 어떤 변수도 반복되지 않는 형태로 쓰일 수 있다면 더 빡빡한 오차 한계를 생성할 것이라고 말한다.
따라서 그녀는 @code{par2}가 @code{par1}보다 병렬 저항에 대해 ``더 나은'' 프로그램이라고 말한다.
그녀가 옳은가? 왜 그런가?
@end quotation

@quotation
@strong{@anchor{Exercise 2.16}연습문제 2.16:} 일반적으로 왜 대수적으로 동등한 표현식이 다른 답으로 이어질 수 있는지 설명하라.
이 결점이 없는 구간 산술 패키지를 고안할 수 있는가, 아니면 이 작업은 불가능한가?
(경고: 이 문제는 매우 어렵다.)
@end quotation


@node	2.2, 2.3, 2.1, Chapter 2
@section 계층적 데이터와 클로저 속성 (Hierarchical Data and the Closure Property)

우리가 보았듯이, 쌍은 복합 데이터 객체를 구축하는 데 사용할 수 있는 원시적인 ``풀(glue)''을 제공한다.
@ref{Figure 2.2}는 쌍을 시각화하는 표준 방법을 보여준다---이 경우 @code{(cons 1 2)}에 의해 형성된 쌍이다.
@newterm{박스 앤 포인터 표기법(box-and-pointer notation)}이라고 불리는 이 표현에서, 각 객체는 박스에 대한 @newterm{포인터(pointer)}로 표시된다.
원시 객체를 위한 박스는 객체의 표현을 포함한다.
예를 들어, 숫자를 위한 박스는 숫자를 포함한다.
쌍을 위한 박스는 실제로는 이중 박스인데, 왼쪽 부분은 쌍의 @code{car}에 대한 (포인터)를 포함하고 오른쪽 부분은 @code{cdr}를 포함한다.

@float
@anchor{Figure 2.2}
@ifinfo
@quotation
@strong{Figure 2.2:} @code{(cons 1 2)}의 박스 앤 포인터 표현.

@example
     +---+---+     +---+
---->| * | *-+---->| 2 |
     +-|-+---+     +---+
       |
       V
     +---+
     | 1 |
     +---+
@end example

@end quotation
@end ifinfo
@iftex
@image{fig/chap2/Fig2.2e,57mm,,,.std.svg}
@caption{@strong{Figure 2.2:} @code{(cons 1 2)}의 박스 앤 포인터 표현.}
@end iftex
@end float

우리는 이미 @code{cons}가 숫자뿐만 아니라 쌍도 결합하는 데 사용될 수 있음을 보았다. (@ref{Exercise 2.2}와 @ref{Exercise 2.3}을 수행할 때 이 사실을 활용했거나 그랬어야 했다.)
그 결과, 쌍은 모든 종류의 데이터 구조를 구축할 수 있는 보편적인 구성 요소를 제공한다.
@ref{Figure 2.3}은 쌍을 사용하여 숫자 1, 2, 3, 4를 결합하는 두 가지 방법을 보여준다.

@float
@anchor{Figure 2.3}
@ifinfo
@quotation
@strong{Figure 2.3:} 쌍을 사용하여 1, 2, 3, 4를 결합하는 두 가지 방법.

@example
     +---+---+     +---+---+         +---+---+     +---+
---->| * | *-+---->| * | * |    ---->| * | *-+---->| 4 |
     +-|-+---+     +-|-+-|-+         +-|-+---+     +---+
       |             |   |             |
       V             V   V             V
   +---+---+      +---+ +---+      +---+---+     +---+---+
   | * | * |      | 3 | | 4 |      | * | *-+---->| * | * |
   +-|-+-|-+      +---+ +---+      +-|-+---+     +-|-+-|-+
     |   |                           |             |   |
     V   V                           V             V   V
  +---+ +---+                      +---+        +---+ +---+
  | 1 | | 2 |                      | 1 |        | 2 | | 3 |
  +---+ +---+                      +---+        +---+ +---+

  cons(cons(1, 2),                 cons(cons(1,
       cons(3, 4)))                     cons(2, 3)),
                                        4))
@end example

@end quotation
@end ifinfo
@iftex
@image{fig/chap2/Fig2.3e,147mm,,,.std.svg}
@caption{@strong{Figure 2.3:} 쌍을 사용하여 1, 2, 3, 4를 결합하는 두 가지 방법.}
@end iftex
@end float

@noindent
요소가 쌍인 쌍을 생성할 수 있는 능력은 표현 도구로서 리스트 구조의 중요성의 본질이다.
우리는 이 능력을 @code{cons}의 @newterm{클로저 속성(closure property)}이라고 부른다.
일반적으로, 데이터 객체를 결합하는 연산은 그 연산으로 결합한 결과가 다시 그 연산으로 결합될 수 있다면 클로저 속성을 만족한다.@footnote{여기서 ``클로저(closure)''라는 단어의 사용은 추상 대수학에서 유래했는데, 집합의 요소에 연산을 적용하여 생성된 요소가 다시 그 집합의 요소라면 그 집합은 연산에 대해 닫혀 있다(closed)고 말한다. Lisp 커뮤니티는 (불행히도) 자유 변수를 가진 프로시저를 표현하기 위한 구현 기술을 설명하기 위해 전혀 관계없는 개념인 ``클로저''라는 단어를 사용한다. 이 책에서 우리는 이 두 번째 의미로 ``클로저''라는 단어를 사용하지 않는다.}
클로저는 어떤 조합 수단에서든 힘의 열쇠이다. 왜냐하면 그것은 우리가 @newterm{계층적(hierarchical)} 구조---부분들로 구성되고, 그 부분들이 다시 부분들로 구성되며, 이렇게 계속되는 구조---를 생성할 수 있게 해주기 때문이다.

@ref{Chapter 1}의 시작부터, 우리는 프로시저를 다룰 때 클로저를 필수적으로 사용해 왔다. 왜냐하면 가장 단순한 프로그램을 제외한 모든 프로그램은 조합의 요소가 그 자체로 조합일 수 있다는 사실에 의존하기 때문이다.
이 절에서, 우리는 복합 데이터에 대한 클로저의 결과를 다룬다.
우리는 시퀀스와 트리를 표현하기 위해 쌍을 사용하는 몇 가지 관습적인 기술을 설명하고, 클로저를 생생한 방식으로 보여주는 그래픽 언어를 제시한다.@footnote{조합 수단이 클로저를 만족해야 한다는 개념은 간단한 아이디어이다. 불행히도, 많은 대중적인 프로그래밍 언어에서 제공하는 데이터 결합기는 클로저를 만족하지 않거나 클로저를 활용하기 번거롭게 만든다. Fortran이나 Basic에서는 일반적으로 데이터 요소를 배열로 조립하여 결합하지만, 요소가 배열인 배열을 형성할 수는 없다. Pascal과 C는 요소가 구조체인 구조체를 허용한다. 그러나 이를 위해서는 프로그래머가 포인터를 명시적으로 조작해야 하고, 구조체의 각 필드가 미리 지정된 형태의 요소만 포함할 수 있다는 제약을 준수해야 한다. 쌍을 가진 Lisp와 달리, 이러한 언어들은 복합 데이터를 균일한 방식으로 조작하기 쉽게 만드는 내장된 범용 풀(glue)이 없다. 이 제한은 이 책의 서문에서 앨런 펄리스가 한 논평의 배경에 있다: ``Pascal에서는 선언 가능한 데이터 구조의 과잉이 함수 내의 전문화를 유도하여 우연한 협력을 억제하고 불이익을 줍니다. 10개의 함수가 10개의 데이터 구조에서 작동하게 하는 것보다 100개의 함수가 하나의 데이터 구조에서 작동하게 하는 것이 더 낫습니다.''}

@menu
* 2.2.1::            Representing Sequences
* 2.2.2::            Hierarchical Structures
* 2.2.3::            Sequences as Conventional Interfaces
* 2.2.4::            Example: A Picture Language
* 2.2.5::            Algebraic Data Types
@end menu

@node	2.2.1, 2.2.2, 2.2, 2.2
@subsection 시퀀스 표현 (Representing Sequences)

우리가 쌍으로 구축할 수 있는 유용한 구조 중 하나는 @newterm{시퀀스(sequence)}---데이터 객체의 정렬된 컬렉션---이다.
물론 쌍의 관점에서 시퀀스를 표현하는 방법은 많이 있다.
특히 간단한 표현 하나가 @ref{Figure 2.4}에 예시되어 있는데, 여기서 시퀀스 1, 2, 3, 4는 쌍의 체인으로 표현된다.
각 쌍의 @code{car}는 체인의 해당 항목이고, 쌍의 @code{cdr}는 체인의 다음 쌍이다.
마지막 쌍의 @code{cdr}는 빈 슬라이스로 끝을 나타내거나 고정 길이 컬렉션을 사용하여 시퀀스의 끝을 알린다.
Rust에서, 우리는 동적 시퀀스를 위해 @code{Vec}을 사용한다:

@example
// In Rust, we use Vec for sequences
vec![1, 2, 3, 4]
@end example

@float
@anchor{Figure 2.4}
@ifinfo
@quotation
@strong{Figure 2.4:} 쌍의 체인으로 표현된 시퀀스 1, 2, 3, 4.

@example
     +---+---+     +---+---+     +---+---+     +---+---+
---->| * | *-+---->| * | *-+---->| * | *-+---->| * | / |
     +-|-+---+     +-|-+---+     +-|-+---+     +-|-+---+
       |             |             |             |
       V             V             V             V
     +---+         +---+         +---+         +---+
     | 1 |         | 2 |         | 3 |         | 4 |
     +---+         +---+         +---+         +---+
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap2/Fig2.4e,125mm,,,.std.svg}
@caption{@strong{Figure 2.4:} 쌍의 체인으로 표현된 시퀀스 1, 2, 3, 4.}
@end iftex
@end float

@noindent
Rust에서 그러한 시퀀스는 @newterm{벡터(vector)}라고 불리며, @code{vec!} 매크로로 생성된다.@footnote{Rust의 @code{Vec<T>}는 힙에 저장되는 크기 조절 가능한 배열이다. Scheme의 연결 리스트와 달리, 벡터는 O(1) 인덱스 접근을 제공하지만 앞부분 삽입은 O(n)이다. 연결 리스트 의미론을 위해 Rust는 @code{LinkedList<T>}를 제공하지만, 더 나은 캐시 지역성 때문에 대부분의 사용 사례에서 벡터가 선호된다.} 위의 시퀀스는 다음과 같이 쓰여진다:

@example
let one_through_four = vec![1, 2, 3, 4];
@end example

@noindent
Rust는 디버그 서식 지정을 사용하여 벡터를 표시한다:

@example
let one_through_four = vec![1, 2, 3, 4];

println!("@{:?@}", one_through_four);
// => [1, 2, 3, 4]
@end example

@noindent
우리는 @code{first()}나 @code{[0]}으로 인덱싱하는 것을 리스트의 첫 번째 항목을 선택하는 것으로, @code{&list[1..]}을 첫 번째 항목을 제외한 모든 것으로 구성된 서브리스트를 선택하는 것으로 생각할 수 있다. 요소를 앞에 붙이기 위해, 우리는 @code{concat}을 사용하거나 새로운 벡터를 구축할 수 있다:@footnote{Rust에서 벡터나 슬라이스를 인덱싱하는 것은 간단하다: @code{list[0]}은 첫 번째 요소를 얻고, @code{list[1]}은 두 번째 요소를 얻는 식이다. @code{&list[1..]}로 슬라이싱하면 첫 번째 요소 이후의 모든 요소에 대한 참조를 반환한다.}

@example
let one_through_four = vec![1, 2, 3, 4];

one_through_four[0]
// => 1

&one_through_four[1..]
// => [2, 3, 4]

one_through_four[1]  // second element
// => 2

// Prepend 10 to create new vector
[vec![10], one_through_four.clone()].concat()
// => [10, 1, 2, 3, 4]

// Or using iterators
std::iter::once(5).chain(one_through_four.iter().copied()).collect::<Vec<_>>()
// => [5, 1, 2, 3, 4]
@end example

@noindent
쌍의 체인을 종료하는 데 사용되는 @code{nil} 값은 요소가 없는 시퀀스, 즉 @newterm{빈 리스트(empty list)}로 생각할 수 있다.
@newterm{nil}이라는 단어는 라틴어 @emph{nihil}의 축약형으로, ``아무것도 없음(nothing)''을 의미한다.@footnote{Lisp 방언 표준화에서 말 그대로 아무것도 아닌 것(nothing)에 대한 논쟁에 얼마나 많은 에너지가 소모되었는지는 놀랍다:@code{nil}은 일반 이름이어야 하는가? @code{nil}의 값은 기호(symbol)여야 하는가?
리스트여야 하는가? 쌍(pair)이어야 하는가?
Scheme에서 @code{nil}은 일반 이름이며, 이 절에서 우리는 이를 리스트의 끝을 나타내는 마커의 값을 가진 변수로 사용한다(@code{true}가 참 값을 가진 일반 변수인 것과 마찬가지로).
Common Lisp를 포함한 다른 Lisp 방언들은 @code{nil}을 특수 기호로 취급한다.
너무 많은 언어 표준화 싸움을 겪어온 이 책의 저자들은 이 문제 전체를 피하고 싶다.
@ref{2.3}에서 인용(quotation)을 소개하고 나면, 우리는 빈 리스트를 @code{'()}로 나타내고 변수 @code{nil}은 완전히 없앨 것이다.}

@subsubheading 리스트 연산 (List operations)

요소의 시퀀스를 리스트로 표현하기 위해 쌍을 사용하는 것은 리스트를 차례로 ``@code{cdr}하며 내려가는(cdring down)'' 방식으로 리스트를 조작하는 관습적인 프로그래밍 기술을 동반한다.
예를 들어, 프로시저 @code{list-ref}는 리스트와 숫자 @math{n}을 인자로 받아 리스트의 @math{n}번째 항목을 반환한다.
리스트의 요소는 0부터 번호를 매기는 것이 관례이다.
@code{list-ref}를 계산하는 방법은 다음과 같다:

@itemize @bullet

@item
@math{{n = 0}}이면, 리스트의 첫 번째 요소를 반환한다.

@item
그렇지 않으면, 리스트의 나머지(rest) 부분의 @math{{(n - 1)}}번째 항목을 반환한다.

@end itemize

@noindent
Rust에서 벡터는 직접 인덱싱을 제공하므로, 단순히 @code{items[n]}을 사용한다:

@example
fn list_ref<T: Clone>(items: &[T], n: usize) -> T @{
    items[n].clone()
@}

let squares = vec![1, 4, 9, 16, 25];

list_ref(&squares, 3)
// => 16

// Or simply use indexing directly:
squares[3]
// => 16
@end example

@noindent
리스트의 길이를 얻기 위해, Rust는 @code{len()} 메서드를 제공한다.
Scheme 버전을 반영하는 재귀적 구현은 다음과 같다:

@example
fn length<T>(items: &[T]) -> usize @{
    if items.is_empty() @{
        0
    @} else @{
        1 + length(&items[1..])
    @}
@}

let odds = vec![1, 3, 5, 7];

length(&odds)
// => 4

// Or simply use the built-in method:
odds.len()
// => 4
@end example

@noindent
@code{length} 프로시저는 간단한 재귀적 계획을 구현한다. 축소(reduction) 단계는 다음과 같다:

@itemize @bullet

@item
어떤 리스트의 @code{length}는 1 더하기 그 리스트의 @code{cdr}의 @code{length}이다.

@end itemize

@noindent
이것은 기본 단계(base case)에 도달할 때까지 연속적으로 적용된다:

@itemize @bullet

@item
빈 리스트의 @code{length}는 0이다.

@end itemize

@noindent
우리는 또한 @code{fold}를 사용하여 반복적인 스타일로 @code{length}를 계산할 수 있다:

@example
fn length_iter<T>(items: &[T]) -> usize @{
    items.iter().fold(0, |count, _| count + 1)
@}
@end example

@noindent
또 다른 관습적인 프로그래밍 기술은 리스트를 반복하면서 답 벡터를 구축하는 것이다. 연결(concatenation)이 그 예로, 두 리스트를 인자로 받아 그 요소들을 결합하여 새로운 리스트를 만든다:

@example
let squares = vec![1, 4, 9, 16, 25];
let odds = vec![1, 3, 5, 7];

[squares.clone(), odds.clone()].concat()
// => [1, 4, 9, 16, 25, 1, 3, 5, 7]

[odds.clone(), squares.clone()].concat()
// => [1, 3, 5, 7, 1, 4, 9, 16, 25]
@end example

@noindent
Scheme 버전을 반영하는 재귀적 구현은 다음과 같다:

@example
fn append<T: Clone>(list1: &[T], list2: &[T]) -> Vec<T> @{
    if list1.is_empty() @{
        list2.to_vec()
    @} else @{
        let mut result = vec![list1[0].clone()];
        result.extend(append(&list1[1..], list2));
        result
    @}
@}
@end example

@quotation
@strong{@anchor{Exercise 2.17}연습문제 2.17:} 주어진 (비어 있지 않은) 리스트의 마지막 요소를 반환하는 함수 @code{last_element}를 정의하라:

@example
fn last_element<T: Clone>(items: &[T]) -> T @{
    items.last().unwrap().clone()
@}

last_element(&vec![23, 72, 149, 34])
// => 34
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 2.18}연습문제 2.18:} 리스트를 인자로 받아 같은 요소들을 역순으로 포함하는 리스트를 반환하는 함수 @code{reverse}를 정의하라:

@example
fn reverse<T: Clone>(items: &[T]) -> Vec<T> @{
    items.iter().rev().cloned().collect()
@}

reverse(&vec![1, 4, 9, 16, 25])
// => [25, 16, 9, 4, 1]
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 2.19}연습문제 2.19:} @ref{1.2.2}의 거스름돈 계산 프로그램을 고려해 보자.
프로그램이 사용하는 통화를 쉽게 변경할 수 있다면 좋을 것이다. 예를 들어, 영국 파운드를 거슬러 주는 방법의 수를 계산할 수 있도록 말이다.
작성된 프로그램에서 통화에 대한 지식은 부분적으로 @code{first_denomination} 프로시저에, 그리고 부분적으로 @code{count_change} 프로시저(미국 동전이 5종류라는 것을 아는)에 분산되어 있다.
거스름돈을 만드는 데 사용할 동전 리스트를 제공할 수 있다면 더 좋을 것이다.

우리는 @code{cc} 함수를 다시 작성하여 두 번째 인자가 사용할 동전을 지정하는 정수가 아니라 사용할 동전 가치들의 슬라이스가 되도록 하고 싶다.
그러면 각 종류의 통화를 정의하는 배열을 가질 수 있다:

@example
const US_COINS: &[i32] = &[50, 25, 10, 5, 1];
const UK_COINS: &[i32] = &[100, 50, 20, 10, 5, 2, 1];
@end example

그러면 우리는 다음과 같이 @code{cc}를 호출할 수 있다:

@example
cc(100, US_COINS)
// => 292
@end example

이것을 하려면 @code{cc} 프로그램을 약간 변경해야 한다.
여전히 같은 형태를 갖겠지만, 다음과 같이 두 번째 인자에 다르게 접근할 것이다:

@example
fn cc(amount: i32, coin_values: &[i32]) -> i32 @{
    if amount == 0 @{
        1
    @} else if amount < 0 || coin_values.is_empty() @{
        0
    @} else @{
        cc(amount, &coin_values[1..])  // except first denomination
            + cc(amount - coin_values[0], coin_values)  // first denomination
    @}
@}
@end example

Rust에서 @code{coin_values[0]}은 첫 번째 액면가를 제공하고, @code{&coin_values[1..]}은 첫 번째를 제외한 나머지를 제공하며, @code{coin_values.is_empty()}는 더 이상 동전이 없는지 테스트한다.
@code{coin_values} 슬라이스의 순서가 @code{cc}가 생성하는 답에 영향을 미치는가? 왜 그런가, 또는 왜 그렇지 않은가?
@end quotation

@quotation
@strong{@anchor{Exercise 2.20}연습문제 2.20:} @code{sum}과 @code{product} 같은 함수들은 임의의 개수의 인자를 받는다.
Rust에서는 슬라이스나 반복자로 이를 처리한다. 예를 들어, 다음과 같은 정의가 있다면

@example
fn f(x: i32, y: i32, rest: &[i32]) @{ /* body */ @}
@end example

@noindent
함수 @code{f}는 나머지 인자들에 대해 슬라이스로 호출될 수 있다.
만약 우리가

@example
f(1, 2, &[3, 4, 5, 6])
@end example

@noindent
과 같이 호출하면, @code{f}의 본문에서 @code{x}는 1, @code{y}는 2, 그리고 @code{rest}는 슬라이스 @code{[3, 4, 5, 6]}이 될 것이다.
다음과 같은 정의가 있다면

@example
fn g(args: &[i32]) @{ /* body */ @}
@end example

@noindent
함수 @code{g}는 슬라이스에 0개 이상의 인자를 넣어 호출할 수 있다.
만약 우리가

@example
g(&[1, 2, 3, 4, 5, 6])
@end example

@noindent
과 같이 호출하면, @code{g}의 본문에서 @code{args}는 슬라이스 @code{[1, 2, 3, 4, 5, 6]}이 될 것이다.

슬라이스와 반복자 메서드를 사용하여 정수 슬라이스를 받아 첫 번째 요소와 홀짝성(even-odd parity)이 같은 모든 요소의 벡터를 반환하는 함수 @code{same_parity}를 작성하라. 예를 들어,

@example
fn same_parity(items: &[i32]) -> Vec<i32> @{
    let first = items[0];
    let parity = first % 2;
    items.iter()
        .filter(|&&x| x % 2 == parity)
        .copied()
        .collect()
@}

same_parity(&[1, 2, 3, 4, 5, 6, 7])
// => [1, 3, 5, 7]

same_parity(&[2, 3, 4, 5, 6, 7])
// => [2, 4, 6]
@end example
@end quotation

@subsubheading 리스트에 대한 매핑 (Mapping over lists)

매우 유용한 연산 중 하나는 리스트의 각 요소에 어떤 변환을 적용하여 결과의 리스트를 생성하는 것이다.
예를 들어, 다음 함수는 리스트의 각 숫자를 주어진 배율로 스케일링한다:

@example
fn scale_list(items: &[i32], factor: i32) -> Vec<i32> @{
    if items.is_empty() @{
        vec![]
    @} else @{
        let mut result = vec![items[0] * factor];
        result.extend(scale_list(&items[1..], factor));
        result
    @}
@}

scale_list(&[1, 2, 3, 4, 5], 10)
// => [10, 20, 30, 40, 50]
@end example

@noindent
우리는 이 일반적인 아이디어를 추상화하여 @ref{1.3}에서처럼 고차 함수로 표현된 공통 패턴으로 포착할 수 있다.
여기서의 고차 연산은 @code{map} 반복자 어댑터이다. @code{map}은 클로저를 받아 각 요소에 클로저를 적용하는 반복자를 반환한다:@footnote{
Rust의 @code{Iterator::map}은 지연(lazy) 평가된다---소비될 때까지 값을 계산하지 않는다.
여러 반복자에 대해 병렬 매핑을 하려면 @code{zip}을 사용하라:

@example
let a = [1, 2, 3];
let b = [40, 50, 60];
let c = [700, 800, 900];

a.iter().zip(b.iter()).zip(c.iter())
    .map(|((&x, &y), &z)| x + y + z)
    .collect::<Vec<_>>()
// => [741, 852, 963]

a.iter().zip(b.iter())
    .map(|(&x, &y)| x + 2 * y)
    .collect::<Vec<_>>()
// => [9, 12, 15]
@end example
}

@example
// Rust provides map as an iterator method
vec![-10.0, 2.5, -11.6, 17.0].iter()
    .map(|x| x.abs())
    .collect::<Vec<_>>()
// => [10.0, 2.5, 11.6, 17.0]

vec![1, 2, 3, 4].iter()
    .map(|x| x * x)
    .collect::<Vec<_>>()
// => [1, 4, 9, 16]
@end example

@noindent
이제 우리는 @code{map}을 사용하여 @code{scale_list}의 더 깔끔한 정의를 줄 수 있다:

@example
fn scale_list(items: &[i32], factor: i32) -> Vec<i32> @{
    items.iter().map(|x| x * factor).collect()
@}
@end example

@noindent
@code{Map}은 공통 패턴을 포착하기 때문만이 아니라 리스트를 다루는 데 있어 더 높은 수준의 추상화를 확립하기 때문에 중요한 구성 요소이다.
@code{scale-list}의 원래 정의에서, 프로그램의 재귀적 구조는 리스트의 요소별 처리에 주의를 집중시킨다.
@code{map}의 관점에서 @code{scale-list}를 정의하는 것은 그러한 세부 수준을 억제하고 스케일링이 요소의 리스트를 결과의 리스트로 변환한다는 점을 강조한다.
두 정의의 차이는 컴퓨터가 다른 프로세스를 수행한다는 것이 아니라(그렇지 않다) 우리가 프로세스에 대해 다르게 생각한다는 것이다.
사실상, @code{map}은 리스트를 변환하는 프로시저의 구현을 리스트의 요소가 추출되고 결합되는 방법의 세부 사항으로부터 격리하는 추상화 장벽을 세우는 데 도움을 준다.
@ref{Figure 2.1}에 표시된 장벽과 마찬가지로, 이 추상화는 시퀀스를 시퀀스로 변환하는 연산이라는 개념적 프레임워크를 보존하면서 시퀀스가 구현되는 저수준 세부 사항을 변경할 수 있는 유연성을 제공한다.
@ref{2.2.3} 절에서는 프로그램을 조직하기 위한 프레임워크로서 시퀀스의 이러한 사용을 확장한다.

@quotation
@strong{@anchor{Exercise 2.21}연습문제 2.21:} 함수 @code{square_list}는 숫자 슬라이스를 인자로 받아 그 숫자들의 제곱의 벡터를 반환한다.

@example
square_list(&[1, 2, 3, 4])
// => [1, 4, 9, 16]
@end example

여기 @code{square_list}의 두 가지 다른 정의가 있다. 누락된 표현식을 채워 두 정의를 모두 완성하라:

@example
fn square_list(items: &[i32]) -> Vec<i32> @{
    if items.is_empty() @{
        vec![]
    @} else @{
        let mut result = vec![/* ?? */];
        result.extend(/* ?? */);
        result
    @}
@}

fn square_list(items: &[i32]) -> Vec<i32> @{
    items.iter().map(/* ?? */).collect()
@}
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 2.22}연습문제 2.22:} Louis Reasoner는 반복적 프로세스를 발전시키도록 @ref{Exercise 2.21}의 첫 번째 @code{square_list} 함수를 다시 작성하려고 시도한다:

@example
fn square_list(items: &[i32]) -> Vec<i32> @{
    fn iter(things: &[i32], mut answer: Vec<i32>) -> Vec<i32> @{
        if things.is_empty() @{
            answer
        @} else @{
            answer.insert(0, things[0] * things[0]);  // prepend
            iter(&things[1..], answer)
        @}
    @}
    iter(items, vec![])
@}
@end example

불행히도, 이런 식으로 @code{square_list}를 정의하면 원하는 것과 역순인 답 리스트가 생성된다. 왜 그런가?

Louis는 그 후 대신 끝에 푸시(push)함으로써 버그를 고치려고 시도한다:

@example
fn square_list(items: &[i32]) -> Vec<i32> @{
    fn iter(things: &[i32], mut answer: Vec<i32>) -> Vec<i32> @{
        if things.is_empty() @{
            answer
        @} else @{
            answer.push(things[0] * things[0]);  // append
            iter(&things[1..], answer)
        @}
    @}
    iter(items, vec![])
@}
@end example

이것은 Rust에서 실제로 작동한다! 하지만 만약 우리가 앞에 붙이는(prepend) 것만으로 제한된다면, 왜 원래 접근 방식이 역순 출력을 생성하는지 설명하라.
@end quotation

@quotation
@strong{@anchor{Exercise 2.23}연습문제 2.23:} Rust의 @code{for_each} 반복자 메서드는 @code{map}과 유사하다. 이것은 클로저를 받아 각 요소에 차례로 적용한다.
그러나 결과의 반복자를 생성하는 대신, @code{for_each}는 단지 부수 효과(side effects)를 위해 클로저를 적용한다.
@code{for_each}는 출력과 같은 작업을 수행하는 클로저와 함께 사용된다. 예를 들어,

@example
[57, 321, 88].iter().for_each(|x| println!("@{@}", x));
// Output:
// 57
// 321
// 88
@end example

클로저와 슬라이스를 받아 각 요소에 클로저를 적용하는 함수 @code{for_each}를 구현하라.
@end quotation

@node	2.2.2, 2.2.3, 2.2.1, 2.2
@subsection 계층적 구조 (Hierarchical Structures)

벡터를 사용한 시퀀스 표현은 요소가 그 자체로 시퀀스일 수 있는 시퀀스를 표현하도록 자연스럽게 일반화된다.
예를 들어, 우리는 Rust의 @code{enum} 타입이나 중첩된 벡터를 사용하여 중첩된 데이터를 표현할 수 있다:

@example
// 중첩 벡터 사용 (동적)
let nested: Vec<Vec<i32>> = vec![vec![1, 2], vec![3, 4]];

// 또는 혼합 구조를 위한 열거형 사용
#[derive(Debug)]
enum NestedList @{
    Elem(i32),
    List(Vec<NestedList>),
@}
use NestedList::*;

let x = List(vec![List(vec![Elem(1), Elem(2)]), Elem(3), Elem(4)]);
// ((1 2) 3 4)를 표현함
@end example

@noindent
이것은 3개의 항목을 가진 리스트이며, 그중 첫 번째 항목이 그 자체로 리스트 @code{(1 2)}이다.
실제로 이것은 인터프리터가 결과를 출력하는 형태에서도 암시된다.
@ref{Figure 2.5}는 쌍의 관점에서 이 구조의 표현을 보여준다.

@float
@anchor{Figure 2.5}
@ifinfo
@quotation
@strong{Figure 2.5:} Structure formed by @code{(cons (list 1 2) (list 3 4))}.

@example
                                          (3 4)
                                            |
                                            V
((1 2) 3 4)  +---+---+                  +---+---+     +---+---+
        ---->| * | *-+----------------->| * | *-+---->| * | / |
             +-|-+---+                  +-|-+---+     +-|-+---+
               |                          |             |
               V                          V             V
      (1 2)  +---+---+     +---+---+    +---+         +---+
        ---->| * | *-+---->| * | / |    | 3 |         | 4 |
             +-|-+---+     +-|-+---+    +---+         +---+
               |             |
               V             V
             +---+         +---+
             | 1 |         | 2 |
             +---+         +---+
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap2/Fig2.5e,140mm,,,.std.svg}
@caption{@strong{Figure 2.5:} Structure formed by @code{(cons (list 1 2) (list 3 4))}.}
@end iftex
@end float

요소가 시퀀스인 시퀀스를 생각하는 또 다른 방법은 @newterm{트리(trees)}이다.
시퀀스의 요소들은 트리의 가지(branches)이고, 그 자체로 시퀀스인 요소들은 서브트리(subtrees)이다.
@ref{Figure 2.6}은 @ref{Figure 2.5}의 구조를 트리로 본 것을 보여준다.

@float
@anchor{Figure 2.6}
@ifinfo
@quotation
@strong{Figure 2.6:} The list structure in @ref{Figure 2.5} viewed as a tree.

@example
 ((1 2) 3 4)
     /\\
    /  | \
(1 2)  3 4
 / \
 1 2
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap2/Fig2.6b,40mm,,,.std.svg}
@caption{@strong{Figure 2.6:} The list structure in @ref{Figure 2.5} viewed as a tree.}
@end iftex
@end float

@noindent
재귀는 트리 구조를 다루는 데 자연스러운 도구이다. 왜냐하면 우리는 트리에 대한 연산을 그 가지들에 대한 연산으로 축소할 수 있고, 이는 다시 가지의 가지들에 대한 연산으로 축소되며, 이렇게 트리의 잎(leaves)에 도달할 때까지 계속되기 때문이다.
예를 들어, 벡터의 @code{len()} 메서드와 트리의 총 잎 수를 반환하는 @code{count_leaves} 함수를 비교해 보라:

@example
use NestedList::*;

// x = ((1 2) 3 4)
let x = List(vec![List(vec![Elem(1), Elem(2)]), Elem(3), Elem(4)]);

// 최상위 수준의 길이 (3개 항목)
fn length(list: &NestedList) -> usize @{
    match list @{
        Elem(_) => 1,
        List(items) => items.len(),
    @}
@}

length(&x)
// => 3

fn count_leaves(tree: &NestedList) -> usize @{
    match tree @{
        Elem(_) => 1,
        List(items) => items.iter().map(count_leaves).sum(),
    @}
@}

count_leaves(&x)
// => 4

// (list x x) = (((1 2) 3 4) ((1 2) 3 4))
let xx = List(vec![x.clone(), x.clone()]);

length(&xx)
// => 2

count_leaves(&xx)
// => 8
@end example

@noindent
@code{count-leaves}를 구현하기 위해, @code{length}를 계산하기 위한 재귀적 계획을 상기해 보라:

@itemize @bullet

@item
리스트 @code{x}의 @code{Length}는 1 더하기 @code{x}의 @code{cdr}의 @code{length}이다.

@item
빈 리스트의 @code{Length}는 0이다.

@end itemize

@noindent
@code{Count-leaves}도 비슷하다. 빈 리스트에 대한 값은 같다:

@itemize @bullet

@item
빈 리스트의 @code{Count-leaves}는 0이다.

@end itemize

@noindent
하지만 우리가 리스트의 @code{car}를 떼어내는 축소 단계에서, 우리는 그 @code{car} 자체가 잎을 세어야 할 트리일 수 있다는 점을 고려해야 한다.
따라서 적절한 축소 단계는 다음과 같다:

@itemize @bullet

@item
트리 @code{x}의 @code{Count-leaves}는 @code{x}의 @code{car}의 @code{count-leaves} 더하기 @code{x}의 @code{cdr}의 @code{count-leaves}이다.

@end itemize

@noindent
마지막으로, @code{car}를 취함으로써 우리는 실제 잎에 도달하므로, 또 다른 기본 단계가 필요하다:

@itemize @bullet

@item
잎의 @code{Count-leaves}는 1이다.

@end itemize

@noindent
트리에 대한 재귀 함수 작성을 돕기 위해, Rust는 열거형 변형에 대한 패턴 매칭을 제공한다. 전체 함수는 다음과 같다:

@example
fn count_leaves(tree: &NestedList) -> usize @{
    match tree @{
        Elem(_) => 1,
        List(items) if items.is_empty() => 0,
        List(items) => items.iter().map(count_leaves).sum(),
    @}
@}
@end example

@quotation
@strong{@anchor{Exercise 2.24}연습문제 2.24:} 우리가 @code{List(vec![Elem(1), List(vec![Elem(2), List(vec![Elem(3), Elem(4)])])])}를 생성한다고 가정하자.
디버그 서식 지정에 의해 출력되는 결과, 해당하는 구조, 그리고 이것을 트리로 해석한 것(@ref{Figure 2.6}에서처럼)을 제시하라.
@end quotation

@quotation
@strong{@anchor{Exercise 2.25}연습문제 2.25:} 다음 각 구조에서 7을 골라낼 인덱싱 조합을 제시하라:

@example
// (1 3 (5 7) 9) as nested vector
let a: Vec<Vec<i32>> = vec![vec![1], vec![3], vec![5, 7], vec![9]];
// How to get 7?

// ((7))
let b = vec![vec![7]];
// How to get 7?

// Deeply nested
let c = vec![1, vec![2, vec![3, vec![4, vec![5, vec![6, 7]]]]]];
// (Requires NestedList enum for mixed types)
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 2.26}연습문제 2.26:} @code{x}와 @code{y}를 두 벡터로 정의한다고 가정하자:

@example
let x = vec![1, 2, 3];
let y = vec![4, 5, 6];
@end example

다음 각 표현식을 평가하면 어떤 결과가 생성되는가:

@example
[x.clone(), y.clone()].concat()  // append
// => ?

vec![x.clone(), y.clone()]       // as nested
// => ?

// 차이점은 무엇인가?
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 2.27}연습문제 2.27:} @ref{Exercise 2.18}의 @code{reverse} 함수를 수정하여 트리를 인자로 받아 그 요소들이 역순이고 모든 서브트리 또한 깊은 역순(deep-reversed)인 트리를 값으로 반환하는 @code{deep_reverse} 함수를 생성하라. 예를 들어,

@example
// x = ((1 2) (3 4))
let x = List(vec![
    List(vec![Elem(1), Elem(2)]),
    List(vec![Elem(3), Elem(4)])
]);

// reverse: ((3 4) (1 2))
// deep_reverse: ((4 3) (2 1))

fn deep_reverse(tree: &NestedList) -> NestedList @{
    match tree @{
        Elem(n) => Elem(*n),
        List(items) => List(
            items.iter()
                .rev()
                .map(deep_reverse)
                .collect()
        ),
    @}
@}
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 2.28}연습문제 2.28:} 트리를 받아 그 요소들이 왼쪽에서 오른쪽 순서로 배열된 트리의 모든 잎인 벡터를 반환하는 함수 @code{fringe}를 작성하라. 예를 들어,

@example
fn fringe(tree: &NestedList) -> Vec<i32> @{
    match tree @{
        Elem(n) => vec![*n],
        List(items) => items.iter().flat_map(fringe).collect(),
    @}
@}

// x = ((1 2) (3 4))
fringe(&x)
// => [1, 2, 3, 4]

fringe(&List(vec![x.clone(), x.clone()]))
// => [1, 2, 3, 4, 1, 2, 3, 4]
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 2.29}연습문제 2.29:} 이진 모빌(binary mobile)은 두 개의 가지, 즉 왼쪽 가지와 오른쪽 가지로 구성된다.
각 가지는 특정 길이의 막대이며, 거기에는 무게 추나 또 다른 이진 모빌이 매달려 있다.
우리는 Rust 구조체와 열거형을 사용하여 이진 모빌을 표현할 수 있다:

@example
struct Mobile @{
    left: Branch,
    right: Branch,
@}

struct Branch @{
    length: f64,
    structure: Structure,
@}

enum Structure @{
    Weight(f64),
    SubMobile(Box<Mobile>),
@}
@end example

@enumerate a

@item
선택자들은 구조체 필드 접근으로 자동으로 사용 가능하다:
@code{mobile.left}, @code{mobile.right}, @code{branch.length}, 그리고
@code{branch.structure}.

@item
패턴 매칭을 사용하여 모빌의 총 무게를 반환하는 함수 @code{total_weight}를 정의하라.

@item
모빌은 왼쪽 맨 위 가지가 가하는 회전력(torque)이 오른쪽 맨 위 가지가 가하는 회전력과 같고(즉, 왼쪽 막대의 길이에 그 막대에 매달린 무게를 곱한 것이 오른쪽의 해당 곱과 같다면), 가지에 매달린 각 서브모빌이 균형 잡혀 있다면 @newterm{균형 잡혔다(balanced)}고 말한다.
이진 모빌이 균형 잡혀 있는지 테스트하는 함수를 설계하라.

@item
Rust에서 두 필드를 가진 구조체에서 튜플 구조체로 변경하려면 모든 필드 접근을 @code{.left/.right}에서 @code{.0/.1}로 업데이트해야 한다.
Rust의 구조체 시스템은 Scheme의 접근 방식과 어떻게 비교되는가?

@end enumerate
@end quotation

@subsubheading 트리에 대한 매핑 (Mapping over trees)

@code{map}이 시퀀스를 다루기 위한 강력한 추상화인 것과 마찬가지로, 재귀와 함께 사용되는 @code{map}은 트리를 다루기 위한 강력한 추상화이다.
예를 들어, @ref{2.2.1}의 @code{scale_list}와 유사한 @code{scale_tree} 함수는 숫자 인자와 잎이 숫자인 트리를 인자로 받는다.
이 함수는 각 숫자에 인자를 곱한, 같은 모양의 트리를 반환한다.
@code{scale_tree}에 대한 재귀적 계획은 @code{count_leaves}에 대한 것과 유사하다:

@example
fn scale_tree(tree: &NestedList, factor: i32) -> NestedList @{
    match tree @{
        Elem(n) => Elem(n * factor),
        List(items) => List(
            items.iter()
                .map(|t| scale_tree(t, factor))
                .collect()
        ),
    @}
@}

// (1 (2 (3 4) 5) (6 7))
let tree = List(vec![
    Elem(1),
    List(vec![Elem(2), List(vec![Elem(3), Elem(4)]), Elem(5)]),
    List(vec![Elem(6), Elem(7)])
]);

scale_tree(&tree, 10)
// => (10 (20 (30 40) 50) (60 70))
@end example

@noindent
이 구현은 패턴 매칭을 사용하여 잎(직접 스케일링됨)과 가지(자식들을 재귀적으로 스케일링함)를 모두 처리한다.
반복자의 @code{map} 메서드는 스케일링 변환을 각 서브트리에 적용한다.

@noindent
많은 트리 연산이 반복자 메서드와 재귀의 유사한 조합으로 구현될 수 있다.

@quotation
@strong{@anchor{Exercise 2.30}연습문제 2.30:} @ref{Exercise 2.21}의 @code{square_list} 함수와 유사한 함수 @code{square_tree}를 정의하라.
즉, @code{square_tree}는 다음과 같이 동작해야 한다:

@example
// (1 (2 (3 4) 5) (6 7))
square_tree(&tree)
// => (1 (4 (9 16) 25) (36 49))
@end example

@code{square_tree}를 직접(@code{map}을 사용하지 않고) 정의하고, 또한 @code{map}과 재귀를 사용하여 정의하라.
@end quotation

@quotation
@strong{@anchor{Exercise 2.31}연습문제 2.31:} @ref{Exercise 2.30}에 대한 답을 추상화하여 @code{square_tree}가 다음과 같이 정의될 수 있는 성질을 가진 함수 @code{tree_map}을 생성하라.

@example
fn square_tree(tree: &NestedList) -> NestedList @{
    tree_map(|n| n * n, tree)
@}
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 2.32}연습문제 2.32:} 우리는 집합을 서로 다른 요소들의 벡터로 표현할 수 있고, 그 집합의 모든 부분집합의 집합을 벡터의 벡터로 표현할 수 있다.
예를 들어, 집합이 @code{[1, 2, 3]}이라면, 모든 부분집합의 집합은 @code{[[], [3], [2], [2, 3], [1], [1, 3], [1, 2], [1, 2, 3]]}이다.
부분집합의 집합을 생성하는 다음 함수 정의를 완성하고, 그것이 왜 작동하는지 명확하게 설명하라:

@example
fn subsets(s: &[i32]) -> Vec<Vec<i32>> @{
    if s.is_empty() @{
        vec![vec![]]
    @} else @{
        let rest = subsets(&s[1..]);
        let with_first: Vec<Vec<i32>> = rest.iter()
            .map(|subset| /* ?? */)
            .collect();
        [rest, with_first].concat()
    @}
@}
@end example
@end quotation

@node	2.2.3, 2.2.4, 2.2.2, 2.2
@subsection 관습적인 인터페이스로서의 시퀀스 (Sequences as Conventional Interfaces)

복합 데이터를 다룰 때, 우리는 데이터 추상화가 어떻게 우리가 데이터 표현의 세부 사항에 얽히지 않고 프로그램을 설계할 수 있게 해주며, 추상화가 어떻게 우리에게 대안적인 표현으로 실험할 수 있는 유연성을 보존해 주는지 강조했다.
이 절에서 우리는 데이터 구조를 다루기 위한 또 다른 강력한 설계 원칙인 @newterm{관습적인 인터페이스(conventional interfaces)}의 사용을 소개한다.

@ref{1.3}에서 우리는 고차 프로시저로 구현된 프로그램 추상화가 수치 데이터를 다루는 프로그램의 공통 패턴을 포착할 수 있음을 보았다.
복합 데이터를 다루기 위한 유사한 연산을 정식화하는 우리의 능력은 우리가 데이터 구조를 조작하는 스타일에 결정적으로 달려 있다.
예를 들어, @ref{2.2.2}의 @code{count-leaves} 프로시저와 유사하게, 트리를 인자로 받아 홀수인 잎들의 제곱의 합을 계산하는 다음 프로시저를 고려해 보자:

@example
fn sum_odd_squares(tree: &NestedList) -> i32 @{
    match tree @{
        Elem(n) => if n % 2 != 0 @{ n * n @} else @{ 0 @},
        List(items) => items.iter()
            .map(sum_odd_squares)
            .sum(),
    @}
@}
@end example

@noindent
표면적으로, 이 프로시저는 주어진 정수 @math{n}보다 작거나 같은 @math{k}에 대해 모든 짝수 피보나치 수 @math{{\text{Fib}(k)}}의 리스트를 구성하는 다음 프로시저와 매우 달라 보인다:

@example
fn even_fibs(n: u32) -> Vec<u64> @{
    (0..=n)
        .map(fib)
        .filter(|f| f % 2 == 0)
        .collect()
@}
@end example

@noindent
이 두 프로시저가 구조적으로 매우 다르다는 사실에도 불구하고, 두 계산에 대한 더 추상적인 설명은 상당한 유사성을 드러낸다.
첫 번째 프로그램은

@itemize @bullet

@item
트리의 잎들을 열거하고(enumerates);

@item
그것들을 필터링하여(filters), 홀수인 것들을 선택하고;

@item
선택된 각각을 제곱하고(squares);

@item
0부터 시작하여 @code{+}를 사용하여 결과들을 누산한다(accumulates).

@end itemize

@noindent
두 번째 프로그램은

@itemize @bullet

@item
0부터 @math{n}까지의 정수들을 열거하고;

@item
각 정수에 대해 피보나치 수를 계산하고;

@item
그것들을 필터링하여, 짝수인 것들을 선택하고;

@item
빈 리스트부터 시작하여 @code{cons}를 사용하여 결과들을 누산한다.

@end itemize

@noindent
신호 처리 엔지니어는 @ref{Figure 2.7}에 표시된 것처럼 각각이 프로그램 계획의 일부를 구현하는 단계들의 캐스케이드(cascade)를 통해 흐르는 신호의 관점에서 이러한 프로세스를 개념화하는 것이 자연스럽다고 생각할 것이다.
@code{sum-odd-squares}에서, 우리는 주어진 트리의 잎들로 구성된 ``신호''를 생성하는 @newterm{열거자(enumerator)}로 시작한다.
이 신호는 홀수 요소가 아닌 모든 것을 제거하는 @newterm{필터(filter)}를 통과한다.
결과 신호는 차례로 각 요소에 @code{square} 프로시저를 적용하는 ``변환기(transducer)''인 @newterm{맵(map)}을 통과한다.
맵의 출력은 그 후 초기 0부터 시작하여 @code{+}를 사용하여 요소들을 결합하는 @newterm{누산기(accumulator)}로 공급된다.
@code{even-fibs}에 대한 계획도 유사하다.

@float
@anchor{Figure 2.7}
@ifinfo
@quotation
@strong{Figure 2.7:} 프로시저 @code{sum-odd-squares} (위)와 @code{even-fibs} (아래)에 대한 신호 흐름 계획은 두 프로그램 사이의 공통점을 드러낸다.

@example
+-------------+   +-------------+   +-------------+   +-------------+
| enumerate:  |-->| filter:     |-->| map:        |-->| accumulate: |
| tree leaves |   | odd?        |   | square      |   | +, 0        |
+-------------+   +-------------+   +-------------+   +-------------+

+-------------+   +-------------+   +-------------+   +-------------+
| enumerate:  |-->| map:        |-->| filter:     |-->| accumulate: |
| integers    |   | fib         |   | even?       |   | cons, ()    |
+-------------+   +-------------+   +-------------+   +-------------+
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap2/Fig2.7e,147mm,,,.std.svg} 
@caption{@strong{Figure 2.7:} 프로시저 @code{sum-odd-squares} (위)와 @code{even-fibs} (아래)에 대한 신호 흐름 계획은 두 프로그램 사이의 공통점을 드러낸다.}
@end iftex
@end float

@noindent
불행히도, 위의 두 프로시저 정의는 이 신호 흐름 구조를 보여주지 못한다.
예를 들어, @code{sum-odd-squares} 프로시저를 살펴보면, 열거는 부분적으로 @code{null?}과 @code{pair?} 테스트에 의해, 그리고 부분적으로 프로시저의 트리 재귀 구조에 의해 구현되어 있음을 알 수 있다.
마찬가지로, 누산은 부분적으로 테스트에서, 그리고 부분적으로 재귀에 사용된 덧셈에서 발견된다.
일반적으로, 두 프로시저 어디에도 신호 흐름 설명의 요소에 대응하는 명확한 부분은 없다.
우리의 두 프로시저는 계산을 다른 방식으로 분해하여, 열거를 프로그램 전체에 퍼뜨리고 맵, 필터, 그리고 누산과 섞어버린다.
만약 우리가 작성하는 프로시저에서 신호 흐름 구조가 드러나도록 프로그램을 조직할 수 있다면, 이는 결과 코드의 개념적 명확성을 높일 것이다.

@subsubheading 시퀀스 연산 (Sequence Operations)

신호 흐름 구조를 더 명확하게 반영하도록 프로그램을 조직하는 열쇠는 프로세스의 한 단계에서 다음 단계로 흐르는 ``신호''에 집중하는 것이다.
이 신호들을 리스트로 표현한다면, 우리는 리스트 연산을 사용하여 각 단계의 처리를 구현할 수 있다.
예를 들어, 우리는 @ref{2.2.1}의 @code{map} 프로시저를 사용하여 신호 흐름 다이어그램의 매핑 단계를 구현할 수 있다:

@example
vec![1, 2, 3, 4, 5].iter().map(|x| x * x).collect::<Vec<_>>()
// => [1, 4, 9, 16, 25]
@end example

@noindent
주어진 술어를 만족하는 요소만 선택하기 위해 시퀀스를 필터링하는 것은 다음과 같이 달성된다:

@example
// Rust에서 filter는 내장 반복자 어댑터이다:
// sequence.iter().filter(predicate).collect()

// 비교를 위한 명시적 재귀 버전:
fn filter<T: Clone>(predicate: impl Fn(&T) -> bool, sequence: &[T]) -> Vec<T> @{
    match sequence @{
        [] => vec![],
        [first, rest @ ..] => @{
            let mut result = filter(&predicate, rest);
            if predicate(first) @{
                result.insert(0, first.clone());
            @}
            result
        @}
    @}
@}
@end example

@noindent
예를 들어,

@example
vec![1, 2, 3, 4, 5].iter().filter(|&x| x % 2 != 0).collect::<Vec<_>>()
// => [1, 3, 5]
@end example

@noindent
누산은 다음과 같이 구현될 수 있다:

@example
// Rust에서 accumulate는 fold (왼쪽 접기) 또는 rfold (오른쪽 접기)라고 불린다.
// 위의 Scheme 버전은 오른쪽 접기이다.

fn accumulate<T, R>(
    op: impl Fn(T, R) -> R,
    initial: R,
    sequence: impl DoubleEndedIterator<Item = T>,
) -> R @{
    sequence.rfold(initial, |acc, x| op(x, acc))
@}

vec![1, 2, 3, 4, 5].iter().fold(0, |acc, x| acc + x)
// => 15

vec![1, 2, 3, 4, 5].iter().fold(1, |acc, x| acc * x)
// => 120

// collect 같은 동작을 위해서는 직접 collect를 사용한다:
vec![1, 2, 3, 4, 5].iter().cloned().collect::<Vec<_>>()
// => [1, 2, 3, 4, 5]
@end example

@noindent
신호 흐름 다이어그램을 구현하기 위해 남은 것은 처리할 요소들의 시퀀스를 열거하는 것이다.
@code{even-fibs}의 경우, 우리는 주어진 범위의 정수 시퀀스를 생성해야 하는데, 이는 다음과 같이 할 수 있다:

@example
// Rust에서는 범위 문법을 직접 사용한다:
(2..=7).collect::<Vec<_>>()
// => [2, 3, 4, 5, 6, 7]

// 또는 명시적 패턴을 위한 함수로:
fn enumerate_interval(low: i32, high: i32) -> Vec<i32> @{
    (low..=high).collect()
@}
@end example

@noindent
트리의 잎을 열거하기 위해, 우리는 다음을 사용할 수 있다:@footnote{이것은 사실 @ref{Exercise 2.28}의 @code{fringe} 프로시저와 정확히 같다. 여기서 우리는 이것이 일반적인 시퀀스 조작 프로시저 패밀리의 일부임을 강조하기 위해 이름을 바꾸었다.}

@example
fn enumerate_tree(tree: &NestedList) -> Vec<i32> @{
    match tree @{
        Elem(n) => vec![*n],
        List(items) => items.iter()
            .flat_map(enumerate_tree)
            .collect(),
    @}
@}

// List(vec![Elem(1), List(vec![Elem(2), List(vec![Elem(3), Elem(4)])]), Elem(5)])
enumerate_tree(&tree)
// => [1, 2, 3, 4, 5]
@end example

@noindent
이제 우리는 신호 흐름 다이어그램에서처럼 @code{sum-odd-squares}와 @code{even-fibs}를 재구성할 수 있다.
@code{sum-odd-squares}의 경우, 우리는 트리의 잎 시퀀스를 열거하고, 이것을 필터링하여 시퀀스의 홀수만 남기고, 각 요소를 제곱하고, 결과를 합산한다:

@example
fn sum_odd_squares(tree: &NestedList) -> i32 @{
    enumerate_tree(tree)
        .into_iter()
        .filter(|x| x % 2 != 0)
        .map(|x| x * x)
        .sum()
@}
@end example

@noindent
@code{even-fibs}의 경우, 우리는 0부터 @math{n}까지의 정수를 열거하고, 이 정수들 각각에 대해 피보나치 수를 생성하고, 결과 시퀀스를 필터링하여 짝수 요소만 남기고, 결과를 리스트로 누산한다:

@example
fn even_fibs(n: u32) -> Vec<u64> @{
    (0..=n)
        .map(fib)
        .filter(|f| f % 2 == 0)
        .collect()
@}
@end example

@noindent
프로그램을 시퀀스 연산으로 표현하는 것의 가치는 이것이 모듈식 프로그램 설계를 돕는다는 것이다. 즉, 상대적으로 독립적인 조각들을 결합하여 구축되는 설계 말이다.
우리는 표준 구성 요소 라이브러리와 구성 요소들을 유연한 방식으로 연결하기 위한 관습적인 인터페이스를 함께 제공함으로써 모듈식 설계를 장려할 수 있다.

모듈식 구성은 공학 설계에서 복잡성을 제어하기 위한 강력한 전략이다.
예를 들어 실제 신호 처리 응용 분야에서, 설계자들은 표준화된 필터 및 변환기 패밀리에서 선택된 요소들을 캐스케이드 방식으로 연결하여 시스템을 정기적으로 구축한다.
마찬가지로, 시퀀스 연산은 우리가 믹스 앤 매치할 수 있는 표준 프로그램 요소들의 라이브러리를 제공한다.
예를 들어, 우리는 처음 @math{{n + 1}}개의 피보나치 수의 제곱의 리스트를 구성하는 프로그램에서 @code{sum-odd-squares}와 @code{even-fibs} 프로시저의 조각들을 재사용할 수 있다:

@example
fn list_fib_squares(n: u32) -> Vec<u64> @{
    (0..=n)
        .map(fib)
        .map(|f| f * f)
        .collect()
@}

list_fib_squares(10)
// => [0, 1, 1, 4, 9, 25, 64, 169, 441, 1156, 3025]
@end example

@noindent
우리는 조각들을 재배열하여 시퀀스의 홀수 정수 제곱의 곱을 계산하는 데 사용할 수 있다:

@example
fn product_of_squares_of_odd_elements(sequence: &[i64]) -> i64 @{
    sequence.iter()
        .filter(|&x| x % 2 != 0)
        .map(|x| x * x)
        .product()
@}

product_of_squares_of_odd_elements(&[1, 2, 3, 4, 5])
// => 225  (1*1 * 3*3 * 5*5 = 1 * 9 * 25)
@end example

@noindent
우리는 또한 시퀀스 연산의 관점에서 관습적인 데이터 처리 응용 프로그램을 정식화할 수 있다.
인사 기록의 시퀀스가 있고 가장 높은 급여를 받는 프로그래머의 급여를 찾고 싶다고 가정해 보자.
기록의 급여를 반환하는 선택자 @code{salary}와 기록이 프로그래머를 위한 것인지 테스트하는 술어 @code{programmer?}가 있다고 가정하자.
그러면 우리는 다음과 같이 쓸 수 있다:

@example
fn salary_of_highest_paid_programmer(records: &[Employee]) -> u64 @{
    records.iter()
        .filter(|r| r.is_programmer())
        .map(|r| r.salary())
        .max()
        .unwrap_or(0)
@}
@end example

@noindent
이 예제들은 시퀀스 연산으로 표현될 수 있는 광범위한 연산들의 힌트만 줄 뿐이다.@footnote{Richard @ref{Waters (1979)}는 전통적인 포트란 프로그램을 자동으로 분석하여 맵, 필터, 그리고 누산의 관점에서 보는 프로그램을 개발했다. 그는 Fortran Scientific Subroutine Package 코드의 90%가 이 패러다임에 깔끔하게 들어맞는다는 것을 발견했다. Lisp가 프로그래밍 언어로서 성공한 이유 중 하나는 리스트가 정렬된 컬렉션을 표현하기 위한 표준 매체를 제공하여 고차 연산을 사용하여 조작될 수 있게 하기 때문이다. 프로그래밍 언어 APL은 유사한 선택 덕분에 많은 힘과 매력을 가지고 있다. APL에서 모든 데이터는 배열로 표현되며, 모든 종류의 배열 연산을 위한 보편적이고 편리한 제네릭 연산자 세트가 있다.}

여기서 리스트로 구현된 시퀀스는 우리가 처리 모듈을 결합할 수 있게 해주는 관습적인 인터페이스 역할을 한다.
추가적으로, 우리가 구조를 시퀀스로 균일하게 표현할 때, 우리는 프로그램의 데이터 구조 의존성을 소수의 시퀀스 연산으로 국한시켰다.
이것들을 변경함으로써, 우리는 프로그램의 전체 설계를 손상시키지 않으면서 시퀀스의 대안적인 표현을 실험할 수 있다.
우리는 @ref{3.5}에서 무한 시퀀스를 허용하도록 시퀀스 처리 패러다임을 일반화할 때 이 기능을 활용할 것이다.

@quotation
@strong{@anchor{Exercise 2.33}연습문제 2.33:} 누산으로서의 기본 리스트 조작 연산들의 다음 정의를 완성하기 위해 누락된 표현식을 채워라:

@example
// fold/rfold를 사용하여 빈칸을 채워라:

fn map_via_fold<T, R>(
    p: impl Fn(&T) -> R,
    sequence: &[T],
) -> Vec<R> @{
    sequence.iter().rfold(vec![], |mut acc, x| @{
        acc.insert(0, p(x));  // ⟨??⟩ = p(x)를 결과 앞에 붙임
        acc
    @})
@}

fn append_via_fold<T: Clone>(seq1: &[T], seq2: &[T]) -> Vec<T> @{
    seq1.iter().cloned()
        .rfold(seq2.to_vec(), |mut acc, x| @{  // ⟨??⟩ = seq2, seq1
            acc.insert(0, x);
            acc
        @})
@}

fn length_via_fold<T>(sequence: &[T]) -> usize @{
    sequence.iter().fold(0, |acc, _| acc + 1)  // ⟨??⟩ = |acc, _| acc + 1
@}
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 2.34}연습문제 2.34:} 주어진 @math{x} 값에서 @math{x}에 대한 다항식을 평가하는 것은 누산으로 정식화될 수 있다.
우리는 다항식
@ifinfo

@example
a_n x^n + a_(n-1) x^(n-1) + ... + a_1 x + a_0
@end example

@end ifinfo
@tex
\[ % :35:
  {a_n x^n} + {a_{n-1} x^{n-1}} + \dots + {a_1 x} + a_0  \]
@end tex
@noindent
을 @newterm{호너의 규칙(Horner's rule)}이라고 불리는 잘 알려진 알고리즘을 사용하여 평가한다. 이 알고리즘은 계산을 다음과 같이 구조화한다.
@ifinfo

@example
(... (a_n x + a_(n-1)) x + ... + a_1) x + a_0
@end example

@end ifinfo
@tex
\[ % :36:
  {(\dots (a_n x} + {a_{n-1}) x} + \dots + {a_1) x} + {a_0.}  \]
@end tex
@noindent
달리 말하면, 우리는 @math{a_n}으로 시작해서 @math{x}를 곱하고, @math{a_{n-1}}을 더하고, @math{x}를 곱하고, 이렇게 @math{a_0}에 도달할 때까지 계속한다.@footnote{@ref{Knuth 1981}에 따르면, 이 규칙은 19세기 초 W. G. Horner에 의해 정식화되었지만, 실제로는 뉴턴이 백 년도 더 전에 이 방법을 사용했다. 호너의 규칙은 @math{{a_n x^n}}을 먼저 계산하고, 그 다음 @math{{a_{n-1}x^{n-1}}}을 더하는 식의 직접적인 방법보다 더 적은 덧셈과 곱셈을 사용하여 다항식을 평가한다. 사실, 임의의 다항식을 평가하는 어떤 알고리즘이라도 적어도 호너의 규칙만큼 많은 덧셈과 곱셈을 사용해야 하며, 따라서 호너의 규칙은 다항식 평가를 위한 최적의 알고리즘임이 증명 가능하다. 이것은 (덧셈의 횟수에 대해) 1954년 A. M. Ostrowski에 의해 증명되었는데, 이 논문은 본질적으로 최적 알고리즘에 대한 현대적 연구를 창시했다. 곱셈에 대한 유사한 진술은 1966년 V. Y. Pan에 의해 증명되었다. @ref{Borodin and Munro (1975)}의 책은 최적 알고리즘에 대한 이 결과들과 다른 결과들에 대한 개요를 제공한다.}

호너의 규칙을 사용하여 다항식을 평가하는 프로시저를 생성하기 위해 다음 템플릿을 채워라.
다항식의 계수들은 @math{a_0}부터 @math{a_n}까지 시퀀스로 배열되어 있다고 가정하라.

@example
fn horner_eval(x: f64, coefficients: &[f64]) -> f64 @{
    coefficients.iter().rfold(0.0, |higher_terms, &this_coeff| @{
        this_coeff + x * higher_terms  // ⟨??⟩
    @})
@}
@end example

예를 들어, @math{{x = 2}}에서 @math{{1 + 3x} + {5x^3 + x^5}}을 계산하려면 다음과 같이 평가한다.

@example
horner_eval(2.0, &[1.0, 3.0, 0.0, 5.0, 0.0, 1.0])
// => 79.0
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 2.35}연습문제 2.35:} @ref{2.2.2}의 @code{count-leaves}를 누산으로 재정의하라:

@example
fn count_leaves(t: &NestedList) -> usize @{
    // 반복자 콤비네이터 사용:
    enumerate_tree(t).len()  // enumerate가 평탄화한 다음 개수를 셈

    // 또는 fold를 통해 더 명시적으로:
    // match t @{
    //     Elem(_) => 1,
    //     List(items) => items.iter().map(count_leaves).sum(),
    // @}
@}
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 2.36}연습문제 2.36:} 프로시저 @code{accumulate-n}은 세 번째 인자로 시퀀스들의 시퀀스를 받는다는 점을 제외하고는 @code{accumulate}와 유사하다. 시퀀스들은 모두 같은 수의 요소를 가지고 있다고 가정한다.
이것은 지정된 누산 프로시저를 적용하여 모든 시퀀스의 첫 번째 요소들을 결합하고, 모든 시퀀스의 두 번째 요소들을 결합하고, 등등을 수행하여 결과의 시퀀스를 반환한다.
예를 들어, @code{s}가 4개의 시퀀스를 포함하는 시퀀스 @code{((1 2 3) (4 5 6) (7 8 9) (10 11 12))}라면, @code{(accumulate-n + 0 s)}의 값은 시퀀스 @code{(22 26 30)}이어야 한다.
@code{accumulate-n}의 다음 정의에서 누락된 표현식을 채워라:

@example
fn accumulate_n<T: Clone + Default>(
    op: impl Fn(T, T) -> T + Copy,
    init: T,
    seqs: &[Vec<T>],
) -> Vec<T> @{
    if seqs[0].is_empty() @{
        return vec![];
    @}
    let firsts: Vec<T> = seqs.iter().map(|s| s[0].clone()).collect();
    let rests: Vec<Vec<T>> = seqs.iter().map(|s| s[1..].to_vec()).collect();

    let mut result = vec![firsts.into_iter().fold(init.clone(), &op)];
    result.extend(accumulate_n(op, init, &rests));
    result
@}
// ⟨??⟩ = seqs.iter().map(|s| s[0])  // 첫 번째 요소들
// ⟨??⟩ = seqs.iter().map(|s| &s[1..])  // 각 시퀀스의 나머지
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 2.37}연습문제 2.37:}
벡터 @b{v} = @math{{(v_i)}}를 숫자의 시퀀스로 표현하고, 행렬 @b{m} = @math{{(m_{ij})}}를 벡터의 시퀀스(행렬의 행들)로 표현한다고 가정하자.
예를 들어, 행렬
@ifinfo

@example
+-         -+
|  1 2 3 4  |
|  4 5 6 6  |
|  6 7 8 9  |
+-         -+
@end example

@end ifinfo
@tex
\[ % :37:
  
\left(\matrix{	1 & 2 & 3 & 4 \cr
		4 & 5 & 6 & 6 \cr
		6 & 7 & 8 & 9 \cr }\right)  \]
@end tex
@noindent
은 시퀀스 @code{((1 2 3 4) (4 5 6 6) (6 7 8 9))}로 표현된다.
이 표현을 사용하여, 우리는 기본 행렬 및 벡터 연산을 시퀀스 연산으로 간결하게 표현할 수 있다.
이 연산들은 (행렬 대수에 관한 어떤 책에도 설명되어 있듯이) 다음과 같다:
@ifinfo

@example
                                       __
(dot-product v w)      returns the sum >_i v_i w_i

(matrix-*-vector m v)  returns the vector t,
                                   __
                       where t_i = >_j m_(ij) v_j

(matrix-*-matrix m n)  returns the matrix p,
                                      __
                       where p_(ij) = >_k m_(ik) n_(kj)

(transpose m)          returns the matrix n,
                       where n_(ij) = m_(ji)
@end example

@end ifinfo
@tex
\[ % :38:
  
\eqalign{ 
	\text{(dot-product v w)} 	& \text{returns the sum}\;\Sigma_i v_i w_i; \cr
	\text{(matrix-*-vector m v)} 	& \text{returns the vector}\;{\bf t}, \cr
		& \text{where}\; t_i = \Sigma_j m_{ij} v_j; \cr
	\text{(matrix-*-matrix m n)} 	& \text{returns the matrix}\;{\bf p}, \cr
		& \text{where}\; p_{ij} = \Sigma_k m_{ik} n_{kj}; \cr
	\text{(transpose m)} 		& \text{returns the matrix}\;{\bf n}, \cr
		& \text{where}\; n_{ij} = m_{ji}. \cr
}  \]
@end tex
우리는 내적(dot product)을 다음과 같이 정의할 수 있다:@footnote{이 정의는 @ref{2.2.1}에서 설명된, 여러 시퀀스를 받는 @code{map}의 확장된 버전을 사용한다. Rust에서 우리는 @code{zip} 반복자 어댑터로 이를 달성한다.}

@example
fn dot_product(v: &[f64], w: &[f64]) -> f64 @{
    v.iter().zip(w.iter()).map(|(a, b)| a * b).sum()
@}
@end example

다른 행렬 연산을 계산하는 다음 프로시저에서 누락된 표현식을 채워라.
(@code{accumulate-n} 프로시저는 @ref{Exercise 2.36}에 정의되어 있다.)

@example
type Matrix = Vec<Vec<f64>>;
type Vector = Vec<f64>;

fn matrix_times_vector(m: &Matrix, v: &Vector) -> Vector @{
    m.iter()
        .map(|row| dot_product(row, v))  // ⟨??⟩ = |row| dot_product(row, v)
        .collect()
@}

fn transpose(mat: &Matrix) -> Matrix @{
    (0..mat[0].len())
        .map(|col| mat.iter().map(|row| row[col]).collect())
        .collect()  // ⟨??⟩ = cons, nil (collect columns)
@}

fn matrix_times_matrix(m: &Matrix, n: &Matrix) -> Matrix @{
    let cols = transpose(n);
    m.iter()
        .map(|row| matrix_times_vector(&cols, row))  // ⟨??⟩
        .map(|v| v.into_iter().collect())
        .collect()
@}
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 2.38}연습문제 2.38:} @code{accumulate} 프로시저는 시퀀스의 첫 번째 요소를 오른쪽의 모든 요소를 결합한 결과와 결합하기 때문에 @code{fold-right}라고도 알려져 있다.
@code{fold-left}도 있는데, 이는 반대 방향으로 작업하며 요소를 결합한다는 점을 제외하고는 @code{fold-right}와 유사하다:

@example
// Rust에서 이것은 표준 fold 메서드이다:
fn fold_left<T, R>(
    op: impl Fn(R, T) -> R,
    initial: R,
    sequence: impl Iterator<Item = T>,
) -> R @{
    sequence.fold(initial, op)
@}

// 표준 라이브러리는 둘 다 제공한다:
// .fold()  - 왼쪽 접기, 반복자를 왼쪽에서 오른쪽으로 소비
// .rfold() - 오른쪽 접기, 반복자를 오른쪽에서 왼쪽으로 소비
@end example

다음의 값은 무엇인가?

@example
// fold-right: 1 / (2 / (3 / 1)) = 1 / (2 / 3) = 1.5
vec![1.0, 2.0, 3.0].iter().rfold(1.0, |acc, &x| x / acc)
// => 1.5

// fold-left: ((1 / 1) / 2) / 3 = 1/6
vec![1.0, 2.0, 3.0].iter().fold(1.0, |acc, &x| acc / x)
// => 0.166...

// 중첩을 사용한 fold-right: [1, [2, [3, []]]]를 구축
// 중첩을 사용한 fold-left:  [[[[], 1], 2], 3]을 구축
// fold-left == fold-right이려면 연산은 결합법칙을 만족해야 한다
@end example

어떤 시퀀스에 대해서도 @code{fold-right}와 @code{fold-left}가 같은 값을 생성하도록 보장하기 위해 @code{op}가 만족해야 할 속성을 제시하라.
@end quotation

@quotation
@strong{@anchor{Exercise 2.39}연습문제 2.39:} @ref{Exercise 2.38}의 @code{fold-right}와 @code{fold-left}의 관점에서 @code{reverse} (@ref{Exercise 2.18})에 대한 다음 정의를 완성하라:

@example
// rfold (fold-right) 사용:
fn reverse_rfold<T: Clone>(sequence: &[T]) -> Vec<T> @{
    sequence.iter().rfold(vec![], |mut acc, x| @{
        acc.insert(0, x.clone());  // ⟨??⟩ = x를 y 앞에 붙임
        acc
    @})
@}

// fold (fold-left) 사용 - Rust에서 더 자연스러움:
fn reverse_fold<T: Clone>(sequence: &[T]) -> Vec<T> @{
    sequence.iter().fold(vec![], |mut acc, x| @{
        acc.insert(0, x.clone());  // ⟨??⟩ = y를 x 앞에 붙임
        acc
    @})
@}

// 관용적인 Rust: .rev() 사용
fn reverse<T: Clone>(sequence: &[T]) -> Vec<T> @{
    sequence.iter().rev().cloned().collect()
@}
@end example
@end quotation

@subsubheading 중첩된 매핑 (Nested Mappings)

우리는 시퀀스 패러다임을 확장하여 중첩된 루프를 사용하여 일반적으로 표현되는 많은 계산을 포함할 수 있다.@footnote{중첩된 매핑에 대한 이 접근 방식은 데이비드 터너(David Turner)가 우리에게 보여주었는데, 그의 언어 KRC와 Miranda는 이러한 구성을 다루기 위한 우아한 형식주의를 제공한다. 이 절의 예제들(@ref{Exercise 2.42} 참조)은 @ref{Turner 1981}에서 수정되었다. @ref{3.5.3}에서 우리는 이 접근 방식이 무한 시퀀스로 어떻게 일반화되는지 볼 것이다.}
이 문제를 고려해 보자: 양의 정수 @math{n}이 주어졌을 때, @math{{1 \le j} < {i \le n}}이고 @math{{i + j}}가 소수인 모든 서로 다른 양의 정수 @math{i}와 @math{j}의 순서쌍 @math{{(i, j)}}를 찾아라.
예를 들어, @math{n}이 6이면, 쌍들은 다음과 같다:
@ifinfo

@example
  i   | 2 3 4 4 5 6 6
  j   | 1 2 1 3 2 1 5
------+---------------
i + j | 3 5 5 7 7 7 11
@end example

@end ifinfo
@tex
\[ % :39:
 
\begin{array}{c|ccccccc}
i 	& 2 & 3 & 4 & 4 & 5 & 6 & 6 \\
j 	& 1 & 2 & 1 & 3 & 2 & 1 & 5 \\
\hline
i + j	& 3 & 5 & 5 & 7 & 7 & 7 & 11 
\end{array}
\]
@end tex
이 계산을 조직하는 자연스러운 방법은 @math{n}보다 작거나 같은 양의 정수의 모든 순서쌍 시퀀스를 생성하고, 합이 소수인 쌍들을 선택하도록 필터링한 다음, 필터를 통과한 각 쌍 @math{{(i, j)}}에 대해 세 쌍 @math{{(i, j, i + j)}}를 생성하는 것이다.

쌍들의 시퀀스를 생성하는 방법은 다음과 같다: 각 정수 @math{{i \le n}}에 대해, 정수 @math{{j < i}}를 열거하고, 각 @math{i}와 @math{j}에 대해 쌍 @math{{(i, j)}}를 생성한다.
시퀀스 연산의 관점에서, 우리는 시퀀스 @code{(enumerate-interval 1 n)}을 따라 매핑한다.
이 시퀀스의 각 @math{i}에 대해, 시퀀스 @code{(enumerate-interval 1 (- i 1))}을 따라 매핑한다.
이 후자의 시퀀스에 있는 각 @math{j}에 대해, 쌍 @code{(list i j)}를 생성한다.
이것은 각 @math{i}에 대한 쌍들의 시퀀스를 제공한다.
모든 @math{i}에 대한 시퀀스들을 결합하면(@code{append}로 누산하여) 필요한 쌍들의 시퀀스가 생성된다:@footnote{우리는 여기서 쌍을 Lisp 쌍이 아니라 두 요소의 리스트로 표현하고 있다. 따라서 ``쌍'' @math{{(i, j)}}는 @code{(cons i j)}가 아니라 @code{(list i j)}로 표현된다.}

@example
// 1 <= j < i <= n 인 모든 쌍 (i, j) 생성
fn pairs_up_to(n: usize) -> Vec<(usize, usize)> @{
    (1..=n)
        .flat_map(|i| (1..i).map(move |j| (i, j)))
        .collect()
@}
// flat_map = map + flatten, Scheme의 accumulate + append + map과 동등함
@end example

@noindent
매핑과 @code{append}를 사용한 누산의 결합은 이런 종류의 프로그램에서 매우 흔하므로 우리는 이것을 별도의 프로시저로 격리할 것이다:

@example
// Rust에서, flat_map은 반복자에 내장되어 있다:
// seq.iter().flat_map(proc).collect()

// 명시적 구현을 위해:
fn flatmap<T, R>(proc: impl Fn(&T) -> Vec<R>, seq: &[T]) -> Vec<R> @{
    seq.iter().flat_map(proc).collect()
@}
@end example

@noindent
이제 이 쌍들의 시퀀스를 필터링하여 합이 소수인 것들을 찾는다.
필터 술어는 시퀀스의 각 요소에 대해 호출된다; 그 인자는 쌍이며 쌍에서 정수들을 추출해야 한다.
따라서 시퀀스의 각 요소에 적용할 술어는 다음과 같다.

@example
fn prime_sum(pair: &(usize, usize)) -> bool @{
    is_prime(pair.0 + pair.1)
@}
@end example

@noindent
마지막으로, 필터링된 쌍들에 대해 매핑하여 결과의 시퀀스를 생성한다. 이때 쌍의 두 요소와 그 합으로 구성된 세 쌍을 구성하는 다음 프로시저를 사용한다:

@example
fn make_pair_sum(pair: (usize, usize)) -> (usize, usize, usize) @{
    (pair.0, pair.1, pair.0 + pair.1)
@}
@end example

@noindent
이 모든 단계를 결합하면 전체 프로시저가 산출된다:

@example
fn prime_sum_pairs(n: usize) -> Vec<(usize, usize, usize)> @{
    (1..=n)
        .flat_map(|i| (1..i).map(move |j| (i, j)))
        .filter(|pair| is_prime(pair.0 + pair.1))
        .map(make_pair_sum)
        .collect()
@}
@end example

@noindent
중첩된 매핑은 구간을 열거하는 시퀀스 외의 시퀀스에도 유용하다.
집합 @math{S}의 모든 순열(permutation), 즉 집합의 항목들을 정렬하는 모든 방법을 생성하고 싶다고 가정해 보자.
예를 들어, @math{{\{1, 2, 3\}}}의 순열은 @math{{\{1, 2, 3\}}}, @math{{\{1, 3, 2\}}}, @math{{\{2, 1, 3\}}}, @math{{\{2, 3, 1\}}}, @math{{\{3, 1, 2\}}}, 그리고 @math{{\{3, 2, 1\}}}이다.
@math{S}의 순열을 생성하기 위한 계획은 다음과 같다: @math{S}의 각 항목 @math{x}에 대해, @math{{S - x}}의 순열 시퀀스를 재귀적으로 생성하고,@footnote{집합 @math{{S - x}}는 @math{x}를 제외한 @math{S}의 모든 요소의 집합이다.} 각 순열의 앞에 @math{x}를 붙인다.
이것은 @math{S}의 각 @math{x}에 대해 @math{x}로 시작하는 @math{S}의 순열 시퀀스를 산출한다.
모든 @math{x}에 대한 이 시퀀스들을 결합하면 @math{S}의 모든 순열을 얻는다:@footnote{Scheme 코드에서 세미콜론은 @newterm{주석(comments)}을 도입하는 데 사용된다. 세미콜론부터 줄 끝까지의 모든 것은 인터프리터에 의해 무시된다. 이 책에서 우리는 주석을 많이 사용하지 않는다; 우리는 서술적인 이름을 사용하여 우리 프로그램이 자체 문서화되도록 노력한다.}

@example
fn permutations<T: Clone + PartialEq>(s: Vec<T>) -> Vec<Vec<T>> @{
    if s.is_empty() @{
        return vec![vec![]];  // 빈 집합을 포함하는 시퀀스
    @}
    s.iter()
        .flat_map(|x| @{
            let rest: Vec<T> = s.iter()
                .filter(|&y| y != x)
                .cloned()
                .collect();
            permutations(rest)
                .into_iter()
                .map(|mut p| @{
                    p.insert(0, x.clone());
                    p
                @})
                .collect::<Vec<_>>()
        @})
        .collect()
@}
@end example

@noindent
이 전략이 @math{S}의 순열을 생성하는 문제를 @math{S}보다 적은 요소를 가진 집합의 순열을 생성하는 문제로 어떻게 환원하는지 주목하라.
종료 단계(terminal case)에서, 우리는 요소가 없는 집합을 나타내는 빈 리스트로 내려간다.
이를 위해 우리는 @code{(list nil)}을 생성하는데, 이는 하나의 항목, 즉 요소가 없는 집합을 가진 시퀀스이다.
@code{permutations}에서 사용된 @code{remove} 프로시저는 주어진 시퀀스에서 주어진 항목을 제외한 모든 항목을 반환한다.
이것은 간단한 필터로 표현될 수 있다:

@example
fn remove<T: Clone + PartialEq>(item: &T, sequence: &[T]) -> Vec<T> @{
    sequence.iter()
        .filter(|&x| x != item)
        .cloned()
        .collect()
@}
@end example

@quotation
@strong{@anchor{Exercise 2.40}연습문제 2.40:} 정수 @math{n}이 주어졌을 때, @math{{1 \le j} < {i \le n}}인 쌍 @math{{(i, j)}}의 시퀀스를 생성하는 프로시저 @code{unique-pairs}를 정의하라.
위에서 주어진 @code{prime-sum-pairs}의 정의를 단순화하기 위해 @code{unique-pairs}를 사용하라.
@end quotation

@quotation
@strong{@anchor{Exercise 2.41}연습문제 2.41:} 주어진 정수 @math{n}보다 작거나 같은 서로 다른 양의 정수 @math{i}, @math{j}, @math{k}의 순서 있는 세 쌍(ordered triples) 중에서 합이 주어진 정수 @math{s}인 모든 세 쌍을 찾는 프로시저를 작성하라.
@end quotation

@quotation
@strong{@anchor{Exercise 2.42}연습문제 2.42:} ``8-퀸 퍼즐(eight-queens puzzle)''은 체스판에 8개의 퀸을 놓되 서로가 서로를 위협하지 않도록(즉, 두 퀸이 같은 행, 열, 또는 대각선에 있지 않도록) 하는 방법을 묻는다.
가능한 해결책 중 하나가 @ref{Figure 2.8}에 나와 있다.
퍼즐을 푸는 한 가지 방법은 체스판을 가로질러 작업하면서 각 열에 퀸을 하나씩 놓는 것이다.
우리가 @math{{k - 1}}개의 퀸을 놓았다면, 우리는 이미 체스판에 있는 어떤 퀸도 체크하지 않는 위치에 @math{k}번째 퀸을 놓아야 한다.
우리는 이 접근 방식을 재귀적으로 정식화할 수 있다: 우리가 체스판의 처음 @math{{k - 1}} 열에 @math{{k - 1}} 퀸을 놓는 모든 가능한 방법의 시퀀스를 이미 생성했다고 가정하자.
이 방법들 각각에 대해, @math{k}번째 열의 각 행에 퀸을 놓음으로써 확장된 위치 집합을 생성한다.
이제 이것들을 필터링하여, @math{k}번째 열의 퀸이 다른 퀸들에 대해 안전한 위치들만 유지한다.
이것은 처음 @math{k} 열에 @math{k} 퀸을 놓는 모든 방법의 시퀀스를 생성한다.
이 과정을 계속함으로써, 우리는 하나의 해뿐만 아니라 퍼즐의 모든 해를 생성하게 될 것이다.

@float
@anchor{Figure 2.8}
@ifinfo
@strong{Figure 2.8:} 8-퀸 퍼즐의 해답.

@example
+---+---+---+---+---+---+---+---+
|   |   |   |   |   | Q |   |   |
+---+---+---+---+---+---+---+---+
|   |   | Q |   |   |   |   |   |
+---+---+---+---+---+---+---+---+
| Q |   |   |   |   |   |   |   |
+---+---+---+---+---+---+---+---+
|   |   |   |   |   |   | Q |   |
+---+---+---+---+---+---+---+---+
|   |   |   |   | Q |   |   |   |
+---+---+---+---+---+---+---+---+
|   |   |   |   |   |   |   | Q |
+---+---+---+---+---+---+---+---+
|   | Q |   |   |   |   |   |   |
+---+---+---+---+---+---+---+---+
|   |   |   | Q |   |   |   |   |
+---+---+---+---+---+---+---+---+
@end example
@end ifinfo
@iftex
@image{fig/chap2/Fig2.8c,73mm,,,.std.svg}
@caption{@strong{Figure 2.8:} 8-퀸 퍼즐의 해답.}
@end iftex
@end float

우리는 이 해결책을 @math{{n \times n}} 체스판에 @math{n}개의 퀸을 놓는 문제의 모든 해의 시퀀스를 반환하는 프로시저 @code{queens}로 구현한다.
@code{Queens}는 체스판의 처음 @math{k} 열에 퀸을 놓는 모든 방법의 시퀀스를 반환하는 내부 프로시저 @code{queen-cols}를 가지고 있다.

@example
type Board = Vec<usize>;  // 각 열의 행 위치

fn queens(board_size: usize) -> Vec<Board> @{
    fn queen_cols(k: usize, board_size: usize) -> Vec<Board> @{
        if k == 0 @{
            return vec![vec![]];  // 빈 체스판
        @}
        queen_cols(k - 1, board_size)
            .into_iter()
            .flat_map(|rest_of_queens| @{
                (1..=board_size)
                    .filter_map(|new_row| @{
                        let mut positions = rest_of_queens.clone();
                        positions.push(new_row);
                        if safe(k, &positions) @{
                            Some(positions)
                        @} else @{
                            None
                        @}
                    @})
                    .collect::<Vec<_>>()
            @})
            .collect()
    @}
    queen_cols(board_size, board_size)
@}
@end example

이 프로시저에서 @code{rest-of-queens}는 처음 @math{{k - 1}} 열에 @math{{k - 1}} 퀸을 놓는 방법이고, @code{new-row}는 @math{k}번째 열을 위해 퀸을 놓을 제안된 행이다.
새로운 행-열 위치를 위치 집합에 추가하는 프로시저 @code{adjoin-position}과 빈 위치 집합을 나타내는 @code{empty-board}를 포함하여, 체스판 위치 집합에 대한 표현을 구현함으로써 프로그램을 완성하라.
또한 위치 집합에 대해 @math{k}번째 열의 퀸이 다른 퀸들에 대해 안전한지 결정하는 프로시저 @code{safe?}를 작성해야 한다.
(우리는 새 퀸이 안전한지만 확인하면 된다는 점에 주목하라---다른 퀸들은 이미 서로에 대해 안전하다고 보장된다.)
@end quotation

@quotation
@strong{@anchor{Exercise 2.43}연습문제 2.43:} Louis Reasoner는 @ref{Exercise 2.42}를 하는 데 끔찍한 시간을 보내고 있다.
그의 @code{queens} 프로시저는 작동하는 것 같지만, 매우 느리게 실행된다. (Louis는 @math{{6\times6}} 케이스조차 해결하는 것을 기다리지 못했다.)
Louis가 Eva Lu Ator에게 도움을 요청했을 때, 그녀는 그가 @code{flatmap}의 중첩된 매핑 순서를 바꿔서 다음과 같이 썼다고 지적한다:

@example
// Louis의 느린 버전 - 각 행마다 queen_cols를 다시 계산한다!
(1..=board_size)
    .flat_map(|new_row| @{
        queen_cols(k - 1, board_size)  // board_size 번 호출된다!
            .into_iter()
            .map(move |mut rest_of_queens| @{
                rest_of_queens.push(new_row);
                rest_of_queens
            @})
            .collect::<Vec<_>>()
    @})
    .collect()
@end example

왜 이 순서 변경이 프로그램을 느리게 실행되게 하는지 설명하라.
@ref{Exercise 2.42}의 프로그램이 퍼즐을 푸는 데 시간 @math{T}가 걸린다고 가정할 때, Louis의 프로그램이 8-퀸 퍼즐을 푸는 데 얼마나 걸릴지 추정하라.
@end quotation

@node	2.2.4, 2.2.5, 2.2.3, 2.2
@subsection 예제: 그림 언어 (Example: A Picture Language)

이 절에서는 데이터 추상화와 클로저의 위력을 보여주고 고차 프로시저를 본질적인 방식으로 활용하는 간단한 그림 그리기 언어를 제시한다.
이 언어는 @ref{Figure 2.9}와 같이 이동하고 크기가 조정된 반복적인 요소들로 구성된 패턴을 쉽게 실험할 수 있도록 설계되었다.@footnote{이 그림 언어는 M.C. 에셔(M.C. Escher)의 ``Square Limit'' 목판화와 같은 이미지를 구성하기 위해 피터 헨더슨(Peter Henderson)이 만든 언어에 기초하고 있다(@ref{Henderson 1982} 참조).
이 목판화는 이 절의 @code{square_limit} 프로시저를 사용하여 그린 배열과 유사한 반복적인 스케일링 패턴을 포함한다.}
이 언어에서 결합되는 데이터 객체는 리스트 구조가 아니라 프로시저로 표현된다.
클로저 속성을 만족하는 @code{cons}가 임의로 복잡한 리스트 구조를 쉽게 만들 수 있게 해주었던 것처럼, 역시 클로저 속성을 만족하는 이 언어의 연산들은 임의로 복잡한 패턴을 쉽게 만들 수 있게 해준다.

@float
@anchor{Figure 2.9}
@ifinfo
@quotation
@strong{Figure 2.9:} 그림 언어로 생성된 디자인.

[two graphic images not included]
@end quotation
@end ifinfo
@iftex
@image{fig/chap2/Fig2.9,139mm,60mm,,.std.svg}
@caption{@strong{Figure 2.9:} 그림 언어로 생성된 디자인.}
@end iftex
@end float

@subsubheading 그림 언어 (The picture language)

우리가 @ref{1.1}에서 프로그래밍 공부를 시작했을 때, 우리는 언어의 원시 요소, 조합 수단, 그리고 추상화 수단에 초점을 맞춤으로써 언어를 설명하는 것의 중요성을 강조했다.
여기서도 그 프레임워크를 따를 것이다.

이 그림 언어의 우아함 중 일부는 @newterm{페인터(painter)}라고 불리는 단 한 종류의 요소만 있다는 것이다.
페인터는 지정된 평행사변형 모양의 프레임 안에 맞도록 이동되고 크기가 조정된 이미지를 그린다.
예를 들어, @ref{Figure 2.10}과 같이 조잡한 선 그림을 그리는 @code{wave}라는 원시 페인터가 있다.
그림의 실제 모양은 프레임에 따라 달라진다---그림 2.10의 네 이미지는 모두 같은 @code{wave} 페인터에 의해 생성되었지만, 네 개의 서로 다른 프레임에 대한 것이다.
페인터는 이것보다 더 정교할 수 있다: @code{rogers}라는 원시 페인터는 @ref{Figure 2.11}과 같이 @abbr{MIT}의 설립자인 윌리엄 바턴 로저스(William Barton Rogers)의 그림을 그린다.@footnote{윌리엄 바턴 로저스(William Barton Rogers, 1804-1882)는 @abbr{MIT}의 설립자이자 초대 총장이었다. 지질학자이자 재능 있는 교사였던 그는 윌리엄 앤 메리 대학(William and Mary College)과 버지니아 대학(University of Virginia)에서 가르쳤다. 1859년 그는 보스턴으로 이주하여 연구할 시간을 더 많이 가졌고, ``폴리테크닉 연구소(polytechnic institute)'' 설립 계획을 세웠으며, 매사추세츠주 최초의 가스 계량기 검사관으로 일했다.

1861년 @abbr{MIT}가 설립되었을 때, 로저스는 초대 총장으로 선출되었다.
로저스는 당시의 대학 교육과는 다른 ``유용한 배움(useful learning)''이라는 이상을 옹호했는데, 당시의 교육은 그가 썼듯이 ``자연과학과 사회과학의 더 광범위하고, 더 높으며, 더 실용적인 교육과 훈련을 방해하는'' 고전에 지나치게 치중해 있었다.
이 교육은 또한 좁은 직업 학교 교육과는 달라야 했다.
로저스의 말에 따르면:

@quotation
실무자와 과학자 사이의 강제된 구분은 완전히 헛된 것이며, 근대의 모든 경험은 그것의 완전한 무가치함을 증명했다.
@end quotation

로저스는 건강 악화로 사임한 1870년까지 @abbr{MIT} 총장으로 재직했다.
1878년 @abbr{MIT}의 2대 총장 존 런클(John Runkle)이 1873년 공황으로 인한 재정 위기와 하버드의 @abbr{MIT} 인수 시도를 막아내는 압박감 속에서 사임했다.
로저스는 1881년까지 다시 총장직을 맡았다.

로저스는 1882년 졸업식에서 @abbr{MIT} 졸업반 학생들에게 연설하던 중 쓰러져 사망했다.
런클은 같은 해 행한 추모 연설에서 로저스의 마지막 말을 인용했다:

@quotation
``오늘 여기에 서서 연구소가 무엇인지 보니, @dots{} 과학의 시작이 떠오릅니다. 150년 전 스티븐 헤일스(Stephen Hales)가 조명용 가스에 관한 팸플릿을 출판했는데, 그곳에서 그는 자신의 연구가 128그레인의 역청탄이 -- '' ``역청탄(Bituminous coal),'' 이것이 이 땅에서 그의 마지막 말이었습니다. 여기서 그는 마치 앞에 있는 탁자 위의 노트를 참고하려는 듯 몸을 굽혔다가, 천천히 다시 똑바로 선 자세를 회복하며 두 손을 위로 던졌고, 지상의 노고와 승리의 현장에서 ``죽음의 내일''로 옮겨졌습니다. 그곳에서 생명의 신비는 풀리고, 육체를 떠난 영혼은 무한한 미래의 새롭고 여전히 헤아릴 수 없는 신비를 응시하며 끝없는 만족을 찾을 것입니다.
@end quotation

프랜시스 A. 워커(Francis A. Walker, @abbr{MIT} 3대 총장)의 말에 따르면:

@quotation
평생 동안 그는 자신을 가장 충실하고 영웅적으로 지탱했으며, 훌륭한 기사가 바랐을 법한 모습으로, 갑옷을 입고, 자신의 초소에서, 그리고 공무의 바로 그 부분과 행동 중에 죽었습니다.
@end quotation
} 그림 2.11의 네 이미지는 그림 2.10의 @code{wave} 이미지와 같은 네 개의 프레임에 대해 그려졌다.

@float
@anchor{Figure 2.10}
@ifinfo
@quotation
@strong{Figure 2.10:} @code{wave} 페인터가 네 개의 서로 다른 프레임에 대해 생성한 이미지.
점선으로 표시된 프레임은 이미지의 일부가 아니다.

[four graphic images not included]
@end quotation
@end ifinfo
@iftex
@image{fig/chap2/Fig2.10,58mm,,,.std.svg}
@caption{@strong{Figure 2.10:} @code{wave} 페인터가 네 개의 서로 다른 프레임에 대해 생성한 이미지. 점선으로 표시된 프레임은 이미지의 일부가 아니다.}
@end iftex
@end float

@float
@anchor{Figure 2.11}
@ifinfo
@quotation
@strong{Figure 2.11:} @abbr{MIT}의 설립자이자 초대 총장인 윌리엄 바턴 로저스의 이미지. @ref{Figure 2.10}과 같은 네 개의 프레임에 대해 그려졌다(원본 이미지는 @abbr{MIT} 박물관의 허가를 받아 재인쇄됨).

[four graphic images not included]
@end quotation
@end ifinfo
@iftex
@image{fig/chap2/Fig2.11,58mm,,,.std.svg}
@caption{@strong{Figure 2.11:} @abbr{MIT}의 설립자이자 초대 총장인 윌리엄 바턴 로저스의 이미지. @ref{Figure 2.10}과 같은 네 개의 프레임에 대해 그려졌다(원본 이미지는 위키미디어 공용에서 가져옴).}
@end iftex
@end float

@noindent
이미지를 결합하기 위해, 우리는 주어진 페인터로부터 새로운 페인터를 구성하는 다양한 연산을 사용한다.
예를 들어, @code{beside} 연산은 두 페인터를 받아 첫 번째 페인터의 이미지를 프레임의 왼쪽 절반에 그리고 두 번째 페인터의 이미지를 오른쪽 절반에 그리는 새로운 복합 페인터를 생성한다.
마찬가지로, @code{below}는 두 페인터를 받아 첫 번째 페인터의 이미지를 두 번째 페인터의 이미지 아래에 그리는 복합 페인터를 생성한다.
어떤 연산들은 단일 페인터를 변환하여 새로운 페인터를 생성한다.
예를 들어, @code{flip_vert}는 페인터를 받아 이미지를 위아래로 뒤집어 그리는 페인터를 생성하고, @code{flip_horiz}는 원래 페인터의 이미지를 좌우 반전하여 그리는 페인터를 생성한다.

@ref{Figure 2.12}는 @code{wave}에서 시작하여 두 단계로 구축된 @code{wave4}라는 페인터의 그림을 보여준다:

@example
let wave2 = beside(&wave, &flip_vert(&wave));
let wave4 = below(&wave2, &wave2);
@end example

@float
@anchor{Figure 2.12}
@ifinfo
@quotation
@strong{Figure 2.12:} @ref{Figure 2.10}의 @code{wave} 페인터에서 시작하여 복잡한 도형 만들기.

[two graphic images not included]

@example
let wave2 = beside(&wave,       let wave4 = below(&wave2,
                   &flip_vert(&wave));             &wave2);
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap2/Fig2.12,118mm,,,.std.svg}
@caption{@strong{Figure 2.12:} @ref{Figure 2.10}의 @code{wave} 페인터에서 시작하여 복잡한 도형 만들기.}
@end iftex
@end float

@noindent
이런 방식으로 복잡한 이미지를 구축할 때 우리는 페인터가 언어의 조합 수단에 대해 닫혀 있다는(closed) 사실을 이용하고 있다.
두 페인터의 @code{beside}나 @code{below}는 그 자체로 페인터이다; 따라서 우리는 이것을 더 복잡한 페인터를 만드는 요소로 사용할 수 있다.
@code{cons}를 사용하여 리스트 구조를 구축할 때와 마찬가지로, 조합 수단에 대한 데이터의 폐포(closure)는 적은 수의 연산만으로 복잡한 구조를 생성할 수 있는 능력의 핵심이다.

일단 페인터를 결합할 수 있게 되면, 우리는 페인터를 결합하는 전형적인 패턴을 추상화하고 싶을 것이다.
우리는 페인터 연산을 Scheme 프로시저로 구현할 것이다.
이것은 우리가 그림 언어에 특별한 추상화 메커니즘을 필요로 하지 않음을 의미한다: 조합 수단이 일반적인 Scheme 프로시저이므로, 우리는 프로시저로 할 수 있는 모든 것을 페인터 연산으로도 할 수 있는 능력을 자동으로 갖게 된다.
예를 들어, 우리는 @code{wave4}의 패턴을 다음과 같이 추상화할 수 있다

@example
fn flipped_pairs(painter: &Painter) -> Painter @{
    let painter2 = beside(painter, &flip_vert(painter));
    below(&painter2, &painter2)
@}
@end example

@noindent
그리고 @code{wave4}를 이 패턴의 인스턴스로 정의한다:

@example
let wave4 = flipped_pairs(&wave);
@end example

@noindent
우리는 또한 재귀적 연산을 정의할 수 있다. 다음은 @ref{Figure 2.13}과 @ref{Figure 2.14}에 보이는 것처럼 페인터가 오른쪽으로 쪼개지고 가지치게 만드는 연산이다:

@example
fn right_split(painter: &Painter, n: usize) -> Painter @{
    if n == 0 @{
        painter.clone()
    @} else @{
        let smaller = right_split(painter, n - 1);
        beside(painter, &below(&smaller, &smaller))
    @}
@}
@end example

@float
@anchor{Figure 2.13}
@ifinfo
@quotation
@strong{Figure 2.13:} @code{right_split}과 @code{corner_split}을 위한 재귀적 계획.

@example
+-------------+-------------+    +------+------+-------------+
|             |             |    | up-  | up-  |             |
|             | right-split |    | split| split| corner-split|
|             |             |    |      |      |             |
|             |     n-1     |    |  n-1 |  n-1 |     n-1     |
|             |             |    |      |      |             |
|  identity   +-------------+    +------+------+-------------+
|             |             |    |             | right-split |
|             | right-split |    |             |     n-1     |
|             |             |    |  identity   +-------------+
|             |     n-1     |    |             | right-split |
|             |             |    |             |     n-1     |
+-------------+-------------+    +-------------+-------------+

       right-split n                    corner-split n
@end example

@end quotation
@end ifinfo
@iftex
@image{fig/chap2/Fig2.13a,132mm,,,.std.svg}
@caption{@strong{Figure 2.13:} @code{right_split}과 @code{corner_split}을 위한 재귀적 계획.}
@end iftex
@end float

@noindent
우리는 오른쪽뿐만 아니라 위쪽으로도 가지를 침으로써 균형 잡힌 패턴을 생성할 수 있다(@ref{Exercise 2.44}, @ref{Figure 2.13}, @ref{Figure 2.14} 참조):

@example
fn corner_split(painter: &Painter, n: usize) -> Painter @{
    if n == 0 @{
        painter.clone()
    @} else @{
        let up = up_split(painter, n - 1);
        let right = right_split(painter, n - 1);
        let top_left = beside(&up, &up);
        let bottom_right = below(&right, &right);
        let corner = corner_split(painter, n - 1);
        beside(
            &below(painter, &top_left),
            &below(&bottom_right, &corner),
        )
    @}
@}
@end example

@float
@anchor{Figure 2.14}
@ifinfo
@quotation
@strong{Figure 2.14:} 페인터 @code{wave}와 @code{rogers}에 적용된 재귀적 연산 @code{right_split}과 @code{corner_split}. @code{corner_split} 도형 네 개를 결합하면 @ref{Figure 2.9}에 보이는 것과 같은 대칭적인 @code{square_limit} 디자인이 생성된다.

[two graphic images not included]

@example
right_split(&wave, 4)        right_split(&rogers, 4)
@end example

[two graphic images not included]

@example
corner_split(&wave, 4)       corner_split(&rogers, 4)
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap2/Fig2.14b,136mm,,,.std.svg}
@caption{@strong{Figure 2.14:} 페인터 @code{wave}와 @code{rogers}에 적용된 재귀적 연산 @code{right_split}과 @code{corner_split}. @code{corner_split} 도형 네 개를 결합하면 @ref{Figure 2.9}에 보이는 것과 같은 대칭적인 @code{square_limit} 디자인이 생성된다.}
@end iftex
@end float

@code{corner_split}의 사본 네 개를 적절히 배치함으로써, 우리는 @code{square_limit}라고 불리는 패턴을 얻는다. @code{wave}와 @code{rogers}에 대한 적용이 @ref{Figure 2.9}에 나와 있다:

@example
fn square_limit(painter: &Painter, n: usize) -> Painter @{
    let quarter = corner_split(painter, n);
    let half = beside(&flip_horiz(&quarter), &quarter);
    below(&flip_vert(&half), &half)
@}
@end example

@quotation
@strong{@anchor{Exercise 2.44}연습문제 2.44:} @code{corner_split}에서 사용되는 프로시저 @code{up_split}을 정의하라. 이것은 @code{below}와 @code{beside}의 역할을 바꾼다는 점을 제외하면 @code{right_split}과 유사하다.
@end quotation

@subsubheading 고차 연산 (Higher-order operations)

페인터를 결합하는 패턴을 추상화하는 것 외에도, 우리는 더 높은 수준에서 작업하여 페인터 연산을 결합하는 패턴을 추상화할 수 있다.
즉, 우리는 페인터 연산을 조작할 요소로 간주할 수 있고, 이 요소들을 위한 조합 수단---페인터 연산을 인자로 받아 새로운 페인터 연산을 생성하는 프로시저---을 작성할 수 있다.

예를 들어, @code{flipped_pairs}와 @code{square_limit}는 각각 페인터 이미지의 네 사본을 사각형 패턴으로 배열한다; 그것들은 오직 사본들을 어떻게 지향시키느냐에 있어서만 다르다.
이 페인터 결합 패턴을 추상화하는 한 가지 방법은 다음 프로시저를 사용하는 것이다. 이 프로시저는 네 개의 1인자 페인터 연산을 받아 주어진 페인터를 그 네 연산으로 변환하고 결과를 사각형으로 배열하는 페인터 연산을 생성한다.
@code{Tl}, @code{tr}, @code{bl}, 그리고 @code{br}은 각각 왼쪽 위 사본, 오른쪽 위 사본, 왼쪽 아래 사본, 그리고 오른쪽 아래 사본에 적용할 변환이다.

@example
fn square_of_four<F1, F2, F3, F4>(tl: F1, tr: F2, bl: F3, br: F4)
    -> impl Fn(&Painter) -> Painter
where
    F1: Fn(&Painter) -> Painter,
    F2: Fn(&Painter) -> Painter,
    F3: Fn(&Painter) -> Painter,
    F4: Fn(&Painter) -> Painter,
@{
    move |painter| @{
        let top = beside(&tl(painter), &tr(painter));
        let bottom = beside(&bl(painter), &br(painter));
        below(&bottom, &top)
    @}
@}
@end example

@noindent
그러면 @code{flipped_pairs}는 @code{square_of_four}의 관점에서 다음과 같이 정의될 수 있다:@footnote{동등하게, 우리는 다음과 같이 쓸 수 있다

@example
let flipped_pairs = square_of_four(identity, flip_vert, identity, flip_vert);
@end example
}

@example
fn flipped_pairs(painter: &Painter) -> Painter @{
    let combine4 = square_of_four(identity, flip_vert, identity, flip_vert);
    combine4(painter)
@}
@end example

@noindent
그리고 @code{square_limit}은 다음과 같이 표현될 수 있다@footnote{@code{Rotate180}은 페인터를 180도 회전시킨다(@ref{Exercise 2.50} 참조). @code{rotate180} 대신 @ref{Exercise 1.42}의 @code{compose} 프로시저를 사용하여 @code{(compose flip-vert flip-horiz)}라고 말할 수도 있다.}

@example
fn square_limit(painter: &Painter, n: usize) -> Painter @{
    let combine4 = square_of_four(flip_horiz, identity, rotate180, flip_vert);
    combine4(&corner_split(painter, n))
@}
@end example

@quotation
@strong{@anchor{Exercise 2.45}연습문제 2.45:} @code{Right-split}과 @code{up_split}은 일반적인 분할 연산의 인스턴스로 표현될 수 있다.
다음을 평가하면

@example
let right_split = split(beside, below);
let up_split = split(below, beside);
@end example

@noindent
이미 정의된 것과 동일한 동작을 하는 프로시저 @code{right_split}과 @code{up_split}을 생성하는 성질을 가진 프로시저 @code{split}을 정의하라.
@end quotation

@subsubheading 프레임 (Frames)

페인터와 그 조합 수단을 어떻게 구현하는지 보여주기 전에, 우리는 먼저 프레임을 고려해야 한다.
프레임은 세 개의 벡터---원점 벡터와 두 개의 가장자리 벡터---로 기술될 수 있다.
원점 벡터는 평면의 어떤 절대 원점으로부터 프레임 원점의 오프셋을 지정하고, 가장자리 벡터들은 원점으로부터 프레임 코너들의 오프셋을 지정한다.
가장자리들이 수직이면 프레임은 직사각형일 것이다.
그렇지 않으면 프레임은 더 일반적인 평행사변형이 될 것이다.

@ref{Figure 2.15}는 프레임과 관련 벡터들을 보여준다.
데이터 추상화에 따라, 우리는 아직 프레임이 어떻게 표현되는지에 대해 구체적일 필요가 없다. 단지 세 개의 벡터를 받아 프레임을 생성하는 생성자 @code{Frame::new}와 세 개의 해당 선택자 @code{origin_frame}, @code{edge1_frame}, 그리고 @code{edge2_frame}이 있다는 것만 말하면 된다(@ref{Exercise 2.47} 참조).

@float
@anchor{Figure 2.15}
@ifinfo
@quotation
@strong{Figure 2.15:} 프레임은 세 개의 벡터---원점과 두 가장자리---로 기술된다.

@example
                         __
                     __--  \
                 __--       \
      __     __--            \   __
     |\  __--                 \__-|
       \-                  __--
frame   \              __--
edge2    \         __--    frame
vector    \    __--        edge1
           \_--            vector
            -   <--+
          frame    |
          origin   +-- (0, 0) point
          vector       on display screen
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap2/Fig2.15a,78mm,,,.std.svg}
@caption{@strong{Figure 2.15:} 프레임은 세 개의 벡터---원점과 두 가장자리---로 기술된다.}
@end iftex
@end float

@noindent
우리는 이미지를 지정하기 위해 단위 정사각형 @math{{(0 \le x, y \le 1)}} 내의 좌표를 사용할 것이다.
각 프레임에는 @newterm{프레임 좌표 맵(frame coordinate map)}을 연관시키는데, 이는 이미지를 프레임에 맞도록 이동하고 크기를 조정하는 데 사용될 것이다.
이 맵은 벡터 @math{{{\bf v} = (x, y)}}를 다음 벡터 합으로 매핑함으로써 단위 정사각형을 프레임으로 변환한다.
@ifinfo

@example
Origin(Frame) + x * Edge_1(Frame) + y * Edge_2(Frame)
@end example

@end ifinfo
@tex
\[ % :40:
  {\text{Origin(Frame)}} + {x \cdot \text{Edge}_1\text{(Frame)}} + {y \cdot \text{Edge}_2\text{(Frame)}.} \]
@end tex
@noindent
예를 들어, (0, 0)은 프레임의 원점으로, (1, 1)은 원점의 대각선 반대편 꼭짓점으로, (0.5, 0.5)는 프레임의 중심으로 매핑된다.
우리는 다음 프로시저로 프레임의 좌표 맵을 생성할 수 있다:@footnote{@code{Frame-coord-map}은 아래 @ref{Exercise 2.46}에서 설명된 벡터 연산을 사용하는데, 우리는 이것이 벡터에 대한 어떤 표현을 사용하여 구현되었다고 가정한다. 데이터 추상화 때문에, 벡터 연산이 올바르게 동작하는 한 이 벡터 표현이 무엇인지는 중요하지 않다.}

@example
fn frame_coord_map(frame: &Frame) -> impl Fn(Vec2) -> Vec2 + '_ @{
    move |v| @{
        frame.origin
            .add(&frame.edge1.scale(v.x))
            .add(&frame.edge2.scale(v.y))
    @}
@}
@end example

@noindent
@code{frame_coord_map}을 프레임에 적용하면 벡터가 주어졌을 때 벡터를 반환하는 프로시저가 반환된다는 점을 관찰하라.
만약 인자 벡터가 단위 정사각형 안에 있다면, 결과 벡터는 프레임 안에 있을 것이다.
예를 들어,

@example
frame_coord_map(&a_frame)(Vec2 @{ x: 0.0, y: 0.0 @})
@end example

@noindent
은 다음과 같은 벡터를 반환한다

@example
a_frame.origin
@end example

@quotation
@strong{@anchor{Exercise 2.46}연습문제 2.46:} 원점에서 어떤 점으로 이어지는 2차원 벡터 @math{\bf v}는 @math{x} 좌표와 @math{y} 좌표로 구성된 쌍으로 표현될 수 있다.
생성자 @code{Vec2::new}와 해당 선택자 @code{xcor_vect} 및 @code{ycor_vect}를 제공하여 벡터에 대한 데이터 추상화를 구현하라.
여러분의 선택자와 생성자의 관점에서, 벡터 덧셈, 벡터 뺄셈, 그리고 벡터에 스칼라 곱하기 연산을 수행하는 프로시저 @code{add_vect}, @code{sub_vect}, 그리고 @code{scale_vect}를 구현하라:
@ifinfo

@example
(x_1, y_1) + (x_2, y_2) = (x_1 + x_2, y_1 + y_2)
(x_1, y_1) - (x_2, y_2) = (x_1 - x_2, y_1 - y_2)
             s * (x, y) = (sx, sy)
@end example
@end ifinfo
@tex
\[ % :41:
  
\begin{eqnarray}
	(x_1, y_1) + (x_2, y_2)  &=&  (x_1 + x_2, y_1 + y_2), \\
	(x_1, y_1) - (x_2, y_2)  &=&  (x_1 - x_2, y_1 - y_2), \\
	s \cdot (x, y) 		 &=&  (sx, sy).
\end{eqnarray}
\]
@end tex
@end quotation

@quotation
@strong{@anchor{Exercise 2.47}연습문제 2.47:} 여기 프레임에 대한 두 가지 가능한 생성자가 있다:

@example
// In Rust, we use a struct with named fields:
#[derive(Clone)]
struct Frame @{
    origin: Vec2,
    edge1: Vec2,
    edge2: Vec2,
@}

impl Frame @{
    fn new(origin: Vec2, edge1: Vec2, edge2: Vec2) -> Self @{
        Self @{ origin, edge1, edge2 @}
    @}
@}
@end example

각 생성자에 대해 적절한 선택자를 제공하여 프레임 구현을 생성하라.
@end quotation

@subsubheading 페인터 (Painters)

페인터는 프레임을 인자로 받아 특정 이미지를 프레임에 맞도록 이동하고 크기를 조정하여 그리는 프로시저로 표현된다.
즉, 만약 @code{p}가 페인터이고 @code{f}가 프레임이라면, 우리는 @code{p}를 @code{f}를 인자로 하여 호출함으로써 @code{f} 안에 @code{p}의 이미지를 생성한다.

원시 페인터가 어떻게 구현되는지에 대한 세부 사항은 그래픽 시스템의 특정 특성과 그려질 이미지의 종류에 따라 다르다.
예를 들어, 지정된 두 점 사이에 화면에 선을 그리는 프로시저 @code{draw_line}이 있다고 가정해 보자.
그러면 우리는 다음과 같이 선분 리스트로부터 @ref{Figure 2.10}의 @code{wave} 페인터와 같은 선 그림을 위한 페인터를 생성할 수 있다:@footnote{@code{Segments->painter}는 아래 @ref{Exercise 2.48}에서 설명된 선분 표현을 사용한다. 또한 @ref{Exercise 2.23}에서 설명된 @code{for-each} 프로시저를 사용한다.}

@example
fn segments_to_painter(segment_list: Vec<Segment>) -> Painter @{
    Box::new(move |frame: &Frame| @{
        let mapper = frame_coord_map(frame);
        for segment in &segment_list @{
            draw_line(
                mapper(segment.start),
                mapper(segment.end),
            );
        @}
    @})
@}
@end example

@noindent
선분들은 단위 정사각형에 대한 좌표를 사용하여 주어진다.
리스트의 각 선분에 대해, 페인터는 프레임 좌표 맵을 사용하여 선분 끝점을 변환하고 변환된 점들 사이에 선을 그린다.

페인터를 프로시저로 표현하는 것은 그림 언어에 강력한 추상화 장벽을 세운다.
우리는 다양한 그래픽 기능에 기초하여 모든 종류의 원시 페인터를 생성하고 혼합할 수 있다. 그 구현의 세부 사항은 중요하지 않다.
어떤 프로시저라도 프레임을 인자로 받아 지정된 프레임 안에 맞게 스케일링된 무언가를 그리기만 한다면 페인터 역할을 할 수 있다.@footnote{예를 들어, @ref{Figure 2.11}의 @code{rogers} 페인터는 회색조(gray-level) 이미지로부터 구축되었다. 주어진 프레임의 각 점에 대해, @code{rogers} 페인터는 프레임 좌표 맵에 따라 그 점으로 매핑되는 이미지상의 점을 결정하고, 그에 따라 음영을 칠한다. 다른 유형의 페인터를 허용함으로써, 우리는 @ref{2.1.3}에서 논의했던 추상 데이터 아이디어를 활용하고 있다. 거기서 우리는 유리수 표현이 적절한 조건을 만족하는 한 무엇이든 될 수 있다고 주장했다. 여기서 우리는 페인터가 지정된 프레임 안에 무언가를 그리기만 한다면 어떤 방식으로든 구현될 수 있다는 사실을 사용하고 있다. @ref{2.1.3}은 또한 쌍이 프로시저로 구현될 수 있음을 보여주었다. 페인터는 데이터를 위한 절차적 표현의 두 번째 예이다.}

@quotation
@strong{@anchor{Exercise 2.48}연습문제 2.48:} 평면상의 방향 있는 선분은 벡터의 쌍---원점에서 선분의 시작점으로 이어지는 벡터와 원점에서 선분의 끝점으로 이어지는 벡터---으로 표현될 수 있다.
@ref{Exercise 2.46}의 벡터 표현을 사용하여 생성자 @code{Segment::new}와 선택자 @code{start_segment} 및 @code{end_segment}를 가진 선분 표현을 정의하라.
@end quotation

@quotation
@strong{@anchor{Exercise 2.49}연습문제 2.49:} @code{segments_to_painter}를 사용하여 다음 원시 페인터들을 정의하라:

@enumerate a

@item
지정된 프레임의 외곽선을 그리는 페인터.

@item
프레임의 반대편 모서리를 연결하여 ``X''를 그리는 페인터.

@item
프레임 변들의 중점을 연결하여 다이아몬드 모양을 그리는 페인터.

@item
@code{wave} 페인터.

@end enumerate
@end quotation

@subsubheading 페인터 변환 및 결합 (Transforming and combining painters)

페인터에 대한 연산(@code{flip_vert}나 @code{beside}와 같은)은 인자 프레임으로부터 파생된 프레임에 대해 원래 페인터를 호출하는 페인터를 생성함으로써 작동한다.
따라서, 예를 들어 @code{flip_vert}는 페인터를 뒤집기 위해 페인터가 어떻게 작동하는지 알 필요가 없다---단지 프레임을 위아래로 뒤집는 법만 알면 된다: 뒤집힌 페인터는 단지 원래 페인터를 사용하되 반전된 프레임에서 사용한다.

페인터 연산은 프로시저 @code{transform_painter}에 기초한다. 이 프로시저는 페인터와 프레임 변환 방법에 대한 정보를 인자로 받아 새로운 페인터를 생성한다.
변환된 페인터는 프레임에 대해 호출될 때, 프레임을 변환하고 변환된 프레임에 대해 원래 페인터를 호출한다.
@code{transform_painter}에 대한 인자는 새로운 프레임의 모서리를 지정하는 점(벡터로 표현됨)들이다: 프레임으로 매핑될 때, 첫 번째 점은 새로운 프레임의 원점을 지정하고 다른 두 점은 가장자리 벡터의 끝을 지정한다.
따라서 단위 정사각형 내의 인자들은 원래 프레임 안에 포함된 프레임을 지정한다.

@example
fn transform_painter(
    painter: Painter,
    origin: Vec2,
    corner1: Vec2,
    corner2: Vec2,
) -> Painter @{
    Box::new(move |frame: &Frame| @{
        let m = frame_coord_map(frame);
        let new_origin = m(origin);
        let new_frame = Frame::new(
            new_origin,
            m(corner1).sub(&new_origin),
            m(corner2).sub(&new_origin),
        );
        painter(&new_frame)
    @})
@}
@end example

@noindent
다음은 페인터 이미지를 수직으로 뒤집는 방법이다:

@example
fn flip_vert(painter: Painter) -> Painter @{
    transform_painter(
        painter,
        Vec2 @{ x: 0.0, y: 1.0 @},  // new origin
        Vec2 @{ x: 1.0, y: 1.0 @},  // new end of edge1
        Vec2 @{ x: 0.0, y: 0.0 @},  // new end of edge2
    )
@}
@end example

@noindent
@code{transform_painter}를 사용하여 우리는 새로운 변환을 쉽게 정의할 수 있다.
예를 들어, 이미지를 주어진 프레임의 오른쪽 위 4분면으로 축소하는 페인터를 정의할 수 있다:

@example
fn shrink_to_upper_right(painter: Painter) -> Painter @{
    transform_painter(
        painter,
        Vec2 @{ x: 0.5, y: 0.5 @},
        Vec2 @{ x: 1.0, y: 0.5 @},
        Vec2 @{ x: 0.5, y: 1.0 @},
    )
@}
@end example

@noindent
다른 변환들은 이미지를 시계 반대 방향으로 90도 회전시키거나@footnote{@code{Rotate90}은 정사각형 프레임에 대해서만 순수한 회전인데, 왜냐하면 이것은 이미지를 회전된 프레임에 맞추기 위해 늘리고 줄이기도 하기 때문이다.}

@example
fn rotate90(painter: Painter) -> Painter @{
    transform_painter(
        painter,
        Vec2 @{ x: 1.0, y: 0.0 @},
        Vec2 @{ x: 1.0, y: 1.0 @},
        Vec2 @{ x: 0.0, y: 0.0 @},
    )
@}
@end example

@noindent
또는 이미지를 프레임의 중심을 향해 찌그러뜨린다:@footnote{@ref{Figure 2.10}과 @ref{Figure 2.11}의 다이아몬드 모양 이미지는 @code{wave}와 @code{rogers}에 @code{squash_inwards}를 적용하여 생성되었다.}

@example
fn squash_inwards(painter: Painter) -> Painter @{
    transform_painter(
        painter,
        Vec2 @{ x: 0.0, y: 0.0 @},
        Vec2 @{ x: 0.65, y: 0.35 @},
        Vec2 @{ x: 0.35, y: 0.65 @},
    )
@}
@end example

@noindent
프레임 변환은 또한 두 개 이상의 페인터를 결합하는 수단을 정의하는 열쇠이다.
예를 들어, @code{beside} 프로시저는 두 페인터를 받아 각각을 인자 프레임의 왼쪽과 오른쪽 절반에 그리도록 변환하고, 새로운 복합 페인터를 생성한다.
복합 페인터가 프레임을 받으면, 첫 번째 변환된 페인터를 호출하여 프레임의 왼쪽 절반에 그리게 하고 두 번째 변환된 페인터를 호출하여 프레임의 오른쪽 절반에 그리게 한다:

@example
fn beside(painter1: Painter, painter2: Painter) -> Painter @{
    let split = Vec2 @{ x: 0.5, y: 0.0 @};
    let paint_left = transform_painter(
        painter1,
        Vec2 @{ x: 0.0, y: 0.0 @},
        split,
        Vec2 @{ x: 0.0, y: 1.0 @},
    );
    let paint_right = transform_painter(
        painter2,
        split,
        Vec2 @{ x: 1.0, y: 0.0 @},
        Vec2 @{ x: 0.5, y: 1.0 @},
    );
    Box::new(move |frame: &Frame| @{
        paint_left(frame);
        paint_right(frame);
    @})
@}
@end example

@noindent
페인터 데이터 추상화, 특히 페인터를 프로시저로 표현하는 것이 @code{beside}를 얼마나 구현하기 쉽게 만드는지 관찰하라.
@code{beside} 프로시저는 구성 요소 페인터들이 지정된 프레임에 무언가를 그린다는 것 외에는 그 세부 사항에 대해 아무것도 알 필요가 없다.

@quotation
@strong{@anchor{Exercise 2.50}연습문제 2.50:} 페인터를 수평으로 뒤집는 변환 @code{flip_horiz}, 그리고 페인터를 시계 반대 방향으로 180도와 270도 회전시키는 변환을 정의하라.
@end quotation

@quotation
@strong{@anchor{Exercise 2.51}연습문제 2.51:} 페인터에 대한 @code{below} 연산을 정의하라. @code{Below}는 두 페인터를 인자로 받는다.
결과 페인터는 프레임이 주어지면 첫 번째 페인터로 프레임의 아래쪽에 그리고 두 번째 페인터로 위쪽에 그린다.
@code{below}를 두 가지 다른 방법으로 정의하라---첫 번째는 위에서 주어진 @code{beside} 프로시저와 유사한 프로시저를 작성함으로써, 그리고 다시 @code{beside}와 적절한 회전 연산(@ref{Exercise 2.50}에서 가져온)의 관점에서.
@end quotation

@subsubheading 견고한 설계를 위한 언어의 레벨 (Levels of language for robust design)

그림 언어는 프로시저와 데이터를 사용한 추상화에 대해 우리가 소개한 몇 가지 중요한 아이디어를 연습한다.
기본 데이터 추상화인 페인터는 절차적 표현을 사용하여 구현되며, 이는 언어가 다양한 기본 그리기 기능을 균일한 방식으로 처리할 수 있게 해준다.
조합 수단은 클로저 속성을 만족하며, 이는 우리가 복잡한 디자인을 쉽게 구축할 수 있게 해준다.
마지막으로, 프로시저를 추상화하기 위한 모든 도구를 페인터에 대한 조합 수단을 추상화하는 데 사용할 수 있다.

우리는 또한 언어와 프로그램 설계에 대한 또 다른 중요한 아이디어를 엿보았다.
이것은 @newterm{계층화된 설계(stratified design)}라는 접근 방식으로, 복잡한 시스템이 일련의 언어를 사용하여 기술된 레벨의 시퀀스로 구조화되어야 한다는 개념이다.
각 레벨은 그 레벨에서 원시적으로 간주되는 부분들을 결합하여 구축되며, 각 레벨에서 구축된 부분들은 다음 레벨에서 원시 요소로 사용된다.
계층화된 설계의 각 레벨에서 사용되는 언어는 그 세부 수준에 적합한 원시 요소, 조합 수단, 그리고 추상화 수단을 갖는다.

계층화된 설계는 복잡한 시스템의 공학에 널리 퍼져 있다.
예를 들어, 컴퓨터 공학에서 저항과 트랜지스터는 결합되어(아날로그 회로 언어를 사용하여 기술됨) AND 게이트나 OR 게이트 같은 부품을 생성하며, 이들은 디지털 회로 설계를 위한 언어의 원시 요소를 형성한다.@footnote{@ref{3.3.4} 절은 그러한 언어 하나를 설명한다.} 이 부품들은 프로세서, 버스 구조, 메모리 시스템을 구축하기 위해 결합되고, 이것들은 다시 컴퓨터 아키텍처에 적합한 언어를 사용하여 컴퓨터를 형성하기 위해 결합된다. 컴퓨터들은 네트워크 상호 연결을 기술하기에 적합한 언어를 사용하여 분산 시스템을 형성하기 위해 결합되며, 이런 식으로 계속된다.

계층화의 작은 예로, 우리의 그림 언어는 점과 선을 지정하는 언어를 사용하여 생성된 원시 요소(원시 페인터)를 사용하여 @code{segments_to_painter}를 위한 선분 리스트를 제공하거나, @code{rogers}와 같은 페인터를 위한 음영 세부 사항을 제공한다.
그림 언어에 대한 우리 설명의 대부분은 @code{beside}와 @code{below} 같은 기하학적 결합기를 사용하여 이러한 원시 요소들을 결합하는 데 초점을 맞추었다.
우리는 또한 더 높은 수준에서 작업하여, @code{beside}와 @code{below}를 기하학적 결합기를 결합하는 공통 패턴을 포착하는 @code{square_of_four}와 같은 연산을 가진 언어에서 조작될 원시 요소로 간주했다.

계층화된 설계는 프로그램을 @newterm{견고하게(robust)} 만드는 데 도움을 준다. 즉, 명세의 작은 변경이 프로그램의 상응하는 작은 변경만을 필요로 할 가능성을 높인다.
예를 들어, 우리가 @ref{Figure 2.9}에 표시된 @code{wave}에 기초한 이미지를 변경하고 싶다고 가정해 보자.
우리는 @code{wave} 요소의 상세한 모양을 변경하기 위해 가장 낮은 레벨에서 작업할 수 있다; 우리는 @code{corner_split}이 @code{wave}를 복제하는 방식을 변경하기 위해 중간 레벨에서 작업할 수 있다; 우리는 @code{square_limit}이 코너의 네 사본을 배열하는 방식을 변경하기 위해 가장 높은 레벨에서 작업할 수 있다.
일반적으로, 계층화된 설계의 각 레벨은 시스템의 특성을 표현하기 위한 서로 다른 어휘와 그것을 변경하기 위한 서로 다른 종류의 능력을 제공한다.

@quotation
@strong{@anchor{Exercise 2.52}연습문제 2.52:} 위에서 설명한 각 레벨에서 작업하여 @ref{Figure 2.9}에 표시된 @code{wave}의 @code{square_limit}을 변경하라. 구체적으로:

@enumerate a

@item
@ref{Exercise 2.49}의 원시 @code{wave} 페인터에 몇 개의 선분을 추가하라(예를 들어, 미소를 추가하기 위해).

@item
@code{corner_split}에 의해 구성된 패턴을 변경하라(예를 들어, @code{up_split}과 @code{right_split} 이미지의 두 사본 대신 하나만 사용하여).

@item
@code{square_of_four}를 사용하는 @code{square_limit} 버전을 수정하여 코너들을 다른 패턴으로 조립하도록 하라. (예를 들어, 큰 미스터 로저스가 사각형의 각 코너에서 바깥쪽을 보게 만들 수 있다.)

@end enumerate
@end quotation
@node	2.2.5, 2.3, 2.2.4, 2.2
@subsection 대수적 데이터 타입 (Algebraic Data Types)

@cindex algebraic data types
@cindex enums
@cindex sum types
@cindex product types
@cindex pattern matching

데이터 추상화의 여정에서, 우리는 점점 더 정교한 데이터 구조를 구축하기 위해 쌍, 리스트, 그리고 트리를 사용하는 방법을 보았다.
@ref{2.1}에서 우리는 데이터의 표현과 사용 사이의 근본적인 추상화 장벽을 소개했다.
이 절에서 우리는 데이터 추상화를 위한 Rust의 가장 강력한 도구를 검토한다: 다양한 형태를 취할 수 있는 데이터를 표현하기 위한 엄격한 수학적 기초를 제공하는 @newterm{대수적 데이터 타입(algebraic data types)}이다.

``대수적''이라는 용어는 우리가 타입에 대해 수행할 수 있는 대수적 연산에서 유래했다.
대수가 덧셈과 곱셈을 통해 숫자를 결합하는 것처럼, 우리는 두 가지 기본 연산을 통해 타입을 결합할 수 있다: @newterm{곱 타입(product types)}(여러 값을 결합)과 @newterm{합 타입(sum types)}(대안 중에서 선택).
Rust의 @code{struct}와 튜플 타입은 곱을 구현하고, @code{enum} 타입은 합을 구현한다.

@subsubheading 곱 타입: 데이터 결합 (Product Types: Combining Data)

우리는 이미 작업에서 곱 타입을 접했다. @code{struct}나 튜플은 여러 값을 단일 복합 값으로 결합한다:

@example
// Product type: Rational contains BOTH a numerator AND a denominator
struct Rational @{
    numer: i64,
    denom: i64,
@}

// Tuple product: contains ALL three elements simultaneously
type Point3D = (f64, f64, f64);
@end example

@noindent
곱 타입의 가능한 값의 수는 각 구성 요소의 값의 수의 @emph{곱(product)}이다.
만약 @code{bool}이 2개의 값을 갖고 @code{u8}이 256개의 값을 갖는다면, @code{(bool, u8)}은 @math{{2 \times 256 = 512}}개의 가능한 값을 갖는다.
이 곱셈 속성이 우리가 그것들을 곱 타입이라고 부르는 이유이다.

@subsubheading 합 타입: 대안 선택 (Sum Types: Choosing Alternatives)

@cindex discriminated union

대조적으로, @newterm{합 타입(sum type)}은 여러 다른 형태 중 하나를 취할 수 있는 데이터를 나타낸다.
Rust의 @code{enum} 구조는 @newterm{구별된 유니언(discriminated unions)}---어떤 변형을 포함하는지 나타내는 태그를 지닌 값---을 통해 이 기능을 제공한다:

@example
enum Shape @{
    Circle(f64),              // radius
    Rectangle(f64, f64),      // width, height
    Triangle(f64, f64, f64),  // three sides
@}
@end example

@noindent
@code{Shape} 값은 @code{Circle} @emph{이거나} @code{Rectangle} @emph{이거나} @code{Triangle}이다---동시에 두 가지 이상일 수는 없다.
가능한 값의 총 수는 각 변형의 값들의 @emph{합(sum)}이므로, ``합 타입''이다.

이것은 객체 지향의 서브타이핑과는 근본적으로 다르다.
전통적인 OOP에서는 여러 구현을 가진 @code{Shape} 인터페이스를 정의할 수 있다.
하지만 그 구현들은 개방되어 있어서---누구든지 새로운 도형을 추가할 수 있다.
합 타입을 사용하면, 변형의 집합은 컴파일 타임에 @emph{닫혀 있고(closed)} @emph{완전하게 알려져 있다(exhaustively known)}.
이 겉보기에 제한적인 속성은 사실 컴파일러가 우리 코드의 정확성을 검증할 수 있게 해주는 강력한 보장이다.

@subsubheading 열거형 변형: 세 가지 맛 (Enum Variants: Three Flavors)

Rust는 서로 다른 데이터 표현 요구에 적합한 세 가지 종류의 열거형 변형을 제공한다:

@example
enum Message @{
    // Unit variant: no associated data (like a constant)
    Quit,

    // Tuple variant: unnamed fields (like a tuple struct)
    Move @{ x: i32, y: i32 @},

    // Struct variant: named fields (like a regular struct)
    Write(String),

    // Can mix variant types in one enum
    ChangeColor(u8, u8, u8),
@}
@end example

@noindent
@code{Quit}과 같은 유닛 변형은 데이터를 운반하지 않으며---단순히 상태나 신호를 나타낸다.
@code{ChangeColor}와 같은 튜플 변형은 필드 이름을 지정하지 않고 관련 데이터를 묶는다.
@code{Move}와 같은 구조체 변형은 위치만으로는 의미가 명확하지 않을 때 명확성을 위해 명명된 필드를 제공한다.

각 변형은 열거형의 네임스페이스를 통해 접근된다:

@example
let m1 = Message::Quit;
let m2 = Message::Move @{ x: 10, y: 20 @};
let m3 = Message::Write(String::from("hello"));
let m4 = Message::ChangeColor(255, 0, 0);
@end example

@subsubheading 패턴 매칭: 합 타입 구조 분해 (Pattern Matching: Destructuring Sum Types)

@cindex exhaustive matching
@cindex match expression

합 타입의 힘은 @newterm{패턴 매칭(pattern matching)}과 결합될 때 드러난다.
@code{match} 표현식을 사용하면 각 변형을 처리하고 그 데이터를 단일의 타입 안전한 연산으로 추출할 수 있다:

@example
fn describe_shape(shape: &Shape) -> String @{
    match shape @{
        Shape::Circle(r) =>
            format!("Circle with radius @{@}", r),
        Shape::Rectangle(w, h) =>
            format!("Rectangle @{@} x @{@}", w, h),
        Shape::Triangle(a, b, c) =>
            format!("Triangle with sides @{@}, @{@}, @{@}", a, b, c),
    @}
@}
@end example

@noindent
@code{match} 표현식은 몇 가지 중요한 속성을 갖는다:

@enumerate
@item
@strong{완전성(Exhaustiveness):} 컴파일러는 모든 가능한 변형이 처리되었는지 확인한다. 케이스를 하나라도 잊어버리면 코드는 컴파일되지 않는다. 이것은 버그의 전체 클래스를 제거한다.

@item
@strong{패턴 바인딩(Pattern binding):} 각 갈래(arm)는 변수를 변형의 데이터(@code{r}, @code{w}, @code{h} 등)에 바인딩하여 갈래의 표현식에서 사용할 수 있게 한다.

@item
@strong{표현식 기반(Expression-based):} @code{match}는 단순한 문(statement)이 아니라 값을 생성하는 표현식이다. 모든 갈래는 같은 타입을 반환해야 한다.

@item
@strong{폴스루 없음(No fallthrough):} C의 @code{switch}와 달리, 일치하는 갈래만 실행된다. @code{break} 문은 필요 없다.
@end enumerate

완전성 검사는 특히 심오하다. 이것은 데이터 정의와 그것을 사용하는 모든 코드 사이에 계약을 생성한다: 새로운 변형을 추가하면, 컴파일러는 @emph{모든} 매치 표현식을 업데이트하도록 강제한다.
이 ``조수로서의 컴파일러'' 속성은 리팩토링을 안전하고 기계적으로 만든다.

@subsubheading Option과 Result: 표준 라이브러리의 합 타입 (Option and Result: Sum Types in the Standard Library)

@cindex Option type
@cindex Result type
@cindex null safety

Rust에서 가장 널리 퍼진 합 타입은 @code{Option<T>}와 @code{Result<T, E>}로, 선택적 값과 오류 처리의 기본 패턴을 인코딩한다:

@example
enum Option<T> @{
    None,
    Some(T),
@}

enum Result<T, E> @{
    Ok(T),
    Err(E),
@}
@end example

@noindent
@code{Option<T>}는 없을 수도 있는 값을 나타낸다. 이것은 C나 Java 같은 언어의 널(null) 포인터를 대체한다.
임의의 참조가 널이 될 수 있도록 허용(하고 어디서나 런타임 검사를 요구)하는 대신, Rust는 타입 시스템에서 선택성을 명시적으로 만든다:

@example
fn find_first_even(numbers: &[i32]) -> Option<i32> @{
    numbers.iter()
        .find(|&&n| n % 2 == 0)
        .copied()
@}

fn main() @{
    let nums = vec![1, 3, 4, 5];

    match find_first_even(&nums) @{
        Some(n) => println!("Found: @{@}", n),
        None => println!("No even number found"),
    @}
@}
@end example

@noindent
타입 @code{Option<i32>}는 ``이 함수는 값을 찾지 못할 수도 있다''는 것을 명확히 나타낸다. 호출자는 두 경우를 모두 처리하도록 강제된다.
실수로 @code{None} 값을 숫자처럼 사용할 수 없다---타입 시스템이 이를 방지한다.

마찬가지로, @code{Result<T, E>}는 오류 처리를 명시적으로 만든다:

@example
use std::fs::File;
use std::io::@{self, Read@};

fn read_username_from_file(path: &str) -> Result<String, io::Error> @{
    let mut file = File::open(path)?;  // ? propagates errors
    let mut username = String::new();
    file.read_to_string(&mut username)?;
    Ok(username)
@}
@end example

@noindent
반환 타입 @code{Result<String, io::Error>}는 이 함수가 I/O 오류로 실패할 수 있음을 문서화한다.
@code{?} 연산자는 오류 전파를 위한 문법적 설탕을 제공한다: 연산이 실패하면 오류와 함께 일찍 반환하고, 그렇지 않으면 성공 값을 푼다(unwrap).

@subsubheading 재귀적 열거형: 리스트와 트리 (Recursive Enums: Lists and Trees)

@cindex recursive types
@cindex Box type

합 타입의 가장 강력한 응용 중 하나는 재귀적 데이터 구조를 정의하는 것이다. 그러나 순진한 시도는 실패한다:

@example
// ERROR: infinite size!
enum List @{
    Nil,
    Cons(i32, List),  // List contains itself directly
@}
@end example

@noindent
컴파일러는 이것을 거부하는데, 왜냐하면 @code{List}의 크기를 결정할 수 없기 때문이다.
@code{Cons}는 @code{List}를 포함하고, 그것은 다시 @code{List}를 포함하는 @code{Cons}일 수 있으며, 이런 식으로 크기가 무한하다.

해결책은 @newterm{간접 참조(indirection)}이다: 재귀적 부분을 포인터 뒤에 저장한다. @code{Box<T>}는 고정 크기 포인터와 함께 힙 할당을 제공한다:

@example
enum List @{
    Nil,
    Cons(i32, Box<List>),
@}

impl List @{
    fn new() -> Self @{
        List::Nil
    @}

    fn cons(head: i32, tail: List) -> Self @{
        List::Cons(head, Box::new(tail))
    @}

    fn length(&self) -> usize @{
        match self @{
            List::Nil => 0,
            List::Cons(_, tail) => 1 + tail.length(),
        @}
    @}
@}

// Usage
let list = List::cons(1, List::cons(2, List::cons(3, List::new())));
assert_eq!(list.length(), 3);
@end example

@noindent
이제 @code{Cons}는 @code{i32}(4바이트)와 @code{Box<List>}(64비트 시스템에서 8바이트)를 포함하여, (패딩 포함) 16바이트의 고정된 크기를 갖는다.
@code{Box}는 힙에 있는 다음 @code{List} 노드를 소유한다.

이진 트리도 같은 패턴을 따른다:

@example
enum BinaryTree<T> @{
    Empty,
    Node @{
        value: T,
        left: Box<BinaryTree<T>>,
        right: Box<BinaryTree<T>>,
    @},
@}

impl<T> BinaryTree<T> @{
    fn leaf(value: T) -> Self @{
        BinaryTree::Node @{
            value,
            left: Box::new(BinaryTree::Empty),
            right: Box::new(BinaryTree::Empty),
        @}
    @}

    fn node(value: T, left: BinaryTree<T>, right: BinaryTree<T>) -> Self @{
        BinaryTree::Node @{
            value,
            left: Box::new(left),
            right: Box::new(right),
        @}
    @}
@}

// Usage: representing ((1 + 2) * 3)
let expr = BinaryTree::node(
    '*',
    BinaryTree::node(
        '+',
        BinaryTree::leaf('1'),
        BinaryTree::leaf('2'),
    ),
    BinaryTree::leaf('3'),
);
@end example

@subsubheading 열거형 대 트레이트: 언제 무엇을 사용할까 (Enums vs. Traits: When to Use Each)

@cindex trait objects
@cindex dynamic dispatch

학생들은 종종 묻는다: 언제 열거형을 사용하고 언제 트레이트를 사용해야 합니까? 둘 다 ``다른 종류의 것들''을 표현할 수 있지만, 서로 다른 트레이드오프를 구현한다:

@strong{열거형을 사용할 때:}

@itemize @bullet
@item
변형의 집합이 @emph{고정되어 있고 알려져 있다}. 완전성 검사를 원한다.

@item
@emph{서로 다른 크기}의 변형들을 효율적으로 저장해야 한다. 열거형의 크기는 가장 큰 변형의 크기에 판별자 태그를 더한 것이다.

@item
성능이 중요하다: 열거형은 간접 참조 없이 정적으로 디스패치된다.

@item
확장을 @emph{방지}하고 싶다. 열거형은 새로운 변형에 대해 닫혀 있다.
@end itemize

@strong{트레이트를 사용할 때:}

@itemize @bullet
@item
타입의 집합이 @emph{개방되어 있다}. 누구든지 새로운 타입을 위해 트레이트를 구현할 수 있다.

@item
별도의 컴파일(separate compilation)을 원한다. 기존 코드를 다시 컴파일하지 않고 새로운 구현을 추가할 수 있다.

@item
@emph{동적 디스패치(dynamic dispatch)}가 필요하다(@code{dyn Trait}). 서로 다른 구체적인 타입들을 컬렉션에 저장한다.

@item
확장을 @emph{가능하게} 하고 싶다. 트레이트는 새로운 구현에 대해 열려 있다.
@end itemize

예를 들어, 계산기를 상상해 보라:

@example
// Enum: closed set of operations
enum Expr @{
    Number(f64),
    Add(Box<Expr>, Box<Expr>),
    Multiply(Box<Expr>, Box<Expr>),
@}

fn eval(expr: &Expr) -> f64 @{
    match expr @{
        Expr::Number(n) => *n,
        Expr::Add(l, r) => eval(l) + eval(r),
        Expr::Multiply(l, r) => eval(l) * eval(r),
    @}
@}
@end example

@noindent
이 열거형 기반 설계는 표현식에 대한 새로운 연산(예: @code{print}, @code{optimize}, @code{type_check})을 추가하기는 쉽지만, 새로운 표현식 타입을 추가하기는 어렵다.

트레이트 기반 설계와 대조해 보라:

@example
trait Expr @{
    fn eval(&self) -> f64;
@}

struct Number(f64);
struct Add(Box<dyn Expr>, Box<dyn Expr>);

impl Expr for Number @{
    fn eval(&self) -> f64 @{ self.0 @}
@}

impl Expr for Add @{
    fn eval(&self) -> f64 @{ self.0.eval() + self.1.eval() @}
@}
@end example

@noindent
트레이트 설계는 새로운 표현식 타입을 추가하기는 쉽지만(그저 @code{Expr}를 구현하면 된다), 새로운 연산을 추가하기는 어렵다(트레이트와 모든 구현을 수정해야 한다).

이것은 프로그래밍 언어 이론의 고전적인 @newterm{표현 문제(expression problem)}이다. 열거형은 ``연산'' 차원을 선호하고, 트레이트는 ``타입'' 차원을 선호한다. 어느 차원이 더 성장할 가능성이 높은지에 따라 선택하라.

@subsubheading 태그된 디스패치와의 연결 (Connection to Tagged Dispatch)

@ref{2.4}에서, 우리는 @newterm{데이터 주도 프로그래밍(data-directed programming)}과 태그된 디스패치(tagged dispatch)---타입 태그를 가진 데이터에 대해 작동하는 기술---를 공부할 것이다.
Rust의 열거형은 태그된 디스패치에 대한 내장된, 타입 안전한 지원으로 이해될 수 있다:

@example
// Manual tagged dispatch (what you might do in C)
struct TaggedValue @{
    tag: u8,
    data: [u8; 16],  // Union represented as raw bytes
@}

// Rust enum (compiler-verified tagged dispatch)
enum Value @{
    Integer(i64),    // tag = 0, implicitly
    Float(f64),      // tag = 1, implicitly
    Boolean(bool),   // tag = 2, implicitly
@}
@end example

@noindent
열거형은 수동 태깅과 동일한 기능---고정된 크기의 공간에 여러 타입 중 하나를 저장하는 것---을 제공하지만, 결정적인 장점을 갖는다:

@enumerate
@item
@strong{타입 안전성(Type safety):} 잘못된 변형에 접근할 수 없다. @code{match}는 활성화된 변형의 데이터만 사용하도록 보장한다.

@item
@strong{메모리 안전성(Memory safety):} 컴파일러는 데이터가 올바르게 초기화되었음을 보장하고 해제 후 사용(use-after-free)을 방지한다.

@item
@strong{완전성(Exhaustiveness):} 컴파일러는 모든 경우가 처리되었음을 검증하여, ``태그 3 처리를 잊어버린'' 종류의 버그를 방지한다.
@end enumerate

열거형은 수동 태그된 구조체의 보일러플레이트와 위험을 제거하면서도 동일한 효율성을 제공한다.
그것들은 @emph{제로 비용 추상화}이다---생성된 기계 코드는 수작업으로 작성된 태그된 구조체와 동일하지만, 컴파일 타임 검증이 추가된다.

@subsubheading 타입의 대수 (The Algebra of Types)

@cindex type algebra

마무리로, 수학적 관점으로 돌아가 보자. 타입은 대수를 형성한다:

@itemize @bullet
@item
@strong{유닛 타입 @code{()}}: 1개의 값 (곱셈의 항등원)

@item
@strong{네버 타입 @code{!}}: 0개의 값 (발산, divergence를 나타냄)

@item
@strong{곱 @code{(A, B)}}: @math{{|A| \times |B|}}개의 값

@item
@strong{합 @code{enum @{ A, B @}}}: @math{{|A| + |B|}}개의 값

@item
@strong{함수 @code{fn(A) -> B}}: @math{{|B|^{|A|}}}개의 값 (지수!)
@end itemize

이러한 대수적 속성은 실용적인 의미를 갖는다. 예를 들어, 타입 @code{(A, !)}는 0개의 값을 가지며(왜냐하면 @math{{|A| \times 0 = 0}}이므로), 따라서 거주 불가능하다(uninhabitable).
마찬가지로, @code{(A, ())}는 @code{A}와 동형이다(왜냐하면 @math{{|A| \times 1 = |A|}}이므로).

더 심오하게, 우리는 데이터 구조 속성을 유도하기 위해 대수적 추론을 사용할 수 있다. 리스트의 타입:

@example
List<A> = Nil | Cons(A, List<A>)
@end example

@noindent
은 다음 대수 방정식으로 번역된다:

@ifinfo
@example
L = 1 + A × L
@end example
@end ifinfo
@tex
\[
  L = 1 + A \times L
\]
@end tex

@noindent
@math{L}에 대해 풀면:

@ifinfo
@example
L = 1 + A × L
L - A × L = 1
L(1 - A) = 1
L = 1 / (1 - A)
L = 1 + A + A² + A³ + ...
@end example
@end ifinfo
@tex
\begin{align*}
  L &= 1 + A \times L \\
  L - A \times L &= 1 \\
  L(1 - A) &= 1 \\
  L &= \frac{1}{1-A} \\
  L &= 1 + A + A^2 + A^3 + \cdots
\end{align*}
@end tex

@noindent
이것은 리스트가 비어 있거나(1), 하나의 요소이거나(@math{A}), 두 개의 요소이거나(@math{{A^2}}), 등등임을 말해준다---정확히 직관과 일치한다!

이 대수적 관점은 우리가 타입을 공식적으로 추론하고, 동형(isomorphisms)을 유도하고, 두 가지 다른 표현이 언제 근본적으로 동등한지 이해하는 데 도움을 준다. 이것은 수학과 프로그래밍 사이의 가장 깊은 연결 고리 중 하나이다.

@quotation
@strong{@anchor{Exercise 2.44a}연습문제 2.44a:} @code{Option<T>} 타입은 ``타입 @code{T}의 값, 또는 없음''을 인코딩하는 것으로 생각할 수 있다.
``타입 @code{L}의 값 또는 타입 @code{R}의 값''을 나타내는 열거형 @code{Either<L, R>}를 정의하라.

그런 다음 다음 함수들을 구현하라:

@example
fn map_left<L, R, L2>(either: Either<L, R>, f: impl Fn(L) -> L2)
    -> Either<L2, R>;

fn map_right<L, R, R2>(either: Either<L, R>, f: impl Fn(R) -> R2)
    -> Either<L, R2>;
@end example

@noindent
@code{map_left} 함수는 왼쪽 값이 있으면 @code{f}를 적용하고, 오른쪽 값은 변경하지 않고 둔다. @code{map_right} 함수는 대칭적이다.

@code{Either<bool, u8>}은 몇 개의 값을 갖는가? 이것은 @code{(bool, u8)}과 어떻게 비교되는가?
@end quotation

@quotation
@strong{@anchor{Exercise 2.45a}연습문제 2.45a:} 이 절의 @code{BinaryTree<T>} 타입을 다음 메서드들로 확장하라:

@example
impl<T> BinaryTree<T> @{
    fn height(&self) -> usize;
    fn count_leaves(&self) -> usize;
    fn map<U>(self, f: impl Fn(T) -> U) -> BinaryTree<U>;
@}
@end example

@noindent
@code{height} 메서드는 루트에서 잎까지의 최대 거리를 반환한다(빈 트리는 높이 0, 잎은 높이 1).
@code{count_leaves} 메서드는 자식이 없는 노드를 센다.
@code{map} 메서드는 함수 @code{f}를 사용하여 트리의 모든 값을 변환한다.

그런 다음 @code{fold} 연산을 구현하라:

@example
fn fold<T, A>(tree: &BinaryTree<T>,
              empty: A,
              node: impl Fn(&T, A, A) -> A) -> A;
@end example

@noindent
이것은 트리를 재귀적으로 처리해야 하며, @code{Empty} 노드에 대해 @code{empty}를 사용하고 @code{Node}에 대해 @code{node(value, left_result, right_result)}를 호출해야 한다.
@code{fold}를 사용하여 @code{height}, @code{count_leaves}, 그리고 합계 연산을 구현할 수 있음을 확인하라.
@end quotation

@quotation
@strong{@anchor{Exercise 2.46a}연습문제 2.46a:} 이 연습 문제에서 우리는 열거형과 표현 문제 사이의 관계를 탐구한다.

JSON 데이터를 나타내는 열거형 @code{JsonValue}를 정의하라:

@example
enum JsonValue @{
    Null,
    Boolean(bool),
    Number(f64),
    String(String),
    Array(Vec<JsonValue>),
    Object(std::collections::HashMap<String, JsonValue>),
@}
@end example

@noindent
다음 연산들을 구현하라:

@enumerate
@item
@code{fn pretty_print(value: &JsonValue) -> String} --- 들여쓰기를 사용하여 JSON을 서식 지정한다.

@item
@code{fn count_values(value: &JsonValue) -> usize} --- (중첩된 것을 포함하여) 총 값의 개수를 센다.

@item
@code{fn find_strings(value: &JsonValue) -> Vec<&str>} --- 모든 문자열 값을 추출한다.
@end enumerate

이제 열거형 대신 트레이트를 사용하는 대안적인 설계를 고려해 보라. @code{JsonValue} 트레이트가 어떻게 생겼을지 스케치하고 다음을 설명하라:

@itemize @bullet
@item
어떤 접근 방식(열거형 또는 트레이트)이 @code{to_yaml}과 같은 새로운 연산을 추가하기 더 쉬운가?

@item
어떤 접근 방식이 @code{Date}와 같은 새로운 JSON 타입을 추가하기 더 쉬운가?

@item
만약 두 확장성 차원이 모두 필요하다면, 열거형과 트레이트를 어떻게 결합할 수 있겠는가?
@end itemize
@end quotation

@node	2.3, 2.4, 2.2.5, Chapter 2
@section 기호 데이터 (Symbolic Data)

지금까지 우리가 사용한 모든 복합 데이터 객체는 궁극적으로 숫자로 구성되었다.
이 절에서 우리는 임의의 기호를 데이터로 사용하여 작업할 수 있는 능력을 도입함으로써 우리 언어의 표현 능력을 확장한다.

@menu
* 2.3.1::            Quotation
* 2.3.2::            Example: Symbolic Differentiation
* 2.3.3::            Example: Representing Sets
* 2.3.4::            Example: Huffman Encoding Trees
* 2.3.4a::           The Newtype Pattern: Zero-Cost Type Safety
@end menu

@node	2.3.1, 2.3.2, 2.3, 2.3
@subsection 인용 (Quotation)

만약 우리가 기호를 사용하여 복합 데이터를 형성할 수 있다면, 다음과 같은 리스트를 가질 수 있다

@example
// In Rust, we use arrays/vectors and enums for symbolic data:
vec!["a", "b", "c", "d"]
vec![23, 45, 17]
vec![("Norah", 12), ("Molly", 9), ("Anna", 7), ("Lauren", 6), ("Charlotte", 4)]
@end example

@noindent
기호를 포함하는 리스트는 우리 언어의 표현식과 똑같이 생길 수 있다:

@example
// Expressions as data - in Rust, we define an AST enum:
// Mul(Add(23, 45), Add(Var("x"), 9))
fn fact(n: u64) -> u64 @{
    if n == 1 @{ 1 @} else @{ n * fact(n - 1) @}
@}
@end example

@noindent
기호를 조작하기 위해 우리는 우리 언어에 새로운 요소가 필요하다: 데이터 객체를 @newterm{인용(quote)}하는 능력이다.
우리가 리스트 @code{(a b)}를 구성하고 싶다고 가정해 보자.
우리는 이것을 @code{(list a b)}로 달성할 수 없다. 왜냐하면 이 표현식은 기호 자체가 아니라 @code{a}와 @code{b}의 @newterm{값(values)}의 리스트를 구성하기 때문이다.
이 문제는 자연어의 맥락에서 잘 알려져 있는데, 단어와 문장은 의미론적 실체(semantic entities)로 간주되거나 문자열(syntactic entities)로 간주될 수 있다.
자연어의 일반적인 관행은 단어나 문장이 문자들의 문자열로서 문자 그대로 취급되어야 함을 나타내기 위해 따옴표를 사용하는 것이다.
예를 들어, ``John''의 첫 글자는 분명히 ``J''이다.
만약 우리가 누군가에게 ``say your name aloud''라고 말한다면, 우리는 그 사람의 이름을 듣기를 기대한다.
하지만 만약 우리가 누군가에게 ``say `your name' aloud''라고 말한다면, 우리는 ``your name''이라는 단어들을 듣기를 기대한다.
우리가 다른 누군가가 말할지도 모르는 것을 기술하기 위해 따옴표를 중첩해야 한다는 점에 주목하라.@footnote{언어에 인용을 허용하는 것은 언어를 간단한 용어로 추론하는 능력을 엉망으로 만드는데, 왜냐하면 그것이 ``같은 것은 같은 것으로 대체될 수 있다''는 개념을 파괴하기 때문이다. 예를 들어, 3은 1 더하기 2이지만, ``3''이라는 단어는 ``1 더하기 2''라는 구가 아니다. 인용은 강력하다. 왜냐하면 그것이 다른 표현식을 조작하는 표현식을 구축할 수 있는 방법을 제공하기 때문이다(@ref{Chapter 4}에서 인터프리터를 작성할 때 보게 될 것이다). 하지만 언어가 그 언어의 다른 문장에 대해 이야기하는 문장을 허용하면, ``같은 것은 같은 것으로 대체될 수 있다''는 것이 무엇을 의미해야 하는지에 대한 일관된 원칙을 유지하기가 매우 어려워진다. 예를 들어, 만약 우리가 저녁별(개밥바라기별)이 샛별이라는 것을 안다면, ``저녁별은 금성이다''라는 진술로부터 ``샛별은 금성이다''를 추론할 수 있다. 그러나 ``John은 저녁별이 금성이라는 것을 안다''가 주어졌을 때 우리는 ``John은 샛별이 금성이라는 것을 안다''를 추론할 수 없다.}

우리는 리스트와 기호가 평가될 표현식이 아니라 데이터 객체로 취급되어야 함을 식별하기 위해 이와 같은 관행을 따를 수 있다.
그러나 우리의 인용 형식은 따옴표(전통적으로, 작은따옴표 기호 @code{'})를 인용할 객체의 시작 부분에만 둔다는 점에서 자연어의 것과 다르다.
우리는 Scheme 문법에서 빈칸과 괄호에 의존하여 객체를 구분하기 때문에 이것으로 충분하다.
따라서 작은따옴표 문자의 의미는 다음 객체를 인용하는 것이다.@footnote{작은따옴표(single quote)는 우리가 출력될 문자열을 감싸기 위해 사용해 온 큰따옴표(double quote)와는 다르다. 작은따옴표는 리스트나 기호를 나타내는 데 사용될 수 있는 반면, 큰따옴표는 문자열에만 사용된다. 이 책에서 문자열의 유일한 용도는 출력될 항목으로서이다.}

이제 우리는 기호와 그 값을 구별할 수 있다:

@example
let a = 1;
let b = 2;

vec![a, b]
// => [1, 2]

// For symbolic data, we use string literals or an enum:
vec!["a", "b"]
// => ["a", "b"]

// Mixing symbols and values requires an enum:
enum Item @{ Sym(&'static str), Num(i32) @}
vec![Item::Sym("a"), Item::Num(b)]
// => [Sym("a"), Num(2)]
@end example

@noindent
인용은 또한 우리가 리스트에 대한 관습적인 인쇄된 표현을 사용하여 복합 객체를 입력할 수 있게 해준다:@footnote{엄밀히 말하면, 우리의 따옴표 사용은 우리 언어의 모든 복합 표현식이 괄호로 구분되어야 하고 리스트처럼 보여야 한다는 일반 규칙을 위반한다. 우리는 따옴표와 같은 목적을 수행하는 특수 형태 @code{quote}를 도입함으로써 이 일관성을 회복할 수 있다. 따라서 우리는 @code{'a} 대신 @code{(quote a)}를 입력하고, @code{'(a b c)} 대신 @code{(quote (a b c))}를 입력할 것이다. 이것이 정확히 인터프리터가 작동하는 방식이다. 따옴표는 다음의 완전한 표현식을 @code{quote}로 감싸서 @code{(quote ⟨@var{expression}⟩)}를 형성하는 단일 문자 약어일 뿐이다. 이것은 인터프리터가 보는 모든 표현식이 데이터 객체로서 조작될 수 있다는 원칙을 유지하기 때문에 중요하다. 예를 들어, 우리는 @code{(list 'car (list 'quote '(a b c)))}를 평가함으로써 표현식 @code{(car '(a b c))}---이것은 @code{(car (quote (a b c)))}와 같다---를 구성할 수 있다.}

@example
let list = vec!["a", "b", "c"];
list[0]
// => "a"

&list[1..]
// => ["b", "c"]
@end example

@noindent
이것과 일관되게, 우리는 @code{'()}를 평가함으로써 빈 리스트를 얻을 수 있으며, 따라서 변수 @code{nil}을 없앨 수 있다.

기호를 조작하는 데 사용되는 또 하나의 원시 요소는 @code{eq?}인데, 이는 두 기호를 인자로 받아 그것들이 같은지 테스트한다.@footnote{우리는 두 기호가 같은 순서로 같은 문자로 구성되어 있다면 ``같다''고 간주할 수 있다. 그러한 정의는 우리가 아직 다룰 준비가 되지 않은 깊은 문제, 즉 프로그래밍 언어에서 ``동일성(sameness)''의 의미를 회피한다. 우리는 @ref{Chapter 3} (@ref{3.1.3})에서 이 문제로 돌아올 것이다.}
@code{eq?}를 사용하여, 우리는 @code{memq}라고 불리는 유용한 프로시저를 구현할 수 있다.
이것은 두 인자, 기호와 리스트를 받는다.
만약 기호가 리스트에 포함되어 있지 않다면(즉, 리스트의 어떤 항목과도 @code{eq?}하지 않다면), @code{memq}는 거짓을 반환한다.
그렇지 않다면, 기호의 첫 번째 출현으로 시작하는 리스트의 서브리스트를 반환한다:

@example
fn memq<'a, T: PartialEq>(item: &T, x: &'a [T]) -> Option<&'a [T]> @{
    match x @{
        [] => None,
        [first, rest @ ..] if first == item => Some(x),
        [_, rest @ ..] => memq(item, rest),
    @}
@}
@end example

@noindent
예를 들어, 다음의 값은

@example
memq(&"apple", &["pear", "banana", "prune"])
// => None
@end example

@noindent
거짓인 반면, 다음의 값은

@example
// Note: nested lists require enum; flat example:
memq(&"apple", &["x", "y", "apple", "pear"])
// => Some(["apple", "pear"])
@end example

@noindent
@code{(apple pear)}이다.

@quotation
@strong{@anchor{Exercise 2.53}연습문제 2.53:} 다음 각 표현식을 평가하면 인터프리터는 무엇을 출력하겠는가?

@example
vec!["a", "b", "c"]                          // => ["a", "b", "c"]
vec![vec!["george"]]                         // => [["george"]]
&[["x1", "x2"], ["y1", "y2"]][1..]           // => [["y1", "y2"]]
[["x1", "x2"], ["y1", "y2"]][1]              // => ["y1", "y2"]
["a", "short", "list"][0].is_empty() == false // "a" is a string, not list
memq(&"red", &["red", "shoes", "blue"])      // => Some(["red", ...])
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 2.54}연습문제 2.54:} 두 리스트가 같은 순서로 배열된 같은 요소들을 포함한다면 @code{equal?}하다고 말한다.
예를 들어,

@example
vec!["this", "is", "a", "list"] == vec!["this", "is", "a", "list"]
// => true (Rust's == derives PartialEq)
@end example

@noindent
은 참이지만,

@example
// Different structure requires an enum for nested data
// vec!["this", "is", "a", "list"] != vec!["this", nested, "list"]
// => false
@end example

@noindent
은 거짓이다.
더 정확하게, 우리는 @code{equal?}을 기본적인 기호 동등성 @code{eq?}의 관점에서 재귀적으로 정의할 수 있다: 만약 @code{a}와 @code{b}가 둘 다 기호이고 그 기호들이 @code{eq?}하다면, 또는 만약 @code{a}와 @code{b}가 둘 다 리스트이면서 @code{(car a)}가 @code{(car b)}와 @code{equal?}하고 @code{(cdr a)}가 @code{(cdr b)}와 @code{equal?}하다면 @code{a}와 @code{b}는 @code{equal?}하다.
이 아이디어를 사용하여 @code{equal?}을 프로시저로 구현하라.@footnote{실제로는 프로그래머들이 기호뿐만 아니라 숫자를 포함하는 리스트를 비교하기 위해 @code{equal?}을 사용한다. 숫자는 기호로 간주되지 않는다. 수치적으로 같은 두 숫자(@code{=}로 테스트됨)가 @code{eq?}하기도 한지는 구현에 따라 크게 다르다. @code{equal?}의 더 나은 정의(Scheme에 원시 요소로 제공되는 것과 같은)는 만약 @code{a}와 @code{b}가 둘 다 숫자라면, 그것들이 수치적으로 같을 때 @code{equal?}하다고 규정할 것이다.}
@end quotation

@quotation
@strong{@anchor{Exercise 2.55}연습문제 2.55:} Eva Lu Ator는 인터프리터에게 다음 표현식을 입력한다

@example
// In Scheme, ''x expands to (quote (quote x))
// (car ''abracadabra) => 'quote
// In Rust, we would model this with an AST enum:
// Quote(Quote(Symbol("abracadabra")))
// first element is: Quote
@end example

그녀가 놀랍게도, 인터프리터는 @code{quote}를 다시 출력한다. 설명하라.
@end quotation

@node	2.3.2, 2.3.3, 2.3.1, 2.3
@subsection 예제: 기호 미분 (Example: Symbolic Differentiation)

기호 조작의 예시이자 데이터 추상화의 추가적인 예시로서, 대수 표현식의 기호 미분을 수행하는 프로시저의 설계를 고려해 보자.
우리는 대수 표현식과 변수를 인자로 받아 변수에 대한 표현식의 도함수를 반환하는 프로시저를 원한다.
예를 들어, 프로시저에 대한 인자가 @math{{ax^2 + bx + c}}와 @math{x}라면, 프로시저는 @math{{2ax + b}}를 반환해야 한다.
기호 미분은 Lisp에서 특별한 역사적 중요성을 갖는다.
이것은 기호 조작을 위한 컴퓨터 언어 개발의 배경이 된 동기 부여 예제 중 하나였다.
게다가, 이것은 현재 점점 더 많은 수의 응용 수학자와 물리학자가 사용하고 있는 강력한 기호 수학 작업을 위한 시스템의 개발로 이어진 연구 라인의 시작을 표시했다.

기호 미분 프로그램을 개발할 때, 우리는 @ref{2.1.1}의 유리수 시스템을 개발할 때 따랐던 것과 같은 데이터 추상화 전략을 따를 것이다.
즉, 우리는 먼저 ``합'', ``곱'', 그리고 ``변수''와 같은 추상 객체에 대해 작동하는 미분 알고리즘을 정의할 것이며, 이것들이 어떻게 표현될지에 대해서는 걱정하지 않을 것이다.
나중에야 표현 문제를 다룰 것이다.

@subsubheading 추상 데이터를 이용한 미분 프로그램 (The differentiation program with abstract data)

단순함을 유지하기 위해, 우리는 덧셈과 곱셈 연산만 사용하여 두 개의 인자로 구성된 표현식을 다루는 매우 간단한 기호 미분 프로그램을 고려할 것이다.
그러한 표현식의 미분은 다음 축소 규칙을 적용하여 수행할 수 있다:
@ifinfo

@example
dc
-- = 0  for c a constant, or a variable different from x
dx

dx
-- = 1
dx

d(u + v)   du   dv
-------- = -- + --
   dx      dx   dx

d(uv)     / dv \     / du \
----- = u | -- | + v | -- |
 dx       \ dx /     \ dx /
@end example

@end ifinfo
@tex
\[ % :42:
{{dc \over dx} \,=\, 0,} 
  \quad {\text{for } c \text{ a constant }} {\text{or a variable }} {\text{different from } x,}
\]
@end tex
@tex
\[ % :43:
\begin{eqnarray}
{dx \over dx}         &=&   1, \\
{d(u + v) \over dx}   &=&   {du \over dx} + {dv \over dx}, \\
{d(uv) \over dx}      &=&   u \kern0.1em {dv \over dx} + v \kern0.1em {du \over dx}.
\end{eqnarray}
\]
@end tex
@noindent
마지막 두 규칙이 본질적으로 재귀적이라는 것을 관찰하라.
즉, 합의 도함수를 얻으려면 먼저 항들의 도함수를 찾아서 더한다.
각 항은 다시 분해되어야 할 표현식일 수 있다.
점점 더 작은 조각으로 분해하면 결국 상수나 변수인 조각들이 생성될 것이며, 그 도함수는 0이나 1이 될 것이다.

이 규칙들을 프로시저로 구현하기 위해 우리는 유리수 구현을 설계할 때 그랬던 것처럼 약간의 희망적 사고를 한다.
만약 우리에게 대수 표현식을 표현하는 수단이 있다면, 우리는 표현식이 합인지, 곱인지, 상수인지, 또는 변수인지 알 수 있어야 한다.
우리는 표현식의 부분들을 추출할 수 있어야 한다.
예를 들어 합의 경우, 우리는 피가산수(첫 번째 항)와 가산수(두 번째 항)를 추출할 수 있기를 원한다.
우리는 또한 부분들로부터 표현식을 구성할 수 있어야 한다.
우리가 다음 선택자, 생성자, 그리고 술어를 구현하는 프로시저를 이미 가지고 있다고 가정하자:

@example
is_variable(e)         @r{@code{e}는 변수인가?}
same_variable(v1, v2)  @r{@code{v1}과 @code{v2}는 같은 변수인가?}
is_sum(e)              @r{@code{e}는 합인가?}
addend(e)              @r{합 @code{e}의 피가산수.}
augend(e)              @r{합 @code{e}의 가산수.}
make_sum(a1, a2)       @r{@code{a1}과 @code{a2}의 합을 구성한다.}
is_product(e)          @r{@code{e}는 곱인가?}
multiplier(e)          @r{곱 @code{e}의 승수.}
multiplicand(e)        @r{곱 @code{e}의 피승수.}
make_product(m1, m2)   @r{@code{m1}과 @code{m2}의 곱을 구성한다.}
@end example

@noindent
이것들과 숫자를 식별하는 원시 술어 @code{number?}를 사용하여, 우리는 미분 규칙을 다음 프로시저로 표현할 수 있다:

@noindent
@example
enum Expr @{
    Const(f64),
    Var(&'static str),
    Sum(Box<Expr>, Box<Expr>),
    Product(Box<Expr>, Box<Expr>),
@}

use Expr::*;

fn deriv(exp: &Expr, var: &str) -> Expr @{
    match exp @{
        Const(_) => Const(0.0),
        Var(v) => if *v == var @{ Const(1.0) @} else @{ Const(0.0) @},
        Sum(a, b) => Sum(
            Box::new(deriv(a, var)),
            Box::new(deriv(b, var))
        ),
        Product(m1, m2) => Sum(
            Box::new(Product(
                m1.clone(),
                Box::new(deriv(m2, var))
            )),
            Box::new(Product(
                Box::new(deriv(m1, var)),
                m2.clone()
            ))
        ),
    @}
@}
@end example

@noindent
이 @code{deriv} 프로시저는 완전한 미분 알고리즘을 통합한다.
이것은 추상 데이터의 관점에서 표현되었으므로, 우리가 적절한 선택자와 생성자 집합을 설계하는 한 대수 표현식을 표현하기 위해 어떤 방법을 선택하든 작동할 것이다.
이것이 우리가 다음에 다루어야 할 문제이다.

@subsubheading 대수 표현식 표현 (Representing algebraic expressions)

우리는 대수 표현식을 표현하기 위해 리스트 구조를 사용하는 많은 방법을 상상할 수 있다.
예를 들어, @math{{ax + b}}를 리스트 @code{(a * x + b)}로 표현하여 일반적인 대수 표기법을 모방하는 기호 리스트를 사용할 수 있다.
그러나 특히 간단한 선택 중 하나는 Lisp가 조합에 사용하는 것과 같은 괄호로 묶인 접두사 표기법을 사용하는 것이다; 즉, @math{{ax + b}}를 @code{(+ (* a x) b)}로 표현하는 것이다.
그러면 미분 문제를 위한 우리의 데이터 표현은 다음과 같다:

@itemize @bullet

@item
변수는 @code{Expr} 열거형의 @code{Var} 변형으로 표현된다:

@example
fn is_variable(x: &Expr) -> bool @{
    matches!(x, Expr::Var(_))
@}
@end example

@item
두 변수는 그것들을 나타내는 기호가 같으면 같다:

@example
fn same_variable(v1: &Expr, v2: &Expr) -> bool @{
    match (v1, v2) @{
        (Expr::Var(a), Expr::Var(b)) => a == b,
        _ => false,
    @}
@}
@end example

@item
합과 곱은 박스형 하위 표현식을 가진 열거형 변형으로 구성된다:

@example
fn make_sum(a1: Expr, a2: Expr) -> Expr @{
    Expr::Sum(Box::new(a1), Box::new(a2))
@}

fn make_product(m1: Expr, m2: Expr) -> Expr @{
    Expr::Product(Box::new(m1), Box::new(m2))
@}
@end example

@item
Rust에서 @code{is_sum}과 같은 술어와 @code{addend}와 같은 선택자는 패턴 매칭으로 대체된다.
합은 @code{Sum} 변형에 의해 식별되며, 그 구성 요소는 매치 갈래에서 직접 추출된다:

@example
// 별도의 술어와 선택자 대신, 우리는 패턴 매칭을 사용한다:
match expr @{
    Expr::Sum(addend, augend) => @{
        // addend와 augend를 직접 사용할 수 있음
    @}
    Expr::Product(multiplier, multiplicand) => @{
        // multiplier와 multiplicand를 직접 사용할 수 있음
    @}
    // ...
@}
@end example

@end itemize

@noindent
따라서 우리는 이것들을 @code{deriv}에 구현된 알고리즘과 결합하기만 하면 작동하는 기호 미분 프로그램을 갖게 된다.
그 동작의 몇 가지 예를 살펴보자:

@example
deriv(&make_sum(var("x"), num(3.0)), "x")
// => Sum(Const(1.0), Const(0.0))

deriv(&make_product(var("x"), var("y")), "x")
// => Sum(Product(Var("x"), Const(0.0)),
//        Product(Const(1.0), Var("y")))

deriv(&make_product(
    make_product(var("x"), var("y")),
    make_sum(var("x"), num(3.0))
), "x")
// => Sum(Product(Product(x, y), Sum(1, 0)),
//        Product(Sum(Product(x, 0), Product(1, y)),
//                Sum(x, 3)))
@end example

@noindent
프로그램은 올바른 답을 생성한다; 그러나 그것들은 단순화되지 않았다.
@ifinfo

@example
d(xy)
----- = x * 0 + 1 * y
 dx
@end example

@end ifinfo
@tex
\[ % :44:
  {d(xy) \over dx} \,=\, {x \cdot 0} + {1 \cdot y,}  \]
@end tex
@noindent
라는 것은 사실이지만, 우리는 프로그램이 @math{{x \cdot 0 = 0}}, @math{{1 \cdot y = y}}, 그리고 @math{{0 + y = y}}라는 것을 알기를 원한다.
두 번째 예제에 대한 답은 단순히 @code{y}였어야 한다.
세 번째 예제가 보여주듯이, 표현식이 복잡할 때 이것은 심각한 문제가 된다.

우리의 어려움은 유리수 구현에서 마주쳤던 것과 매우 비슷하다: 우리는 답을 가장 간단한 형태로 축소하지 않았다.
유리수 축소를 달성하기 위해, 우리는 구현의 생성자와 선택자만 변경하면 되었다.
우리는 여기서도 유사한 전략을 채택할 수 있다.
우리는 @code{deriv}를 전혀 변경하지 않을 것이다.
대신, 우리는 @code{make_sum}을 변경하여 만약 두 피가산수가 모두 숫자라면 @code{make_sum}이 그것들을 더해서 합을 반환하도록 할 것이다.
또한 피가산수 중 하나가 0이면, @code{make_sum}은 다른 피가산수를 반환할 것이다:

@example
fn make_sum(a1: Expr, a2: Expr) -> Expr @{
    match (&a1, &a2) @{
        (Expr::Const(0.0), _) => a2,
        (_, Expr::Const(0.0)) => a1,
        (Expr::Const(n1), Expr::Const(n2)) => Expr::Const(n1 + n2),
        _ => Expr::Sum(Box::new(a1), Box::new(a2)),
    @}
@}
@end example

@noindent
Rust에서 패턴 매칭은 표현식이 특정 값을 가진 상수인지 직접 확인하므로 별도의 @code{is_number?} 술어가 필요 없다.

@noindent
마찬가지로, 우리는 @code{make_product}를 변경하여 0 곱하기 무엇이든 0이고 1 곱하기 무엇이든 그 자체라는 규칙을 내장할 것이다:

@example
fn make_product(m1: Expr, m2: Expr) -> Expr @{
    match (&m1, &m2) @{
        (Expr::Const(0.0), _) | (_, Expr::Const(0.0)) => Expr::Const(0.0),
        (Expr::Const(1.0), _) => m2,
        (_, Expr::Const(1.0)) => m1,
        (Expr::Const(n1), Expr::Const(n2)) => Expr::Const(n1 * n2),
        _ => Expr::Product(Box::new(m1), Box::new(m2)),
    @}
@}
@end example

@noindent
이 버전이 우리의 세 예제에서 어떻게 작동하는지 보자:

@example
deriv(&make_sum(var("x"), num(3.0)), "x")
// => Const(1.0)

deriv(&make_product(var("x"), var("y")), "x")
// => Var("y")

deriv(&make_product(
    make_product(var("x"), var("y")),
    make_sum(var("x"), num(3.0))
), "x")
// => Sum(Product(Var("x"), Var("y")),
//        Product(Var("y"), Sum(Var("x"), Const(3.0))))
@end example

@noindent
이것은 꽤 개선되었지만, 세 번째 예제는 우리가 ``가장 간단한'' 형태라고 동의할 수 있는 표현식에 도달하는 프로그램을 얻기까지 아직 갈 길이 멀다는 것을 보여준다.
대수적 단순화 문제는 복잡한데, 그 이유 중 하나는 어떤 목적에 가장 간단한 형태가 다른 목적에는 그렇지 않을 수 있기 때문이다.

@quotation
@strong{@anchor{Exercise 2.56}연습문제 2.56:} 기본 미분기를 확장하여 더 많은 종류의 표현식을 처리하는 방법을 보여라.
예를 들어, 미분 규칙
@ifinfo

@example
d(u^n)            du
------ = nu^(n-1) --  
  dx              dx
@end example

@end ifinfo
@tex
\[ % :45:
  {d(u^{\kern0.1ex n}) \over dx} \,=\, {nu^{\kern0.1ex n-1} \, {du \over dx}}  \]
@end tex
@noindent
을 @code{deriv} 프로그램에 새로운 절을 추가하고 적절한 프로시저 @code{is_exponentiation}, @code{base}, @code{exponent}, 그리고 @code{make_exponentiation}을 정의함으로써 구현하라. (거듭제곱을 나타내기 위해 기호 @code{**}를 사용할 수 있다.)
0제곱은 1이고 1제곱은 그 자체라는 규칙을 내장하라.
@end quotation

@quotation
@strong{@anchor{Exercise 2.57}연습문제 2.57:} 미분 프로그램을 확장하여 임의의 수(둘 이상)의 항을 가진 합과 곱을 처리하도록 하라.
그러면 위의 마지막 예제는 다음과 같이 표현될 수 있다

@example
// 가변 인자 합/곱을 사용하면 다음과 같이 표현될 수 있다:
deriv(&product(vec![var("x"), var("y"), sum(vec![var("x"), num(3.0)])]), "x")
@end example

@code{deriv} 프로시저는 전혀 변경하지 않고 합과 곱에 대한 표현만 변경하여 이를 수행해 보라.
예를 들어, 합의 @code{addend}는 첫 번째 항이 되고, @code{augend}는 나머지 항들의 합이 될 것이다.
@end quotation

@quotation
@strong{@anchor{Exercise 2.58}연습문제 2.58:} 미분 프로그램을 수정하여 @code{+}와 @code{*}가 전위 연산자가 아니라 중위 연산자인 일반적인 수학 표기법과 작동하도록 하고 싶다고 가정하자.
미분 프로그램은 추상 데이터의 관점에서 정의되었으므로, 우리는 미분기가 작동할 대수 표현식의 표현을 정의하는 술어, 선택자, 그리고 생성자만 변경함으로써 다른 표현식 표현과 작동하도록 수정할 수 있다.

@enumerate a

@item
@code{(x + (3 * (x + (y + 2))))}와 같이 중위 형태로 제시된 대수 표현식을 미분하기 위해 이를 수행하는 방법을 보여라.
작업을 단순화하기 위해, @code{+}와 @code{*}는 항상 두 개의 인자를 취하고 표현식은 완전히 괄호로 묶여 있다고 가정하라.

@item
불필요한 괄호를 생략하고 덧셈보다 곱셈이 먼저 수행된다고 가정하는 @code{(x + 3 * (x + y + 2))}와 같은 표준 대수 표기법을 허용하면 문제는 상당히 더 어려워진다.
우리의 미분 프로그램이 여전히 작동하도록 이 표기법에 대한 적절한 술어, 선택자, 그리고 생성자를 설계할 수 있는가?

@end enumerate
@end quotation

@node	2.3.3, 2.3.4, 2.3.2, 2.3
@subsection 예제: 집합 표현 (Example: Representing Sets)

이전 예제들에서 우리는 두 가지 종류의 복합 데이터 객체, 즉 유리수와 대수 표현식에 대한 표현을 구축했다.
이 예제들 중 하나에서 우리는 표현식을 구성 시점이나 선택 시점에 단순화(축소)할 수 있는 선택권을 가졌지만, 그 외에는 리스트 구조의 관점에서 이 구조들을 표현하는 선택이 간단했다.
집합의 표현으로 넘어가면, 표현의 선택이 그렇게 명확하지 않다.
실제로 가능한 표현이 많이 있으며, 그것들은 여러 면에서 서로 크게 다르다.

비공식적으로, 집합은 단순히 서로 다른 객체들의 컬렉션이다.
더 정확한 정의를 내리기 위해 우리는 데이터 추상화 방법을 사용할 수 있다.
즉, 우리는 집합에 사용될 연산들을 지정함으로써 ``집합''을 정의한다.
이 연산들은 @code{union_set}, @code{intersection_set}, @code{element_of_set}, 그리고 @code{adjoin_set}이다.
@code{Element-of-set?}은 주어진 요소가 집합의 구성원인지 결정하는 술어이다.
@code{Adjoin-set}은 객체와 집합을 인자로 받아 원래 집합의 요소들과 추가된 요소를 포함하는 집합을 반환한다.
@code{Union-set}은 두 집합의 합집합을 계산하는데, 이는 두 인자 중 하나에 나타나는 각 요소를 포함하는 집합이다.
@code{Intersection-set}은 두 집합의 교집합을 계산하는데, 이는 두 인자 모두에 나타나는 요소들만 포함하는 집합이다.
데이터 추상화의 관점에서, 우리는 위에 주어진 해석과 일관된 방식으로 이러한 연산들을 구현하는 어떤 표현이든 자유롭게 설계할 수 있다.@footnote{더 공식적으로 말하고 싶다면, 우리는 ``위에 주어진 해석과 일관된''이라는 말을 연산들이 다음과 같은 규칙들을 만족한다는 의미로 지정할 수 있다:

@itemize @bullet

@item
어떤 집합 @code{S}와 어떤 객체 @code{x}에 대해서도,
@code{(element-of-set? x (adjoin-set x S))}는 참이다
(비공식적으로: ``객체를 집합에 추가하면 그 객체를 포함하는 집합이 생성된다'').

@item
어떤 집합 @code{S}와 @code{T}, 그리고 어떤 객체 @code{x}에 대해서도,
@code{(element-of-set? x (union-set S T))}는
@code{(or (element-of-set? x S) (element-of-set? x T))}와 같다
(비공식적으로: ``@code{(union S T)}의 요소는 @code{S}에 있거나 @code{T}에 있는 요소들이다'').

@item
어떤 객체 @code{x}에 대해서도,
@code{(element-of-set? x '())}는 거짓이다
(비공식적으로: ``어떤 객체도 빈 집합의 요소가 아니다'').

@end itemize
}

@subsubheading 비정렬 리스트로서의 집합 (Sets as unordered lists)

집합을 표현하는 한 가지 방법은 어떤 요소도 한 번 이상 나타나지 않는 요소들의 리스트로 표현하는 것이다.
빈 집합은 빈 리스트로 표현된다.
이 표현에서, @code{element_of_set}은 @ref{2.3.1}의 @code{memq} 프로시저와 유사하다.
이것은 집합 요소가 기호일 필요가 없도록 @code{eq?} 대신 @code{equal?}을 사용한다:

@example
fn element_of_set<T: PartialEq>(x: &T, set: &[T]) -> bool @{
    set.iter().any(|elem| elem == x)
@}
@end example

@noindent
이것을 사용하여 우리는 @code{adjoin_set}을 작성할 수 있다.
추가할 객체가 이미 집합에 있다면, 우리는 그냥 집합을 반환한다.
그렇지 않다면, 우리는 객체를 집합을 나타내는 리스트에 추가하기 위해 @code{cons}를 사용한다:

@example
fn adjoin_set<T: PartialEq + Clone>(x: T, set: &[T]) -> Vec<T> @{
    if element_of_set(&x, set) @{
        set.to_vec()
    @} else @{
        let mut result = vec![x];
        result.extend(set.iter().cloned());
        result
    @}
@}
@end example

@noindent
@code{intersection_set}의 경우 우리는 재귀적 전략을 사용할 수 있다.
만약 우리가 @code{set2}와 @code{set1}의 @code{cdr}의 교집합을 형성하는 법을 안다면, 우리는 단지 @code{set1}의 @code{car}를 여기에 포함할지 결정하기만 하면 된다.
하지만 이것은 @code{(car set1)}이 @code{set2}에도 있는지에 달려 있다.
다음은 결과 프로시저이다:

@example
fn intersection_set<T: PartialEq + Clone>(set1: &[T], set2: &[T]) -> Vec<T> @{
    set1.iter()
        .filter(|&x| element_of_set(x, set2))
        .cloned()
        .collect()
@}
@end example

@noindent
표현을 설계할 때 우리가 관심을 가져야 할 문제 중 하나는 효율성이다.
우리의 집합 연산에 필요한 단계 수를 고려해 보자.
그것들은 모두 @code{element_of_set}을 사용하므로, 이 연산의 속도는 집합 구현 전체의 효율성에 큰 영향을 미친다.
이제, 객체가 집합의 구성원인지 확인하기 위해 @code{element_of_set}은 전체 집합을 스캔해야 할 수도 있다. (최악의 경우, 객체가 집합에 없는 것으로 판명된다.)
따라서 집합에 @math{n}개의 요소가 있다면 @code{element_of_set}은 최대 @math{n} 단계를 취할 수 있다.
따라서 필요한 단계 수는 @math{{\Theta(n)}}으로 증가한다.
이 연산을 사용하는 @code{adjoin_set}에 필요한 단계 수 또한 @math{{\Theta(n)}}으로 증가한다.
@code{set1}의 각 요소에 대해 @code{element_of_set} 검사를 수행하는 @code{intersection_set}의 경우, 필요한 단계 수는 관련된 집합들의 크기의 곱으로 증가하며, 크기 @math{n}인 두 집합의 경우 @math{{\Theta(n^2)}}이다.
@code{union_set}의 경우에도 마찬가지일 것이다.

@quotation
@strong{@anchor{Exercise 2.59}연습문제 2.59:} 집합의 비정렬 리스트 표현에 대한 @code{union_set} 연산을 구현하라.
@end quotation

@quotation
@strong{@anchor{Exercise 2.60}연습문제 2.60:} 우리는 집합이 중복 없는 리스트로 표현될 것이라고 명시했다.
이제 중복을 허용한다고 가정해 보자.
예를 들어, 집합 @math{{\{1, 2, 3\}}}은 리스트 @code{(2 3 2 1 3 2 2)}로 표현될 수 있다.
이 표현에 대해 작동하는 프로시저 @code{element_of_set}, @code{adjoin_set}, @code{union_set}, 그리고 @code{intersection_set}을 설계하라.
각각의 효율성은 중복 없는 표현에 대한 해당 프로시저와 어떻게 비교되는가?
중복 없는 표현보다 이 표현을 선호하여 사용할 응용 프로그램이 있는가?
@end quotation

@subsubheading 정렬된 리스트로서의 집합 (Sets as ordered lists)

집합 연산의 속도를 높이는 한 가지 방법은 집합 요소들이 증가하는 순서로 나열되도록 표현을 변경하는 것이다.
이를 위해 우리는 어떤 것이 더 큰지 말할 수 있도록 두 객체를 비교하는 방법이 필요하다.
예를 들어, 우리는 기호를 사전순으로 비교할 수 있고, 또는 객체에 고유한 숫자를 할당하고 해당 숫자를 비교함으로써 요소를 비교하는 어떤 방법에 동의할 수 있다.
논의를 단순하게 유지하기 위해, 우리는 집합 요소가 숫자인 경우만 고려하여 @code{>}와 @code{<}를 사용하여 요소를 비교할 수 있도록 할 것이다.
우리는 요소들을 증가하는 순서로 나열함으로써 숫자 집합을 표현할 것이다.
위의 첫 번째 표현이 요소들을 어떤 순서로든 나열함으로써 집합 @math{{\{1, 3, 6, 10\}}}을 표현하도록 허용했던 것과 달리, 우리의 새로운 표현은 오직 리스트 @code{(1 3 6 10)}만을 허용한다.

정렬의 한 가지 장점은 @code{element_of_set}에서 나타난다: 항목의 존재를 확인할 때, 우리는 더 이상 전체 집합을 스캔할 필요가 없다.
만약 우리가 찾고 있는 항목보다 더 큰 집합 요소에 도달하면, 우리는 그 항목이 집합에 없다는 것을 알게 된다:

@example
fn element_of_ordered_set<T: Ord>(x: &T, set: &[T]) -> bool @{
    for elem in set @{
        match x.cmp(elem) @{
            std::cmp::Ordering::Equal => return true,
            std::cmp::Ordering::Less => return false,
            std::cmp::Ordering::Greater => continue,
        @}
    @}
    false
@}
@end example

이것은 얼마나 많은 단계를 절약하는가?
최악의 경우, 우리가 찾고 있는 항목이 집합에서 가장 큰 항목일 수 있으므로 단계 수는 비정렬 표현과 같다.
반면에, 만약 우리가 많은 다른 크기의 항목을 검색한다면, 때로는 리스트의 시작 부분 근처에서 검색을 멈출 수 있고 다른 때는 리스트의 대부분을 조사해야 할 것이라고 예상할 수 있다.
평균적으로 우리는 집합 항목의 절반 정도를 조사해야 할 것으로 예상해야 한다.
따라서 필요한 평균 단계 수는 약 @math{{n / 2}}가 될 것이다.
이것은 여전히 @math{{\Theta(n)}} 증가이지만, 이전 구현에 비해 평균적으로 단계 수를 2배 절약해 준다.

우리는 @code{intersection_set}으로 더 인상적인 속도 향상을 얻는다.
비정렬 표현에서 이 연산은 @code{set1}의 각 요소에 대해 @code{set2}의 전체 스캔을 수행했기 때문에 @math{{\Theta(n^2)}} 단계를 필요로 했다.
하지만 정렬된 표현을 사용하면 더 영리한 방법을 사용할 수 있다.
두 집합의 초기 요소 @code{x1}과 @code{x2}를 비교하는 것으로 시작하라.
만약 @code{x1}이 @code{x2}와 같다면, 그것은 교집합의 요소를 제공하며, 나머지 교집합은 두 집합의 @code{cdr}-들의 교집합이다.
하지만 만약 @code{x1}이 @code{x2}보다 작다면 어떨까?
@code{x2}는 @code{set2}에서 가장 작은 요소이므로, 우리는 즉시 @code{x1}이 @code{set2}의 어디에도 나타날 수 없으며 따라서 교집합에 없다고 결론지을 수 있다.
따라서 교집합은 @code{set2}와 @code{set1}의 @code{cdr}의 교집합과 같다.
마찬가지로, 만약 @code{x2}가 @code{x1}보다 작다면, 교집합은 @code{set1}과 @code{set2}의 @code{cdr}의 교집합으로 주어진다.
다음은 그 프로시저이다:

@example
fn intersection_ordered_set<T: Ord + Clone>(set1: &[T], set2: &[T]) -> Vec<T> @{
    let mut result = Vec::new();
    let (mut i, mut j) = (0, 0);
    while i < set1.len() && j < set2.len() @{
        match set1[i].cmp(&set2[j]) @{
            std::cmp::Ordering::Equal => @{
                result.push(set1[i].clone());
                i += 1;
                j += 1;
            @}
            std::cmp::Ordering::Less => i += 1,
            std::cmp::Ordering::Greater => j += 1,
        @}
    @}
    result
@}
@end example

@noindent
이 프로세스에 필요한 단계 수를 추정하기 위해, 각 단계에서 우리는 @code{set1}이나 @code{set2} 또는 둘 다에서 첫 번째 요소를 제거함으로써 교집합 문제를 더 작은 집합들의 교집합을 계산하는 문제로 축소한다는 것을 관찰하라.
따라서 필요한 단계 수는 비정렬 표현과 같은 크기의 곱이 아니라 @code{set1}과 @code{set2}의 크기의 합이 최대가 된다.
이것은 @math{{\Theta(n^2)}}이 아닌 @math{{\Theta(n)}} 증가이며, 중간 크기의 집합에 대해서도 상당한 속도 향상이다.

@quotation
@strong{@anchor{Exercise 2.61}연습문제 2.61:} 정렬된 표현을 사용하여 @code{adjoin_set}을 구현하라.
@code{element_of_set}과의 유추를 통해, 정렬을 활용하여 비정렬 표현보다 평균적으로 약 절반의 단계를 필요로 하는 프로시저를 생성하는 방법을 보여라.
@end quotation

@quotation
@strong{@anchor{Exercise 2.62}연습문제 2.62:} 정렬된 리스트로 표현된 집합에 대해 @code{union_set}의 @math{{\Theta(n)}} 구현을 제시하라.
@end quotation

@subsubheading 이진 트리로서의 집합 (Sets as binary trees)

우리는 집합 요소를 트리 형태로 배열함으로써 정렬된 리스트 표현보다 더 잘할 수 있다.
트리의 각 노드는 해당 노드의 ``항목(entry)''이라고 불리는 집합의 한 요소와, 두 개의 다른 (비어 있을 수 있는) 노드에 대한 링크를 보유한다.
``왼쪽'' 링크는 노드의 항목보다 작은 요소들을 가리키고, ``오른쪽'' 링크는 노드의 항목보다 큰 요소들을 가리킨다.
@ref{Figure 2.16}은 집합 @math{{\{1, 3, 5, 7, 9, 11\}}}을 나타내는 몇 가지 트리를 보여준다.
동일한 집합이 다양한 방식으로 트리로 표현될 수 있다.
우리가 유효한 표현을 위해 요구하는 유일한 것은 왼쪽 서브트리의 모든 요소가 노드 항목보다 작아야 하고 오른쪽 서브트리의 모든 요소가 노드 항목보다 커야 한다는 것이다.

@float
@anchor{Figure 2.16}
@ifinfo
@quotation
@strong{Figure 2.16:} 집합 @math{{\{1, 3, 5, 7, 9, 11\}}}을 나타내는 다양한 이진 트리들.

@example
   7          3             5
   /\         /\            /\
  3  9       1  7          3  9
 /\   \         /\        /   /\
1  5  11       5  9      1   7  11
                   \
                   11
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap2/Fig2.16c,120mm,,,.std.svg}
@caption{@strong{Figure 2.16:} 집합 @math{{\{1, 3, 5, 7, 9, 11\}}}을 나타내는 다양한 이진 트리들.}
@end iftex
@end float

트리 표현의 장점은 이것이다: 우리가 숫자 @math{x}가 집합에 포함되어 있는지 확인하고 싶다고 가정하자.
우리는 @math{x}를 최상위 노드의 항목과 비교하는 것으로 시작한다.
만약 @math{x}가 이것보다 작다면, 우리는 왼쪽 서브트리만 검색하면 된다는 것을 안다; 만약 @math{x}가 더 크다면, 오른쪽 서브트리만 검색하면 된다.
이제, 만약 트리가 ``균형 잡혀(balanced)'' 있다면, 이 서브트리들 각각은 원본 크기의 약 절반이 될 것이다.
따라서 한 단계 만에 우리는 크기 @math{n}인 트리를 검색하는 문제를 크기 @math{{n / 2}}인 트리를 검색하는 문제로 줄였다.
트리의 크기가 각 단계에서 절반으로 줄어들기 때문에, 우리는 크기 @math{n}인 트리를 검색하는 데 필요한 단계 수가 @math{{\Theta(\log n)}}으로 증가할 것이라고 예상해야 한다.@footnote{각 단계에서 문제의 크기를 절반으로 줄이는 것은 로그형 증가의 특징적인 특성으로, 우리는 @ref{1.2.4}의 빠른 거듭제곱 알고리즘과 @ref{1.3.3}의 반값 검색 방법에서 이를 보았다.} 큰 집합의 경우, 이것은 이전 표현들에 비해 상당한 속도 향상이 될 것이다.

우리는 리스트를 사용하여 트리를 표현할 수 있다.
각 노드는 세 항목의 리스트가 될 것이다: 노드의 항목, 왼쪽 서브트리, 그리고 오른쪽 서브트리.
빈 리스트의 왼쪽 또는 오른쪽 서브트리는 거기에 연결된 서브트리가 없음을 나타낸다.
우리는 다음 프로시저들로 이 표현을 기술할 수 있다:@footnote{우리는 집합을 트리의 관점에서 표현하고, 트리를 리스트의 관점에서 표현하고 있다---사실상, 데이터 추상화 위에 구축된 데이터 추상화이다. 우리는 프로시저 @code{entry}, @code{left-branch}, @code{right-branch}, 그리고 @code{make-tree}를 ``이진 트리''라는 추상화를 리스트 구조의 관점에서 우리가 원할 수 있는 특정 표현 방식으로부터 격리하는 방법으로 간주할 수 있다.}

@example
#[derive(Debug, Clone)]
enum Tree<T> @{
    Empty,
    Node @{
        entry: T,
        left: Box<Tree<T>>,
        right: Box<Tree<T>>,
    @},
@}

fn make_tree<T>(entry: T, left: Tree<T>, right: Tree<T>) -> Tree<T> @{
    Tree::Node @{
        entry,
        left: Box::new(left),
        right: Box::new(right),
    @}
@}
@end example

@noindent
이제 우리는 위에서 설명한 전략을 사용하여 @code{element_of_set} 프로시저를 작성할 수 있다:

@example
fn element_of_tree<T: Ord>(x: &T, tree: &Tree<T>) -> bool @{
    match tree @{
        Tree::Empty => false,
        Tree::Node @{ entry, left, right @} => match x.cmp(entry) @{
            std::cmp::Ordering::Equal => true,
            std::cmp::Ordering::Less => element_of_tree(x, left),
            std::cmp::Ordering::Greater => element_of_tree(x, right),
        @},
    @}
@}
@end example

@noindent
항목을 집합에 추가하는 것도 비슷하게 구현되며 또한 @math{{\Theta(\log n)}} 단계를 필요로 한다.
항목 @code{x}를 추가하기 위해, 우리는 @code{x}를 노드 항목과 비교하여 @code{x}가 오른쪽 가지에 추가되어야 할지 왼쪽 가지에 추가되어야 할지 결정하고, @code{x}를 적절한 가지에 추가한 후 이 새로 구성된 가지를 원래 항목 및 다른 가지와 함께 조립한다.
만약 @code{x}가 항목과 같다면, 우리는 그냥 노드를 반환한다.
만약 우리가 @code{x}를 빈 트리에 추가하라는 요청을 받으면, 우리는 @code{x}를 항목으로 갖고 빈 오른쪽 및 왼쪽 가지를 가진 트리를 생성한다.
다음은 그 프로시저이다:

@example
fn adjoin_tree<T: Ord + Clone>(x: T, tree: Tree<T>) -> Tree<T> @{
    match tree @{
        Tree::Empty => make_tree(x, Tree::Empty, Tree::Empty),
        Tree::Node @{ entry, left, right @} => match x.cmp(&entry) @{
            std::cmp::Ordering::Equal => Tree::Node @{ entry, left, right @},
            std::cmp::Ordering::Less => make_tree(
                entry,
                adjoin_tree(x, *left),
                *right,
            ),
            std::cmp::Ordering::Greater => make_tree(
                entry,
                *left,
                adjoin_tree(x, *right),
            ),
        @},
    @}
@}
@end example

@noindent
트리 검색이 로그형 단계 수로 수행될 수 있다는 위의 주장은 트리가 ``균형 잡혀'' 있다는 가정, 즉 모든 트리의 왼쪽과 오른쪽 서브트리가 대략 같은 수의 요소를 가지고 있어서 각 서브트리가 부모 요소의 약 절반을 포함한다는 가정에 기초한다.
하지만 우리가 구축하는 트리가 균형 잡혀 있을 것이라고 어떻게 확신할 수 있는가?
균형 잡힌 트리로 시작하더라도, @code{adjoin_set}으로 요소를 추가하면 불균형한 결과가 생성될 수 있다.
새로 추가되는 요소의 위치는 그 요소가 이미 집합에 있는 항목들과 어떻게 비교되느냐에 따라 달라지므로, 만약 우리가 요소를 ``무작위로'' 추가한다면 트리가 평균적으로 균형을 이루는 경향이 있을 것이라고 기대할 수 있다.
하지만 이것은 보장이 아니다.
예를 들어, 만약 우리가 빈 집합으로 시작해서 숫자 1부터 7까지 순서대로 추가한다면 @ref{Figure 2.17}에 보이는 것과 같은 매우 불균형한 트리를 얻게 된다.
이 트리에서는 모든 왼쪽 서브트리가 비어 있으므로, 단순한 정렬된 리스트에 비해 이점이 없다.
이 문제를 해결하는 한 가지 방법은 임의의 트리를 동일한 요소를 가진 균형 잡힌 트리로 변환하는 연산을 정의하는 것이다.
그러면 우리는 매 몇 번의 @code{adjoin_set} 연산 후에 이 변환을 수행하여 집합의 균형을 유지할 수 있다.
이 문제를 해결하는 다른 방법들도 있으며, 그중 대부분은 검색과 삽입 모두 @math{{\Theta(\log n)}} 단계에 수행될 수 있는 새로운 데이터 구조를 설계하는 것을 포함한다.@footnote{그러한 구조의 예로는 @newterm{B-트리(B-trees)}와 @newterm{레드-블랙 트리(red-black trees)}가 있다. 이 문제에 헌신하는 방대한 데이터 구조 문헌이 있다. @ref{Cormen et al. 1990}을 참조하라.}

@float
@anchor{Figure 2.17}
@ifinfo
@quotation
@strong{Figure 2.17:} 1부터 7까지 순서대로 추가하여 생성된 불균형 트리.

@example
1
 \
  2
   \
    4
     \
      5
       \
        6
         \
          7
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap2/Fig2.17a,68mm,,,.std.svg}
@caption{@strong{Figure 2.17:} 1부터 7까지 순서대로 추가하여 생성된 불균형 트리.}
@end iftex
@end float

@quotation
@strong{@anchor{Exercise 2.63}연습문제 2.63:} 다음 두 프로시저는 각각 이진 트리를 리스트로 변환한다.

@example
// Version 1: Using Vec::extend (like append)
fn tree_to_list_1<T: Clone>(tree: &Tree<T>) -> Vec<T> @{
    match tree @{
        Tree::Empty => vec![],
        Tree::Node @{ entry, left, right @} => @{
            let mut result = tree_to_list_1(left);
            result.push(entry.clone());
            result.extend(tree_to_list_1(right));
            result
        @}
    @}
@}

// Version 2: Using accumulator (more efficient)
fn tree_to_list_2<T: Clone>(tree: &Tree<T>) -> Vec<T> @{
    fn copy_to_list<T: Clone>(tree: &Tree<T>, acc: &mut Vec<T>) @{
        if let Tree::Node @{ entry, left, right @} = tree @{
            copy_to_list(left, acc);
            acc.push(entry.clone());
            copy_to_list(right, acc);
        @}
    @}
    let mut result = Vec::new();
    copy_to_list(tree, &mut result);
    result
@}
@end example

@enumerate a

@item
두 프로시저는 모든 트리에 대해 같은 결과를 생성하는가? 그렇지 않다면, 결과는 어떻게 다른가? @ref{Figure 2.16}의 트리에 대해 두 프로시저는 어떤 리스트를 생성하는가?

@item
두 프로시저는 @math{n}개의 요소를 가진 균형 잡힌 트리를 리스트로 변환하는 데 필요한 단계 수에서 같은 증가 차수를 갖는가? 그렇지 않다면, 어느 것이 더 천천히 증가하는가?

@end enumerate
@end quotation

@quotation
@strong{@anchor{Exercise 2.64}연습문제 2.64:} 다음 프로시저 @code{list->tree}는 정렬된 리스트를 균형 잡힌 이진 트리로 변환한다.
보조 프로시저 @code{partial-tree}는 정수 @math{n}과 적어도 @math{n}개의 요소를 가진 리스트를 인자로 받아 리스트의 처음 @math{n}개 요소를 포함하는 균형 잡힌 트리를 구성한다.
@code{partial-tree}가 반환하는 결과는 (@code{cons}로 형성된) 쌍인데, @code{car}는 구성된 트리이고 @code{cdr}는 트리에 포함되지 않은 나머지 요소들의 리스트이다.

@example
fn list_to_tree<T: Clone>(elements: &[T]) -> Tree<T> @{
    partial_tree(elements, elements.len()).0
@}

fn partial_tree<T: Clone>(elts: &[T], n: usize) -> (Tree<T>, &[T]) @{
    if n == 0 @{
        (Tree::Empty, elts)
    @} else @{
        let left_size = (n - 1) / 2;
        let (left_tree, non_left_elts) = partial_tree(elts, left_size);
        let this_entry = non_left_elts[0].clone();
        let right_size = n - left_size - 1;
        let (right_tree, remaining) = partial_tree(&non_left_elts[1..], right_size);
        (make_tree(this_entry, left_tree, right_tree), remaining)
    @}
@}
@end example

@enumerate a

@item
@code{partial-tree}가 어떻게 작동하는지 가능한 한 명확하게 설명하는 짧은 단락을 작성하라. 리스트 @code{(1 3 5 7 9 11)}에 대해 @code{list->tree}가 생성하는 트리를 그려라.

@item
@code{list->tree}가 @math{n}개의 요소를 가진 리스트를 변환하는 데 필요한 단계 수의 증가 차수는 무엇인가?

@end enumerate
@end quotation

@quotation
@strong{@anchor{Exercise 2.65}연습문제 2.65:} @ref{Exercise 2.63}과 @ref{Exercise 2.64}의 결과를 사용하여 (균형 잡힌) 이진 트리로 구현된 집합에 대해 @code{union_set}과 @code{intersection_set}의 @math{{\Theta(n)}} 구현을 제시하라.@footnote{@ref{Exercise 2.63}부터 @ref{Exercise 2.65}는 Paul Hilfinger에 의한 것이다.}
@end quotation

@subsubheading 집합과 정보 검색 (Sets and information retrieval)

우리는 집합을 표현하기 위해 리스트를 사용하는 옵션들을 검토했고 데이터 객체에 대한 표현의 선택이 데이터를 사용하는 프로그램의 성능에 어떻게 큰 영향을 미칠 수 있는지 보았다.
집합에 집중하는 또 다른 이유는 여기서 논의된 기술들이 정보 검색과 관련된 응용 프로그램에서 반복해서 나타나기 때문이다.

회사의 인사 파일이나 회계 시스템의 거래 내역과 같이 많은 수의 개별 레코드를 포함하는 데이터베이스를 고려해 보자.
전형적인 데이터 관리 시스템은 레코드의 데이터에 접근하거나 수정하는 데 많은 시간을 소비하므로 레코드에 접근하는 효율적인 방법을 필요로 한다.
이것은 각 레코드의 한 부분을 식별용 @newterm{키(key)}로 지정함으로써 수행된다.
키는 레코드를 고유하게 식별하는 어떤 것이든 될 수 있다.
인사 파일의 경우, 그것은 직원의 ID 번호일 수 있다.
회계 시스템의 경우, 그것은 거래 번호일 수 있다.
키가 무엇이든, 우리가 레코드를 데이터 구조로 정의할 때 우리는 주어진 레코드와 연관된 키를 검색하는 @code{key} 선택자 프로시저를 포함해야 한다.

이제 우리는 데이터베이스를 레코드의 집합으로 표현한다.
주어진 키를 가진 레코드를 찾기 위해 우리는 프로시저 @code{lookup}을 사용하는데, 이것은 키와 데이터베이스를 인자로 받아 그 키를 가진 레코드를 반환하거나, 그러한 레코드가 없으면 거짓을 반환한다.
@code{Lookup}은 @code{element_of_set}과 거의 같은 방식으로 구현된다.
예를 들어, 레코드 집합이 비정렬 리스트로 구현되었다면, 우리는 다음을 사용할 수 있다

@example
fn lookup<'a, K, R>(given_key: &K, set_of_records: &'a [R]) -> Option<&'a R>
where
    K: PartialEq,
    R: HasKey<K>,
@{
    set_of_records.iter().find(|record| record.key() == given_key)
@}

trait HasKey<K> @{
    fn key(&self) -> &K;
@}
@end example

@noindent
물론, 큰 집합을 표현하는 데는 비정렬 리스트보다 더 나은 방법이 있다.
레코드가 ``무작위로 접근''되어야 하는 정보 검색 시스템은 일반적으로 앞서 논의한 이진 트리 표현과 같은 트리 기반 방법으로 구현된다.
그러한 시스템을 설계할 때 데이터 추상화 방법론은 큰 도움이 될 수 있다.
설계자는 비정렬 리스트와 같은 간단하고 직접적인 표현을 사용하여 초기 구현을 만들 수 있다.
이것은 최종 시스템에는 부적합하겠지만, 시스템의 나머지 부분을 테스트하기 위한 ``빠르고 더러운(quick and dirty)'' 데이터베이스를 제공하는 데 유용할 수 있다.
나중에 데이터 표현은 더 정교하게 수정될 수 있다.
데이터베이스가 추상 선택자와 생성자의 관점에서 접근된다면, 이 표현의 변경은 시스템의 나머지 부분에 어떤 변경도 요구하지 않을 것이다.

@quotation
@strong{@anchor{Exercise 2.66}연습문제 2.66:} 레코드 집합이 키의 수치 값에 따라 정렬된 이진 트리로 구조화된 경우에 대해 @code{lookup} 프로시저를 구현하라.
@end quotation

@node	2.3.4, 2.3.4a, 2.3.3, 2.3
@subsection 예제: 허프만 인코딩 트리 (Example: Huffman Encoding Trees)

이 절은 집합과 트리를 조작하기 위해 리스트 구조와 데이터 추상화를 사용하는 연습을 제공한다.
응용 분야는 데이터를 0과 1(비트)의 시퀀스로 표현하는 방법이다.
예를 들어, 컴퓨터에서 텍스트를 표현하는 데 사용되는 ASCII 표준 코드는 각 문자를 7비트 시퀀스로 인코딩한다.
7비트를 사용하면 우리는 @math{2^7}, 즉 128개의 서로 다른 문자를 구별할 수 있다.
일반적으로, 만약 우리가 @math{n}개의 서로 다른 기호를 구별하고 싶다면, 기호당 @math{{\log_2n}} 비트를 사용해야 할 것이다.
만약 우리의 모든 메시지가 8개의 기호 A, B, C, D, E, F, G, H로 구성되어 있다면, 우리는 문자당 3비트인 코드를 선택할 수 있다. 예를 들어

@example
A 000  C 010  E 100  G 110
B 001  D 011  F 101  H 111
@end example

@noindent
이 코드로 메시지

@example
BACADAEAFABBAAAGAH
@end example

@noindent
는 54비트 문자열로 인코딩된다.

@example
001000010000011000100000101
000001001000000000110000111
@end example

@noindent
ASCII나 위의 A부터 H까지의 코드와 같은 코드는 @newterm{고정 길이(fixed-length)} 코드로 알려져 있는데, 왜냐하면 메시지의 각 기호를 같은 수의 비트로 표현하기 때문이다.
때로는 @newterm{가변 길이(variable-length)} 코드를 사용하는 것이 유리한데, 여기서는 서로 다른 기호가 서로 다른 수의 비트로 표현될 수 있다.
예를 들어, 모스 부호는 알파벳의 각 글자에 대해 같은 수의 점과 대시를 사용하지 않는다.
특히 가장 빈번한 글자인 E는 하나의 점으로 표현된다.
일반적으로, 만약 우리의 메시지가 어떤 기호는 매우 자주 나타나고 어떤 기호는 매우 드물게 나타나는 식이라면, 빈번한 기호에 더 짧은 코드를 할당함으로써 데이터를 더 효율적으로(즉, 메시지당 더 적은 비트를 사용하여) 인코딩할 수 있다.
문자 A부터 H에 대해 다음의 대안 코드를 고려해 보자:

@example
A 0    C 1010  E 1100  G 1110
B 100  D 1011  F 1101  H 1111
@end example

@noindent
이 코드로 위와 같은 메시지는 다음 문자열로 인코딩된다.

@example
100010100101101100011
010100100000111001111
@end example

@noindent
이 문자열은 42비트를 포함하므로, 위에 표시된 고정 길이 코드와 비교하여 공간을 20% 이상 절약한다.

가변 길이 코드를 사용할 때의 어려움 중 하나는 0과 1의 시퀀스를 읽을 때 언제 기호의 끝에 도달했는지 아는 것이다.
모스 부호는 각 글자의 점과 대시 시퀀스 뒤에 특별한 @newterm{구분자 코드(separator code)}(이 경우 일시 중지)를 사용하여 이 문제를 해결한다.
또 다른 해결책은 어떤 기호에 대한 완전한 코드도 다른 기호에 대한 코드의 시작(또는 @newterm{접두사(prefix)})이 되지 않도록 코드를 설계하는 것이다.
그러한 코드를 @newterm{접두사 코드(prefix code)}라고 부른다.
위의 예에서 A는 0으로 인코딩되고 B는 100으로 인코딩되므로, 0이나 100으로 시작하는 코드를 가진 다른 기호는 있을 수 없다.

일반적으로, 인코딩될 메시지에서 기호들의 상대적 빈도를 이용하는 가변 길이 접두사 코드를 사용하면 상당한 절약을 달성할 수 있다.
이를 수행하는 한 가지 특별한 방법은 발견자인 데이비드 허프만(David Huffman)의 이름을 딴 허프만 인코딩 방법이라고 불린다.
허프만 코드는 이진 트리로 표현될 수 있는데, 트리의 잎은 인코딩되는 기호들이다.
트리의 각 비-잎(non-leaf) 노드에는 그 노드 아래에 있는 잎들의 모든 기호를 포함하는 집합이 있다.
또한 잎에 있는 각 기호에는 가중치(상대적 빈도)가 할당되며, 각 비-잎 노드는 그 아래에 있는 잎들의 모든 가중치의 합인 가중치를 포함한다.
가중치는 인코딩이나 디코딩 프로세스에서 사용되지 않는다.
우리는 아래에서 트리를 구축하는 데 가중치가 어떻게 사용되는지 볼 것이다.

@ref{Figure 2.18}은 위에서 주어진 A부터 H까지의 코드에 대한 허프만 트리를 보여준다.
잎의 가중치는 트리가 A가 상대적 빈도 8로, B가 상대적 빈도 3으로, 그리고 다른 글자들은 각각 상대적 빈도 1로 나타나는 메시지를 위해 설계되었음을 나타낸다.

@float
@anchor{Figure 2.18}
@ifinfo
@strong{Figure 2.18:} 허프만 인코딩 트리.

@example
           @{A B C D E F G H@} 17
                    *
                   / \
                  /   \
                A 8    * @{B C D E F G H@} 9
            __________/ \_____________
           /                          \
@{B C D@} 5 *                            * @{E F G H@} 4
         / \                       ___/ \___
        /   \                     /         \
      B 3    * @{C D@} 2   @{E F@} 2 *           * @{G H@} 2
            / \                 / \         / \
           /   \               /   \       /   \
         C 1   D 1           E 1   F 1   G 1   H 1
@end example
@end ifinfo
@iftex
@image{fig/chap2/Fig2.18a,135mm,,,.std.svg}
@caption{@strong{Figure 2.18:} 허프만 인코딩 트리.}
@end iftex
@end float

허프만 트리가 주어지면, 우리는 루트에서 시작하여 기호를 담고 있는 잎에 도달할 때까지 아래로 이동함으로써 임의의 기호에 대한 인코딩을 찾을 수 있다.
왼쪽 가지로 내려갈 때마다 코드에 0을 추가하고, 오른쪽 가지로 내려갈 때마다 1을 추가한다.
(우리는 어느 가지가 기호에 대한 잎 노드이거나 집합에 그 기호를 포함하고 있는지 테스트하여 어느 가지를 따라갈지 결정한다.)
예를 들어, @ref{Figure 2.18}의 트리 루트에서 시작하여, 오른쪽 가지, 그다음 왼쪽 가지, 그다음 오른쪽 가지, 그다음 오른쪽 가지를 따라가면 D에 대한 잎에 도달한다; 따라서 D에 대한 코드는 1011이다.

@noindent
허프만 트리를 사용하여 비트 시퀀스를 디코딩하기 위해, 우리는 루트에서 시작하여 비트 시퀀스의 연속적인 0과 1을 사용하여 왼쪽 가지로 갈지 오른쪽 가지로 갈지 결정한다.
잎에 도달할 때마다 우리는 메시지에서 새로운 기호를 생성한 것이며, 그 지점에서 다음 기호를 찾기 위해 트리의 루트에서 다시 시작한다.
예를 들어, 위의 트리와 시퀀스 10001010이 주어졌다고 가정하자.
루트에서 시작하여, 우리는 오른쪽 가지로 내려가고(문자열의 첫 번째 비트가 1이므로), 그다음 왼쪽 가지로(두 번째 비트가 0이므로), 그다음 왼쪽 가지로(세 번째 비트도 0이므로) 내려간다.
이것은 우리를 B에 대한 잎으로 데려가므로, 디코딩된 메시지의 첫 번째 기호는 B이다.
이제 우리는 루트에서 다시 시작하고, 문자열의 다음 비트가 0이므로 왼쪽으로 이동한다.
이것은 우리를 A에 대한 잎으로 데려간다.
그러면 우리는 문자열의 나머지 1010을 가지고 루트에서 다시 시작하므로, 오른쪽, 왼쪽, 오른쪽, 왼쪽으로 이동하여 C에 도달한다.
따라서 전체 메시지는 BAC이다.

@subsubheading 허프만 트리 생성 (Generating Huffman trees)

기호들의 ``알파벳''과 상대적 빈도가 주어졌을 때, 어떻게 ``최고의'' 코드를 구성할까? (다시 말해, 어떤 트리가 가장 적은 비트로 메시지를 인코딩할까?)
허프만은 이를 수행하는 알고리즘을 제시했고 결과 코드가 실제로 기호의 상대적 빈도가 코드가 구성된 빈도와 일치하는 메시지에 대해 최고의 가변 길이 코드임을 보였다.
우리는 여기서 허프만 코드의 최적성을 증명하지는 않겠지만, 허프만 트리가 어떻게 구성되는지 보여줄 것이다.@footnote{허프만 코드의 수학적 속성에 대한 논의는 @ref{Hamming 1980}을 참조하라.}

허프만 트리를 생성하는 알고리즘은 매우 간단하다.
아이디어는 빈도가 가장 낮은 기호가 루트에서 가장 멀리 나타나도록 트리를 배열하는 것이다.
코드가 구성될 초기 데이터에 의해 결정된 대로 기호와 빈도를 포함하는 잎 노드들의 집합으로 시작하라.
이제 가장 낮은 가중치를 가진 두 잎을 찾아 그것들을 병합하여 이 두 노드를 왼쪽과 오른쪽 가지로 갖는 노드를 생성하라.
새 노드의 가중치는 두 가중치의 합이다.
원래 집합에서 두 잎을 제거하고 이 새 노드로 대체하라.
이제 이 과정을 계속하라.
각 단계에서 가장 작은 가중치를 가진 두 노드를 병합하여 집합에서 제거하고, 이 둘을 왼쪽과 오른쪽 가지로 갖는 노드로 대체하라.
이 과정은 노드가 하나만 남았을 때 멈추는데, 이것이 전체 트리의 루트이다.
다음은 @ref{Figure 2.18}의 허프만 트리가 생성된 방법이다:

@example
Initial @{(A 8) (B 3) (C 1) (D 1) 
leaves   (E 1) (F 1) (G 1) (H 1)@}

Merge   @{(A 8) (B 3) (@{C D@} 2) 
         (E 1) (F 1) (G 1) (H 1)@}

Merge   @{(A 8) (B 3) (@{C D@} 2) 
         (@{E F@} 2) (G 1) (H 1)@}

Merge   @{(A 8) (B 3) (@{C D@} 2) 
         (@{E F@} 2) (@{G H@} 2)@}

Merge   @{(A 8) (B 3) (@{C D@} 2) 
         (@{E F G H@} 4)@}

Merge   @{(A 8) (@{B C D@} 5) 
         (@{E F G H@} 4)@}

Merge   @{(A 8) (@{B C D E F G H@} 9)@}

Final   @{(@{A B C D E F G H@} 17)@}
merge    
@end example

@noindent
알고리즘은 항상 유일한 트리를 지정하지는 않는데, 왜냐하면 각 단계에서 유일한 가장 작은 가중치 노드들이 없을 수도 있기 때문이다.
또한 두 노드가 병합되는 순서(즉, 어느 것이 오른쪽 가지가 되고 어느 것이 왼쪽 가지가 될지)의 선택은 임의적이다.

@subsubheading 허프만 트리 표현 (Representing Huffman trees)

아래의 연습 문제에서 우리는 허프만 트리를 사용하여 메시지를 인코딩 및 디코딩하고 위에 개요가 서술된 알고리즘에 따라 허프만 트리를 생성하는 시스템으로 작업할 것이다.
우리는 트리가 어떻게 표현되는지 논의하는 것으로 시작할 것이다.

트리의 잎은 기호 @code{leaf}, 잎에 있는 기호, 그리고 가중치로 구성된 리스트로 표현된다:

@example
#[derive(Debug, Clone)]
enum HuffmanTree @{
    Leaf @{ symbol: char, weight: u32 @},
    Branch @{
        left: Box<HuffmanTree>,
        right: Box<HuffmanTree>,
        symbols: Vec<char>,
        weight: u32,
    @},
@}

fn make_leaf(symbol: char, weight: u32) -> HuffmanTree @{
    HuffmanTree::Leaf @{ symbol, weight @}
@}
@end example

@noindent
일반 트리는 왼쪽 가지, 오른쪽 가지, 기호 집합, 그리고 가중치의 리스트가 될 것이다.
기호 집합은 더 정교한 집합 표현보다는 단순히 기호들의 리스트가 될 것이다.
우리가 두 노드를 병합하여 트리를 만들 때, 우리는 트리의 가중치를 노드들의 가중치의 합으로 얻고, 기호 집합을 노드들의 기호 집합의 합집합으로 얻는다.
우리의 기호 집합은 리스트로 표현되므로, 우리는 @ref{2.2.1}에서 정의한 @code{append} 프로시저를 사용하여 합집합을 형성할 수 있다:

@example
fn make_code_tree(left: HuffmanTree, right: HuffmanTree) -> HuffmanTree @{
    let symbols = [get_symbols(&left), get_symbols(&right)].concat();
    let weight = get_weight(&left) + get_weight(&right);
    HuffmanTree::Branch @{
        left: Box::new(left),
        right: Box::new(right),
        symbols,
        weight,
    @}
@}
@end example

@noindent
만약 우리가 이런 식으로 트리를 만든다면, 다음과 같은 선택자를 갖게 된다:

@example
fn get_symbols(tree: &HuffmanTree) -> Vec<char> @{
    match tree @{
        HuffmanTree::Leaf @{ symbol, .. @} => vec![*symbol],
        HuffmanTree::Branch @{ symbols, .. @} => symbols.clone(),
    @}
@}

fn get_weight(tree: &HuffmanTree) -> u32 @{
    match tree @{
        HuffmanTree::Leaf @{ weight, .. @} => *weight,
        HuffmanTree::Branch @{ weight, .. @} => *weight,
    @}
@}
@end example

@noindent
프로시저 @code{symbols}와 @code{weight}는 잎으로 호출되느냐 일반 트리로 호출되느냐에 따라 약간 다른 일을 해야 한다.
이것들은 @newterm{제네릭 프로시저(generic procedures)}(한 종류 이상의 데이터를 다룰 수 있는 프로시저)의 간단한 예이며, 이에 대해서는 @ref{2.4}와 @ref{2.5}에서 훨씬 더 많이 이야기할 것이다.

@subsubheading 디코딩 프로시저 (The decoding procedure)

다음 프로시저는 디코딩 알고리즘을 구현한다.
이것은 0과 1의 리스트를 허프만 트리와 함께 인자로 받는다.

@example
fn decode(bits: &[u8], tree: &HuffmanTree) -> Vec<char> @{
    let mut result = Vec::new();
    let mut current = tree;
    for &bit in bits @{
        current = choose_branch(bit, current);
        if let HuffmanTree::Leaf @{ symbol, .. @} = current @{
            result.push(*symbol);
            current = tree; // restart from root
        @}
    @}
    result
@}

fn choose_branch(bit: u8, branch: &HuffmanTree) -> &HuffmanTree @{
    match branch @{
        HuffmanTree::Branch @{ left, right, .. @} => match bit @{
            0 => left,
            1 => right,
            _ => panic!("bad bit: @{@}", bit),
        @},
        HuffmanTree::Leaf @{ .. @} => panic!("cannot branch from leaf"),
    @}
@}
@end example

@noindent
프로시저 @code{decode-1}은 두 인자를 받는다: 남은 비트 리스트와 트리 내의 현재 위치.
이것은 리스트의 다음 비트가 0인지 1인지에 따라 왼쪽 또는 오른쪽 가지를 선택하면서 트리를 계속 ``내려''간다. (이것은 프로시저 @code{choose-branch}로 수행된다.)
잎에 도달하면, 잎에 있는 기호를 메시지의 다음 기호로 반환하고, 트리의 루트에서 시작하여 메시지의 나머지 부분을 디코딩한 결과에 그것을 @code{cons}한다.
@code{choose-branch}의 마지막 절에 있는 오류 검사에 주목하라. 입력 데이터에서 0이나 1 이외의 것을 발견하면 불평한다.

@subsubheading 가중치 있는 요소의 집합 (Sets of weighted elements)

우리의 트리 표현에서, 각 비-잎 노드는 기호 집합을 포함하며, 우리는 이것을 단순한 리스트로 표현했다.
그러나 위에서 논의한 트리 생성 알고리즘은 우리가 잎과 트리의 집합도 다루며, 가장 작은 두 항목을 연속적으로 병합할 것을 요구한다.
우리는 집합에서 가장 작은 항목을 반복적으로 찾아야 하므로, 이런 종류의 집합에는 정렬된 표현을 사용하는 것이 편리하다.

우리는 잎과 트리의 집합을 가중치가 증가하는 순서로 배열된 요소들의 리스트로 표현할 것이다.
집합을 구성하기 위한 다음 @code{adjoin_set} 프로시저는 @ref{Exercise 2.61}에서 설명한 것과 유사하다; 그러나 항목들은 가중치에 의해 비교되며, 집합에 추가되는 요소는 결코 이미 그 안에 있지 않다.

@example
fn adjoin_set_weighted(x: HuffmanTree, set: Vec<HuffmanTree>) -> Vec<HuffmanTree> @{
    let x_weight = get_weight(&x);
    let pos = set.iter().position(|t| get_weight(t) > x_weight);
    let mut result = set;
    match pos @{
        Some(i) => result.insert(i, x),
        None => result.push(x),
    @}
    result
@}
@end example

@noindent
다음 프로시저는 @code{((A 4) (B 2) (C 1) (D 1))}과 같은 기호-빈도 쌍의 리스트를 받아 허프만 알고리즘에 따라 병합될 준비가 된 잎들의 초기 정렬된 집합을 구성한다:

@example
fn make_leaf_set(pairs: &[(char, u32)]) -> Vec<HuffmanTree> @{
    pairs.iter()
        .fold(Vec::new(), |set, &(symbol, freq)| @{
            adjoin_set_weighted(make_leaf(symbol, freq), set)
        @})
@}
@end example

@quotation
@strong{@anchor{Exercise 2.67}연습문제 2.67:} 인코딩 트리와 샘플 메시지를 정의하라:

@example
let sample_tree = make_code_tree(
    make_leaf('A', 4),
    make_code_tree(
        make_leaf('B', 2),
        make_code_tree(
            make_leaf('D', 1),
            make_leaf('C', 1),
        ),
    ),
);

let sample_message: &[u8] = &[0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0];
@end example

@code{decode} 프로시저를 사용하여 메시지를 디코딩하고 결과를 제시하라.
@end quotation

@quotation
@strong{@anchor{Exercise 2.68}연습문제 2.68:} @code{encode} 프로시저는 메시지와 트리를 인자로 받아 인코딩된 메시지를 주는 비트 리스트를 생성한다.

@example
fn encode(message: &[char], tree: &HuffmanTree) -> Vec<u8> @{
    message.iter()
        .flat_map(|symbol| encode_symbol(*symbol, tree))
        .collect()
@}
@end example

@code{Encode-symbol}은 여러분이 작성해야 할 프로시저로, 주어진 트리에 따라 주어진 기호를 인코딩하는 비트 리스트를 반환한다.
기호가 트리에 전혀 없다면 오류를 신호하도록 @code{encode-symbol}을 설계해야 한다.
@ref{Exercise 2.67}에서 얻은 결과를 샘플 트리로 인코딩해 보고 원래 샘플 메시지와 같은지 확인하여 프로시저를 테스트하라.
@end quotation

@quotation
@strong{@anchor{Exercise 2.69}연습문제 2.69:} 다음 프로시저는 기호-빈도 쌍의 리스트(어떤 기호도 두 번 이상 나타나지 않음)를 인자로 받아 허프만 알고리즘에 따라 허프만 인코딩 트리를 생성한다.

@example
fn generate_huffman_tree(pairs: &[(char, u32)]) -> HuffmanTree @{
    successive_merge(make_leaf_set(pairs))
@}
@end example

@code{Make-leaf-set}은 쌍의 리스트를 정렬된 잎 집합으로 변환하는 위에서 주어진 프로시저이다.
@code{Successive-merge}는 여러분이 작성해야 할 프로시저로, @code{make-code-tree}를 사용하여 집합의 가장 작은 가중치 요소들을 하나만 남을 때까지(원하는 허프만 트리) 연속적으로 병합한다.
(이 프로시저는 약간 까다롭지만, 정말 복잡하지는 않다. 만약 복잡한 프로시저를 설계하고 있다면, 거의 확실히 뭔가 잘못하고 있는 것이다. 정렬된 집합 표현을 사용하고 있다는 사실을 상당히 활용할 수 있다.)
@end quotation

@quotation
@strong{@anchor{Exercise 2.70}연습문제 2.70:} 연관된 상대적 빈도를 가진 다음 8-기호 알파벳은 1950년대 록 노래의 가사를 효율적으로 인코딩하기 위해 설계되었다. (``알파벳''의 ``기호''가 개별 문자일 필요는 없음에 유의하라.)

@example

A    2    NA  16
BOOM 1    SHA  3
GET  2    YIP  9
JOB  2    WAH  1
@end example

@code{generate-huffman-tree} (@ref{Exercise 2.69})를 사용하여 해당 허프만 트리를 생성하고, @code{encode} (@ref{Exercise 2.68})를 사용하여 다음 메시지를 인코딩하라:

@example
Get a job
Sha na na na na na na na na

Get a job
Sha na na na na na na na na

Wah yip yip yip yip 
yip yip yip yip yip
Sha boom
@end example

인코딩에 몇 비트가 필요한가? 8-기호 알파벳에 대해 고정 길이 코드를 사용했다면 이 노래를 인코딩하는 데 필요한 최소 비트 수는 얼마인가?
@end quotation

@quotation
@strong{@anchor{Exercise 2.71}연습문제 2.71:} @math{n}개의 기호 알파벳에 대한 허프만 트리가 있고, 기호들의 상대적 빈도가 @math{{1, 2, 4, \dots, 2^{n-1}}}이라고 가정하자.
@math{{n=5}}일 때 트리를 그려라; @math{{n=10}}일 때 그려라.
그러한 트리에서(일반적인 @math{n}에 대해) 가장 빈번한 기호를 인코딩하는 데 몇 비트가 필요한가? 가장 덜 빈번한 기호는?
@end quotation

@quotation
@strong{@anchor{Exercise 2.72}연습문제 2.72:} @ref{Exercise 2.68}에서 설계한 인코딩 프로시저를 고려해 보자.
기호를 인코딩하는 데 필요한 단계 수의 증가 차수는 무엇인가?
각 노드에서 기호 리스트를 검색하는 데 필요한 단계 수를 포함해야 한다.
이 질문에 일반적으로 답하는 것은 어렵다.
@math{n}개의 기호의 상대적 빈도가 @ref{Exercise 2.71}에서 설명된 것과 같은 특수한 경우를 고려하고, 알파벳에서 가장 빈번한 기호와 가장 덜 빈번한 기호를 인코딩하는 데 필요한 단계 수의 증가 차수(@math{n}의 함수로서)를 제시하라.
@end quotation

@node 2.3.4a, 2.4, 2.3.4, 2.3
@subsection The Newtype Pattern: Zero-Cost Type Safety
@cindex newtype pattern
@cindex type safety
@cindex wrapper types
@cindex zero-cost abstraction

In the previous section, we saw how Huffman encoding trees use distinct types
to represent leaves and internal nodes. Rust provides a powerful technique
called the @newterm{newtype pattern} that allows us to create distinct types
with zero runtime cost, enforcing type safety at compile time while maintaining
the same performance as using the underlying type directly.

The newtype pattern addresses a fundamental challenge in programming: how do we
prevent mixing up values that have the same representation but different
semantic meanings? Consider a system that works with both meters and feet. Both
are represented as @code{f64} values, but mixing them up leads to catastrophic
errors---as NASA discovered when the Mars Climate Orbiter crashed due to a
unit conversion mistake.

@subsubheading Creating Type-Safe Wrappers

A @newterm{newtype} is a tuple struct with a single field, creating a new type
that wraps an existing one:

@example
@cindex units of measurement
// Wrapper types for units of measurement
struct Meters(f64);
struct Feet(f64);

// These are distinct types, even though both wrap f64
let distance_m = Meters(100.0);
let distance_ft = Feet(328.0);

// This would cause a compile error:
// let total = distance_m + distance_ft;  // Type mismatch!
@end example

@noindent
The key insight is that @code{Meters} and @code{Feet} are @emph{different
types} despite having identical memory layouts. The Rust compiler prevents us
from accidentally mixing them, eliminating an entire class of bugs at compile
time with zero runtime cost.

This pattern extends beyond physical units to any domain where we want to
distinguish values by their semantic meaning rather than their representation:

@example
@cindex type aliases vs newtypes
// User IDs and Product IDs are both u64, but semantically different
struct UserId(u64);
struct ProductId(u64);

fn get_user(id: UserId) -> User @{
    // Implementation
@}

fn get_product(id: ProductId) -> Product @{
    // Implementation
@}

// Type safety prevents mistakes
let user_id = UserId(42);
let product_id = ProductId(100);

get_user(user_id);        // OK
// get_user(product_id);  // Compile error: expected UserId, found ProductId
@end example

@noindent
Compare this to type aliases, which create synonyms rather than distinct types:

@example
type UserId = u64;
type ProductId = u64;

// These are interchangeable---no type safety!
let user_id: UserId = 42;
let product_id: ProductId = 100;
get_user(product_id);  // Compiles but semantically wrong
@end example

@subsubheading Transparent Representation and FFI

For newtypes that need to interact with foreign functions or have guaranteed
memory layout, Rust provides the @code{#[repr(transparent)]} attribute:

@example
@cindex FFI (Foreign Function Interface)
@cindex repr(transparent)
#[repr(transparent)]
struct FileDescriptor(i32);

// Guaranteed to have the same layout as i32
// Safe to pass across FFI boundaries
extern "C" @{
    fn close(fd: FileDescriptor) -> i32;
@}
@end example

@noindent
The @code{#[repr(transparent)]} attribute guarantees that the newtype has the
same memory layout, size, and alignment as its inner type. This is essential
for interfacing with C code, as the newtype can be safely passed to and from
foreign functions while maintaining type safety on the Rust side.

@subsubheading Implementing Traits on Newtypes

Newtypes allow us to implement traits on types we don't own---a key workaround
for Rust's @newterm{orphan rule}, which states that we can only implement a
trait if either the trait or the type is defined in our crate.

@example
@cindex orphan rule
@cindex trait implementation
use std::fmt;

struct Meters(f64);

// We can implement Display for our newtype
impl fmt::Display for Meters @{
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result @{
        write!(f, "@{@} m", self.0)
    @}
@}

// We can also implement custom operations
impl Meters @{
    fn new(value: f64) -> Self @{
        assert!(value >= 0.0, "Distance cannot be negative");
        Meters(value)
    @}

    fn to_feet(&self) -> Feet @{
        Feet(self.0 * 3.28084)
    @}
@}

let distance = Meters::new(100.0);
println!("Distance: @{@}", distance);  // "Distance: 100 m"
@end example

@noindent
This pattern is particularly powerful when we want to add behavior to external
types. For example, we cannot implement @code{Display} directly on @code{Vec<T>}
because we don't own either @code{Display} or @code{Vec}. But we can create a
newtype:

@example
@cindex newtype for external types
struct PrettyVec<T>(Vec<T>);

impl<T: fmt::Display> fmt::Display for PrettyVec<T> @{
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result @{
        write!(f, "[")?;
        for (i, item) in self.0.iter().enumerate() @{
            if i > 0 @{ write!(f, ", ")?; @}
            write!(f, "@{@}", item)?;
        @}
        write!(f, "]")
    @}
@}

let numbers = PrettyVec(vec![1, 2, 3, 4, 5]);
println!("@{@}", numbers);  // "[1, 2, 3, 4, 5]"
@end example

@subsubheading Ergonomic Access with Deref

To make newtypes more ergonomic, we can implement the @code{Deref} trait,
allowing the newtype to automatically coerce to its inner type in certain
contexts:

@example
@cindex Deref trait
@cindex deref coercion
use std::ops::Deref;

struct Meters(f64);

impl Deref for Meters @{
    type Target = f64;

    fn deref(&self) -> &Self::Target @{
        &self.0
    @}
@}

let distance = Meters(100.0);
// Can call f64 methods directly
let rounded = distance.round();  // Deref coercion to &f64
let absolute = distance.abs();
@end example

@noindent
However, use @code{Deref} judiciously. It should be implemented only when the
newtype truly @emph{is-a} special case of the inner type, not just when it
@emph{has-a} inner type. Overuse of @code{Deref} can break encapsulation and
lead to confusing APIs. Consider providing explicit methods instead:

@example
impl Meters @{
    fn value(&self) -> f64 @{
        self.0
    @}

    fn add(&self, other: &Meters) -> Meters @{
        Meters(self.0 + other.0)
    @}
@}
@end example

@subsubheading Type Conversions with From and Into

The @code{From} and @code{Into} traits enable explicit conversions between
types, making newtypes more ergonomic while maintaining type safety:

@example
@cindex From trait
@cindex Into trait
@cindex type conversion
struct Meters(f64);
struct Feet(f64);

impl From<f64> for Meters @{
    fn from(value: f64) -> Self @{
        Meters(value)
    @}
@}

impl From<Meters> for Feet @{
    fn from(m: Meters) -> Self @{
        Feet(m.0 * 3.28084)
    @}
@}

// Into is automatically implemented when From is implemented
let distance: Meters = 100.0.into();
let distance_ft: Feet = distance.into();
@end example

@noindent
Note that Rust automatically provides an @code{Into} implementation whenever
we implement @code{From}, so we only need to implement one direction. By
convention, implement @code{From} unless the conversion can fail, in which
case implement @code{TryFrom}.

@subsubheading Zero Runtime Cost

The newtype pattern is a @newterm{zero-cost abstraction}. The compiler
completely erases the type distinction during compilation, generating identical
machine code to using the wrapped type directly:

@example
struct Meters(f64);

fn distance_squared(d: Meters) -> f64 @{
    d.0 * d.0
@}

fn raw_distance_squared(d: f64) -> f64 @{
    d * d
@}

// Both functions compile to identical assembly:
// mulsd %xmm0, %xmm0
// ret
@end example

@noindent
We can verify this with cargo's assembly output:

@example
cargo rustc --release -- --emit asm
@end example

@noindent
This is the essence of Rust's philosophy: abstractions that provide safety and
clarity without sacrificing performance. The type checking happens entirely at
compile time; at runtime, a @code{Meters} is exactly an @code{f64}.

@subsubheading Newtypes in Practice: Validated Values

A powerful application of newtypes is enforcing invariants through construction:

@example
@cindex invariants
@cindex validated types
pub struct NonEmptyString(String);

impl NonEmptyString @{
    pub fn new(s: String) -> Option<Self> @{
        if s.is_empty() @{
            None
        @} else @{
            Some(NonEmptyString(s))
        @}
    @}

    // Guaranteed to be non-empty
    pub fn as_str(&self) -> &str @{
        &self.0
    @}
@}

// Once created, a NonEmptyString is guaranteed valid
fn process_name(name: NonEmptyString) @{
    // No need to check if empty---type system guarantees it
    println!("First character: @{@}", name.as_str().chars().next().unwrap());
@}
@end example

@noindent
This pattern, often called @newterm{parse, don't validate}, pushes validation
to the boundaries of the system. Once a value is wrapped in a validated
newtype, all subsequent code can trust its invariants without redundant checks.

@quotation
@strong{@anchor{Exercise 2.68a}Exercise 2.68a:} Design a library for working
with temperature values that supports Celsius, Fahrenheit, and Kelvin scales.
Create newtypes for each scale and implement conversions between them. Ensure
that Kelvin values cannot be negative (absolute zero is 0 K). Your implementation
should:

@enumerate
@item
Define newtypes @code{Celsius}, @code{Fahrenheit}, and @code{Kelvin}
@item
Implement a @code{new} method for @code{Kelvin} that returns @code{Option<Kelvin>}
to enforce the absolute zero constraint
@item
Implement @code{From} traits for conversions between all three scales
@item
Implement @code{Display} to show temperatures with their unit symbols
@item
Demonstrate that the compiler prevents mixing different temperature scales
@end enumerate

Conversion formulas:
@itemize @bullet
@item C = K - 273.15
@item F = C × 9/5 + 32
@item K = C + 273.15
@end itemize
@end quotation

@quotation
@strong{@anchor{Exercise 2.68b}Exercise 2.68b:} The @newterm{type state pattern}
uses newtypes to encode state machine transitions in the type system. Implement
a @code{Connection} type that can be in three states: @code{Disconnected},
@code{Connected}, and @code{Authenticated}. Each state should be represented by
a different type, and methods should only be available in appropriate states:

@example
struct Connection<State> @{
    address: String,
    state: PhantomData<State>,
@}

// State marker types
struct Disconnected;
struct Connected;
struct Authenticated;

impl Connection<Disconnected> @{
    fn new(address: String) -> Self @{ /* ... */ @}
    fn connect(self) -> Connection<Connected> @{ /* ... */ @}
@}

impl Connection<Connected> @{
    fn authenticate(self, password: &str) -> Option<Connection<Authenticated>> @{ /* ... */ @}
    fn disconnect(self) -> Connection<Disconnected> @{ /* ... */ @}
@}

impl Connection<Authenticated> @{
    fn send_data(&self, data: &[u8]) @{ /* ... */ @}
    fn disconnect(self) -> Connection<Disconnected> @{ /* ... */ @}
@}
@end example

@noindent
Complete the implementation so that:
@enumerate
@item
@code{send_data} is only available on authenticated connections
@item
@code{authenticate} is only available on connected (but not authenticated) connections
@item
State transitions consume the old state and return the new state
@item
The compiler prevents calling methods in the wrong state
@end enumerate

Demonstrate the API with example usage showing successful authentication and an
attempt to call @code{send_data} on an unauthenticated connection (which should
fail to compile).
@end quotation

The newtype pattern exemplifies Rust's approach to safety: by encoding
invariants in the type system, we move error detection from runtime to compile
time. This gives us the confidence to write complex systems knowing that entire
classes of bugs---unit confusion, identifier mix-ups, invalid state
transitions---are impossible by construction.

@node	2.4, 2.5, 2.3.4a, Chapter 2
@section 추상 데이터의 다중 표현 (Multiple Representations for Abstract Data)

우리는 데이터 추상화, 즉 시스템을 구조화하여 프로그램의 많은 부분이 프로그램이 조작하는 데이터 객체를 구현하는 데 관련된 선택과 독립적으로 지정될 수 있도록 하는 방법론을 소개했다.
예를 들어, 우리는 @ref{2.1.1}에서 유리수를 사용하는 프로그램을 설계하는 작업과 컴퓨터 언어의 복합 데이터 구성 원시 메커니즘의 관점에서 유리수를 구현하는 작업을 분리하는 방법을 보았다.
핵심 아이디어는 추상화 장벽을 세우는 것이었다---이 경우, 유리수에 대한 선택자와 생성자(@code{Rational::new}, @code{num}, @code{denom})---이것은 유리수가 사용되는 방식을 리스트 구조의 관점에서의 기본 표현으로부터 격리한다.
유사한 추상화 장벽이 유리수 산술 연산을 수행하는 프로시저(@code{add_rat}, @code{sub_rat}, @code{mul_rat}, 그리고 @code{div_rat})의 세부 사항을 유리수를 사용하는 ``더 높은 수준''의 프로시저로부터 격리한다.
결과 프로그램은 @ref{Figure 2.1}에 표시된 구조를 갖는다.

이러한 데이터 추상화 장벽은 복잡성을 제어하는 강력한 도구이다.
데이터 객체의 기본 표현을 격리함으로써, 우리는 대규모 프로그램을 설계하는 작업을 별도로 수행할 수 있는 더 작은 작업으로 나눌 수 있다.
하지만 이런 종류의 데이터 추상화는 아직 충분히 강력하지 않은데, 왜냐하면 데이터 객체에 대해 ``기본 표현''을 말하는 것이 항상 말이 되는 것은 아니기 때문이다.

우선, 데이터 객체에 대해 하나 이상의 유용한 표현이 있을 수 있으며, 우리는 다중 표현을 다룰 수 있는 시스템을 설계하고 싶을 수 있다.
간단한 예를 들자면, 복소수는 두 가지 거의 동등한 방식, 즉 직교 좌표 형식(실수부와 허수부)과 극좌표 형식(크기와 각도)으로 표현될 수 있다.
때로는 직교 좌표 형식이 더 적절하고 때로는 극좌표 형식이 더 적절하다.
실제로, 복소수가 두 가지 방식 모두로 표현되고 복소수를 조작하는 프로시저가 두 표현 중 하나와 작동하는 시스템을 상상하는 것은 완벽하게 타당하다.

더 중요한 것은, 프로그래밍 시스템이 종종 오랜 기간에 걸쳐 많은 사람들에 의해 설계되며, 시간이 지남에 따라 요구 사항이 변경된다는 점이다.
그러한 환경에서는 모든 사람이 데이터 표현의 선택에 대해 미리 동의하는 것이 단순히 불가능하다.
따라서 표현을 사용으로부터 격리하는 데이터 추상화 장벽 외에도, 우리는 서로 다른 설계 선택을 격리하고 단일 프로그램 내에 서로 다른 선택이 공존할 수 있도록 하는 추상화 장벽이 필요하다.
게다가, 대규모 프로그램은 종종 격리되어 설계된 기존 모듈을 결합하여 생성되므로, 우리는 프로그래머가 모듈을 다시 설계하거나 다시 구현할 필요 없이 더 큰 시스템에 @newterm{가법적으로(additively)} 통합할 수 있게 해주는 관습이 필요하다.

이 절에서 우리는 프로그램의 다른 부분에 의해 서로 다른 방식으로 표현될 수 있는 데이터에 대처하는 법을 배울 것이다.
이를 위해서는 @newterm{제네릭 프로시저(generic procedures)}---두 가지 이상의 방식으로 표현될 수 있는 데이터에 대해 작동할 수 있는 프로시저---를 구축해야 한다.
제네릭 프로시저를 구축하는 우리의 주요 기술은 @newterm{타입 태그(type tags)}를 가진 데이터 객체, 즉 데이터 객체가 어떻게 처리되어야 하는지에 대한 명시적인 정보를 포함하는 데이터 객체의 관점에서 작업하는 것이다.
우리는 또한 제네릭 연산을 가진 시스템을 가법적으로 조립하기 위한 강력하고 편리한 구현 전략인 @newterm{데이터 주도(data-directed)} 프로그래밍에 대해서도 논의할 것이다.

우리는 간단한 복소수 예제로 시작한다.
우리는 타입 태그와 데이터 주도 스타일이 어떻게 우리가 복소수에 대한 별도의 직교 좌표 및 극좌표 표현을 설계하면서도 추상적인 ``복소수'' 데이터 객체의 개념을 유지할 수 있게 해주는지 볼 것이다.
우리는 숫자가 어떻게 표현되는지와 무관하게 복소수의 부분에 접근하는 제네릭 선택자의 관점에서 복소수에 대한 산술 프로시저(@code{add_complex}, @code{sub_complex}, @code{mul_complex}, 그리고 @code{div_complex})를 정의함으로써 이것을 달성할 것이다.
결과적으로 얻어지는 복소수 시스템은 @ref{Figure 2.19}에 표시된 것처럼 두 가지 다른 종류의 추상화 장벽을 포함한다.
``수평'' 추상화 장벽은 @ref{Figure 2.1}에 있는 것들과 같은 역할을 한다.
그것들은 ``더 높은 수준''의 연산을 ``더 낮은 수준''의 표현으로부터 격리한다.
또한, 대안적인 표현을 개별적으로 설계하고 설치할 수 있는 능력을 제공하는 ``수직'' 장벽이 있다.

@float
@anchor{Figure 2.19}
@ifinfo
@quotation
@strong{Figure 2.19:} 복소수 시스템의 데이터 추상화 장벽.

@example
           Programs that use complex numbers
  +-------------------------------------------------+
--| add-complex sub-complex mul-complex div-complex |--
  +-------------------------------------------------+
              Complex arithmetic package
---------------------------+---------------------------
          Rectangular      |         Polar
        representation     |     representation
---------------------------+---------------------------
    List structure and primitive machine arithmetic
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap2/Fig2.19a,147mm,,,.std.svg}
@caption{@strong{Figure 2.19:} 복소수 시스템의 데이터 추상화 장벽.}
@end iftex
@end float

@noindent
@ref{2.5}에서 우리는 제네릭 산술 패키지를 개발하기 위해 타입 태그와 데이터 주도 스타일을 사용하는 방법을 보여줄 것이다.
이것은 모든 종류의 ``숫자''를 조작하는 데 사용될 수 있고 새로운 종류의 숫자가 필요할 때 쉽게 확장될 수 있는 프로시저(@code{add}, @code{mul} 등)를 제공한다.
@ref{2.5.3}에서, 우리는 기호 대수를 수행하는 시스템에서 제네릭 산술을 사용하는 방법을 보여줄 것이다.

@menu
* 2.4.1::            Representations for Complex Numbers
* 2.4.2::            Tagged data
* 2.4.3::            Data-Directed Programming and Additivity
* 2.4.3a::           Traits as Interfaces
@end menu

@node	2.4.1, 2.4.2, 2.4, 2.4
@subsection 복소수 표현 (Representations for Complex Numbers)

우리는 제네릭 연산을 사용하는 프로그램의 간단하지만 비현실적인 예로서 복소수에 대한 산술 연산을 수행하는 시스템을 개발할 것이다.
우리는 순서쌍으로서의 복소수에 대한 두 가지 그럴듯한 표현을 논의하는 것으로 시작한다: 직교 좌표 형식(실수부와 허수부)과 극좌표 형식(크기와 각도).@footnote{실제 계산 시스템에서는 직교 좌표 형식과 극좌표 형식 간의 변환 시 발생하는 반올림 오차 때문에 대부분의 경우 직교 좌표 형식이 극좌표 형식보다 선호된다. 이것이 복소수 예제가 비현실적인 이유이다. 그럼에도 불구하고, 이것은 제네릭 연산을 사용하는 시스템의 설계를 명확하게 보여주며, 이 장의 뒷부분에서 개발될 더 실질적인 시스템에 대한 좋은 소개가 된다.}
@ref{2.4.2} 절은 타입 태그와 제네릭 연산을 사용하여 두 표현이 단일 시스템 내에 공존하도록 만드는 방법을 보여줄 것이다.

유리수와 마찬가지로, 복소수는 자연스럽게 순서쌍으로 표현된다.
복소수 집합은 두 개의 직교하는 축, 즉 ``실수'' 축과 ``허수'' 축을 가진 2차원 공간으로 생각할 수 있다. (@ref{Figure 2.20}을 보라.)
이 관점에서, 복소수 @math{{z = x + iy}} (여기서 @math{{i^{\kern0.1em 2} = \text{−1}}})는 실수 좌표가 @math{x}이고 허수 좌표가 @math{y}인 평면상의 점으로 생각할 수 있다.
복소수의 덧셈은 이 표현에서 좌표의 덧셈으로 환원된다:
@ifinfo

@example
Real-part(z_1 + z_2) = Real-part(z_1) + Real-part(z_2)

Imaginary-part(z_1 + z_2) = Imaginary-part(z_1) + Imaginary-part(z_2)
@end example

@end ifinfo
@tex
\[ % :46:
\begin{eqnarray}
\text{Real-part} (z_1 + z_2) 	    &=& \text{Real-part} (z_1) + \\
                                    & & \text{Real-part} (z_2),  \\
\text{Imaginary-part} (z_1 + z_2)   &=& \text{Imaginary-part} (z_1) + \\
                                    & & \text{Imaginary-part} (z_2).
\end{eqnarray}
\]
@end tex

@float
@anchor{Figure 2.20}
@ifinfo
@strong{Figure 2.20:} 평면상의 점으로서의 복소수.

@example
 Imaginary
    ^
    |
  y |.........................* z = x + ?y = r e^(?A)
    |                    __-- .
    |                __--     .
    |          r __--         .
    |        __--             .
    |    __-- \               .
    |__--    A |              .
----+----------+-------------------> Real
                              x
@end example
@end ifinfo
@iftex
@image{fig/chap2/Fig2.20,147mm,,,.std.svg}
@caption{@strong{Figure 2.20:} 평면상의 점으로서의 복소수.}
@end iftex
@end float

@noindent
복소수를 곱할 때는 복소수를 극좌표 형식, 즉 크기와 각도(@ref{Figure 2.20}의 @math{r}과 @math{A})로 표현하는 관점에서 생각하는 것이 더 자연스럽다.
두 복소수의 곱은 한 복소수를 다른 복소수의 길이만큼 늘리고 다른 복소수의 각도만큼 회전시켜 얻은 벡터이다:
@ifinfo

@example
Magnitude(z_1 * z_2) = Magnitude(z_1) * Magnitude(z_2)

Angle(z_1 * z_2) = Angle(z_1) + Angle(z_2)
@end example

@end ifinfo
@tex
\[ % :47:
\begin{eqnarray}
  \text{Magnitude} (z_1 \cdot z_2)  &=& 
    \text{Magnitude} (z_1) \cdot \text{Magnitude} (z_2), \\
  \text{Angle} (z_1 \cdot z_2)      &=& 
    \text{Angle} (z_1) + \text{Angle} (z_2).
\end{eqnarray}
\]
@end tex

@noindent
따라서 복소수에는 서로 다른 연산에 적합한 두 가지 다른 표현이 있다.
하지만 복소수를 사용하는 프로그램을 작성하는 사람의 관점에서는, 데이터 추상화의 원칙에 따라 컴퓨터가 어떤 표현을 사용하든 복소수를 조작하는 모든 연산을 사용할 수 있어야 한다.
예를 들어, 직교 좌표로 지정된 복소수의 크기를 찾을 수 있는 것은 종종 유용하다.
마찬가지로, 극좌표로 지정된 복소수의 실수부를 결정할 수 있는 것도 종종 유용하다.

그러한 시스템을 설계하기 위해, 우리는 @ref{2.1.1}의 유리수 패키지를 설계할 때 따랐던 것과 같은 데이터 추상화 전략을 따를 수 있다.
복소수에 대한 연산들이 네 개의 선택자 @code{real_part}, @code{imag_part}, @code{magnitude}, 그리고 @code{angle}의 관점에서 구현되었다고 가정하자.
또한 지정된 실수부와 허수부를 가진 복소수를 반환하는 @code{make_from_real_imag}와 지정된 크기와 각도를 가진 복소수를 반환하는 @code{make_from_mag_ang}, 이 두 프로시저가 있다고 가정하자.
이 프로시저들은 어떤 복소수 @code{z}에 대해서도

@example
make_from_real_imag(z.real_part(), z.imag_part())
@end example

@noindent
와

@example
make_from_mag_ang(z.magnitude(), z.angle())
@end example

@noindent
모두 @code{z}와 같은 복소수를 생성하는 성질을 갖는다.

이 생성자와 선택자를 사용하여, 우리는 @ref{2.1.1}에서 유리수에 대해 그랬던 것처럼 생성자와 선택자에 의해 지정된 ``추상 데이터''를 사용하여 복소수에 대한 산술 연산을 구현할 수 있다.
위의 공식에 표시된 것처럼, 우리는 실수부와 허수부의 관점에서 복소수를 더하고 뺄 수 있으며, 크기와 각도의 관점에서 복소수를 곱하고 나눌 수 있다:

@example
fn add_complex(z1: &impl ComplexOps, z2: &impl ComplexOps) -> Complex @{
    make_from_real_imag(
        z1.real_part() + z2.real_part(),
        z1.imag_part() + z2.imag_part())
@}

fn sub_complex(z1: &impl ComplexOps, z2: &impl ComplexOps) -> Complex @{
    make_from_real_imag(
        z1.real_part() - z2.real_part(),
        z1.imag_part() - z2.imag_part())
@}

fn mul_complex(z1: &impl ComplexOps, z2: &impl ComplexOps) -> Complex @{
    make_from_mag_ang(
        z1.magnitude() * z2.magnitude(),
        z1.angle() + z2.angle())
@}

fn div_complex(z1: &impl ComplexOps, z2: &impl ComplexOps) -> Complex @{
    make_from_mag_ang(
        z1.magnitude() / z2.magnitude(),
        z1.angle() - z2.angle())
@}
@end example

@noindent
복소수 패키지를 완성하기 위해, 우리는 표현을 선택해야 하고 원시 숫자와 원시 리스트 구조의 관점에서 생성자와 선택자를 구현해야 한다.
이를 수행하는 두 가지 명백한 방법이 있다: 우리는 복소수를 쌍(실수부, 허수부)인 ``직교 좌표 형식''으로 표현하거나 쌍(크기, 각도)인 ``극좌표 형식''으로 표현할 수 있다.
어떤 것을 선택해야 할까?

서로 다른 선택을 구체적으로 만들기 위해, 두 프로그래머 Ben Bitdiddle과 Alyssa P. Hacker가 독립적으로 복소수 시스템을 위한 표현을 설계하고 있다고 상상해 보자.
Ben은 복소수를 직교 좌표 형식으로 표현하기로 선택한다.
이 선택으로 복소수의 실수부와 허수부를 선택하는 것은 간단하며, 주어진 실수부와 허수부로 복소수를 구성하는 것도 그렇다.
크기와 각도를 찾거나 주어진 크기와 각도로 복소수를 구성하기 위해, 그는 다음 삼각 관계식을 사용한다.

@ifinfo

@example
                      __________
x = r cos A     r = ./ x^2 + y^2

y = r sin A     A = arctan(y,x)
@end example

@end ifinfo
@tex
\[ % :48:
\begin{eqnarray}
  x &=& r \cos A, \\
  y &=& r \sin A, \\
  r &=& \sqrt{x^2 + y^2,} \\
  A &=& \arctan(y, x),
\end{eqnarray}
\]
@end tex

@noindent
이것은 실수부와 허수부 @math{{(x, y)}}를 크기와 각도 @math{{(r, A)}}와 연관시킨다.@footnote{여기서 언급된 아크탄젠트 함수는 Scheme의 @code{atan} 프로시저로 계산되며, 두 인자 @math{y}와 @math{x}를 받아 탄젠트가 @math{{y / x}}인 각도를 반환하도록 정의된다. 인자의 부호가 각도의 사분면을 결정한다.}
따라서 Ben의 표현은 다음 선택자와 생성자로 주어진다:

@example
// Ben의 직교 좌표 표현
struct Rectangular @{
    x: f64,
    y: f64,
@}

impl Rectangular @{
    fn real_part(&self) -> f64 @{ self.x @}
    fn imag_part(&self) -> f64 @{ self.y @}

    fn magnitude(&self) -> f64 @{
        (self.real_part().powi(2) + self.imag_part().powi(2)).sqrt()
    @}

    fn angle(&self) -> f64 @{
        self.imag_part().atan2(self.real_part())
    @}

    fn make_from_real_imag(x: f64, y: f64) -> Self @{
        Rectangular @{ x, y @}
    @}

    fn make_from_mag_ang(r: f64, a: f64) -> Self @{
        Rectangular @{ x: r * a.cos(), y: r * a.sin() @}
    @}
@}
@end example

@noindent
대조적으로, Alyssa는 복소수를 극좌표 형식으로 표현하기로 선택한다.
그녀에게는 크기와 각도를 선택하는 것은 간단하지만, 실수부와 허수부를 얻기 위해 삼각 관계식을 사용해야 한다.
Alyssa의 표현은 다음과 같다:

@example
// Alyssa의 극좌표 표현
struct Polar @{
    r: f64,
    angle: f64,
@}

impl Polar @{
    fn real_part(&self) -> f64 @{
        self.magnitude() * self.angle().cos()
    @}

    fn imag_part(&self) -> f64 @{
        self.magnitude() * self.angle().sin()
    @}

    fn magnitude(&self) -> f64 @{ self.r @}
    fn angle(&self) -> f64 @{ self.angle @}

    fn make_from_real_imag(x: f64, y: f64) -> Self @{
        Polar @{
            r: (x.powi(2) + y.powi(2)).sqrt(),
            angle: y.atan2(x),
        @}
    @}

    fn make_from_mag_ang(r: f64, a: f64) -> Self @{
        Polar @{ r, angle: a @}
    @}
@}
@end example

@noindent
데이터 추상화 규율은 @code{add_complex}, @code{sub_complex}, @code{mul_complex}, 그리고 @code{div_complex}의 동일한 구현이 Ben의 표현이나 Alyssa의 표현 모두와 작동하도록 보장한다.

@node	2.4.2, 2.4.3, 2.4.1, 2.4
@subsection 태그된 데이터 (Tagged data)

데이터 추상화를 보는 한 가지 방법은 ``최소 약속의 원칙(principle of least commitment)''의 적용으로 보는 것이다.
@ref{2.4.1}에서 복소수 시스템을 구현할 때, 우리는 Ben의 직교 좌표 표현이나 Alyssa의 극좌표 표현 중 하나를 사용할 수 있다.
선택자와 생성자에 의해 형성된 추상화 장벽은 데이터 객체에 대한 구체적인 표현의 선택을 가능한 한 마지막 순간까지 미룰 수 있게 해주며, 따라서 시스템 설계에 있어 최대한의 유연성을 유지하게 해준다.

최소 약속의 원칙은 훨씬 더 극단적으로 적용될 수 있다.
원한다면 우리는 선택자와 생성자를 설계한 @emph{후에도} 표현의 모호성을 유지할 수 있으며, Ben의 표현 @emph{과} Alyssa의 표현을 모두 사용하기로 결정할 수 있다.
그러나 두 표현이 단일 시스템에 포함된다면, 우리는 극좌표 형식의 데이터와 직교 좌표 형식의 데이터를 구별할 방법이 필요하다.
그렇지 않고 예를 들어 쌍 (3, 4)의 @code{magnitude}를 찾으라고 요청받았다면, 우리는 5(숫자를 직교 좌표 형식으로 해석할 때)라고 답해야 할지 3(숫자를 극좌표 형식으로 해석할 때)이라고 답해야 할지 모를 것이다.
이 구별을 달성하는 간단한 방법은 각 복소수의 일부로 @newterm{타입 태그(type tag)}---기호 @code{rectangular} 또는 @code{polar}---를 포함시키는 것이다.
그러면 우리가 복소수를 조작해야 할 때 태그를 사용하여 어떤 선택자를 적용할지 결정할 수 있다.

태그된 데이터를 조작하기 위해, 우리는 데이터 객체에서 태그와 실제 내용(복소수의 경우 극좌표 또는 직교 좌표)을 추출하는 프로시저 @code{type_tag}와 @code{contents}가 있다고 가정할 것이다.
우리는 또한 태그와 내용을 받아 태그된 데이터 객체를 생성하는 프로시저 @code{attach_tag}를 가정할 것이다.
이를 구현하는 간단한 방법은 일반적인 리스트 구조를 사용하는 것이다:

@example
// Rust 열거형을 사용한 태그된 데이터
enum Complex @{
    Rectangular(f64, f64),  // (x, y)
    Polar(f64, f64),        // (r, angle)
@}

impl Complex @{
    // 패턴 매칭이 자동으로 타입 태그를 처리한다
    fn type_tag(&self) -> &str @{
        match self @{
            Complex::Rectangular(_, _) => "rectangular",
            Complex::Polar(_, _) => "polar",
        @}
    @}

    fn contents(&self) -> (f64, f64) @{
        match self @{
            Complex::Rectangular(x, y) => (*x, *y),
            Complex::Polar(r, a) => (*r, *a),
        @}
    @}
@}
@end example

@noindent
이 프로시저들을 사용하여, 우리는 직교 좌표와 극좌표 숫자를 각각 인식하는 술어 @code{rectangular?}와 @code{polar?}를 정의할 수 있다:

@example
impl Complex @{
    fn is_rectangular(&self) -> bool @{
        matches!(self, Complex::Rectangular(_, _))
    @}

    fn is_polar(&self) -> bool @{
        matches!(self, Complex::Polar(_, _))
    @}
@}
@end example

@noindent
타입 태그를 사용하면, Ben과 Alyssa는 이제 그들의 두 가지 다른 표현이 동일한 시스템 내에 공존할 수 있도록 코드를 수정할 수 있다.
Ben이 복소수를 구성할 때마다, 그는 그것을 직교 좌표로 태그한다.
Alyssa가 복소수를 구성할 때마다, 그녀는 그것을 극좌표로 태그한다.
또한, Ben과 Alyssa는 그들의 프로시저 이름이 충돌하지 않도록 해야 한다.
이를 수행하는 한 가지 방법은 Ben이 그의 각 표현 프로시저 이름 뒤에 접미사 @code{rectangular}를 붙이고 Alyssa는 그녀의 것에 @code{polar}를 붙이는 것이다.
다음은 @ref{2.4.1}에서 수정된 Ben의 직교 좌표 표현이다:

@example
// Ben의 직교 좌표 표현을 열거형 변형으로
#[derive(Debug, Clone)]
enum Complex @{
    Rectangular(f64, f64),  // (real, imag)
    Polar(f64, f64),        // (magnitude, angle)
@}

impl Complex @{
    fn make_from_real_imag(x: f64, y: f64) -> Self @{
        Complex::Rectangular(x, y)
    @}

    fn make_from_mag_ang(r: f64, a: f64) -> Self @{
        Complex::Polar(r, a)
    @}
@}
@end example

@noindent
Rust에서 극좌표 표현은 단순히 @code{Complex} 열거형의 또 다른 변형이다.
타입 시스템은 패턴 매칭을 통해 올바른 디스패치를 보장한다:

@noindent
각 제네릭 선택자는 인자의 태그를 확인하고 해당 유형의 데이터를 처리하기 위한 적절한 프로시저를 호출하는 프로시저로 구현된다.
예를 들어, 복소수의 실수부를 얻기 위해, @code{real_part}는 태그를 검사하여 Ben의 @code{real-part-rectangular}를 사용할지 Alyssa의 @code{real-part-polar}를 사용할지 결정한다.
어느 경우든, 우리는 @code{contents}를 사용하여 태그 없는 데이터를 추출하고 이를 필요에 따라 직교 좌표 또는 극좌표 프로시저로 보낸다:

@example
// 패턴 매칭을 사용한 제네릭 선택자
trait ComplexOps @{
    fn real_part(&self) -> f64;
    fn imag_part(&self) -> f64;
    fn magnitude(&self) -> f64;
    fn angle(&self) -> f64;
@}

impl ComplexOps for Complex @{
    fn real_part(&self) -> f64 @{
        match self @{
            Complex::Rectangular(x, _y) => *x,
            Complex::Polar(r, a) => r * a.cos(),
        @}
    @}

    fn imag_part(&self) -> f64 @{
        match self @{
            Complex::Rectangular(_x, y) => *y,
            Complex::Polar(r, a) => r * a.sin(),
        @}
    @}

    fn magnitude(&self) -> f64 @{
        match self @{
            Complex::Rectangular(x, y) =>
                (x.powi(2) + y.powi(2)).sqrt(),
            Complex::Polar(r, _a) => *r,
        @}
    @}

    fn angle(&self) -> f64 @{
        match self @{
            Complex::Rectangular(x, y) => y.atan2(*x),
            Complex::Polar(_r, a) => *a,
        @}
    @}
@}
@end example

@noindent
복소수 산술 연산을 구현하기 위해, 우리는 @ref{2.4.1}의 동일한 프로시저 @code{add_complex}, @code{sub_complex}, @code{mul_complex}, 그리고 @code{div_complex}를 사용할 수 있다. 왜냐하면 이들이 호출하는 선택자들이 제네릭이며, 따라서 어떤 표현과도 작동할 것이기 때문이다.
예를 들어, 프로시저 @code{add_complex}는 여전히 다음과 같다

@example
fn add_complex(z1: &Complex, z2: &Complex) -> Complex @{
    Complex::make_from_real_imag(
        z1.real_part() + z2.real_part(),
        z1.imag_part() + z2.imag_part(),
    )
@}
@end example

@noindent
마지막으로, 우리는 복소수를 Ben의 표현을 사용하여 구성할지 Alyssa의 표현을 사용하여 구성할지 선택해야 한다.
한 가지 합리적인 선택은 실수부와 허수부가 있을 때는 직교 좌표 숫자를 구성하고 크기와 각도가 있을 때는 극좌표 숫자를 구성하는 것이다:

@example
// 최상위 생성자는 적절한 표현에 위임한다
fn make_from_real_imag(x: f64, y: f64) -> Complex @{
    Complex::Rectangular(x, y)  // 실수/허수를 위해 직교 좌표 사용
@}

fn make_from_mag_ang(r: f64, a: f64) -> Complex @{
    Complex::Polar(r, a)  // 크기/각도를 위해 극좌표 사용
@}
@end example

@noindent
결과적인 복소수 시스템은 @ref{Figure 2.21}에 표시된 구조를 갖는다.
시스템은 상대적으로 독립적인 세 부분으로 분해되었다: 복소수 산술 연산, Alyssa의 극좌표 구현, 그리고 Ben의 직교 좌표 구현.
극좌표와 직교 좌표 구현은 Ben과 Alyssa가 따로 작업하여 작성할 수 있었으며, 이 둘 모두 제 3의 프로그래머가 추상 생성자/선택자 인터페이스의 관점에서 복소수 산술 프로시저를 구현할 때 기본 표현으로 사용할 수 있다.

@float
@anchor{Figure 2.21}
@ifinfo
@quotation
@strong{Figure 2.21:} 제네릭 복소수 산술 시스템의 구조.

@example
    +-------------------------------------------------+
----| add-complex sub-complex mul-complex div-complex |----
    +-------------------------------------------------+
                Complex arithmetic package
                 +-----------------------+
                 | real-part   imag-part |
-----------------|                       |------------------
                 | magnitude   angle     |
                 +-----------+-----------+
           Rectangular       |          Polar
          representation     |     representation
-----------------------------+------------------------------
       List structure and primitive machine arithmetic
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap2/Fig2.21a,147mm,,,.std.svg}
@caption{@strong{Figure 2.21:} 제네릭 복소수 산술 시스템의 구조.}
@end iftex
@end float

각 데이터 객체가 그 타입으로 태그되어 있으므로, 선택자들은 데이터에 대해 제네릭 방식으로 작동한다.
즉, 각 선택자는 적용되는 데이터의 특정 타입에 따라 달라지는 동작을 갖도록 정의된다.
별도의 표현들을 인터페이싱하기 위한 일반적인 메커니즘에 주목하라: 주어진 표현 구현(예: Alyssa의 극좌표 패키지) 내에서 복소수는 타입 없는 쌍(크기, 각도)이다.
제네릭 선택자가 @code{polar} 타입의 숫자에 대해 작동할 때, 그것은 태그를 떼어내고 내용을 Alyssa의 코드로 전달한다.
반대로, Alyssa가 일반적인 사용을 위해 숫자를 구성할 때, 그녀는 상위 수준 프로시저가 적절하게 인식할 수 있도록 그것을 타입으로 태그한다.
데이터 객체가 한 레벨에서 다른 레벨로 전달될 때 태그를 떼어내고 붙이는 이 규율은 중요한 조직화 전략이 될 수 있으며, 우리는 @ref{2.5}에서 이를 보게 될 것이다.

@node	2.4.3, 2.4.3a, 2.4.2, 2.4
@subsection 데이터 주도 프로그래밍과 가법성 (Data-Directed Programming and Additivity)

데이터의 타입을 확인하고 적절한 프로시저를 호출하는 일반적인 전략을 @newterm{타입에 따른 디스패치(dispatching on type)}라고 한다.
이것은 시스템 설계에서 모듈성을 얻기 위한 강력한 전략이다.
반면, @ref{2.4.2}에서처럼 디스패치를 구현하는 것은 두 가지 중요한 약점을 가지고 있다.
한 가지 약점은 제네릭 인터페이스 프로시저(@code{real_part}, @code{imag_part}, @code{magnitude}, 그리고 @code{angle})가 모든 다른 표현에 대해 알아야 한다는 것이다.
예를 들어, 우리가 복소수 시스템에 새로운 복소수 표현을 통합하고 싶다고 가정해 보자.
우리는 이 새로운 표현을 타입으로 식별해야 하고, 그 다음 각 제네릭 인터페이스 프로시저에 절을 추가하여 새 타입을 확인하고 해당 표현에 적합한 선택자를 적용하도록 해야 한다.

이 기술의 또 다른 약점은 개별 표현이 별도로 설계될 수 있다 하더라도, 전체 시스템에서 두 프로시저가 같은 이름을 갖지 않도록 보장해야 한다는 것이다.
이것이 Ben과 Alyssa가 @ref{2.4.1}에서 그들의 원래 프로시저 이름을 변경해야 했던 이유이다.

이 두 약점의 근본적인 문제는 제네릭 인터페이스를 구현하는 기술이 @newterm{가법적(additive)}이지 않다는 것이다.
제네릭 선택자 프로시저를 구현하는 사람은 새로운 표현이 설치될 때마다 그 프로시저들을 수정해야 하고, 개별 표현을 인터페이싱하는 사람들은 이름 충돌을 피하기 위해 코드를 수정해야 한다.
이러한 각 경우에, 코드에 가해져야 할 변경은 간단하지만, 그럼에도 불구하고 변경이 이루어져야 하며, 이것은 불편함과 오류의 원천이다.
이것은 현재 상태의 복소수 시스템에는 큰 문제가 아니지만, 복소수에 대해 두 가지가 아니라 수백 가지의 다른 표현이 있다고 가정해 보라.
그리고 추상 데이터 인터페이스에 유지되어야 할 많은 제네릭 선택자가 있다고 가정해 보라.
사실상, 어떤 프로그래머도 모든 인터페이스 프로시저나 모든 표현을 알지 못한다고 가정해 보라.
문제는 실제적이며 대규모 데이터베이스 관리 시스템과 같은 프로그램에서는 반드시 해결되어야 한다.

우리에게 필요한 것은 시스템 설계를 더욱 모듈화하는 수단이다.
이것은 @newterm{데이터 주도 프로그래밍(data-directed programming)}으로 알려진 프로그래밍 기술에 의해 제공된다.
데이터 주도 프로그래밍이 어떻게 작동하는지 이해하기 위해, 서로 다른 타입들의 집합에 공통적인 제네릭 연산들의 집합을 다룰 때마다 우리는 사실상 한 축에는 가능한 연산들이 있고 다른 축에는 가능한 타입들이 있는 2차원 테이블을 다루고 있다는 관찰로 시작하자.
테이블의 항목(entry)들은 제시된 각 타입의 인자에 대해 각 연산을 구현하는 프로시저들이다.
이전 절에서 개발된 복소수 시스템에서, 연산 이름, 데이터 타입, 그리고 실제 프로시저 사이의 대응 관계는 다양한 제네릭 인터페이스 프로시저의 조건부 절들 사이에 흩어져 있었다.
하지만 같은 정보가 @ref{Figure 2.22}에 표시된 것처럼 테이블로 조직될 수 있었다.

@float
@anchor{Figure 2.22}
@ifinfo
@quotation
@strong{Figure 2.22:} 복소수 시스템을 위한 연산 테이블.

@example
           |               Types
Operations | Polar           | Rectangular
===========+=================+======================
real-part  | real-part-polar | real-part-rectangular
imag-part  | imag-part-polar | imag-part-rectangular
magnitude  | magnitude-polar | magnitude-rectangular
angle      | angle-polar     | angle-rectangular
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap2/Fig2.22,147mm,,,.std.svg}
@caption{@strong{Figure 2.22:} 복소수 시스템을 위한 연산 테이블.}
@end iftex
@end float

@noindent
데이터 주도 프로그래밍은 그러한 테이블과 직접 작동하도록 프로그램을 설계하는 기술이다.
이전에는, 복소수 산술 코드와 두 표현 패키지를 인터페이싱하는 메커니즘을 각각 타입에 대해 명시적인 디스패치를 수행하는 프로시저들의 집합으로 구현했다.
여기서 우리는 인터페이스를 단일 프로시저로 구현할 것이다. 이 프로시저는 연산 이름과 인자 타입의 조합을 테이블에서 찾아 적용할 올바른 프로시저를 찾은 다음, 인자의 내용에 그것을 적용한다.
우리가 이렇게 한다면, 시스템에 새로운 표현 패키지를 추가하기 위해 기존 프로시저를 변경할 필요가 없다; 우리는 단지 테이블에 새로운 항목을 추가하기만 하면 된다.

이 계획을 구현하기 위해, 연산 및 타입 테이블을 조작하기 위한 두 프로시저 @code{put}과 @code{get}이 있다고 가정하자:

@itemize @bullet

@item
@code{(put ⟨@var{op}⟩ ⟨@var{type}⟩ ⟨@var{item}⟩)}은 
@code{⟨}@var{op}@code{⟩}와 @code{⟨}@var{type}@code{⟩}으로 인덱싱된 테이블에 
@code{⟨}@var{item}@code{⟩}을 설치한다.

@item
@code{(get ⟨@var{op}⟩ ⟨@var{type}⟩)}은 테이블에서 @code{⟨}@var{op}@code{⟩}, 
@code{⟨}@var{type}@code{⟩} 항목을 찾아서 거기에 있는 항목을 반환한다.
항목이 발견되지 않으면, @code{get}은 거짓을 반환한다.

@end itemize

@noindent
지금은, @code{put}과 @code{get}이 우리 언어에 포함되어 있다고 가정할 수 있다.
@ref{Chapter 3} (@ref{3.3.3})에서 우리는 테이블을 조작하기 위한 이 연산들과 다른 연산들을 구현하는 방법을 보게 될 것이다.

다음은 복소수 시스템에서 데이터 주도 프로그래밍이 어떻게 사용될 수 있는지 보여준다.
직교 좌표 표현을 개발한 Ben은 원래 그랬던 것처럼 코드를 구현한다.
그는 프로시저들의 컬렉션, 즉 @newterm{패키지(package)}를 정의하고, 직교 좌표 숫자에 대해 시스템이 어떻게 작동해야 하는지 알려주는 항목들을 테이블에 추가함으로써 이것들을 시스템의 나머지 부분에 인터페이싱한다.
이것은 다음 프로시저를 호출함으로써 달성된다:

@example
fn install_rectangular_package(table: &mut OperationTable) @{
    // internal procedures
    fn real_part(x: f64, _y: f64) -> f64 @{ x @}
    fn imag_part(_x: f64, y: f64) -> f64 @{ y @}

    fn magnitude(x: f64, y: f64) -> f64 @{
        (x.powi(2) + y.powi(2)).sqrt()
    @}

    fn angle(x: f64, y: f64) -> f64 @{
        y.atan2(x)
    @}

    // interface to the rest of the system
    table.put("real-part", "rectangular",
        Box::new(real_part));
    table.put("imag-part", "rectangular",
        Box::new(imag_part));
    table.put("magnitude", "rectangular",
        Box::new(magnitude));
    table.put("angle", "rectangular",
        Box::new(angle));

    table.put_constructor("make_from_real_imag", "rectangular",
        Box::new(|x, y| Complex::Rectangular(x, y)));

    table.put_constructor("make_from_mag_ang", "rectangular",
        Box::new(|r, a| Complex::Rectangular(r * a.cos(), r * a.sin())));
@}
@end example

@noindent
여기서 내부 프로시저들은 Ben이 격리되어 작업할 때 작성했던 @ref{2.4.1}의 프로시저들과 동일하다는 점에 주목하라.
이것들을 시스템의 나머지 부분에 인터페이싱하기 위해 어떤 변경도 필요하지 않다.
게다가, 이 프로시저 정의들은 설치 프로시저 내부에 있으므로, Ben은 직교 좌표 패키지 외부의 다른 프로시저들과의 이름 충돌에 대해 걱정할 필요가 없다.
이것들을 시스템의 나머지 부분에 인터페이싱하기 위해, Ben은 그의 @code{real_part} 프로시저를 연산 이름 @code{real_part}와 타입 @code{(rectangular)} 아래에 설치하며, 다른 선택자들도 마찬가지이다.@footnote{우리는 타입이 모두 같지 않은 다중 인자를 가진 연산의 가능성을 허용하기 위해 기호 @code{rectangular} 대신 리스트 @code{(rectangular)}를 사용한다.}
인터페이스는 또한 외부 시스템에서 사용될 생성자들을 정의한다.@footnote{생성자는 항상 특정 타입의 객체 하나를 만드는 데 사용되므로 생성자가 설치되는 타입은 리스트일 필요가 없다.}
이것들은 태그를 붙인다는 점을 제외하면 Ben의 내부적으로 정의된 생성자들과 동일하다.

Alyssa의 극좌표 패키지도 유사하다:

@example
fn install_polar_package(table: &mut OperationTable) @{
    // internal procedures
    fn magnitude(r: f64, _angle: f64) -> f64 @{ r @}
    fn angle(_r: f64, angle: f64) -> f64 @{ angle @}

    fn real_part(r: f64, angle: f64) -> f64 @{
        r * angle.cos()
    @}

    fn imag_part(r: f64, angle: f64) -> f64 @{
        r * angle.sin()
    @}

    // interface to the rest of the system
    table.put("real-part", "polar",
        Box::new(real_part));
    table.put("imag-part", "polar",
        Box::new(imag_part));
    table.put("magnitude", "polar",
        Box::new(magnitude));
    table.put("angle", "polar",
        Box::new(angle));

    table.put_constructor("make_from_real_imag", "polar",
        Box::new(|x, y| Complex::Polar(
            (x.powi(2) + y.powi(2)).sqrt(), y.atan2(x))));

    table.put_constructor("make_from_mag_ang", "polar",
        Box::new(|r, a| Complex::Polar(r, a)));
@}
@end example

@noindent
Ben과 Alyssa 둘 다 여전히 서로 같은 이름(예: @code{real_part})으로 정의된 원래의 프로시저들을 사용하지만, 이 정의들은 이제 서로 다른 프로시저 내부에 있으므로(@ref{1.1.8} 참조), 이름 충돌은 없다.

복소수 산술 선택자들은 @code{apply-generic}이라는 일반적인 ``연산'' 프로시저를 통해 테이블에 접근하는데, 이것은 제네릭 연산을 일부 인자에 적용한다.
@code{Apply-generic}은 테이블에서 연산 이름과 인자들의 타입을 찾아보고 만약 존재한다면 결과 프로시저를 적용한다:@footnote{@code{Apply-generic}은 @ref{Exercise 2.20}에서 설명된 점선 꼬리(dotted-tail) 표기법을 사용하는데, 왜냐하면 서로 다른 제네릭 연산이 서로 다른 수의 인자를 취할 수 있기 때문이다. @code{apply-generic}에서, @code{op}는 @code{apply-generic}에 대한 첫 번째 인자를 값으로 갖고 @code{args}는 나머지 인자들의 리스트를 값으로 갖는다.

@code{Apply-generic}은 또한 원시 프로시저 @code{apply}를 사용하는데, 이것은 두 인자, 프로시저와 리스트를 받는다. @code{Apply}는 리스트의 요소들을 인자로 사용하여 프로시저를 적용한다. 예를 들어,

@example
// In Rust: [1, 2, 3, 4].iter().sum::<i32>()
// => 10
@end example

@noindent
는 10을 반환한다.}

@example
fn apply_generic(op: &str, z: &Complex,
                 table: &OperationTable) -> f64 @{
    let type_tag = z.type_tag();
    let contents = z.contents();

    if let Some(proc) = table.get(op, type_tag) @{
        proc(contents.0, contents.1)
    @} else @{
        panic!("No method for type: @{@} (@{@})", op, type_tag)
    @}
@}
@end example

@noindent
@code{apply-generic}을 사용하여, 우리는 제네릭 선택자를 다음과 같이 정의할 수 있다:

@example
fn real_part(z: &Complex, table: &OperationTable) -> f64 @{
    apply_generic("real-part", z, table)
@}

fn imag_part(z: &Complex, table: &OperationTable) -> f64 @{
    apply_generic("imag-part", z, table)
@}

fn magnitude(z: &Complex, table: &OperationTable) -> f64 @{
    apply_generic("magnitude", z, table)
@}

fn angle(z: &Complex, table: &OperationTable) -> f64 @{
    apply_generic("angle", z, table)
@}
@end example

@noindent
새로운 표현이 시스템에 추가되더라도 이것들은 전혀 변하지 않는다는 것을 관찰하라.

우리는 또한 실수부와 허수부로부터, 그리고 크기와 각도로부터 복소수를 만들기 위해 패키지 외부의 프로그램들이 사용할 생성자들을 테이블에서 추출할 수 있다.
@ref{2.4.2}에서처럼, 우리는 실수부와 허수부가 있을 때는 직교 좌표 숫자를 구성하고, 크기와 각도가 있을 때는 극좌표 숫자를 구성한다:

@example
fn make_from_real_imag(x: f64, y: f64, table: &OperationTable) -> Complex @{
    let constructor = table.get("make_from_real_imag", "rectangular")
        .expect("constructor not found");
    constructor(x, y)
@}

fn make_from_mag_ang(r: f64, a: f64, table: &OperationTable) -> Complex @{
    let constructor = table.get("make_from_mag_ang", "polar")
        .expect("constructor not found");
    constructor(r, a)
@}
@end example

@quotation
@strong{@anchor{Exercise 2.73}연습문제 2.73:} @ref{2.3.2}는 기호 미분을 수행하는 프로그램을 설명했다:

@example
fn deriv(exp: &Expr, var: &str) -> Expr @{
    match exp @{
        Expr::Const(_) => Expr::Const(0.0),
        Expr::Var(v) => @{
            if *v == var @{ Expr::Const(1.0) @} else @{ Expr::Const(0.0) @}
        @}
        Expr::Sum(a, b) => make_sum(
            deriv(a, var),
            deriv(b, var),
        ),
        Expr::Product(m, c) => make_sum(
            make_product((**m).clone(), deriv(c, var)),
            make_product(deriv(m, var), (**c).clone()),
        ),
        // 새로운 열거형 변형을 통해 더 많은 규칙을 추가할 수 있다
    @}
@}
@end example

우리는 이 프로그램이 미분될 표현식의 타입에 대해 디스패치를 수행하는 것으로 간주할 수 있다.
이 상황에서 데이터의 ``타입 태그''는 대수 연산자 기호(@code{+}와 같은)이고 수행되는 연산은 @code{deriv}이다.
우리는 기본 미분 프로시저를 다음과 같이 다시 작성함으로써 이 프로그램을 데이터 주도 스타일로 변환할 수 있다

@example
fn deriv(exp: &Expr, var: &str, table: &DerivTable) -> Expr @{
    match exp @{
        Expr::Const(_) => Expr::Const(0.0),
        Expr::Var(v) => @{
            if *v == var @{ Expr::Const(1.0) @} else @{ Expr::Const(0.0) @}
        @}
        _ => @{
            // 테이블에서 연산자 타입에 따라 디스패치
            let op = exp.operator();
            let operands = exp.operands();
            table.get("deriv", op)(operands, var)
        @}
    @}
@}
@end example

@enumerate a

@item
위에서 무엇을 했는지 설명하라. 왜 우리는 술어 @code{number?}와 @code{is_variable}을 데이터 주도 디스패치에 동화시킬 수 없는가?

@item
합과 곱의 미분을 위한 프로시저, 그리고 그것들을 위 프로그램에서 사용하는 테이블에 설치하는 데 필요한 보조 코드를 작성하라.

@item
지수(@ref{Exercise 2.56})에 대한 것과 같은, 여러분이 좋아하는 추가적인 미분 규칙을 하나 선택하여 이 데이터 주도 시스템에 설치하라.

@item
이 간단한 대수 조작기에서 표현식의 타입은 그것을 묶는 대수 연산자이다.
그러나 만약 우리가 프로시저를 반대 방식으로 인덱싱해서 @code{deriv}의 디스패치 라인이 다음과 같다고 가정해 보자.

@example
table.get(exp.operator(), "deriv")(exp.operands(), var)
@end example

@noindent
미분 시스템에 어떤 상응하는 변경이 필요한가?

@end enumerate
@end quotation

@quotation
@strong{@anchor{Exercise 2.74}연습문제 2.74:} Insatiable Enterprises, Inc.는 전 세계에 위치한 수많은 독립적인 부서로 구성된 고도로 분산된 대기업이다.
이 회사의 컴퓨터 시설은 전체 네트워크가 어떤 사용자에게든 단일 컴퓨터처럼 보이게 만드는 영리한 네트워크 인터페이싱 계획에 의해 방금 상호 연결되었다.
Insatiable의 사장은 부서 파일에서 관리 정보를 추출하는 네트워크의 능력을 활용하려는 첫 번째 시도에서, 모든 부서 파일이 Scheme 데이터 구조로 구현되었지만 사용된 특정 데이터 구조가 부서마다 다르다는 사실을 발견하고 낙담한다.
본부의 필요를 충족시키면서 부서의 기존 자율성을 보존하는 파일 통합 전략을 찾기 위해 부서 관리자 회의가 급히 소집되었다.

그러한 전략이 데이터 주도 프로그래밍으로 어떻게 구현될 수 있는지 보여라.
예를 들어, 각 부서의 인사 기록이 직원 이름을 키로 하는 레코드 집합을 포함하는 단일 파일로 구성되어 있다고 가정하자.
집합의 구조는 부서마다 다르다.
게다가 각 직원의 레코드는 그 자체가 (부서마다 구조가 다른) 집합으로, @code{address}나 @code{salary}와 같은 식별자로 키가 지정된 정보를 포함한다.
구체적으로:

@enumerate a

@item
본부를 위해 지정된 직원 파일에서 지정된 직원의 레코드를 검색하는 @code{get-record} 프로시저를 구현하라.
이 프로시저는 어떤 부서의 파일에도 적용 가능해야 한다.
개별 부서의 파일이 어떻게 구조화되어야 하는지 설명하라. 특히 어떤 타입 정보가 제공되어야 하는가?

@item
본부를 위해 임의 부서의 직원 파일에서 주어진 직원의 레코드로부터 급여 정보를 반환하는 @code{get-salary} 프로시저를 구현하라.
이 연산이 작동하려면 레코드가 어떻게 구조화되어야 하는가?

@item
본부를 위해 @code{find-employee-record} 프로시저를 구현하라.
이것은 주어진 직원의 레코드를 찾기 위해 모든 부서의 파일을 검색하고 레코드를 반환해야 한다.
이 프로시저는 직원의 이름과 모든 부서 파일의 리스트를 인자로 받는다고 가정하라.

@item
Insatiable이 새로운 회사를 인수할 때, 새로운 인사 정보를 중앙 시스템에 통합하기 위해 어떤 변경이 이루어져야 하는가?

@end enumerate
@end quotation

@subsubheading 메시지 전달 (Message passing)

데이터 주도 프로그래밍의 핵심 아이디어는 @ref{Figure 2.22}의 테이블과 같은 연산 및 타입 테이블을 명시적으로 다룸으로써 프로그램에서 제네릭 연산을 처리하는 것이다.
우리가 @ref{2.4.2}에서 사용한 프로그래밍 스타일은 각 연산이 자신의 디스패칭을 처리하게 함으로써 필요한 타입별 디스패칭을 조직했다.
사실상, 이것은 연산 및 타입 테이블을 행(row)으로 분해하며, 각 제네릭 연산 프로시저는 테이블의 한 행을 나타낸다.

대안적인 구현 전략은 테이블을 열(column)로 분해하고, 데이터 타입에 따라 디스패치하는 ``지능적인 연산''을 사용하는 대신 연산 이름에 따라 디스패치하는 ``지능적인 데이터 객체''와 작업하는 것이다.
우리는 직교 좌표 숫자와 같은 데이터 객체를 필요한 연산 이름을 입력으로 받아 지시된 연산을 수행하는 프로시저로 표현되도록 배열함으로써 이를 수행할 수 있다.
그러한 규율에서, @code{make_from_real_imag}는 다음과 같이 작성될 수 있다

@example
fn make_from_real_imag(x: f64, y: f64) -> Box<dyn Fn(&str) -> f64> @{
    Box::new(move |op: &str| @{
        match op @{
            "real-part" => x,
            "imag-part" => y,
            "magnitude" => (x.powi(2) + y.powi(2)).sqrt(),
            "angle" => y.atan2(x),
            _ => panic!("Unknown op: MAKE-FROM-REAL-IMAG @{@}", op),
        @}
    @})
@}
@end example

@noindent
제네릭 연산을 인자에 적용하는 해당 @code{apply-generic} 프로시저는 이제 단순히 연산의 이름을 데이터 객체에 공급하고 객체가 일을 하도록 한다:@footnote{이 조직의 한 가지 제한점은 인자가 하나인 제네릭 프로시저만 허용한다는 것이다.}

@example
fn apply_generic(op: &str, arg: &Box<dyn Fn(&str) -> f64>) -> f64 @{
    arg(op)
@}
@end example

@noindent
@code{make_from_real_imag}가 반환하는 값은 프로시저---내부 @code{dispatch} 프로시저---라는 점에 주목하라.
이것은 @code{apply-generic}이 연산 수행을 요청할 때 호출되는 프로시저이다.

이런 스타일의 프로그래밍을 @newterm{메시지 전달(message passing)}이라고 부른다.
이 이름은 데이터 객체가 요청된 연산 이름을 ``메시지''로 받는 엔티티라는 이미지에서 유래했다.
우리는 이미 @ref{2.1.3}에서 메시지 전달의 예를 보았다. 거기서 우리는 데이터 객체 없이 오직 프로시저만으로 @code{cons}, @code{car}, 그리고 @code{cdr}이 어떻게 정의될 수 있는지 보았다.
여기서 우리는 메시지 전달이 수학적 트릭이 아니라 제네릭 연산을 가진 시스템을 조직하는 유용한 기술임을 본다.
이 장의 나머지 부분에서 우리는 제네릭 산술 연산을 논의하기 위해 메시지 전달보다는 데이터 주도 프로그래밍을 계속 사용할 것이다.
@ref{Chapter 3}에서 우리는 메시지 전달로 돌아올 것이며, 이것이 시뮬레이션 프로그램을 구조화하는 강력한 도구가 될 수 있음을 보게 될 것이다.

@quotation
@strong{@anchor{Exercise 2.75}연습문제 2.75:} 메시지 전달 스타일로 생성자 @code{make_from_mag_ang}을 구현하라. 이 프로시저는 위에서 주어진 @code{make_from_real_imag} 프로시저와 유사해야 한다.
@end quotation

@quotation
@strong{@anchor{Exercise 2.76}연습문제 2.76:} 제네릭 연산을 가진 대규모 시스템이 진화함에 따라, 새로운 타입의 데이터 객체나 새로운 연산이 필요할 수 있다.
세 가지 전략---명시적 디스패치를 가진 제네릭 연산, 데이터 주도 스타일, 그리고 메시지 전달 스타일---각각에 대해, 새로운 타입이나 새로운 연산을 추가하기 위해 시스템에 가해져야 할 변경 사항을 기술하라.
새로운 타입이 자주 추가되어야 하는 시스템에는 어떤 조직이 가장 적합하겠는가?
새로운 연산이 자주 추가되어야 하는 시스템에는 어떤 것이 가장 적합하겠는가?
@end quotation

@node 2.4.3a, 2.5, 2.4.3, 2.4
@subsection 인터페이스로서의 트레이트: 정적 및 동적 디스패치 (Traits as Interfaces: Static and Dynamic Dispatch)
@cindex traits
@cindex interfaces
@cindex polymorphism
@cindex dispatch
@cindex static dispatch
@cindex dynamic dispatch

@ref{2.4.3}에서 우리는 데이터 타입에 따라 연산이 선택되는 데이터 주도 프로그래밍을 탐구했다.
Rust는 @newterm{트레이트(traits)}를 통해 이를 위한 강력한 메커니즘을 제공한다. 트레이트는 서로 다른 타입 간에 공유되는 동작을 정의한다.
트레이트는 타입이 구현할 수 있는 인터페이스 역할을 하여 다형성(polymorphism)---여러 타입과 함께 작동하는 코드를 작성하는 능력---을 가능하게 한다.

Rust의 트레이트 시스템은 다형성에 대한 두 가지 근본적으로 다른 접근 방식을 지원한다: 구체적인 타입이 컴파일 타임에 알려지는 제네릭을 사용하는 @newterm{정적 디스패치(static dispatch)}와 타입이 런타임에 결정되는 트레이트 객체를 사용하는 @newterm{동적 디스패치(dynamic dispatch)}이다.
각 접근 방식을 언제 사용할지 이해하는 것은 성능이 뛰어나고 유연한 Rust 코드를 작성하는 데 중요하다.

@subsubheading 트레이트는 공유 동작을 정의한다 (Traits Define Shared Behavior)

트레이트 정의는 구현하는 타입이 제공해야 하는 메서드 서명 집합을 선언한다.
그래픽 시스템의 그릴 수 있는 객체에 대한 트레이트를 고려해 보자:

@example
@cindex trait definition
trait Drawable @{
    fn draw(&self);
    fn bounds(&self) -> Rectangle;

    // 기본 구현
    fn area(&self) -> f64 @{
        let rect = self.bounds();
        rect.width * rect.height
    @}
@}

struct Rectangle @{
    x: f64,
    y: f64,
    width: f64,
    height: f64,
@}

struct Circle @{
    x: f64,
    y: f64,
    radius: f64,
@}
@end example

@noindent
트레이트는 메서드 서명(구현자가 정의해야 함), 기본 구현(구현자가 재정의할 수 있음), 연관 타입 또는 상수를 포함할 수 있다.
이것은 Java의 인터페이스나 Swift의 프로토콜과 유사하지만 디스패치 방식에서 중요한 차이가 있다.

@subsubheading 타입을 위한 트레이트 구현 (Implementing Traits for Types)

타입이 트레이트를 구현하도록 하려면 @code{impl Trait for Type} 블록을 사용한다:

@example
@cindex trait implementation
impl Drawable for Rectangle @{
    fn draw(&self) @{
        println!("Drawing rectangle at (@{@}, @{@}) with size @{@}x@{@}",
                 self.x, self.y, self.width, self.height);
    @}

    fn bounds(&self) -> Rectangle @{
        Rectangle @{
            x: self.x,
            y: self.y,
            width: self.width,
            height: self.height,
        @}
    @}
@}

impl Drawable for Circle @{
    fn draw(&self) @{
        println!("Drawing circle at (@{@}, @{@}) with radius @{@}",
                 self.x, self.y, self.radius);
    @}

    fn bounds(&self) -> Rectangle @{
        Rectangle @{
            x: self.x - self.radius,
            y: self.y - self.radius,
            width: self.radius * 2.0,
            height: self.radius * 2.0,
        @}
    @}
@}
@end example

@noindent
두 타입 모두 이제 @code{Drawable} 트레이트를 구현하며, 이는 필요한 메서드를 제공한다는 의미이다.
둘 다 트레이트에서 기본 @code{area} 구현을 상속받지만, 필요하다면 어느 쪽이든 재정의할 수 있다.

@subsubheading 제네릭을 이용한 정적 디스패치 (Static Dispatch with Generics)

트레이트 구현과 함께 작동하는 코드를 작성하는 가장 일반적인 방법은 @newterm{트레이트 바운드(trait bounds)}가 있는 @newterm{제네릭 함수(generic functions)}를 사용하는 것이다:

@example
@cindex generic functions
@cindex trait bounds
fn render<T: Drawable>(shape: &T) @{
    shape.draw();
    println!("Area: @{@}", shape.area());
@}

let rect = Rectangle @{ x: 0.0, y: 0.0, width: 10.0, height: 20.0 @};
let circle = Circle @{ x: 5.0, y: 5.0, radius: 3.0 @};

render(&rect);    // T = Rectangle
render(&circle);  // T = Circle
@end example

@noindent
표기법 @code{<T: Drawable>}은 @code{T}가 @code{Drawable} 트레이트를 구현해야 하는 제네릭 타입 매개변수임을 선언한다.
이것을 @newterm{트레이트 바운드}라고 부른다.
우리가 @code{render(&rect)}를 호출할 때, 컴파일러는 @code{Rectangle}에 특화된 코드를 생성한다.
우리가 @code{render(&circle)}을 호출할 때, 컴파일러는 @code{Circle}에 특화된 다른 코드를 생성한다.

이 과정을 @newterm{단형성(monomorphization)}이라고 부른다---컴파일러는 사용된 각 구체적인 타입에 대해 함수의 별도 사본을 생성한다.
마치 우리가 다음과 같이 쓴 것과 같다:

@example
// 컴파일러가 생성한 특수화
fn render_rectangle(shape: &Rectangle) @{
    shape.draw();
    println!("Area: @{@}", shape.area());
@}

fn render_circle(shape: &Circle) @{
    shape.draw();
    println!("Area: @{@}", shape.area());
@}
@end example

@noindent
정적 디스패치는 런타임 오버헤드가 없다---메서드 호출은 컴파일 타임에 해결되며 인라인 될 수 있다.
그 대가는 바이너리 크기 증가(코드 중복)와 더 긴 컴파일 시간이다.

@subsubheading impl Trait 문법 (The impl Trait Syntax)

Rust는 트레이트 바운드를 위한 두 가지 편리한 문법을 제공한다: 인자 위치와 반환 위치에서의 @code{impl Trait}.

@newterm{인자 위치(argument position)}에서, @code{impl Trait}은 제네릭 매개변수에 대한 문법적 설탕이다:

@example
@cindex impl Trait syntax
// 이것들은 동등하다
fn render(shape: &impl Drawable) @{ /* ... */ @}
fn render<T: Drawable>(shape: &T) @{ /* ... */ @}
@end example

@noindent
@code{impl Trait} 문법은 간단한 경우에 더 간결하지만, 제네릭 문법은 타입을 여러 번 참조해야 하거나 여러 제약 조건을 추가해야 할 때 더 유연하다:

@example
// 제네릭을 사용하면 두 인자가 같은 타입임을 보장할 수 있다
fn compare_areas<T: Drawable>(a: &T, b: &T) -> bool @{
    a.area() > b.area()
@}

// impl Trait을 사용하면, 이것들은 다른 타입일 수 있다
fn compare_areas_different(a: &impl Drawable, b: &impl Drawable) -> bool @{
    a.area() > b.area()
@}
@end example

@newterm{반환 위치(return position)}에서, @code{impl Trait}은 ``이 트레이트를 구현하는 어떤 타입을 반환함''을 의미한다:

@example
@cindex opaque return types
fn make_shape(use_circle: bool) -> impl Drawable @{
    if use_circle @{
        Circle @{ x: 0.0, y: 0.0, radius: 5.0 @}
    @} else @{
        // 오류: 모든 분기는 동일한 구체적인 타입을 반환해야 한다
        Rectangle @{ x: 0.0, y: 0.0, width: 10.0, height: 10.0 @}
    @}
@}
@end example

@noindent
이것은 컴파일을 시도하지만 실패하는데, 반환 위치의 @code{impl Trait}은 함수가 트레이트를 구현하는 단일 구체적인 타입(컴파일 타임에 알려진)을 반환한다는 것을 의미하기 때문이다---서로 다른 타입을 반환할 수 있다는 것이 아니다.
모든 코드 경로는 동일한 타입을 반환해야 한다. 진정으로 동적인 반환 타입을 위해서는 트레이트 객체가 필요하다.

@subsubheading 트레이트 객체를 이용한 동적 디스패치 (Dynamic Dispatch with Trait Objects)

진정한 런타임 다형성---같은 컬렉션에 다른 타입을 저장하거나 다른 코드 경로에서 다른 타입을 반환하는 능력---이 필요할 때, 우리는 @newterm{트레이트 객체(trait objects)}를 사용한다.
트레이트 객체는 @code{dyn Trait}으로 쓰이며 포인터(@code{&dyn Trait}, @code{Box<dyn Trait>} 등) 뒤에 있어야 한다:

@example
@cindex trait objects
@cindex dyn keyword
fn render_dynamic(shape: &dyn Drawable) @{
    shape.draw();
    println!("Area: @{@}", shape.area());
@}

let rect = Rectangle @{ x: 0.0, y: 0.0, width: 10.0, height: 20.0 @};
let circle = Circle @{ x: 5.0, y: 5.0, radius: 3.0 @};

render_dynamic(&rect);    // &Rectangle이 &dyn Drawable로 강제 변환됨
render_dynamic(&circle);  // &Circle이 &dyn Drawable로 강제 변환됨

// 컬렉션에 서로 다른 타입을 저장할 수 있다
let shapes: Vec<Box<dyn Drawable>> = vec![
    Box::new(Rectangle @{ x: 0.0, y: 0.0, width: 10.0, height: 20.0 @}),
    Box::new(Circle @{ x: 5.0, y: 5.0, radius: 3.0 @}),
];

for shape in &shapes @{
    shape.draw();
@}
@end example

@noindent
트레이트 객체를 사용하면, 메서드 디스패치는 @newterm{vtable}(가상 메서드 테이블)을 사용하여 런타임에 발생한다.
트레이트 객체는 두 개의 포인터로 구성된다: 하나는 데이터에 대한 것이고 하나는 트레이트 메서드에 대한 함수 포인터를 포함하는 vtable에 대한 것이다:

@example
// &dyn Drawable의 개념적 표현
struct TraitObject @{
    data: *const (),           // 실제 데이터에 대한 포인터
    vtable: *const VTable,     // 메서드 구현에 대한 포인터
@}

struct VTable @{
    draw: fn(*const ()),
    bounds: fn(*const ()) -> Rectangle,
    area: fn(*const ()) -> f64,
    // 소멸자, 크기, 정렬 정보도 포함
@}
@end example

@noindent
우리가 @code{shape.draw()}를 호출할 때, 컴파일러는 다음과 같은 코드를 생성한다:
@enumerate
@item vtable에서 @code{draw} 함수 포인터를 찾는다
@item 데이터 포인터로 그것을 호출한다
@end enumerate

이 간접 참조는 약간의 런타임 비용(포인터 역참조 한 번)이 들고 인라인을 방지하지만, 우리에게 진정한 런타임 다형성을 제공한다.

@subsubheading 객체 안전성: 모든 트레이트가 트레이트 객체가 될 수 있는 것은 아니다 (Object Safety)

모든 트레이트가 트레이트 객체로 만들어질 수 있는 것은 아니다. 트레이트는 모든 메서드가 특정 규칙을 따를 때만 @newterm{객체 안전(object-safe)}하다:

@example
@cindex object safety
// 객체 안전: 모든 메서드가 &self, &mut self, 또는 self를 받음
trait ObjectSafe @{
    fn method(&self);
@}

// 객체 안전 아님: 제네릭 메서드가 있음
trait NotObjectSafe1 @{
    fn generic_method<T>(&self, value: T);
@}

// 객체 안전 아님: Self를 반환함
trait NotObjectSafe2 @{
    fn clone_self(&self) -> Self;
@}

// 객체 안전 아님: 연관 함수가 있음 (리시버 없음)
trait NotObjectSafe3 @{
    fn new() -> Self;
@}
@end example

@noindent
이 제한이 존재하는 이유는 트레이트 객체가 구체적인 타입을 지우기 때문이다.
런타임에 컴파일러는 ``이것은 @code{Drawable}을 구현하는 무언가이다''라는 것만 알 뿐---그것이 @code{Rectangle}인지 @code{Circle}인지는 모른다.
따라서:

@itemize @bullet
@item
제네릭 메서드는 디스패치될 수 없다---모든 가능한 타입 @code{T}에 대한 항목이 있는 무한한 vtable이 필요할 것이다
@item
@code{Self}를 반환하는 메서드는 작동할 수 없다---우리는 반환할 것의 크기나 타입을 모른다
@item
연관 함수(생성자 같은)는 호출될 수 없다---vtable 포인터를 제공할 객체가 아직 없다
@end itemize

@noindent
많은 표준 라이브러리 트레이트는 객체 안전하지 않다. 예를 들어, @code{Clone}은 @code{Self}를 반환하므로 @code{&dyn Clone}을 쓸 수 없다. 이를 해결하기 위해, 객체 안전 래퍼를 만들 수 있다:

@example
@cindex object-safe wrappers
trait CloneBox @{
    fn clone_box(&self) -> Box<dyn CloneBox>;
@}

impl<T: Clone + 'static> CloneBox for T @{
    fn clone_box(&self) -> Box<dyn CloneBox> @{
        Box::new(self.clone())
    @}
@}
@end example

@subsubheading 성능: 정적 대 동적 디스패치 (Performance: Static vs Dynamic Dispatch)

정적 디스패치와 동적 디스패치 사이의 선택은 트레이드오프를 수반한다:

@multitable @columnfractions 0.25 0.35 0.40
@headitem 측면 @tab 정적 디스패치 @tab 동적 디스패치
@item @strong{성능} @tab 오버헤드 없음, 인라인 @tab 작은 vtable 조회 비용
@item @strong{바이너리 크기} @tab 더 큼 (중복) @tab 더 작음 (한 사본)
@item @strong{컴파일} @tab 더 느림 (단형성) @tab 더 빠름
@item @strong{유연성} @tab 컴파일 타임에 타입 알림 @tab 런타임에 타입 알림
@item @strong{컬렉션} @tab 동종 타입만 가능 @tab 혼합 타입 허용
@item @strong{최적화} @tab 완전한 인라인 가능 @tab 간접 참조로 인해 제한됨
@end multitable

차이를 보여주는 벤치마크 예제:

@example
@cindex benchmarking
use std::time::Instant;

trait Compute @{
    fn compute(&self) -> i64;
@}

struct Adder(i64);
impl Compute for Adder @{
    #[inline]
    fn compute(&self) -> i64 @{ self.0 + self.0 @}
@}

// 정적 디스패치 - 완전히 인라인 가능
fn static_dispatch<T: Compute>(c: &T, iterations: usize) -> i64 @{
    let mut sum = 0;
    for _ in 0..iterations @{
        sum += c.compute();
    @}
    sum
@}

// 동적 디스패치 - compute()를 인라인 할 수 없음
fn dynamic_dispatch(c: &dyn Compute, iterations: usize) -> i64 @{
    let mut sum = 0;
    for _ in 0..iterations @{
        sum += c.compute();
    @}
    sum
@}

let adder = Adder(5);
let iterations = 100_000_000;

let start = Instant::now();
static_dispatch(&adder, iterations);
println!("Static: @{@:?@}", start.elapsed());

let start = Instant::now();
dynamic_dispatch(&adder, iterations);
println!("Dynamic: @{@:?@}", start.elapsed());

// 현대 하드웨어에서의 일반적인 결과:
// Static: 0ns (완전히 최적화되어 사라짐)
// Dynamic: 200-300ms (vtable 호출을 최적화할 수 없음)
@end example

@subsubheading 정적 디스패치와 동적 디스패치 중 선택하기 (Choosing Between Static and Dynamic Dispatch)

@strong{정적 디스패치}(제네릭)를 사용할 때:
@itemize @bullet
@item
성능이 중요할 때 (핫 루프, 임베디드 시스템)
@item
컴파일러가 적극적으로 인라인하고 최적화하기를 원할 때
@item
컴파일 타임에 모든 타입을 알 때
@item
적은 수의 타입으로 작업할 때 (코드 중복이 허용됨)
@end itemize

@strong{동적 디스패치}(트레이트 객체)를 사용할 때:
@itemize @bullet
@item
이종 컬렉션이 필요할 때 (서로 다른 타입의 벡터)
@item
바이너리 크기나 컴파일 시간을 줄이고 싶을 때
@item
타입이 런타임에 결정될 때 (플러그인, 동적 로딩)
@item
다른 코드 경로에서 다른 타입을 반환할 때
@item
수행되는 작업에 비해 디스패치 오버헤드가 무시할 만할 때
@end itemize

@quotation
@strong{@anchor{Exercise 2.75a}연습문제 2.75a:} 정적 및 동적 디스패치 접근 방식을 모두 사용하여 서로 다른 연산 타입(덧셈, 곱셈, 부정)을 지원하는 간단한 표현식 평가기를 구현하라.

먼저, @strong{정적 디스패치}를 사용하여:

@example
trait Expr @{
    fn eval(&self) -> i64;
@}

struct Literal(i64);
struct Add<L, R> @{ left: L, right: R @}
struct Mul<L, R> @{ left: L, right: R @}
struct Neg<E> @{ expr: E @}

// 각 타입에 대해 Expr 구현
// 사용 예제는 다음과 같은 표현식을 구축해야 함:
// Add @{ left: Literal(5), right: Mul @{ left: Literal(3), right: Literal(4) @} @}
@end example

그 다음, @strong{동적 디스패치}를 사용하여:

@example
enum DynExpr @{
    Literal(i64),
    Add(Box<DynExpr>, Box<DynExpr>),
    Mul(Box<DynExpr>, Box<DynExpr>),
    Neg(Box<DynExpr>),
@}

impl DynExpr @{
    fn eval(&self) -> i64 @{ /* ... */ @}
@}
@end example

두 접근 방식을 비교하라:
@enumerate
@item
어떤 버전이 컴파일 타임에 정확한 타입을 알지 못해도 표현식을 평가할 수 있게 하는가?
@item
작은 표현식에 대해 어떤 버전이 더 나은 성능을 가질까?
@item
어떤 버전이 더 작은 바이너리 코드를 생성할까?
@item
표현식을 구성할 때 인체공학적 차이점은 무엇인가?
@end enumerate
@end quotation

@quotation
@strong{@anchor{Exercise 2.75b}연습문제 2.75b:} 서로 다른 텍스트 변환을 지원하는 텍스트 편집기용 플러그인 시스템을 설계하라. 시스템은 사용자가 런타임에 사용자 정의 변환을 등록할 수 있게 해야 한다.

@example
trait TextTransform @{
    fn name(&self) -> &str;
    fn transform(&self, input: &str) -> String;
@}

struct TransformRegistry @{
    transforms: Vec<Box<dyn TextTransform>>,
@}

impl TransformRegistry @{
    fn new() -> Self @{ /* ... */ @}

    fn register(&mut self, transform: Box<dyn TextTransform>) @{ /* ... */ @}

    fn apply(&self, name: &str, input: &str) -> Option<String> @{ /* ... */ @}

    fn list_transforms(&self) -> Vec<&str> @{ /* ... */ @}
@}
@end example

구현하라:
@enumerate
@item
변환을 등록하고 적용하는 메서드가 있는 @code{TransformRegistry}
@item
적어도 세 가지 내장 변환: @code{Uppercase}, @code{Lowercase}, 그리고 @code{ReverseWords}
@item
변환의 등록과 적용을 보여주는 데모
@item
이 시스템이 왜 동적 디스패치를 필요로 하며 정적 디스패치를 사용할 수 없는지 설명하라
@end enumerate
@end quotation

@quotation
@strong{@anchor{Exercise 2.75c}연습문제 2.75c:} 객체 안전하지 않은 트레이트로부터 트레이트 객체를 생성하려고 시도함으로써 객체 안전성의 한계를 탐구하라.

@enumerate
@item
@code{Box<dyn Clone>}을 생성하려고 시도하고 왜 실패하는지 설명하라
@item
앞서 보여준 @code{CloneBox} 해결책을 구현하고 작동하는 것을 시연하라
@item
연관 함수 @code{fn create() -> Self}가 있는 트레이트 @code{Factory}를 생성하고 왜 그것이 객체 안전하지 않은지 설명하라
@item
트레이트 객체와 함께 사용할 수 있는 @code{Factory}의 객체 안전 버전을 설계하라:

@example
trait Factory @{
    fn create(&self) -> Box<dyn Factory>;
@}
@end example

@item
적어도 두 타입에 대해 @code{Factory}를 구현하고 각 요소에 대해 @code{create()}를 호출할 수 있는 @code{Box<dyn Factory>}의 컬렉션을 보여라
@end enumerate
@end quotation

Rust의 트레이트 시스템은 추상화와 코드 재사용을 위한 강력한 기초를 제공한다.
정적 디스패치와 동적 디스패치의 차이를 이해함으로써, 우리는 유연하고 성능이 뛰어난 코드를 작성할 수 있다.
정적 디스패치는 우리에게 완전한 최적화 잠재력을 가진 제로 비용 추상화를 제공하는 반면, 동적 디스패치는 필요할 때 런타임 다형성을 제공한다.
핵심은 각 상황에 맞는 올바른 도구를 선택하는 것이다.

다음 절에서는 제네릭 타입과 트레이트가 어떻게 함께 작동하여 제네릭 타입 매개변수에 대한 복잡한 제약 조건을 표현하기 위해 트레이트 바운드를 사용하는 것을 포함하여 더 정교한 추상화를 만드는지 볼 것이다.

@node	2.5, Chapter 3, 2.4.3a, Chapter 2
@section 제네릭 연산을 사용하는 시스템 (Systems with Generic Operations)

이전 절에서 우리는 데이터 객체가 한 가지 이상의 방식으로 표현될 수 있는 시스템을 설계하는 방법을 보았다.
핵심 아이디어는 제네릭 인터페이스 프로시저를 통해 데이터 연산을 지정하는 코드를 여러 표현에 연결하는 것이다.
이제 우리는 동일한 아이디어를 사용하여 서로 다른 표현에 대해 제네릭인 연산뿐만 아니라 서로 다른 종류의 인자에 대해 제네릭인 연산을 정의하는 방법을 볼 것이다.
우리는 이미 여러 가지 산술 연산 패키지를 보았다: 우리 언어에 내장된 원시 산술 연산(@code{+}, @code{-}, @code{*}, @code{/}), @ref{2.1.1}의 유리수 산술 연산(@code{add_rat}, @code{sub_rat}, @code{mul-rat}, @code{div_rat}), 그리고 @ref{2.4.3}에서 구현한 복소수 산술 연산.
우리는 이제 우리가 이미 구축한 모든 산술 패키지를 통합하는 산술 연산 패키지를 구성하기 위해 데이터 주도 기술을 사용할 것이다.

@ref{Figure 2.23}은 우리가 구축할 시스템의 구조를 보여준다.
추상화 장벽에 주목하라.
``숫자''를 사용하는 사람의 관점에서는, 제공된 숫자가 무엇이든 작동하는 단일 프로시저 @code{add}가 있다.
@code{Add}는 숫자를 사용하는 프로그램이 별도의 일반 산술, 유리수 산술, 그리고 복소수 산술 패키지에 균일하게 접근할 수 있게 해주는 제네릭 인터페이스의 일부이다.
개별 산술 패키지(복소수 패키지와 같은) 자체는 서로 다른 표현(직교 좌표 및 극좌표와 같은)을 위해 설계된 패키지들을 결합하는 제네릭 프로시저(@code{add_complex}와 같은)를 통해 접근될 수 있다.
게다가 시스템의 구조는 가법적이어서, 개별 산술 패키지를 별도로 설계하고 그것들을 결합하여 제네릭 산술 시스템을 생성할 수 있다.

@float
@anchor{Figure 2.23}
@ifinfo
@quotation
@strong{Figure 2.23:} 제네릭 산술 시스템.

@example
                        Programs that use numbers
                           +-----------------+
---------------------------| add sub mul div |-------------------
                           +-----------------+
                        Generic arithmetic package
 +-----------------+   +-------------------------+
 | add-rat sub-rat |   | add-complex sub-complex |   +---------+
-|                 |-+-|                         |-+-| + - * / |-
 | mul-rat div-rat | | | mul-complex div-complex | | +---------+
 +-----------------+ | +-------------------------+ |
      Rational       |     Complex artithmetic     |   Ordinary
     arithmetic      +--------------+--------------+  arithmetic
                     | Rectangular  |     Polar    |
---------------------+--------------+--------------+-------------
             List structure and primitive machine arithmetic
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap2/Fig2.23b,138mm,,,.std.svg}
@caption{@strong{Figure 2.23:} 제네릭 산술 시스템.}
@end iftex
@end float

@menu
* 2.5.1::            Generic Arithmetic Operations
* 2.5.2::            Combining Data of Different Types
* 2.5.3::            Example: Symbolic Algebra
@end menu

@node	2.5.1, 2.5.2, 2.5, 2.5
@subsection 제네릭 산술 연산 (Generic Arithmetic Operations)

제네릭 산술 연산을 설계하는 작업은 제네릭 복소수 연산을 설계하는 것과 유사하다.
예를 들어, 우리는 일반적인 숫자에 대해서는 일반적인 원시 덧셈 @code{+}처럼, 유리수에 대해서는 @code{add_rat}처럼, 그리고 복소수에 대해서는 @code{add_complex}처럼 동작하는 제네릭 덧셈 프로시저 @code{add}를 갖고 싶다.
우리는 @ref{2.4.3}에서 복소수에 대한 제네릭 선택자를 구현하기 위해 사용했던 것과 같은 전략을 따름으로써 @code{add}와 다른 제네릭 산술 연산을 구현할 수 있다.
우리는 각 종류의 숫자에 타입 태그를 붙이고 인자의 데이터 타입에 따라 적절한 패키지로 디스패치하도록 제네릭 프로시저를 만들 것이다.

제네릭 산술 프로시저는 다음과 같이 정의된다:

@example
// Rust에서 제네릭 연산은 apply-generic 대신 트레이트 디스패치를 사용한다
// Add, Sub, Mul, Div 트레이트는 연산자 오버로딩을 제공한다

impl Add for Number @{
    type Output = Number;
    fn add(self, other: Number) -> Number @{
        match (self, other) @{
            (Number::SchemeNumber(a), Number::SchemeNumber(b)) =>
                Number::SchemeNumber(a + b),
            (Number::Rational(a), Number::Rational(b)) =>
                Number::Rational(a + b),
            (Number::Complex(a), Number::Complex(b)) =>
                Number::Complex(a + b),
            // 혼합 타입은 강제 변환을 사용한다 (2.5.2절 참조)
            (a, b) => @{
                let (a_c, b_c) = coerce_to_common(a, b);
                a_c + b_c
            @}
        @}
    @}
@}
// Sub, Mul, Div에 대해서도 유사한 구현
@end example

@noindent
우리는 @newterm{일반(ordinary)} 숫자, 즉 우리 언어의 원시 숫자를 처리하기 위한 패키지를 설치하는 것으로 시작한다.
우리는 이것들에 기호 @code{SchemeNumber}로 태그를 붙일 것이다.
이 패키지의 산술 연산은 원시 산술 프로시저이다(따라서 태그 없는 숫자를 처리하기 위해 추가 프로시저를 정의할 필요가 없다).
이 연산들은 각각 두 개의 인자를 취하므로, 리스트 @code{(scheme-number scheme-number)}를 키로 하여 테이블에 설치된다:

@example
// Rust에서는 태깅 대신 열거형 변형을 사용한다
// Number 열거형이 이미 타입 판별을 제공한다

#[derive(Debug, Clone, PartialEq)]
pub enum Number @{
    SchemeNumber(i64),   // Tagged with variant name
    Rational(Rational),
    Complex(Complex),
@}

// Arithmetic operations are implemented via trait impls
// (shown above - Add, Sub, Mul, Div traits)

// Constructor function
pub fn make_scheme_number(n: i64) -> Number @{
    Number::SchemeNumber(n)
@}
@end example

@noindent
Users of the Number package will create ordinary numbers by
calling the constructor:

@noindent
Now that the framework of the generic arithmetic system is in place, we can
readily include new kinds of numbers.  Here is a package that performs rational
arithmetic.  Notice that, as a benefit of additivity, we can use without
modification the rational-number code from @ref{2.1.1} as the internal
procedures in the package:

@example
// Rational number package using enum and trait
#[derive(Debug, Clone, Copy)]
struct Rational @{ numer: i64, denom: i64 @}

impl Rational @{
    fn new(n: i64, d: i64) -> Self @{
        let g = gcd(n.abs(), d.abs());
        let sign = if d < 0 @{ -1 @} else @{ 1 @};
        Rational @{ numer: sign * n / g, denom: d.abs() / g @}
    @}
@}

impl std::ops::Add for Rational @{
    type Output = Self;
    fn add(self, other: Self) -> Self @{
        Rational::new(
            self.numer * other.denom + other.numer * self.denom,
            self.denom * other.denom,
        )
    @}
@}

impl std::ops::Sub for Rational @{
    type Output = Self;
    fn sub(self, other: Self) -> Self @{
        Rational::new(
            self.numer * other.denom - other.numer * self.denom,
            self.denom * other.denom,
        )
    @}
@}

impl std::ops::Mul for Rational @{
    type Output = Self;
    fn mul(self, other: Self) -> Self @{
        Rational::new(self.numer * other.numer, self.denom * other.denom)
    @}
@}

impl std::ops::Div for Rational @{
    type Output = Self;
    fn div(self, other: Self) -> Self @{
        Rational::new(self.numer * other.denom, self.denom * other.numer)
    @}
@}
@end example

@noindent
We can install a similar package to handle complex numbers, using the tag
@code{complex}.  In creating the package, we extract from the table the
operations @code{make_from_real_imag} and @code{make_from_mag_ang} that were
defined by the rectangular and polar packages.  Additivity permits us to use,
as the internal operations, the same @code{add_complex}, @code{sub_complex},
@code{mul_complex}, and @code{div_complex} procedures from @ref{2.4.1}.

@example
// Complex number package using std::ops traits
impl std::ops::Add for Complex @{
    type Output = Self;
    fn add(self, other: Self) -> Self @{
        Complex::Rectangular(
            self.real_part() + other.real_part(),
            self.imag_part() + other.imag_part(),
        )
    @}
@}

impl std::ops::Sub for Complex @{
    type Output = Self;
    fn sub(self, other: Self) -> Self @{
        Complex::Rectangular(
            self.real_part() - other.real_part(),
            self.imag_part() - other.imag_part(),
        )
    @}
@}

impl std::ops::Mul for Complex @{
    type Output = Self;
    fn mul(self, other: Self) -> Self @{
        Complex::Polar(
            self.magnitude() * other.magnitude(),
            self.angle() + other.angle(),
        )
    @}
@}

impl std::ops::Div for Complex @{
    type Output = Self;
    fn div(self, other: Self) -> Self @{
        Complex::Polar(
            self.magnitude() / other.magnitude(),
            self.angle() - other.angle(),
        )
    @}
@}
@end example

@noindent
Programs outside the complex-number package can construct complex numbers
either from real and imaginary parts or from magnitudes and angles.  Notice how
the underlying procedures, originally defined in the rectangular and polar
packages, are exported to the complex package, and exported from there to the
outside world.

@example
fn make_complex_from_real_imag(x: f64, y: f64) -> Complex @{
    Complex::Rectangular(x, y)
@}

fn make_complex_from_mag_ang(r: f64, a: f64) -> Complex @{
    Complex::Polar(r, a)
@}
@end example

@noindent
What we have here is a two-level tag system.  A typical complex number, such as
@math{{3 + 4i}} in rectangular form, would be represented as shown in @ref{Figure 2.24}.  
The outer tag (@code{complex}) is used to direct the number to the
complex package.  Once within the complex package, the next tag
(@code{rectangular}) is used to direct the number to the rectangular package.
In a large and complicated system there might be many levels, each interfaced
with the next by means of generic operations.  As a data object is passed
``downward,'' the outer tag that is used to direct it to the appropriate
package is stripped off (by applying @code{contents}) and the next level of tag
(if any) becomes visible to be used for further dispatching.

@float
@anchor{Figure 2.24}
@ifinfo
@quotation
@strong{Figure 2.24:} Representation of @math{{3 + 4i}} in rectangular form.

@example
     +---+---+     +---+---+     +---+---+
---->| * | *-+---->| * | *-+---->| * | * |
     +-|-+---+     +-|-+---+     +-|-+-|-+
       |             |             |   |
       V             V             V   V
 +---------+   +-------------+  +---+ +---+
 | complex |   | rectangular |  | 3 | | 4 |
 +---------+   +-------------+  +---+ +---+
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap2/Fig2.24d,108mm,,,.std.svg}
@caption{@strong{Figure 2.24:} Representation of @math{{3 + 4i}} in rectangular form.}
@end iftex
@end float

@noindent
In the above packages, we used @code{add_rat}, @code{add_complex}, and the
other arithmetic procedures exactly as originally written.  Once these
definitions are internal to different installation procedures, however, they no
longer need names that are distinct from each other: we could simply name them
@code{add}, @code{sub}, @code{mul}, and @code{div} in both packages.

@quotation
@strong{@anchor{Exercise 2.77}Exercise 2.77:} Louis Reasoner tries to evaluate
the expression @code{(magnitude z)} where @code{z} is the object shown in
@ref{Figure 2.24}.  To his surprise, instead of the answer 5 he gets an error
message from @code{apply-generic}, saying there is no method for the operation
@code{magnitude} on the types @code{(complex)}.  He shows this interaction to
Alyssa P. Hacker, who says ``The problem is that the complex-number selectors
were never defined for @code{complex} numbers, just for @code{polar} and
@code{rectangular} numbers.  All you have to do to make this work is add the
following to the @code{complex} package:''

@example
// Methods already available via pattern matching on Complex enum:
// complex.real_part(), complex.imag_part(),
// complex.magnitude(), complex.angle()
// No runtime dispatch table needed - the compiler handles it.
@end example

Describe in detail why this works.  As an example, trace through all the
procedures called in evaluating the expression @code{(magnitude z)} where
@code{z} is the object shown in @ref{Figure 2.24}.  In particular, how many
times is @code{apply-generic} invoked?  What procedure is dispatched to in each
case?
@end quotation

@quotation
@strong{@anchor{Exercise 2.78}Exercise 2.78:} The internal procedures in the
@code{SchemeNumber} package are essentially nothing more than calls to the
primitive procedures @code{+}, @code{-}, etc.  It was not possible to use the
primitives of the language directly because our type-tag system requires that
each data object have a type attached to it.  In fact, however, all Lisp
implementations do have a type system, which they use internally.  Primitive
predicates such as @code{symbol?} and @code{number?}  determine whether data
objects have particular types.  Modify the definitions of @code{type_tag},
@code{contents}, and @code{attach_tag} from @ref{2.4.2} so that our
generic system takes advantage of Scheme's internal type system.  That is to
say, the system should work as before except that ordinary numbers should be
represented simply as Scheme numbers rather than as pairs whose @code{car} is
the symbol @code{SchemeNumber}.
@end quotation

@quotation
@strong{@anchor{Exercise 2.79}Exercise 2.79:} Define a generic equality
predicate @code{equ?} that tests the equality of two numbers, and install it in
the generic arithmetic package.  This operation should work for ordinary
numbers, rational numbers, and complex numbers.
@end quotation

@quotation
@strong{@anchor{Exercise 2.80}Exercise 2.80:} Define a generic predicate
@code{=zero?} that tests if its argument is zero, and install it in the generic
arithmetic package.  This operation should work for ordinary numbers, rational
numbers, and complex numbers.
@end quotation

@node	2.5.2, 2.5.3, 2.5.1, 2.5
@subsection Combining Data of Different Types

We have seen how to define a unified arithmetic system that encompasses
ordinary numbers, complex numbers, rational numbers, and any other type of
number we might decide to invent, but we have ignored an important issue.  The
operations we have defined so far treat the different data types as being
completely independent.  Thus, there are separate packages for adding, say, two
ordinary numbers, or two complex numbers.  What we have not yet considered is
the fact that it is meaningful to define operations that cross the type
boundaries, such as the addition of a complex number to an ordinary number.  We
have gone to great pains to introduce barriers between parts of our programs so
that they can be developed and understood separately.  We would like to
introduce the cross-type operations in some carefully controlled way, so that
we can support them without seriously violating our module boundaries.

One way to handle cross-type operations is to design a different procedure for
each possible combination of types for which the operation is valid.  For
example, we could extend the complex-number package so that it provides a
procedure for adding complex numbers to ordinary numbers and installs this in
the table using the tag @code{(complex scheme-number)}:@footnote{We also have
to supply an almost identical procedure to handle the types
@code{(scheme-number complex)}.}

@example
// In Rust, cross-type operations use From trait for coercion
impl std::ops::Add<f64> for Complex @{
    type Output = Complex;
    fn add(self, x: f64) -> Complex @{
        Complex::Rectangular(
            self.real_part() + x,
            self.imag_part(),
        )
    @}
@}
@end example

@noindent
This technique works, but it is cumbersome.  With such a system, the cost of
introducing a new type is not just the construction of the package of
procedures for that type but also the construction and installation of the
procedures that implement the cross-type operations.  This can easily be much
more code than is needed to define the operations on the type itself.  The
method also undermines our ability to combine separate packages additively, or
at least to limit the extent to which the implementors of the individual packages
need to take account of other packages.  For instance, in the example above, it
seems reasonable that handling mixed operations on complex numbers and ordinary
numbers should be the responsibility of the complex-number package.  Combining
rational numbers and complex numbers, however, might be done by the complex
package, by the rational package, or by some third package that uses operations
extracted from these two packages.  Formulating coherent policies on the
division of responsibility among packages can be an overwhelming task in
designing systems with many packages and many cross-type operations.

@subsubheading Coercion

In the general situation of completely unrelated operations acting on
completely unrelated types, implementing explicit cross-type operations,
cumbersome though it may be, is the best that one can hope for.  Fortunately,
we can usually do better by taking advantage of additional structure that may
be latent in our type system.  Often the different data types are not
completely independent, and there may be ways by which objects of one type may
be viewed as being of another type.  This process is called @newterm{coercion}.
For example, if we are asked to arithmetically combine an ordinary number with
a complex number, we can view the ordinary number as a complex number whose
imaginary part is zero.  This transforms the problem to that of combining two
complex numbers, which can be handled in the ordinary way by the
complex-arithmetic package.

In general, we can implement this idea by designing coercion procedures that
transform an object of one type into an equivalent object of another type.
Here is a typical coercion procedure, which transforms a given ordinary number
to a complex number with that real part and zero imaginary part:

@example
impl From<f64> for Complex @{
    fn from(n: f64) -> Complex @{
        Complex::Rectangular(n, 0.0)
    @}
@}
@end example

@noindent
We install these coercion procedures in a special coercion table, indexed under
the names of the two types:

@example
// The From<f64> impl above registers this coercion.
// Usage: Complex::from(5.0) or 5.0_f64.into()
@end example

@noindent
(We assume that there are @code{put-coercion} and @code{get-coercion}
procedures available for manipulating this table.)  Generally some of the slots
in the table will be empty, because it is not generally possible to coerce an
arbitrary data object of each type into all other types.  For example, there is
no way to coerce an arbitrary complex number to an ordinary number, so there
will be no general @code{complex->scheme-number} procedure included in the
table.

Once the coercion table has been set up, we can handle coercion in a uniform
manner by modifying the @code{apply-generic} procedure of @ref{2.4.3}.
When asked to apply an operation, we first check whether the operation is
defined for the arguments' types, just as before.  If so, we dispatch to the
procedure found in the operation-and-type table.  Otherwise, we try coercion.
For simplicity, we consider only the case where there are two
arguments.@footnote{See @ref{Exercise 2.82} for generalizations.}  We check the
coercion table to see if objects of the first type can be coerced to the second
type.  If so, we coerce the first argument and try the operation again.  If
objects of the first type cannot in general be coerced to the second type, we
try the coercion the other way around to see if there is a way to coerce the
second argument to the type of the first argument.  Finally, if there is no
known way to coerce either type to the other type, we give up.  Here is the
procedure:

@example
// Rust's trait system handles coercion at compile time.
// With From/Into implementations, we can write generic
// functions that accept any coercible type:

fn add_numbers<A, B>(a: A, b: B) -> Complex
where
    A: Into<Complex>,
    B: Into<Complex>,
@{
    let a: Complex = a.into();
    let b: Complex = b.into();
    a + b
@}

// Usage:
let result = add_numbers(3.0_f64, Complex::Rectangular(1.0, 2.0));
// => Complex::Rectangular(4.0, 2.0)
@end example

@noindent
This coercion scheme has many advantages over the method of defining explicit
cross-type operations, as outlined above.  Although we still need to write
coercion procedures to relate the types (possibly @math{n^2} procedures for a
system with @math{n} types), we need to write only one procedure for each pair of
types rather than a different procedure for each collection of types and each
generic operation.@footnote{If we are clever, we can usually get by with fewer
than @math{n^2} coercion procedures.  For instance, if we know how to convert from
type 1 to type 2 and from type 2 to type 3, then we can use this knowledge to
convert from type 1 to type 3.  This can greatly decrease the number of
coercion procedures we need to supply explicitly when we add a new type to the
system.  If we are willing to build the required amount of sophistication into
our system, we can have it search the ``graph'' of relations among types and
automatically generate those coercion procedures that can be inferred from the
ones that are supplied explicitly.}  What we are counting on here is the fact
that the appropriate transformation between types depends only on the types
themselves, not on the operation to be applied.

On the other hand, there may be applications for which our coercion scheme is
not general enough.  Even when neither of the objects to be combined can be
converted to the type of the other it may still be possible to perform the
operation by converting both objects to a third type.  In order to deal with
such complexity and still preserve modularity in our programs, it is usually
necessary to build systems that take advantage of still further structure in
the relations among types, as we discuss next.

@subsubheading Hierarchies of types

The coercion scheme presented above relied on the existence of natural
relations between pairs of types.  Often there is more ``global'' structure in
how the different types relate to each other.  For instance, suppose we are
building a generic arithmetic system to handle integers, rational numbers, real
numbers, and complex numbers.  In such a system, it is quite natural to regard
an integer as a special kind of rational number, which is in turn a special
kind of real number, which is in turn a special kind of complex number.  What
we actually have is a so-called @newterm{hierarchy of types}, in which, for
example, integers are a @newterm{subtype} of rational numbers (i.e., any
operation that can be applied to a rational number can automatically be applied
to an integer).  Conversely, we say that rational numbers form a
@newterm{supertype} of integers.  The particular hierarchy we have here is of a
very simple kind, in which each type has at most one supertype and at most one
subtype.  Such a structure, called a @newterm{tower}, is illustrated in
@ref{Figure 2.25}.

@float
@anchor{Figure 2.25}
@ifinfo
@quotation
@strong{Figure 2.25:} A tower of types.

@example
 complex
   ^
   |
  real
   ^
   |
rational
   ^
   |
integer
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap2/Fig2.25,20mm,,,.std.svg}
@caption{@strong{Figure 2.25:} A tower of types.}
@end iftex
@end float

@noindent
If we have a tower structure, then we can greatly simplify the problem of
adding a new type to the hierarchy, for we need only specify how the new type
is embedded in the next supertype above it and how it is the supertype of the
type below it.  For example, if we want to add an integer to a complex number,
we need not explicitly define a special coercion procedure
@code{integer->complex}.  Instead, we define how an integer can be transformed
into a rational number, how a rational number is transformed into a real
number, and how a real number is transformed into a complex number.  We then
allow the system to transform the integer into a complex number through these
steps and then add the two complex numbers.

We can redesign our @code{apply-generic} procedure in the following way: For
each type, we need to supply a @code{raise} procedure, which ``raises'' objects
of that type one level in the tower.  Then when the system is required to
operate on objects of different types it can successively raise the lower types
until all the objects are at the same level in the tower.  (@ref{Exercise 2.83}
and @ref{Exercise 2.84} concern the details of implementing such a strategy.)

Another advantage of a tower is that we can easily implement the notion that
every type ``inherits'' all operations defined on a supertype.  For instance,
if we do not supply a special procedure for finding the real part of an
integer, we should nevertheless expect that @code{real_part} will be defined
for integers by virtue of the fact that integers are a subtype of complex
numbers.  In a tower, we can arrange for this to happen in a uniform way by
modifying @code{apply-generic}.  If the required operation is not directly
defined for the type of the object given, we raise the object to its supertype
and try again.  We thus crawl up the tower, transforming our argument as we go,
until we either find a level at which the desired operation can be performed or
hit the top (in which case we give up).

Yet another advantage of a tower over a more general hierarchy is that it gives
us a simple way to ``lower'' a data object to the simplest representation.  For
example, if we add @math{{2 + 3i}} to @math{{4 - 3i}}, it would be nice to obtain the
answer as the integer 6 rather than as the complex number @math{{6 + 0i}}.
@ref{Exercise 2.85} discusses a way to implement such a lowering operation.
(The trick is that we need a general way to distinguish those objects that can
be lowered, such as @math{{6 + 0i}}, from those that cannot, such as @math{{6 + 2i}}.)

@subsubheading Inadequacies of hierarchies

If the data types in our system can be naturally arranged in a tower, this
greatly simplifies the problems of dealing with generic operations on different
types, as we have seen.  Unfortunately, this is usually not the case.
@ref{Figure 2.26} illustrates a more complex arrangement of mixed types, this
one showing relations among different types of geometric figures.  We see that,
in general, a type may have more than one subtype.  Triangles and
quadrilaterals, for instance, are both subtypes of polygons.  In addition, a
type may have more than one supertype.  For example, an isosceles right
triangle may be regarded either as an isosceles triangle or as a right
triangle.  This multiple-supertypes issue is particularly thorny, since it
means that there is no unique way to ``raise'' a type in the hierarchy.
Finding the ``correct'' supertype in which to apply an operation to an object
may involve considerable searching through the entire type network on the part
of a procedure such as @code{apply-generic}.  Since there generally are
multiple subtypes for a type, there is a similar problem in coercing a value
``down'' the type hierarchy.  Dealing with large numbers of interrelated types
while still preserving modularity in the design of large systems is very
difficult, and is an area of much current research.@footnote{This statement,
which also appears in the first edition of this book, is just as true now as it
was when we wrote it twelve years ago.  Developing a useful, general framework
for expressing the relations among different types of entities (what
philosophers call ``ontology'') seems intractably difficult.  The main
difference be@-tween the confusion that existed ten years ago and the confusion
that exists now is that now a variety of inadequate ontological theories have
been embodied in a ple@-tho@-ra of correspondingly inadequate programming
languages.  For example, much of the complexity of object-oriented programming
languages---and the subtle and confusing differences among contemporary
object-oriented languages---centers on the treatment of generic operations on
interrelated types.  Our own discussion of computational objects in
@ref{Chapter 3} avoids these issues entirely.  Readers familiar with
object-oriented programming will notice that we have much to say in
chapter 3 about local state, but we do not even mention ``classes'' or
``inheritance.''  In fact, we suspect that these problems cannot be adequately
addressed in terms of computer-language design alone, without also drawing on
work in knowledge representation and automated reasoning.}

@float
@anchor{Figure 2.26}
@ifinfo
@quotation
@strong{Figure 2.26:} Relations among types of geometric figures.

@example
                     polygon
                    /       \
                   /         \
            triangle         quadrilateral
            /     \              /     \
           /       \            /       \
     isosceles   right      trapezoid   kite
     triangle    triangle       |         |
      |     \      |            |         |
      |      \     |            |         |
equilateral   isosceles   parallelogram   |
triangle      right          |       \    |
              triangle       |        \   |
                          rectangle  rhombus
                                \    /
                                 \  /
                                square
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap2/Fig2.26f,147mm,,,.std.svg}
@caption{@strong{Figure 2.26:} Relations among types of geometric figures.}
@end iftex
@end float

@quotation
@strong{@anchor{Exercise 2.81}Exercise 2.81:} Louis Reasoner has noticed that
@code{apply-generic} may try to coerce the arguments to each other's type even
if they already have the same type.  Therefore, he reasons, we need to put
procedures in the coercion table to @newterm{coerce} arguments of each type to
their own type.  For example, in addition to the
@code{scheme-number->complex} coercion shown above, he would do:

@example
// Identity coercion - unnecessary in Rust since types are known
// at compile time. The compiler won't try to coerce f64 to f64.
fn identity<T>(x: T) -> T @{ x @}
@end example

@enumerate a

@item
With Louis's coercion procedures installed, what happens if
@code{apply-generic} is called with two arguments of type @code{SchemeNumber}
or two arguments of type @code{complex} for an operation that is not found in
the table for those types?  For example, assume that we've defined a generic
exponentiation operation:

@example
fn exp<T: num_traits::Pow<T, Output = T>>(x: T, y: T) -> T @{
    x.pow(y)
@}
@end example

@noindent
and have put a procedure for exponentiation in the Scheme-number
package but not in any other package:

@example
// Exponentiation for f64 is built into the language
fn exp_f64(x: f64, y: f64) -> f64 @{
    x.powf(y)  // using primitive powf
@}
@end example

@noindent
What happens if we call @code{exp} with two complex numbers as arguments?

@item
Is Louis correct that something had to be done about coercion with arguments of
the same type, or does @code{apply-generic} work correctly as is?

@item
Modify @code{apply-generic} so that it doesn't try coercion if the two
arguments have the same type.

@end enumerate
@end quotation

@quotation
@strong{@anchor{Exercise 2.82}Exercise 2.82:} Show how to generalize
@code{apply-generic} to handle coercion in the general case of multiple
arguments.  One strategy is to attempt to coerce all the arguments to the type
of the first argument, then to the type of the second argument, and so on.
Give an example of a situation where this strategy (and likewise the
two-argument version given above) is not sufficiently general.  (Hint: Consider
the case where there are some suitable mixed-type operations present in the
table that will not be tried.)
@end quotation

@quotation
@strong{@anchor{Exercise 2.83}Exercise 2.83:} Suppose you are designing a
generic arithmetic system for dealing with the tower of types shown in
@ref{Figure 2.25}: integer, rational, real, complex.  For each type (except
complex), design a procedure that raises objects of that type one level in the
tower.  Show how to install a generic @code{raise} operation that will work for
each type (except complex).
@end quotation

@quotation
@strong{@anchor{Exercise 2.84}Exercise 2.84:} Using the @code{raise} operation
of @ref{Exercise 2.83}, modify the @code{apply-generic} procedure so that it
coerces its arguments to have the same type by the method of successive
raising, as discussed in this section.  You will need to devise a way to test
which of two types is higher in the tower.  Do this in a manner that is
``compatible'' with the rest of the system and will not lead to problems in
adding new levels to the tower.
@end quotation

@quotation
@strong{@anchor{Exercise 2.85}Exercise 2.85:} This section mentioned a method
for ``simplifying'' a data object by lowering it in the tower of types as far
as possible.  Design a procedure @code{drop} that accomplishes this for the
tower described in @ref{Exercise 2.83}.  The key is to decide, in some general
way, whether an object can be lowered.  For example, the complex number 
@math{{1.5 + 0i}} can be lowered as far as @code{real}, the complex number @math{{1 + 0i}} can
be lowered as far as @code{integer}, and the complex number @math{{2 + 3i}} cannot
be lowered at all.  Here is a plan for determining whether an object can be
lowered: Begin by defining a generic operation @code{project} that ``pushes''
an object down in the tower.  For example, projecting a complex number would
involve throwing away the imaginary part.  Then a number can be dropped if,
when we @code{project} it and @code{raise} the result back to the type we
started with, we end up with something equal to what we started with.  Show how
to implement this idea in detail, by writing a @code{drop} procedure that drops
an object as far as possible.  You will need to design the various projection
operations@footnote{A real number can be projected to an integer using the
@code{round} primitive, which returns the closest integer to its argument.} and
install @code{project} as a generic operation in the system.  You will also
need to make use of a generic equality predicate, such as described in
@ref{Exercise 2.79}.  Finally, use @code{drop} to rewrite @code{apply-generic}
from @ref{Exercise 2.84} so that it ``simplifies'' its answers.
@end quotation

@quotation
@strong{@anchor{Exercise 2.86}Exercise 2.86:} Suppose we want to handle complex
numbers whose real parts, imaginary parts, magnitudes, and angles can be either
ordinary numbers, rational numbers, or other numbers we might wish to add to
the system.  Describe and implement the changes to the system needed to
accommodate this.  You will have to define operations such as @code{sine} and
@code{cosine} that are generic over ordinary numbers and rational numbers.
@end quotation

@node	2.5.3, Chapter 3, 2.4, 2.5
@subsection 예제: 기호 대수 (Example: Symbolic Algebra)

기호 대수 표현식의 조작은 대규모 시스템의 설계에서 발생하는 가장 어려운 문제들 중 많은 부분을 보여주는 복잡한 과정이다.
일반적으로 대수 표현식은 계층적 구조, 즉 피연산자에 적용되는 연산자들의 트리로 볼 수 있다.
우리는 상수와 변수 같은 원시 객체 집합으로 시작하여, 덧셈과 곱셈 같은 대수 연산자를 통해 이것들을 결합함으로써 대수 표현식을 구성할 수 있다.
다른 언어에서처럼, 우리는 복합 객체를 간단한 용어로 참조할 수 있게 해주는 추상화를 형성한다.
기호 대수의 전형적인 추상화는 선형 결합, 다항식, 유리 함수, 또는 삼각 함수 같은 아이디어들이다.
우리는 이것들을 복합 ``타입''으로 간주할 수 있으며, 이는 종종 표현식의 처리를 지시하는 데 유용하다.
예를 들어, 우리는 표현식
@ifinfo

@example
x^2 sin (y^2 + 1) + x cos 2y + cos(y^3 - 2y^2)
@end example

@end ifinfo
@tex
\[ % :49:
  {x^2 \sin (y^2 + 1)} + {x \cos 2y} + {\cos(y^3 - 2y^2)}  \]
@end tex
@noindent
을 정수 계수를 가진 @math{y}에 대한 다항식의 삼각 함수들을 계수로 하는 @math{x}에 대한 다항식으로 기술할 수 있다.

우리는 여기서 완전한 대수 조작 시스템을 개발하려고 시도하지는 않을 것이다.
그러한 시스템은 깊은 대수적 지식과 우아한 알고리즘을 구현하는 매우 복잡한 프로그램이다.
우리가 할 일은 대수 조작의 간단하지만 중요한 부분인 다항식 산술을 살펴보는 것이다.
우리는 그러한 시스템의 설계자가 직면하는 결정의 종류와, 이 노력을 조직하는 데 추상 데이터와 제네릭 연산의 아이디어를 어떻게 적용하는지 보여줄 것이다.

@subsubheading 다항식 산술 (Arithmetic on polynomials)

다항식 산술을 수행하는 시스템을 설계하는 우리의 첫 번째 작업은 다항식이 정확히 무엇인지 결정하는 것이다.
다항식은 일반적으로 특정 변수(다항식의 @newterm{부정원(indeterminates)})에 대해 정의된다.
단순화를 위해, 우리는 단 하나의 부정원만 갖는 다항식(@newterm{일변수 다항식(univariate polynomials)})으로 제한할 것이다.@footnote{반면에, 우리는 계수 자체가 다른 변수의 다항식인 다항식을 허용할 것이다. 이것은 우리에게 본질적으로 완전한 다변수 시스템과 동일한 표현력을 줄 것이지만, 아래에서 논의하듯이 강제 변환 문제로 이어진다.} 우리는 다항식을 항들의 합으로 정의할 것이며, 각 항은 계수, 부정원의 거듭제곱, 또는 계수와 부정원의 거듭제곱의 곱이다.
계수는 다항식의 부정원에 의존하지 않는 대수 표현식으로 정의된다.
예를 들어,
@ifinfo

@example
5x^2 + 3x + 7
@end example

@end ifinfo
@tex
\[ % :50:
  {5x^2} + {3x} + 7  \]
@end tex
@noindent
은 @math{x}에 대한 간단한 다항식이고,
@ifinfo

@example
(y^2 + 1)x^3 + (2y)x + 1
@end example

@end ifinfo
@tex
\[ % :51:
  {(y^2 + 1)x^3} + {(2y)x + 1}  \]
@end tex
@noindent
은 계수가 @math{y}에 대한 다항식인 @math{x}에 대한 다항식이다.

이미 우리는 몇 가지 까다로운 문제에 접해 있다.
이 다항식들 중 첫 번째 것은 다항식 @math{{5y^2 + 3y + 7}}과 같은가, 아닌가?
합리적인 대답은 ``만약 우리가 다항식을 순수하게 수학 함수로 고려한다면 그렇지만, 다항식을 문법적 형식으로 고려한다면 아니다''일 것이다.
두 번째 다항식은 대수적으로 계수가 @math{x}에 대한 다항식인 @math{y}에 대한 다항식과 동등하다.
우리 시스템이 이것을 인식해야 하는가, 말아야 하는가?
게다가 다항식을 표현하는 다른 방법들이 있다---예를 들어, 인수들의 곱으로서, 또는 (일변수 다항식의 경우) 근들의 집합으로서, 또는 지정된 점들의 집합에서의 다항식 값들의 목록으로서.@footnote{일변수 다항식의 경우, 주어진 점 집합에서의 다항식 값을 제공하는 것이 특히 좋은 표현이 될 수 있다. 이것은 다항식 산술을 매우 간단하게 만든다. 예를 들어, 이런 식으로 표현된 두 다항식의 합을 얻으려면, 해당 점들에서의 다항식 값들을 더하기만 하면 된다. 더 친숙한 표현으로 다시 변환하기 위해, 우리는 @math{n}차 다항식의 계수를 @math{{n + 1}}개 점에서의 다항식 값으로부터 복구하는 방법을 보여주는 라그랑주 보간 공식(Lagrange interpolation formula)을 사용할 수 있다.}
우리는 우리의 대수 조작 시스템에서 ``다항식''이 기본 수학적 의미가 아니라 특정 문법적 형식이 될 것이라고 결정함으로써 이러한 질문들을 교묘하게 피할 수 있다.

이제 우리는 다항식에 대한 산술을 어떻게 수행할지 고려해야 한다.
이 간단한 시스템에서, 우리는 덧셈과 곱셈만 고려할 것이다.
또한, 결합될 두 다항식은 반드시 같은 부정원을 가져야 한다고 주장할 것이다.

우리는 친숙한 데이터 추상화 규율을 따라 시스템 설계에 접근할 것이다.
우리는 @newterm{poly}라고 불리는 데이터 구조를 사용하여 다항식을 표현할 것인데, 이것은 변수와 항들의 컬렉션으로 구성된다.
우리는 poly에서 그 부분들을 추출하는 선택자 @code{variable}과 @code{term-list}, 그리고 주어진 변수와 항 리스트로부터 poly를 조립하는 생성자 @code{make-poly}가 있다고 가정한다.
변수는 단지 기호일 것이므로, 우리는 변수를 비교하기 위해 @ref{2.3.2}의 @code{same_variable} 프로시저를 사용할 수 있다.
다음 프로시저들은 polys의 덧셈과 곱셈을 정의한다:

@example
fn add_poly(p1: &Poly, p2: &Poly) -> Result<Poly, &'static str> @{
    if p1.variable == p2.variable @{
        Ok(Poly @{
            variable: p1.variable.clone(),
            terms: add_terms(&p1.terms, &p2.terms),
        @})
    @} else @{
        Err("Polys not in same var: ADD-POLY")
    @}
@}

fn mul_poly(p1: &Poly, p2: &Poly) -> Result<Poly, &'static str> @{
    if p1.variable == p2.variable @{
        Ok(Poly @{
            variable: p1.variable.clone(),
            terms: mul_terms(&p1.terms, &p2.terms),
        @})
    @} else @{
        Err("Polys not in same var: MUL-POLY")
    @}
@}
@end example

@noindent
다항식을 우리의 제네릭 산술 시스템에 통합하기 위해, 우리는 그것들에 타입 태그를 제공해야 한다.
우리는 태그 @code{polynomial}을 사용할 것이고, 연산 테이블에 태그된 다항식에 대한 적절한 연산을 설치할 것이다.
우리는 모든 코드를 @ref{2.5.1}의 것들과 유사한 다항식 패키지를 위한 설치 프로시저에 포함시킬 것이다:

@example
// 변수 이름과 항 리스트를 가진 다항식 구조체
#[derive(Debug, Clone, PartialEq)]
struct Poly @{
    variable: String,
    terms: Vec<Term>,
@}

#[derive(Debug, Clone, PartialEq)]
struct Term @{
    order: usize,
    coeff: f64,
@}

impl Poly @{
    fn new(variable: &str, terms: Vec<Term>) -> Self @{
        Poly @{ variable: variable.to_string(), terms @}
    @}
@}

// 트레이트 구현은 제네릭 연산을 제공한다
impl std::ops::Add for Poly @{
    type Output = Result<Poly, &'static str>;
    fn add(self, other: Poly) -> Self::Output @{
        add_poly(&self, &other)
    @}
@}

impl std::ops::Mul for Poly @{
    type Output = Result<Poly, &'static str>;
    fn mul(self, other: Poly) -> Self::Output @{
        mul_poly(&self, &other)
    @}
@}
@end example

@noindent
다항식 덧셈은 항별로 수행된다.
같은 차수(즉, 부정원의 같은 거듭제곱을 가진)의 항들은 결합되어야 한다.
이것은 계수가 피가산수들의 계수의 합인 같은 차수의 새로운 항을 형성함으로써 수행된다.
다른 피가산수에 같은 차수의 항이 없는 한 피가산수의 항들은 단순히 구성 중인 합 다항식으로 누산된다.

항 리스트를 조작하기 위해, 우리는 빈 항 리스트를 반환하는 생성자 empty term list와 항 리스트에 새 항을 추가하는 생성자 @code{adjoin_term}이 있다고 가정할 것이다.
우리는 또한 주어진 항 리스트가 비어 있는지 알려주는 술어 @code{is_empty}(또는 유사한 테스트), 항 리스트에서 가장 높은 차수의 항을 추출하는 선택자 @code{first_term}, 그리고 가장 높은 차수의 항을 제외한 모든 것을 반환하는 선택자 @code{rest_terms}가 있다고 가정할 것이다.
항을 조작하기 위해, 우리는 주어진 차수와 계수로 항을 구성하는 생성자 @code{make_term}, 그리고 각각 항의 차수와 계수를 반환하는 선택자 @code{order}와 @code{coeff}가 있다고 가정할 것이다.
이러한 연산들은 우리가 항과 항 리스트 모두를 데이터 추상화로 고려할 수 있게 해주며, 그 구체적인 표현에 대해서는 별도로 걱정할 수 있다.

다음은 두 다항식의 합을 위한 항 리스트를 구성하는 프로시저이다:@footnote{이 연산은 우리가 @ref{Exercise 2.62}에서 개발한 정렬된 @code{union_set} 연산과 매우 유사하다. 사실, 만약 우리가 다항식의 항들을 부정원의 거듭제곱에 따라 정렬된 집합으로 생각한다면, 합을 위한 항 리스트를 생성하는 프로그램은 @code{union_set}과 거의 동일하다.}

@example
fn add_terms(l1: &[Term], l2: &[Term]) -> Vec<Term> @{
    match (l1.first(), l2.first()) @{
        (None, _) => l2.to_vec(),
        (_, None) => l1.to_vec(),
        (Some(t1), Some(t2)) => match t1.order.cmp(&t2.order) @{
            std::cmp::Ordering::Greater => @{
                let mut result = vec![t1.clone()];
                result.extend(add_terms(&l1[1..], l2));
                result
            @}
            std::cmp::Ordering::Less => @{
                let mut result = vec![t2.clone()];
                result.extend(add_terms(l1, &l2[1..]));
                result
            @}
            std::cmp::Ordering::Equal => @{
                let sum_coeff = t1.coeff + t2.coeff;
                let mut result = if sum_coeff != 0.0 @{
                    vec![Term @{ order: t1.order, coeff: sum_coeff @}]
                @} else @{
                    vec![]
                @};
                result.extend(add_terms(&l1[1..], &l2[1..]));
                result
            @}
        @},
    @}
@}
@end example

@noindent
여기서 주목해야 할 가장 중요한 점은 결합되는 항들의 계수를 더하기 위해 우리가 제네릭 덧셈 프로시저 @code{add}를 사용했다는 것이다.
이것은 아래에서 볼 수 있듯이 강력한 결과를 가져온다.

두 항 리스트를 곱하기 위해, 우리는 첫 번째 리스트의 각 항에 다른 리스트의 모든 항을 곱하며, 이때 주어진 항과 주어진 항 리스트의 모든 항을 곱하는 @code{mul-term-by-all-terms}를 반복적으로 사용한다.
결과 항 리스트들(첫 번째 리스트의 각 항에 대해 하나씩)은 합으로 누산된다.
두 항을 곱하면 차수가 인자들의 차수의 합이고 계수가 인자들의 계수의 곱인 항이 형성된다:

@example
fn mul_terms(l1: &[Term], l2: &[Term]) -> Vec<Term> @{
    if l1.is_empty() @{
        vec![]
    @} else @{
        add_terms(
            &mul_term_by_all_terms(&l1[0], l2),
            &mul_terms(&l1[1..], l2),
        )
    @}
@}

fn mul_term_by_all_terms(t1: &Term, l: &[Term]) -> Vec<Term> @{
    l.iter()
        .map(|t2| Term @{
            order: t1.order + t2.order,
            coeff: t1.coeff * t2.coeff,
        @})
        .collect()
@}
@end example

@noindent
이것이 다항식 덧셈과 곱셈의 전부이다.
우리가 제네릭 프로시저 @code{add}와 @code{mul}을 사용하여 항을 조작하므로, 우리 다항식 패키지는 제네릭 산술 패키지에 의해 알려진 어떤 타입의 계수도 자동으로 처리할 수 있다는 점에 주목하라.
만약 우리가 @ref{2.5.2}에서 논의된 것과 같은 강제 변환 메커니즘을 포함한다면, 우리는 또한 다음과 같은 다른 계수 타입을 가진 다항식에 대한 연산을 자동으로 처리할 수 있다.
@ifinfo

@example
                         /        2                 \
[3x^2 + (2 + 3i)x + 7] * | x^4 + --- x^2 + (5 + 3i) |
                         \        3                 /
@end example

@end ifinfo
@tex
\[ % :52:
  {[3x^2 + (2 + 3i)x + 7] \cdot} {\left[ x^4 + {2\over3} x^2 + (5 + 3i) \right].}  \]
@end tex
우리가 다항식 덧셈 및 곱셈 프로시저 @code{add_poly}와 @code{mul_poly}를 제네릭 산술 시스템에 타입 @code{polynomial}에 대한 @code{add} 및 @code{mul} 연산으로 설치했으므로, 우리 시스템은 다음과 같은 다항식 연산도 자동으로 처리할 수 있다.
@ifinfo

@example
[(y + 1)x^2 + (y^2 + 1)x + (y - 1)] * [(y - 2)x + (y^3 + 7)]
@end example

@end ifinfo
@tex
\[ % :53:
  {\Big[(y + 1)x^2} + {(y^2 + 1)x} + {(y - 1)\Big] \cdot} {\Big[(y - 2)x} + {(y^3 + 7)\Big].}  \]
@end tex
그 이유는 시스템이 계수를 결합하려고 할 때 @code{add}와 @code{mul}을 통해 디스패치할 것이기 때문이다.
계수 자체가 다항식(@math{y}에 대한)이므로, 이것들은 @code{add_poly}와 @code{mul_poly}를 사용하여 결합될 것이다.
그 결과는 일종의 ``데이터 주도 재귀''로, 예를 들어 @code{mul_poly}에 대한 호출은 계수를 곱하기 위해 @code{mul_poly}에 대한 재귀적 호출을 초래할 것이다.
만약 계수의 계수가 그 자체로 다항식이라면(세 변수의 다항식을 표현하는 데 사용될 수 있는 것처럼), 데이터 방향은 시스템이 또 다른 레벨의 재귀 호출을 따르도록 보장할 것이며, 데이터 구조가 지시하는 만큼 많은 레벨을 통해 계속될 것이다.@footnote{이것이 완전히 매끄럽게 작동하게 하려면, 우리는 또한 ``숫자''를 0차 다항식으로 간주하여 다항식으로 강제 변환하는 능력을 제네릭 산술 시스템에 추가해야 한다.
이것은 우리가 다음과 같은 연산을 수행하려 할 때 필요하다
@ifinfo

@example
[x^2 + (y + 1)x + 5] + [x^2 + 2x + 1]
@end example

@end ifinfo
@tex
\[ % :54:
  {[x^2 + (y + 1)x + 5]} + {[x^2 + 2x + 1],}  \]
@end tex
@noindent
이것은 계수 @math{{y + 1}}을 계수 2에 더하는 것을 요구한다.}

@subsubheading 항 리스트 표현 (Representing term lists)

마지막으로, 우리는 항 리스트를 위한 좋은 표현을 구현하는 작업에 직면해야 한다.
항 리스트는 사실상 항의 차수를 키로 하는 계수들의 집합이다.
따라서 @ref{2.3.3}에서 논의된 집합 표현 방법 중 어느 것이든 이 작업에 적용될 수 있다.
반면에, 우리의 프로시저 @code{add-terms}와 @code{mul-terms}는 항상 가장 높은 차수부터 가장 낮은 차수까지 순차적으로 항 리스트에 접근한다.
따라서 우리는 어떤 종류의 정렬된 리스트 표현을 사용할 것이다.

항 리스트를 나타내는 리스트를 어떻게 구조화해야 할까?
한 가지 고려 사항은 우리가 조작하려는 다항식의 ``밀도(density)''이다.
다항식은 대부분의 차수의 항에 0이 아닌 계수가 있으면 @newterm{조밀하다(dense)}고 한다.
만약 많은 0 항이 있으면 @newterm{희소하다(sparse)}고 한다.
예를 들어,
@ifinfo

@example
A : x^5 + 2x^4 + 3x^2 - 2x - 5
@end example

@end ifinfo
@tex
\[ % :55:
  A: \quad {x^5} + {2x^4} + {3x^2} - {2x} - 5  \]
@end tex
@noindent
는 조밀한 다항식인 반면,
@ifinfo

@example
B : x^100 + 2x^2 + 1
@end example

@end ifinfo
@tex
\[ % :56:
  B: \quad x^{100} + {2x^2} + 1  \]
@end tex
@noindent
은 희소하다.

조밀한 다항식의 항 리스트는 계수들의 리스트로 가장 효율적으로 표현된다.
예를 들어, 위의 @math{A}는 @code{(1 2 0 3 -2 -5)}로 멋지게 표현될 수 있다.
이 표현에서 항의 차수는 그 항의 계수로 시작하는 서브리스트의 길이에서 1을 뺀 것이다.@footnote{이 다항식 예제들에서, 우리는 @ref{Exercise 2.78}에서 제안된 타입 메커니즘을 사용하여 제네릭 산술 시스템을 구현했다고 가정한다. 따라서 일반 숫자인 계수는 @code{car}가 기호 @code{SchemeNumber}인 쌍이 아니라 숫자 자체로 표현될 것이다.}
이것은 @math{B}와 같은 희소 다항식에는 끔찍한 표현일 것이다: 몇 개의 외로운 0이 아닌 항들이 점재하는 거대한 0의 리스트가 있을 것이다.
희소 다항식의 항 리스트에 대한 더 합리적인 표현은 0이 아닌 항들의 리스트인데, 여기서 각 항은 항의 차수와 그 차수에 대한 계수를 포함하는 리스트이다.
그러한 계획에서, 다항식 @math{B}는 @code{((100 1) (2 2) (0 1))}로 효율적으로 표현된다.
대부분의 다항식 조작은 희소 다항식에 대해 수행되므로, 우리는 이 방법을 사용할 것이다.
우리는 항 리스트가 가장 높은 차수부터 가장 낮은 차수 항까지 배열된 항들의 리스트로 표현된다고 가정할 것이다.
이 결정을 내리고 나면, 항과 항 리스트에 대한 선택자와 생성자를 구현하는 것은 간단하다:@footnote{우리는 항 리스트가 정렬되어 있다고 가정하지만, @code{adjoin_term}을 단순히 새 항을 기존 항 리스트에 @code{cons}하는 것으로 구현했다. @code{adjoin_term}을 사용하는 프로시저들(@code{add-terms}와 같은)이 항상 리스트에 나타나는 것보다 더 높은 차수의 항으로 그것을 호출한다고 보장하는 한 우리는 이것으로 지낼 수 있다. 만약 그러한 보장을 하고 싶지 않다면, 우리는 @code{adjoin_term}을 정렬된 리스트 집합 표현을 위한 @code{adjoin_set} 생성자와 유사하게 구현할 수 있었을 것이다(@ref{Exercise 2.61}).}

@example
impl Term @{
    fn new(order: usize, coeff: f64) -> Self @{
        Term @{ order, coeff @}
    @}

    fn is_zero(&self) -> bool @{
        self.coeff == 0.0
    @}
@}

fn adjoin_term(term: Term, mut term_list: Vec<Term>) -> Vec<Term> @{
    if !term.is_zero() @{
        term_list.insert(0, term);
    @}
    term_list
@}

// 슬라이스 메서드는 first_term, rest_terms, 그리고 is_empty를 제공한다:
// term_list.first()      -> Option<&Term>
// &term_list[1..]        -> &[Term]  (나머지)
// term_list.is_empty()   -> bool
@end example

@noindent
여기서 @code{=zero?}는 @ref{Exercise 2.80}에서 정의된 것과 같다. (아래 @ref{Exercise 2.87}도 참조하라.)

다항식 패키지의 사용자는 다음 프로시저를 통해 (태그된) 다항식을 생성할 것이다:

@example
fn make_polynomial(var: &str, terms: Vec<Term>) -> Poly @{
    Poly::new(var, terms)
@}
@end example

@quotation
@strong{@anchor{Exercise 2.87}연습문제 2.87:} 제네릭 산술 패키지에 다항식을 위한 @code{=zero?}를 설치하라.
이것은 @code{adjoin_term}이 계수 자체가 다항식인 다항식에 대해 작동하도록 허용할 것이다.
@end quotation

@quotation
@strong{@anchor{Exercise 2.88}연습문제 2.88:} 다항식 시스템을 확장하여 다항식의 뺄셈을 포함하도록 하라. (힌트: 제네릭 부정 연산을 정의하는 것이 도움이 될 수 있다.)
@end quotation

@quotation
@strong{@anchor{Exercise 2.89}연습문제 2.89:} 위에서 설명한 항 리스트 표현을 조밀한 다항식에 적합하게 구현하는 프로시저들을 정의하라.
@end quotation

@quotation
@strong{@anchor{Exercise 2.90}연습문제 2.90:} 희소 다항식과 조밀한 다항식 모두에 효율적인 다항식 시스템을 갖고 싶다고 가정해 보자.
이를 수행하는 한 가지 방법은 우리 시스템에서 두 종류의 항 리스트 표현을 모두 허용하는 것이다.
상황은 @ref{2.4}의 복소수 예제와 유사한데, 거기서 우리는 직교 좌표와 극좌표 표현을 모두 허용했다.
이를 위해 우리는 서로 다른 타입의 항 리스트를 구별하고 항 리스트에 대한 연산을 제네릭하게 만들어야 한다.
이 일반화를 구현하기 위해 다항식 시스템을 재설계하라. 이것은 지역적인 변경이 아니라 주요한 노력이다.
@end quotation

@quotation
@strong{@anchor{Exercise 2.91}연습문제 2.91:} 일변수 다항식은 다른 다항식으로 나뉘어 다항식 몫과 다항식 나머지를 생성할 수 있다. 예를 들어,
@ifinfo

@example
x^5 - 1
------- = x^3 + x, remainder x - 1
x^2 - 1
@end example

@end ifinfo
@tex
\[ % :57:
  {x^5 - 1 \over x^2 - 1} \,=\, {x^3 + x,} \text{  remainder  } {x - 1.}  \]
@end tex
나눗셈은 장제법(long division)을 통해 수행될 수 있다.
즉, 피제수의 최고차항을 제수의 최고차항으로 나눈다.
그 결과가 몫의 첫 번째 항이다.
다음으로, 그 결과에 제수를 곱하고, 그것을 피제수에서 뺀 다음, 그 차이를 제수로 재귀적으로 나누어 나머지 답을 생성한다.
제수의 차수가 피제수의 차수를 초과하면 멈추고 피제수를 나머지로 선언한다.
또한, 피제수가 0이 되면 몫과 나머지 모두 0을 반환한다.

우리는 @code{add_poly}와 @code{mul_poly}를 모델로 @code{div-poly} 프로시저를 설계할 수 있다.
이 프로시저는 두 poly가 같은 변수를 갖는지 확인한다.
그렇다면, @code{div-poly}는 변수를 떼어내고 항 리스트에 대한 나눗셈 연산을 수행하는 @code{div-terms}에 문제를 전달한다.
@code{Div-poly}는 마지막으로 @code{div-terms}가 제공한 결과에 변수를 다시 붙인다.
나눗셈의 몫과 나머지를 모두 계산하도록 @code{div-terms}를 설계하는 것이 편리하다.
@code{Div-terms}는 두 항 리스트를 인자로 받아 몫 항 리스트와 나머지 항 리스트의 리스트를 반환할 수 있다.

다음 @code{div-terms} 정의에서 누락된 표현식을 채워 넣어라.
이것을 사용하여 두 poly를 인자로 받아 몫과 나머지 poly의 리스트를 반환하는 @code{div-poly}를 구현하라.

@example
fn div_terms(l1: &[Term], l2: &[Term]) -> (Vec<Term>, Vec<Term>) @{
    if l1.is_empty() @{
        return (vec![], vec![]);
    @}
    let t1 = &l1[0];
    let t2 = &l2[0];
    if t2.order > t1.order @{
        (vec![], l1.to_vec())
    @} else @{
        let new_c = t1.coeff / t2.coeff;
        let new_o = t1.order - t2.order;
        let new_term = Term::new(new_o, new_c);
        // @emph{나머지 결과를 재귀적으로 계산한다}
        let subtracted = subtract_terms(
            l1,
            &mul_term_by_all_terms(&new_term, l2),
        );
        let (rest_quotient, remainder) = div_terms(&subtracted, l2);
        // @emph{완전한 결과를 형성한다}
        let mut quotient = vec![new_term];
        quotient.extend(rest_quotient);
        (quotient, remainder)
    @}
@}
@end example
@end quotation

@subsubheading 기호 대수의 타입 계층 (Hierarchies of types in symbolic algebra)

우리의 다항식 시스템은 한 타입(다항식)의 객체가 사실상 다른 많은 타입의 객체를 부분으로 갖는 복잡한 객체일 수 있음을 보여준다.
이것은 제네릭 연산을 정의하는 데 실질적인 어려움을 주지 않는다.
우리는 단지 복합 타입의 부분을 필요한 대로 조작하기 위한 적절한 제네릭 연산을 설치하기만 하면 된다.
사실, 우리는 다항식이 그 부분 자체가 다항식일 수 있다는 점에서 일종의 ``재귀적 데이터 추상화''를 형성한다는 것을 보았다.
우리의 제네릭 연산과 데이터 주도 프로그래밍 스타일은 이 복잡성을 별 어려움 없이 처리할 수 있다.

반면에, 다항식 대수는 데이터 타입이 자연스럽게 탑으로 배열될 수 없는 시스템이다.
예를 들어, 계수가 @math{y}에 대한 다항식인 @math{x}에 대한 다항식을 가질 수 있다.
또한 계수가 @math{x}에 대한 다항식인 @math{y}에 대한 다항식을 가질 수도 있다.
이 두 타입 중 어느 것도 자연스러운 방식으로 다른 것 ``위에'' 있지 않지만, 각 집합의 요소를 더해야 할 필요가 종종 있다.
이를 수행하는 여러 가지 방법이 있다.
한 가지 가능성은 한 다항식을 다른 다항식의 타입으로 변환하기 위해 항들을 전개하고 재배열하여 두 다항식이 같은 주 변수를 갖도록 하는 것이다.
변수들에 순서를 부여하고 따라서 항상 모든 다항식을 가장 높은 우선순위 변수가 우세하고 낮은 우선순위 변수가 계수에 묻히는 ``정준형(canonical form)''으로 변환함으로써 여기에 탑 같은 구조를 부과할 수 있다.
이 전략은 변환이 다항식을 불필요하게 확장하여 읽기 어렵게 만들고 작업하기에 덜 효율적으로 만들 수 있다는 점을 제외하면 꽤 잘 작동한다.
탑 전략은 이 도메인이나 삼각 함수, 거듭제곱 급수, 적분과 같은 다양한 결합 형태의 옛 타입을 사용하여 사용자가 동적으로 새 타입을 발명할 수 있는 어떤 도메인에서도 확실히 자연스럽지 않다.

대규모 대수 조작 시스템의 설계에서 강제 변환을 제어하는 것이 심각한 문제라는 것은 놀라운 일이 아니다.
그러한 시스템의 복잡성 중 많은 부분은 다양한 타입 간의 관계와 관련이 있다.
실제로, 우리가 아직 강제 변환을 완전히 이해하지 못했다고 말하는 것이 타당하다.
사실, 우리는 아직 데이터 타입의 개념을 완전히 이해하지 못했다.
그럼에도 불구하고, 우리가 아는 것은 대규모 시스템 설계를 지원하기 위한 강력한 구조화 및 모듈성 원칙을 제공한다.

@quotation
@strong{@anchor{Exercise 2.92}연습문제 2.92:} 변수에 순서를 부여함으로써, 서로 다른 변수의 다항식에 대해 다항식의 덧셈과 곱셈이 작동하도록 다항식 패키지를 확장하라. (이것은 쉽지 않다!)
@end quotation

@subsubheading 심화 연습 문제: 유리 함수 (Extended exercise: Rational functions)

우리는 제네릭 산술 시스템을 확장하여 @newterm{유리 함수(rational functions)}를 포함할 수 있다.
이것들은 분자와 분모가 다항식인 ``분수''이다. 예를 들어
@ifinfo

@example
 x + 1
-------
x^3 - 1
@end example

@end ifinfo
@tex
\[ % :58:
  {{x + 1 \over x^3 - 1}.}  \]
@end tex
시스템은 유리 함수를 더하고, 빼고, 곱하고, 나눌 수 있어야 하며, 다음과 같은 계산을 수행할 수 있어야 한다
@ifinfo

@example
 x + 1       x      x^3 + 2x^2 + 3x + 1
------- + ------- = -------------------
x^3 - 1   x^2 - 1    x^4 + x^3 - x - 1
@end example

@end ifinfo
@tex
\[ % :59:
  {x + 1 \over x^3 - 1} + {x \over x^2 - 1} \,=\, 
  {{x^3 + 2x^2 + 3x + 1 \over x^4 + x^3 - x - 1}.}  \]
@end tex
@noindent
(여기서 합은 공통 인수를 제거함으로써 단순화되었다. 일반적인 ``교차 곱셈''은 5차 다항식 분의 4차 다항식을 생성했을 것이다.)

만약 우리가 유리수 산술 패키지를 수정하여 제네릭 연산을 사용하도록 한다면, 분수를 기약분수로 만드는 문제를 제외하고는 우리가 원하는 것을 수행할 것이다.

@quotation
@strong{@anchor{Exercise 2.93}연습문제 2.93:} 유리수 산술 패키지를 수정하여 제네릭 연산을 사용하도록 하되, @code{Rational::new}가 분수를 기약분수로 만들려고 시도하지 않도록 변경하라.
두 다항식에 대해 @code{make-rational}을 호출하여 유리 함수를 생성함으로써 시스템을 테스트하라:

@example
let p1 = Poly::new("x", vec![Term::new(2, 1.0), Term::new(0, 1.0)]);
let p2 = Poly::new("x", vec![Term::new(3, 1.0), Term::new(0, 1.0)]);
let rf = RationalFn::new(p2, p1);
@end example

이제 @code{add}를 사용하여 @code{rf}를 자신에게 더하라. 이 덧셈 프로시저가 분수를 기약분수로 만들지 않는다는 것을 관찰하게 될 것이다.
@end quotation

@noindent
우리는 정수에서 사용했던 것과 같은 아이디어, 즉 @code{Rational::new}를 수정하여 분자와 분모를 모두 그들의 최대공약수로 나누는 방법을 사용하여 다항식 분수를 기약분수로 만들 수 있다.
``최대공약수''라는 개념은 다항식에 대해서도 말이 된다.
사실, 우리는 본질적으로 정수에 대해 작동하는 것과 같은 유클리드 알고리즘을 사용하여 두 다항식의 @abbr{GCD}를 계산할 수 있다.@footnote{유클리드 알고리즘이 다항식에 대해 작동한다는 사실은 대수학에서 다항식이 @newterm{유클리드 환(Euclidean ring)}이라고 불리는 일종의 대수적 도메인을 형성한다고 말함으로써 공식화된다. 유클리드 환은 덧셈, 뺄셈, 그리고 교환 가능한 곱셈을 허용하며, 환의 각 요소 @math{x}에 대해 양의 정수 ``측도(measure)'' @math{{m(x)}}를 할당하는 방법이 있어 0이 아닌 어떤 @math{x}와 @math{y}에 대해서도 @math{{m(xy) \ge m(x)}}이고, 어떤 @math{x}와 @math{y}가 주어지더라도 @math{{y = qx + r}}이고 @math{{r = 0}}이거나 @math{{m(r) < m(x)}}인 @math{q}가 존재한다는 성질을 갖는 도메인이다. 추상적인 관점에서, 이것이 유클리드 알고리즘이 작동함을 증명하는 데 필요한 것이다. 정수 도메인의 경우, 정수의 측도 @math{m}은 정수 자체의 절댓값이다. 다항식 도메인의 경우, 다항식의 측도는 그 차수이다.} 정수 버전은 다음과 같다

@example
fn gcd(a: i64, b: i64) -> i64 @{
    if b == 0 @{
        a
    @} else @{
        gcd(b, a % b)
    @}
@}
@end example

@noindent
이것을 사용하여, 우리는 명백한 수정을 가해 항 리스트에 대해 작동하는 @abbr{GCD} 연산을 정의할 수 있다:

@example
fn gcd_terms(a: &[Term], b: &[Term]) -> Vec<Term> @{
    if b.is_empty() @{
        a.to_vec()
    @} else @{
        let (_, remainder) = div_terms(a, b);
        gcd_terms(b, &remainder)
    @}
@}
@end example

@noindent
여기서 @code{remainder-terms}는 @ref{Exercise 2.91}에서 구현된 항 리스트 나눗셈 연산 @code{div-terms}에 의해 반환된 리스트의 나머지 성분을 골라낸다.

@quotation
@strong{@anchor{Exercise 2.94}연습문제 2.94:} @code{div-terms}를 사용하여 프로시저 @code{remainder-terms}를 구현하고 이것을 사용하여 위와 같이 @code{gcd-terms}를 정의하라.
이제 두 poly의 다항식 @abbr{GCD}를 계산하는 프로시저 @code{gcd-poly}를 작성하라. (이 프로시저는 두 poly가 같은 변수에 있지 않으면 오류를 신호해야 한다.)
다항식에 대해서는 @code{gcd-poly}로 축소되고 일반 숫자에 대해서는 일반 @code{gcd}로 축소되는 제네릭 연산 @code{greatest-common-divisor}를 시스템에 설치하라.
테스트로 다음을 시도해 보라

@example
let p1 = Poly::new("x", vec![
    Term::new(4, 1.0), Term::new(3, -1.0),
    Term::new(2, -2.0), Term::new(1, 2.0),
]);

let p2 = Poly::new("x", vec![
    Term::new(3, 1.0), Term::new(1, -1.0),
]);

let result = gcd_poly(&p1, &p2);
@end example

@noindent
그리고 결과를 손으로 확인하라.
@end quotation

@quotation
@strong{@anchor{Exercise 2.95}연습문제 2.95:} @math{P_1}, @math{P_2}, 그리고 @math{P_3}을 다음 다항식으로 정의하라
@ifinfo

@example
P_1 : x^2 - 2x + 1

P_2 : 11x^2 + 7

P_3 : 13x + 5
@end example

@end ifinfo
@tex
\[ % :60:
\begin{array}{rl}
  P_1:  &   x^2 - 2x + 1, \\
  P_2:  &   11x^2 + 7,    \\
  P_3:  &   13x + 5.
\end{array}
\]
@end tex
이제 @math{Q_1}을 @math{P_1}과 @math{P_2}의 곱으로, @math{Q_2}를 @math{P_1}과 @math{P_3}의 곱으로 정의하고, @code{greatest-common-divisor}(@ref{Exercise 2.94})를 사용하여 @math{Q_1}과 @math{Q_2}의 @abbr{GCD}를 계산하라.
답이 @math{P_1}과 같지 않음에 주목하라.
이 예제는 계산에 비정수 연산을 도입하여 @abbr{GCD} 알고리즘에 어려움을 일으킨다.@footnote{@abbr{MIT} Scheme과 같은 구현에서는 이것이 실제로 @math{Q_1}과 @math{Q_2}의 약수인 다항식을 생성하지만, 유리수 계수를 가진다. 정수의 나눗셈이 제한된 정밀도의 소수를 생성할 수 있는 다른 많은 Scheme 시스템에서는 유효한 약수를 얻는 데 실패할 수 있다.}
무슨 일이 일어나는지 이해하기 위해, @abbr{GCD}를 계산하는 동안 @code{gcd-terms}를 추적하거나 손으로 나눗셈을 수행해 보라.
@end quotation

@noindent
우리는 @abbr{GCD} 알고리즘의 다음 수정(정수 계수를 가진 다항식의 경우에만 정말로 작동하는)을 사용하면 @ref{Exercise 2.95}에서 보여진 문제를 해결할 수 있다.
@abbr{GCD} 계산에서 다항식 나눗셈을 수행하기 전에, 나눗셈 과정 동안 분수가 발생하지 않도록 보장하기 위해 선택된 정수 상수 인자를 피제수에 곱한다.
우리의 답은 따라서 실제 @abbr{GCD}와 정수 상수 인자만큼 다를 것이지만, 이것은 유리 함수를 기약분수로 만드는 경우에는 중요하지 않다; @abbr{GCD}는 분자와 분모를 모두 나누는 데 사용될 것이므로 정수 상수 인자는 상쇄될 것이다.

더 정확하게, @math{P}와 @math{Q}가 다항식이고, @math{O_1}을 @math{P}의 차수(즉, @math{P}의 가장 큰 항의 차수)라 하고 @math{O_2}를 @math{Q}의 차수라 하자.
@math{c}를 @math{Q}의 선행 계수(leading coefficient)라 하자.
그러면, 만약 우리가 @math{P}에 @newterm{정수화 인자(integerizing factor)} @math{c^{1 + O_1 - O_2}}를 곱하면, 결과 다항식은 분수를 도입하지 않고 @code{div-terms} 알고리즘을 사용하여 @math{Q}로 나누어질 수 있음을 보일 수 있다.
피제수에 이 상수를 곱한 다음 나누는 연산을 때때로 @math{Q}에 의한 @math{P}의 @newterm{의사 나눗셈(pseudodivision)}이라고 부른다.
나눗셈의 나머지를 @newterm{의사 나머지(pseudoremainder)}라고 부른다.

@quotation
@strong{@anchor{Exercise 2.96}연습문제 2.96:}
@enumerate a

@item
@code{div-terms}를 호출하기 전에 위에서 설명한 정수화 인자를 피제수에 곱한다는 점을 제외하고는 @code{remainder-terms}와 똑같은 프로시저 @code{pseudoremainder-terms}를 구현하라.
@code{gcd-terms}가 @code{pseudoremainder-terms}를 사용하도록 수정하고, 이제 @code{greatest-common-divisor}가 @ref{Exercise 2.95}의 예제에서 정수 계수를 가진 답을 생성하는지 확인하라.

@item
@abbr{GCD}는 이제 정수 계수를 갖지만, 그것들은 @math{P_1}의 계수보다 크다.
답의 계수들에서 공통 인수를 제거하기 위해 모든 계수를 그들의 (정수) 최대공약수로 나눔으로써 @code{gcd-terms}를 수정하라.

@end enumerate
@end quotation

@noindent
따라서, 유리 함수를 기약분수로 만드는 방법은 다음과 같다:

@itemize @bullet

@item
@ref{Exercise 2.96}의 @code{gcd-terms} 버전을 사용하여 분자와 분모의 @abbr{GCD}를 계산한다.

@item
@abbr{GCD}를 얻으면, @abbr{GCD}로 나누기 전에 분자와 분모 모두에 같은 정수화 인자를 곱해서 @abbr{GCD}로 나누는 것이 비정수 계수를 도입하지 않도록 한다.
인자로는 @abbr{GCD}의 선행 계수의 @math{{1 + O_1 - O_2}}승을 사용할 수 있다. 여기서 @math{O_2}는 @abbr{GCD}의 차수이고 @math{O_1}은 분자와 분모 차수의 최댓값이다.
이것은 분자와 분모를 @abbr{GCD}로 나누는 것이 분수를 도입하지 않도록 보장할 것이다.

@item
이 연산의 결과는 정수 계수를 가진 분자와 분모일 것이다.
계수들은 대개 모든 정수화 인자들 때문에 매우 클 것이므로, 마지막 단계는 분자와 분모의 모든 계수의 (정수) 최대공약수를 계산하고 이 인자로 나누어 줌으로써 중복된 인자들을 제거하는 것이다.

@end itemize

@quotation
@strong{@anchor{Exercise 2.97}연습문제 2.97:}
@enumerate a

@item
이 알고리즘을 두 항 리스트 @code{n}과 @code{d}를 인자로 받아 위에서 주어진 알고리즘을 통해 기약분수로 축소된 @code{n}과 @code{d}인 리스트 @code{nn}, @code{dd}를 반환하는 프로시저 @code{reduce-terms}로 구현하라.
또한 @code{add_poly}와 유사한 프로시저 @code{reduce-poly}를 작성하라. 이것은 두 poly가 같은 변수를 갖는지 확인한다.
그렇다면, @code{reduce-poly}는 변수를 떼어내고 문제를 @code{reduce-terms}에 전달한 다음, 변수를 @code{reduce-terms}가 제공한 두 항 리스트에 다시 붙인다.

@item
원래 @code{Rational::new}가 정수에 대해 했던 일을 하는, @code{reduce-terms}와 유사한 프로시저를 정의하라:

@example
fn reduce_integers(n: i64, d: i64) -> (i64, i64) @{
    let g = gcd(n, d);
    (n / g, d / g)
@}
@end example

그리고 @code{apply-generic}을 호출하여 (@code{polynomial} 인자에 대해서는) @code{reduce-poly} 또는 (@code{SchemeNumber} 인자에 대해서는) @code{reduce-integers}로 디스패치하는 제네릭 연산 @code{reduce}를 정의하라.
이제 주어진 분자와 분모를 결합하여 유리수를 형성하기 전에 @code{Rational::new}가 @code{reduce}를 호출하게 함으로써 유리수 산술 패키지가 분수를 기약분수로 축소하게 쉽게 만들 수 있다.
시스템은 이제 정수나 다항식의 유리식을 처리한다.
여러분의 프로그램을 테스트하기 위해, 이 심화 연습 문제의 시작 부분에 있는 예제를 시도해 보라:

@example
let p1 = Poly::new("x", vec![Term::new(1, 1.0), Term::new(0, 1.0)]);
let p2 = Poly::new("x", vec![Term::new(3, 1.0), Term::new(0, -1.0)]);
let p3 = Poly::new("x", vec![Term::new(1, 1.0)]);
let p4 = Poly::new("x", vec![Term::new(2, 1.0), Term::new(0, -1.0)]);
let rf1 = RationalFn::new(p1, p2);
let rf2 = RationalFn::new(p3, p4);
let result = rf1 + rf2;
@end example

올바른 답, 즉 올바르게 기약분수로 축소된 답을 얻는지 확인하라.
@end enumerate
@end quotation

@noindent
@abbr{GCD} 계산은 유리 함수에 대한 연산을 수행하는 모든 시스템의 핵심이다.
위에서 사용된 알고리즘은 수학적으로는 간단하지만 매우 느리다.
느림의 원인은 부분적으로는 많은 수의 나눗셈 연산 때문이고 부분적으로는 의사 나눗셈에 의해 생성되는 중간 계수들의 엄청난 크기 때문이다.
대수 조작 시스템 개발의 활발한 분야 중 하나는 다항식 @abbr{GCD}를 계산하기 위한 더 나은 알고리즘의 설계이다.@footnote{다항식 @abbr{GCD}를 계산하기 위한 매우 효율적이고 우아한 방법 하나는 리처드 지펠(Richard @ref{Zippel (1979)})에 의해 발견되었다. 이 방법은 우리가 @ref{Chapter 1}에서 논의한 빠른 소수성 판별과 마찬가지로 확률적 알고리즘이다. 지펠의 책(@ref{Zippel 1993})은 다항식 @abbr{GCD}를 계산하는 다른 방법들과 함께 이 방법을 설명한다.}
password, it invokes the procedure @code{call-the-cops}.
@end quotation

@node	3.1.2, 3.1.3, 3.1.1, 3.1
@subsection The Benefits of Introducing Assignment

As we shall see, introducing assignment into our programming language leads us
into a thicket of difficult conceptual issues.  Nevertheless, viewing systems
as collections of objects with local state is a powerful technique for
maintaining a modular design.  As a simple example, consider the design of a
procedure @code{rand} that, whenever it is called, returns an integer chosen at
random.

It is not at all clear what is meant by ``chosen at random.''  What we
presumably want is for successive calls to @code{rand} to produce a sequence of
numbers that has statistical properties of uniform distribution.  We will not
discuss methods for generating suitable sequences here.  Rather, let us assume
that we have a procedure @code{rand-update} that has the property that if we
start with a given number @math{x_1} and form

@example
let x2 = rand_update(x1);
let x3 = rand_update(x2);
@end example

@noindent
then the sequence of values @math{x_1}, @math{x_2}, @math{x_3}, @dots{} will have the
desired statistical properties.@footnote{One common way to implement
@code{rand-update} is to use the rule that @math{x} is updated to @math{{ax + b}} 
modulo @math{m}, where @math{a}, @math{b}, and @math{m} are appropriately chosen
integers.  Chapter 3 of @ref{Knuth 1981} includes an extensive discussion of
techniques for generating sequences of random numbers and establishing their
statistical properties.  Notice that the @code{rand-update} procedure computes
a mathematical function: Given the same input twice, it produces the same
output.  Therefore, the number sequence produced by @code{rand-update}
certainly is not ``random,'' if by ``random'' we insist that each number in the
sequence is unrelated to the preceding number.  The relation between ``real
randomness'' and so-called @newterm{pseudo-random} sequences, which are
produced by well-determined computations and yet have suitable statistical
properties, is a complex question involving difficult issues in mathematics and
philosophy.  Kolmogorov, Solomonoff, and Chaitin have made great progress in
clarifying these issues; a discussion can be found in @ref{Chaitin 1975}.}

We can implement @code{rand} as a procedure with a local state variable
@code{x} that is initialized to some fixed value @code{random-init}.  Each call
to @code{rand} computes @code{rand-update} of the current value of @code{x},
returns this as the random number, and also stores this as the new value of
@code{x}.

@example
fn make_rand(random_init: u64) -> impl FnMut() -> u64 @{
    let x = std::cell::Cell::new(random_init);
    move || @{
        let new_x = rand_update(x.get());
        x.set(new_x);
        new_x
    @}
@}
@end example

@noindent
Of course, we could generate the same sequence of random numbers without using
assignment by simply calling @code{rand-update} directly.  How@-ever, this would
mean that any part of our program that used random numbers would have to
explicitly remember the current value of @code{x} to be passed as an argument
to @code{rand-update}.  To realize what an annoyance this would be, consider
using random numbers to implement a technique called @newterm{Monte Carlo simulation}.

The Monte Carlo method consists of choosing sample experiments at random from a
large set and then making deductions on the basis of the probabilities
estimated from tabulating the results of those experiments.  For example, we
can approximate @math{\pi} using the fact that @math{{6/\pi^2}} is the probability
that two integers chosen at random will have no factors in common; that is,
that their greatest common divisor will be 1.@footnote{This theorem is due to
E. Ces@`aro.  See section 4.5.2 of @ref{Knuth 1981} for a discussion and a proof.} To
obtain the approximation to @math{\pi}, we perform a large number of experiments.
In each experiment we choose two integers at random and perform a test to see
if their @abbr{GCD} is 1.  The fraction of times that the test is passed
gives us our estimate of @math{{6/\pi^2}}, and from this we obtain our
approximation to @math{\pi}.

The heart of our program is a procedure @code{monte-carlo}, which takes as
arguments the number of times to try an experiment, together with the
experiment, represented as a no-argument procedure that will return either true
or false each time it is run.  @code{Monte-carlo} runs the experiment for the
designated number of trials and returns a number telling the fraction of the
trials in which the experiment was found to be true.

@example
fn estimate_pi(trials: u64) -> f64 @{
    (6.0 / monte_carlo(trials, cesaro_test)).sqrt()
@}

fn cesaro_test(rand: &mut impl FnMut() -> u64) -> bool @{
    gcd(rand(), rand()) == 1
@}

fn monte_carlo<F>(trials: u64, mut experiment: F) -> f64
where
    F: FnMut() -> bool,
@{
    let passed = (0..trials).filter(|_| experiment()).count();
    passed as f64 / trials as f64
@}
@end example

@noindent
Now let us try the same computation using @code{rand-update} directly rather
than @code{rand}, the way we would be forced to proceed if we did not use
assignment to model local state:

@example
fn estimate_pi_explicit(trials: u64, random_init: u64) -> f64 @{
    (6.0 / random_gcd_test(trials, random_init)).sqrt()
@}

fn random_gcd_test(trials: u64, initial_x: u64) -> f64 @{
    let mut passed = 0;
    let mut x = initial_x;
    for _ in 0..trials @{
        let x1 = rand_update(x);
        let x2 = rand_update(x1);
        if gcd(x1, x2) == 1 @{
            passed += 1;
        @}
        x = x2;
    @}
    passed as f64 / trials as f64
@}
@end example

@noindent
While the program is still simple, it betrays some painful breaches of
modularity.  In our first version of the program, using @code{rand}, we can
express the Monte Carlo method directly as a general @code{monte-carlo}
procedure that takes as an argument an arbitrary @code{experiment} procedure.
In our second version of the program, with no local state for the random-number
generator, @code{random-gcd-test} must explicitly manipulate the random numbers
@code{x1} and @code{x2} and recycle @code{x2} through the iterative loop as the
new input to @code{rand-update}.  This explicit handling of the random numbers
intertwines the structure of accumulating test results with the fact that our
particular experiment uses two random numbers, whereas other Monte Carlo
experiments might use one random number or three.  Even the top-level procedure
@code{estimate-pi} has to be concerned with supplying an initial random number.
The fact that the random-number generator's insides are leaking out into other
parts of the program makes it difficult for us to isolate the Monte Carlo idea
so that it can be applied to other tasks.  In the first version of the program,
assignment encapsulates the state of the random-number generator within the
@code{rand} procedure, so that the details of random-number generation remain
independent of the rest of the program.

The general phenomenon illustrated by the Monte Carlo example is this: From the
point of view of one part of a complex process, the other parts appear to
change with time.  They have hidden time-varying local state.  If we wish to
write computer programs whose structure reflects this decomposition, we make
computational objects (such as bank accounts and random-number generators)
whose behavior changes with time.  We model state with local state variables,
and we model the changes of state with assignments to those variables.

It is tempting to conclude this discussion by saying that, by introducing
assignment and the technique of hiding state in local variables, we are able to
structure systems in a more modular fashion than if all state had to be
manipulated explicitly, by passing additional parameters.  Unfortunately, as we
shall see, the story is not so simple.

@quotation
@strong{@anchor{Exercise 3.5}Exercise 3.5:} @newterm{Monte Carlo integration}
is a method of estimating definite integrals by means of Monte Carlo
simulation.  Consider computing the area of a region of space described by a
predicate @math{{P(x, y)}} that is true for points @math{{(x, y)}} in the
region and false for points not in the region.  For example, the region
contained within a circle of radius 3 centered at (5, 7) is described by the
predicate that tests whether @math{{(x - 5)^2} + {(y - 7)^2 \le 3^2}}.  To estimate
the area of the region described by such a predicate, begin by choosing a
rectangle that contains the region.  For example, a rectangle with diagonally
opposite corners at (2, 4) and (8, 10) contains the circle above.  The desired
integral is the area of that portion of the rectangle that lies in the region.
We can estimate the integral by picking, at random, points @math{{(x, y)}} that
lie in the rectangle, and testing @math{{P(x, y)}} for each point to
determine whether the point lies in the region.  If we try this with many
points, then the fraction of points that fall in the region should give an
estimate of the proportion of the rectangle that lies in the region.  Hence,
multiplying this fraction by the area of the entire rectangle should produce an
estimate of the integral.

Implement Monte Carlo integration as a procedure @code{estimate-integral} that
takes as arguments a predicate @code{P}, upper and lower bounds @code{x1},
@code{x2}, @code{y1}, and @code{y2} for the rectangle, and the number of trials
to perform in order to produce the estimate.  Your procedure should use the
same @code{monte-carlo} procedure that was used above to estimate @math{\pi}.
Use your @code{estimate-integral} to produce an estimate of @math{\pi} by
measuring the area of a unit circle.

You will find it useful to have a procedure that returns a number chosen at
random from a given range.  The following @code{random-in-range} procedure
implements this in terms of the @code{random} procedure used in 
@ref{1.2.6}, which returns a nonnegative number less than its
input.@footnote{@abbr{MIT} Scheme provides such a procedure.  If
@code{random} is given an exact integer (as in @ref{1.2.6}) it returns
an exact integer, but if it is given a decimal value (as in this exercise) it
returns a decimal value.}

@example
fn random_in_range(low: f64, high: f64) -> f64 @{
    let range = high - low;
    low + rand::random::<f64>() * range
@}
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 3.6}Exercise 3.6:} It is useful to be able to reset a
random-number generator to produce a sequence starting from a given value.
Design a new @code{rand} procedure that is called with an argument that is
either the symbol @code{generate} or the symbol @code{reset} and behaves as
follows: @code{(rand 'generate)} produces a new random number; @code{((rand
'reset) ⟨@var{new-value}⟩)} resets the internal state variable to the
designated @code{⟨}@var{new-value}@code{⟩}.  Thus, by resetting the state, one can generate
repeatable sequences.  These are very handy to have when testing and debugging
programs that use random numbers.
@end quotation

@node	3.1.3, 3.1.4, 3.1.2, 3.1
@subsection 대입 도입의 대가 (The Costs of Introducing Assignment)

우리가 보았듯이, @code{set!} 연산은 우리가 지역 상태를 가진 객체를 모델링할 수 있게 해준다.
그러나 이 이점에는 대가가 따른다.
우리의 프로그래밍 언어는 더 이상 우리가 @ref{1.1.5}에서 소개했던 프로시저 적용의 치환 모델의 관점에서 해석될 수 없다.
게다가 ``좋은'' 수학적 속성을 가진 어떤 단순한 모델도 프로그래밍 언어에서 객체와 대입을 다루는 적절한 프레임워크가 될 수 없다.

우리가 대입을 사용하지 않는 한, 동일한 인자로 동일한 프로시저를 두 번 평가하면 동일한 결과가 생성되므로, 프로시저는 수학적 함수를 계산하는 것으로 볼 수 있다.
이 책의 처음 두 장 전체에서 우리가 했던 것처럼 대입을 전혀 사용하지 않는 프로그래밍은 따라서 @newterm{함수형 프로그래밍(functional programming)}으로 알려져 있다.

대입이 어떻게 문제를 복잡하게 만드는지 이해하기 위해, 불충분한 금액을 확인하지 않는 @ref{3.1.1}의 @code{make_withdraw} 프로시저의 단순화된 버전을 고려해 보자:

@example
fn make_simplified_withdraw(initial: i64) -> impl FnMut(i64) -> i64 @{
    let balance = std::cell::Cell::new(initial);
    move |amount| @{
        balance.set(balance.get() - amount);
        balance.get()
    @}
@}

let mut w = make_simplified_withdraw(25);

w(20);
// => 5

w(10);
// => -5
@end example

@noindent
이 프로시저를 @code{set!}을 사용하지 않는 다음 @code{make-decrementer} 프로시저와 비교해 보자:

@example
fn make_decrementer(balance: i64) -> impl Fn(i64) -> i64 @{
    move |amount| balance - amount
@}
@end example

@noindent
@code{Make-decrementer}는 지정된 양 @code{balance}에서 입력을 빼는 프로시저를 반환하지만, @code{make-simplified-withdraw}와 같이 연속적인 호출에 걸쳐 누적되는 효과는 없다:

@example
let d = make_decrementer(25);

d(20);
// => 5

d(10);
// => 15
@end example

@noindent
우리는 @code{make-decrementer}가 어떻게 작동하는지 설명하기 위해 치환 모델을 사용할 수 있다.
예를 들어, 다음 표현식의 평가를 분석해 보자

@example
make_decrementer(25)(20)
@end example

@noindent
우리는 먼저 @code{make-decrementer}의 본문에서 @code{balance}를 25로 치환하여 조합의 연산자를 단순화한다.
이것은 표현식을 다음으로 축소한다

@example
(|amount| 25 - amount)(20)
@end example

@noindent
이제 우리는 @code{lambda} 표현식의 본문에서 @code{amount}를 20으로 치환하여 연산자를 적용한다:

@example
25 - 20
@end example

@noindent
최종 답은 5이다.

그러나 @code{make-simplified-withdraw}로 유사한 치환 분석을 시도하면 어떻게 되는지 관찰하라:

@example
make_simplified_withdraw(25)(20)
@end example

@noindent
우리는 먼저 @code{make-simplified-withdraw}의 본문에서 @code{balance}를 25로 치환하여 연산자를 단순화한다.
이것은 표현식을 다음으로 축소한다@footnote{우리는 @code{set!} 표현식에 있는 @code{balance}의 발생을 치환하지 않는데, 왜냐하면 @code{set!}의 @code{⟨}@var{name}@code{⟩}은 평가되지 않기 때문이다. 만약 우리가 그것을 치환한다면, 우리는 @code{(set! 25 (- 25 amount))}를 얻게 될 것인데, 이는 말이 되지 않는다.}

@example
// 명시적 Cell 변경을 사용하는 Rust 등가물:
(|amount| @{
    balance.set(25 - amount);
    25  // 새 값이 아니라 이전 값을 반환한다!
@})(20)
@end example

@noindent
이제 우리는 @code{lambda} 표현식의 본문에서 @code{amount}를 20으로 치환하여 연산자를 적용한다:

@example
@{ balance.set(25 - 20); 25 @}
@end example

@noindent
만약 우리가 치환 모델을 고수한다면, 우리는 프로시저 적용의 의미가 먼저 @code{balance}를 5로 설정한 다음 표현식의 값으로 25를 반환하는 것이라고 말해야 할 것이다.
이것은 잘못된 답을 얻는다.
올바른 답을 얻으려면, 우리는 어떻게든 (@code{set!}의 효과 전의) @code{balance}의 첫 번째 발생과 (@code{set!}의 효과 후의) @code{balance}의 두 번째 발생을 구별해야 할 것이며, 치환 모델은 이것을 할 수 없다.

여기서 문제는 치환이 궁극적으로 우리 언어의 기호가 본질적으로 값의 이름이라는 개념에 기초하고 있다는 것이다.
그러나 우리가 @code{set!}과 변수의 값이 변할 수 있다는 아이디어를 도입하자마자, 변수는 더 이상 단순히 이름일 수 없다.
이제 변수는 어떻게든 값이 저장될 수 있는 장소를 가리키며, 이 장소에 저장된 값은 변할 수 있다.
@ref{3.2}에서 우리는 환경이 우리의 계산 모델에서 이러한 ``장소'' 역할을 어떻게 수행하는지 볼 것이다.

@subsubheading 동일성과 변화 (Sameness and change)

여기서 표면화되는 문제는 단순히 특정 계산 모델의 붕괴보다 더 심오하다.
우리가 계산 모델에 변화를 도입하자마자, 이전에는 간단했던 많은 개념들이 문제가 된다.
두 가지가 ``같다(the same)''는 개념을 고려해 보자.

두 개의 프로시저를 생성하기 위해 같은 인자로 @code{make-decrementer}를 두 번 호출한다고 가정하자:

@example
let d1 = make_decrementer(25);
let d2 = make_decrementer(25);
@end example

@noindent
@code{D1}과 @code{D2}는 같은가?
허용 가능한 대답은 '예'이다. 왜냐하면 @code{D1}과 @code{D2}는 동일한 계산 동작을 갖기 때문이다---각각은 입력은 25에서 빼는 프로시저이다.
사실, @code{D1}은 결과를 변경하지 않고 어떤 계산에서든 @code{D2}로 대체될 수 있다.

이것을 @code{make-simplified-withdraw}에 대한 두 번의 호출과 대조해 보자:

@example
let mut w1 = make_simplified_withdraw(25);
let mut w2 = make_simplified_withdraw(25);
@end example

@noindent
@code{W1}과 @code{W2}는 같은가?
확실히 아니다. 왜냐하면 다음 상호 작용 시퀀스가 보여주듯이 @code{W1}과 @code{W2}에 대한 호출은 서로 다른 효과를 갖기 때문이다:

@example
w1(20);
// => Ok(5)

w1(20);
// => Ok(-15)

w2(20);
// => Ok(5)
@end example

@noindent
비록 @code{W1}과 @code{W2}가 동일한 표현식 @code{(make-simplified-withdraw 25)}를 평가하여 생성되었다는 의미에서 ``동등''할지라도, @code{W1}이 표현식 평가 결과를 변경하지 않고 어떤 표현식에서든 @code{W2}로 대체될 수 있다는 것은 사실이 아니다.

표현식의 값을 변경하지 않고 표현식 내의 ``동등한 것은 동등한 것으로 대체될 수 있다''는 개념을 지원하는 언어는 @newterm{참조 투명성(referentially transparent)}이 있다고 말한다.
참조 투명성은 우리가 컴퓨터 언어에 @code{set!}을 포함할 때 위반된다.
이것은 동등한 표현식을 치환함으로써 언제 표현식을 단순화할 수 있는지 결정하는 것을 까다롭게 만든다.
결과적으로, 대입을 사용하는 프로그램에 대해 추론하는 것은 훨씬 더 어려워진다.

일단 우리가 참조 투명성을 포기하면, 계산 객체가 ``같다''는 것이 무엇을 의미하는지에 대한 개념을 형식적인 방법으로 포착하기 어려워진다.
실제로 우리 프로그램이 모델링하는 실제 세계에서 ``같다''의 의미는 그 자체로 명확하지 않다.
일반적으로, 우리는 하나의 객체를 수정하고 다른 객체가 같은 방식으로 변했는지 관찰함으로써만 겉보기에 동일한 두 객체가 실제로 ``같은 것''인지 결정할 수 있다.
하지만 ``같은'' 객체를 두 번 관찰하고 객체의 어떤 속성이 한 관찰과 다음 관찰 사이에 다른지 보는 것 외에 객체가 ``변했다''는 것을 어떻게 알 수 있는가?
따라서, 우리는 ``동일성''에 대한 어떤 @emph{선험적(a priori)} 개념 없이는 ``변화''를 결정할 수 없으며, 변화의 효과를 관찰하지 않고는 동일성을 결정할 수 없다.

이 문제가 프로그래밍에서 어떻게 발생하는지에 대한 예로서, Peter와 Paul이 100달러가 든 은행 계좌를 가지고 있는 상황을 고려해 보자.
이것을 다음과 같이 모델링하는 것과

@example
let peter_acc = Account::new(100);
let paul_acc = Account::new(100);
@end example

@noindent
다음과 같이 모델링하는 것 사이에는 상당한 차이가 있다

@example
use std::rc::Rc;
let peter_acc = Rc::new(Account::new(100));
let paul_acc = Rc::clone(&peter_acc);  // 둘 다 같은 계좌를 참조함
@end example

@noindent
첫 번째 상황에서, 두 은행 계좌는 구별된다.
Peter가 수행한 거래는 Paul의 계좌에 영향을 미치지 않으며, 그 반대도 마찬가지이다.
그러나 두 번째 상황에서, 우리는 @code{paul-acc}가 @code{peter-acc}와 @emph{같은 것}이라고 정의했다.
사실상 Peter와 Paul은 이제 공동 은행 계좌를 가지고 있으며, 만약 Peter가 @code{peter-acc}에서 인출하면 Paul은 @code{paul-acc}에서 줄어든 돈을 관찰할 것이다.
이 두 가지 유사하지만 구별되는 상황은 계산 모델을 구축할 때 혼란을 일으킬 수 있다.
특히 공유 계좌의 경우, 두 개의 다른 이름(@code{peter-acc}와 @code{paul-acc})을 가진 하나의 객체(은행 계좌)가 있다는 것이 특히 혼란스러울 수 있다;
만약 우리가 프로그램에서 @code{paul-acc}가 변경될 수 있는 모든 곳을 찾고 있다면, 우리는 @code{peter-acc}를 변경하는 것들도 찾아야 함을 기억해야 한다.@footnote{하나의 계산 객체가 둘 이상의 이름으로 접근되는 현상을 @newterm{앨리어싱(aliasing)}이라고 한다. 공동 은행 계좌 상황은 앨리어스의 매우 간단한 예를 보여준다. @ref{3.3}에서 우리는 부분을 공유하는 ``별개의'' 복합 데이터 구조와 같은 훨씬 더 복잡한 예제를 볼 것이다. 만약 우리가 객체에 대한 변경이 ``부작용''으로서 ``다른'' 객체도 변경할 수 있다는 것을 잊어버린다면 우리 프로그램에 버그가 발생할 수 있다. 왜냐하면 두 ``다른'' 객체는 실제로는 다른 앨리어스로 나타나는 단일 객체이기 때문이다. 이러한 소위 @newterm{부작용 버그(side-effect bugs)}는 찾아서 분석하기가 너무 어려워서 일부 사람들은 프로그래밍 언어가 부작용이나 앨리어싱을 허용하지 않는 방식으로 설계되어야 한다고 제안했다(@ref{Lampson et al. 1981}; @ref{Morris et al. 1980}).}

``동일성''과 ``변화''에 대한 위의 언급과 관련하여, 만약 Peter와 Paul이 은행 잔고를 확인할 수만 있고 잔고를 변경하는 작업을 수행할 수 없다면, 두 계좌가 구별되는지에 대한 문제는 의미가 없음을 관찰하라.
일반적으로, 우리가 데이터 객체를 결코 수정하지 않는 한, 우리는 복합 데이터 객체를 정확히 그 조각들의 총체로 간주할 수 있다.
예를 들어, 유리수는 분자와 분모를 제공함으로써 결정된다.
그러나 변화가 존재하는 경우 이 관점은 더 이상 유효하지 않으며, 복합 데이터 객체는 그것이 구성된 조각들과는 다른 ``정체성(identity)''을 갖는다.
은행 계좌는 우리가 인출을 하여 잔액을 변경하더라도 여전히 ``같은'' 은행 계좌이다; 반대로, 우리는 같은 상태 정보를 가진 두 개의 다른 은행 계좌를 가질 수 있다.
이 복잡성은 프로그래밍 언어의 결과가 아니라, 은행 계좌를 객체로 인식하는 우리의 인식의 결과이다.
예를 들어, 우리는 보통 유리수를 정체성을 가진 변경 가능한 객체로 간주하지 않으며, 따라서 분자를 변경해도 여전히 ``같은'' 유리수를 갖는다고 생각하지 않는다.

@subsubheading 명령형 프로그래밍의 함정 (Pitfalls of imperative programming)

함수형 프로그래밍과 대조적으로, 대입을 광범위하게 사용하는 프로그래밍은 @newterm{명령형 프로그래밍(imperative programming)}으로 알려져 있다.
계산 모델에 대한 복잡성을 제기하는 것 외에도, 명령형 스타일로 작성된 프로그램은 함수형 프로그램에서는 발생할 수 없는 버그에 취약하다.
예를 들어, @ref{1.2.1}의 반복적 팩토리얼 프로그램을 상기해 보자:

@example
fn factorial(n: u64) -> u64 @{
    fn iter(product: u64, counter: u64, n: u64) -> u64 @{
        if counter > n @{
            product
        @} else @{
            iter(counter * product, counter + 1, n)
        @}
    @}
    iter(1, 1, n)
@}
@end example

@noindent
내부 반복 루프에서 인자를 전달하는 대신, 우리는 변수 @code{product}와 @code{counter}의 값을 업데이트하기 위해 명시적 대입을 사용하여 더 명령적인 스타일을 채택할 수 있다:

@example
fn factorial(n: u64) -> u64 @{
    let mut product = 1u64;
    let mut counter = 1u64;
    while counter <= n @{
        product *= counter;
        counter += 1;
    @}
    product
@}
@end example

@noindent
이것은 프로그램에 의해 생성되는 결과를 변경하지 않지만, 미묘한 함정을 도입한다.
대입의 순서를 어떻게 결정하는가?
공교롭게도, 작성된 프로그램은 올바르다.
그러나 대입을 반대 순서로 작성하면

@example
counter += 1;
product *= counter;  // 틀림: 증가된 counter를 사용함
@end example

@noindent
다르고 올바르지 않은 결과를 생성했을 것이다.
일반적으로, 대입을 사용한 프로그래밍은 각 문장이 변경된 변수의 올바른 버전을 사용하고 있는지 확인하기 위해 대입의 상대적 순서를 신중하게 고려하도록 강요한다.
이 문제는 함수형 프로그램에서는 전혀 발생하지 않는다.@footnote{이런 관점에서 볼 때, 입문 프로그래밍이 가장 자주 매우 명령적인 스타일로 가르쳐진다는 것은 아이러니하다. 이것은 프로시저를 호출하는 프로그램이 대입을 수행하는 프로그램보다 본질적으로 덜 효율적일 수밖에 없다는 1960년대와 1970년대에 흔했던 믿음의 잔재일 수 있다. (@ref{Steele 1977}은 이 주장을 반박한다.) 대안적으로 그것은 단계별 대입이 초보자가 프로시저 호출보다 시각화하기 쉽다는 견해를 반영할 수 있다. 이유가 무엇이든, 그것은 종종 초보 프로그래머에게 프로그래밍을 복잡하게 만들고 중요한 아이디어를 모호하게 만들 수 있는 ``이 변수를 저 변수보다 먼저 설정해야 하나 나중에 설정해야 하나'' 하는 걱정을 지운다.}

명령형 프로그램의 복잡성은 여러 프로세스가 동시에 실행되는 응용 프로그램을 고려하면 훨씬 더 심각해진다.
우리는 @ref{3.4}에서 이것으로 돌아올 것이다.
그러나 먼저, 우리는 대입을 포함하는 표현식에 대한 계산 모델을 제공하는 문제를 다루고, 시뮬레이션을 설계할 때 지역 상태를 가진 객체의 사용을 탐구할 것이다.

@quotation
@strong{@anchor{Exercise 3.7}연습문제 3.7:} @ref{Exercise 3.3}에서 설명된 비밀번호 수정이 있는, @code{Account::new}에 의해 생성된 은행 계좌 객체를 고려해 보자.
우리 은행 시스템이 공동 계좌를 만드는 기능을 필요로 한다고 가정하자.
이것을 달성하는 프로시저 @code{make-joint}를 정의하라.
@code{Make-joint}는 세 개의 인자를 받아야 한다. 첫 번째는 비밀번호로 보호된 계좌이다. 두 번째 인자는 @code{make-joint} 연산이 진행되기 위해 계좌가 정의될 때 사용된 비밀번호와 일치해야 한다. 세 번째 인자는 새 비밀번호이다.
@code{Make-joint}는 새 비밀번호를 사용하여 원래 계좌에 대한 추가 접근을 생성해야 한다.
예를 들어, @code{peter-acc}가 비밀번호 @code{open-sesame}을 가진 은행 계좌라면,

@example
let paul_acc = make_joint(
    &peter_acc,
    "open-sesame",
    "rosebud"
);
@end example

@noindent
은 @code{paul-acc}라는 이름과 비밀번호 @code{rosebud}를 사용하여 @code{peter-acc}에 대한 거래를 수행할 수 있게 할 것이다.
이 새로운 기능을 수용하기 위해 @ref{Exercise 3.3}에 대한 해결책을 수정하고 싶을 수도 있다.
@end quotation

@quotation
@strong{@anchor{Exercise 3.8}연습문제 3.8:} 우리가 @ref{1.1.3}에서 평가 모델을 정의했을 때, 우리는 표현식을 평가하는 첫 번째 단계가 하위 표현식을 평가하는 것이라고 말했다.
그러나 우리는 하위 표현식이 평가되어야 하는 순서(예: 왼쪽에서 오른쪽 또는 오른쪽에서 왼쪽)를 결코 지정하지 않았다.
우리가 대입을 도입할 때, 프로시저에 대한 인자가 평가되는 순서는 결과에 차이를 만들 수 있다.
다음 평가가

@example
f(0) + f(1)
@end example

@noindent
@code{+}에 대한 인자가 왼쪽에서 오른쪽으로 평가되면 0을 반환하고 오른쪽에서 왼쪽으로 평가되면 1을 반환하도록 하는 간단한 프로시저 @code{f}를 정의하라.
@end quotation

@node 3.1.4, 3.2, 3.1.3, 3.1
@subsection The Borrow Checker as Guardian
@cindex ownership
@cindex borrowing
@cindex borrow checker
@cindex lifetimes
@cindex data races
@cindex memory safety

In the previous section, we explored how assignment complicates our computational
model, breaking the substitution model and introducing thorny questions about
sameness and change. In Rust, these challenges are addressed through a
compile-time system called the @newterm{borrow checker}, which enforces strict
rules about ownership and borrowing. Rather than relying on runtime garbage
collection or manual memory management, Rust's ownership system provides memory
safety and prevents data races at compile time---with zero runtime overhead.

The borrow checker is Rust's guardian against an entire class of bugs that plague
systems programming: use-after-free, double-free, data races, iterator
invalidation, and dangling pointers. By encoding ownership and borrowing rules
in the type system, Rust transforms these runtime errors into compile-time
errors, preventing them before the program ever runs.

@subsubheading Ownership: Each Value Has One Owner

The foundation of Rust's memory model is the principle that @newterm{every value
has exactly one owner}. When the owner goes out of scope, the value is
automatically dropped, freeing its resources. This is called @newterm{RAII}
(Resource Acquisition Is Initialization), a pattern that ensures resources are
cleaned up deterministically.

@example
@cindex ownership transfer
@cindex drop
fn demonstrate_ownership() @{
    let s1 = String::from("hello");
    // s1 owns the String allocation

    println!("@{@}", s1);

@}  // s1 goes out of scope, String is dropped

// The String's memory is freed here automatically
@end example

@noindent
This simple principle has profound implications. Unlike languages with garbage
collection, Rust knows @emph{exactly} when to free memory: when the owner goes
out of scope. There's no need for a runtime garbage collector scanning memory,
no unpredictable pauses, no reference counting overhead.

@subsubheading Move Semantics: Ownership Transfer

When we assign a value to another variable or pass it to a function, ownership
is @newterm{transferred}. The original binding becomes invalid, preventing
use-after-move errors:

@example
@cindex move semantics
fn demonstrate_move() @{
    let s1 = String::from("hello");
    let s2 = s1;  // Ownership moves from s1 to s2

    // println!("@{@}", s1);  // Error: s1 is no longer valid!
    println!("@{@}", s2);      // OK: s2 now owns the String
@}
@end example

@noindent
This prevents double-free bugs: since only one binding owns the value at a time,
it can only be freed once. Compare this to C++, where both variables might try
to free the same memory, or to languages with garbage collection, where the
runtime must track all references.

The move semantics extend to function calls. When we pass a value to a function,
ownership transfers to the function's parameter:

@example
fn take_ownership(s: String) @{
    println!("@{@}", s);
@}  // s is dropped here

fn demonstrate_function_move() @{
    let s = String::from("hello");
    take_ownership(s);
    // println!("@{@}", s);  // Error: s was moved!
@}
@end example

@noindent
To use the value after the function call, we must either return it or use
borrowing, which we'll explore next.

@subsubheading Copy vs. Move: The Copy Trait

Not all types move by default. Types that implement the @code{Copy} trait are
copied implicitly instead of moved. The @code{Copy} trait can only be
implemented for types that can be safely duplicated by simply copying their bits:

@example
@cindex Copy trait
fn demonstrate_copy() @{
    let x = 5;        // i32 implements Copy
    let y = x;        // x is copied, not moved

    println!("@{@}, @{@}", x, y);  // Both are valid

    let s1 = String::from("hello");  // String does NOT implement Copy
    let s2 = s1;                    // s1 is moved
    // println!("@{@}", s1);          // Error: s1 was moved
@}
@end example

@noindent
Types that implement @code{Copy} are typically simple scalar values: integers,
floating-point numbers, booleans, characters, and tuples/arrays containing only
@code{Copy} types. Types that own heap-allocated data (like @code{String} or
@code{Vec<T>}) cannot be @code{Copy}, as duplicating them requires allocating
new memory.

@subsubheading Borrowing: Temporary Access Without Ownership

While move semantics prevent many bugs, moving values in and out of functions
would be cumbersome. Rust's @newterm{borrowing} system allows functions to
temporarily access values without taking ownership:

@example
@cindex shared borrow
@cindex immutable reference
fn calculate_length(s: &String) -> usize @{
    s.len()
@}  // s goes out of scope, but nothing is dropped

fn demonstrate_borrowing() @{
    let s1 = String::from("hello");
    let len = calculate_length(&s1);  // Borrow s1

    println!("Length of '@{@}' is @{@}", s1, len);  // s1 is still valid
@}
@end example

@noindent
The @code{&} operator creates a @newterm{reference}---a pointer that borrows the
value without taking ownership. When the reference goes out of scope, nothing is
dropped because the reference never owned the value.

@subsubheading The Borrowing Rules: Multiple Readers or One Writer

Rust's borrowing system enforces two fundamental rules that prevent data races:

@enumerate
@item
You can have @emph{either} any number of immutable references (@code{&T})
@item
@emph{or} exactly one mutable reference (@code{&mut T})
@item
But never both at the same time
@end enumerate

@noindent
These rules are enforced at compile time, within a scope. Here's why they matter:

@example
@cindex mutable borrow
@cindex exclusive access
fn demonstrate_mutable_borrowing() @{
    let mut s = String::from("hello");

    // Mutable borrow grants exclusive access
    let r1 = &mut s;
    r1.push_str(" world");

    // Cannot have another mutable or immutable borrow while r1 exists
    // let r2 = &s;       // Error: cannot borrow as immutable
    // let r3 = &mut s;   // Error: cannot borrow as mutable

    println!("@{@}", r1);
@}  // r1 goes out of scope here

fn demonstrate_multiple_immutable_borrows() @{
    let s = String::from("hello");

    let r1 = &s;
    let r2 = &s;
    let r3 = &s;

    println!("@{@}, @{@}, @{@}", r1, r2, r3);  // All valid

    // let r4 = &mut s;  // Error: cannot borrow as mutable while immutable borrows exist
@}
@end example

@noindent
These rules prevent data races---situations where two or more pointers access
the same memory location simultaneously, with at least one writing. By ensuring
either multiple readers @emph{or} one writer, Rust guarantees that data cannot
be modified while others are reading it.

The borrow checker tracks the @newterm{scope} of references, not just their
lexical scope:

@example
@cindex non-lexical lifetimes
fn demonstrate_non_lexical_lifetimes() @{
    let mut s = String::from("hello");

    let r1 = &s;
    let r2 = &s;
    println!("@{@} and @{@}", r1, r2);
    // r1 and r2 are no longer used after this point

    let r3 = &mut s;  // OK: r1 and r2's lifetimes have ended
    r3.push_str(" world");
    println!("@{@}", r3);
@}
@end example

@noindent
This feature, called @newterm{non-lexical lifetimes} (NLL), makes the borrow
checker more precise: references are only considered active from where they're
created to their last use, not necessarily until the end of their lexical scope.

@subsubheading Lifetimes: Relating Borrowed References

When functions return references, Rust needs to ensure they remain valid. This
is where @newterm{lifetime annotations} come in---they describe the relationship
between the lifetimes of different references:

@example
@cindex lifetime annotations
@cindex lifetime parameters
// Without lifetime annotation, this won't compile
fn longest<'a>(x: &'a str, y: &'a str) -> &'a str @{
    if x.len() > y.len() @{
        x
    @} else @{
        y
    @}
@}

fn demonstrate_lifetimes() @{
    let string1 = String::from("long string");
    let string2 = String::from("short");

    let result = longest(&string1, &string2);
    println!("Longest: @{@}", result);
@}
@end example

@noindent
The lifetime annotation @code{'a} (pronounced "lifetime a") says: "the returned
reference is valid for as long as both input references are valid." It doesn't
change how long anything lives; it merely describes the relationship to the
borrow checker.

Without this annotation, the compiler cannot determine whether the returned
reference points to @code{x} or @code{y}, and thus cannot verify it remains
valid. The lifetime parameter makes this relationship explicit.

@subsubheading Lifetime Elision Rules

Most of the time, we don't need to write lifetime annotations. The Rust compiler
applies @newterm{lifetime elision rules} to infer lifetimes in common patterns:

@enumerate
@item
Each reference parameter gets its own lifetime parameter
@item
If there's exactly one input lifetime, it's assigned to all output lifetimes
@item
If there's a @code{&self} or @code{&mut self} parameter, its lifetime is assigned to all output lifetimes
@end enumerate

@example
@cindex lifetime elision
// These are equivalent due to elision:
fn first_word(s: &str) -> &str @{ /* ... */ @}
fn first_word<'a>(s: &'a str) -> &'a str @{ /* ... */ @}

// Multiple parameters need explicit lifetimes:
fn longest<'a>(x: &'a str, y: &'a str) -> &'a str @{ /* ... */ @}
@end example

@noindent
For methods, rule 3 is particularly helpful:

@example
@cindex method lifetimes
struct Parser<'a> @{
    source: &'a str,
    pos: usize,
@}

impl<'a> Parser<'a> @{
    // Elided: fn next_token(&self) -> &str
    fn next_token(&self) -> &'a str @{
        // Return a slice of self.source
        &self.source[self.pos..self.pos + 5]
    @}
@}
@end example

@subsubheading Common Borrow Checker Errors and Solutions

Let's examine common patterns that trigger borrow checker errors and their
solutions:

@strong{Problem 1: Returning a reference to local data}

@example
@cindex dangling reference
// Error: dangling reference
fn create_string() -> &str @{
    let s = String::from("hello");
    &s[..]  // Error: s is dropped at end of function
@}

// Solution: Return owned data
fn create_string() -> String @{
    String::from("hello")
@}
@end example

@strong{Problem 2: Modifying while iterating}

@example
@cindex iterator invalidation
// Error: cannot modify while borrowed
fn remove_evens(v: &mut Vec<i32>) @{
    for x in v.iter() @{  // Immutable borrow
        if *x % 2 == 0 @{
            v.retain(|&y| y != *x);  // Error: cannot borrow as mutable
        @}
    @}
@}

// Solution: Collect indices to remove
fn remove_evens(v: &mut Vec<i32>) @{
    v.retain(|&x| x % 2 != 0);
@}
@end example

@strong{Problem 3: Splitting borrows}

@example
@cindex split borrows
struct Data @{
    field1: Vec<i32>,
    field2: Vec<i32>,
@}

impl Data @{
    // Error: cannot borrow self as mutable twice
    fn process_wrong(&mut self) @{
        // let a = &mut self.field1;
        // let b = &mut self.field2;  // Error: self already borrowed
        // process(a, b);
    @}

    // Solution: Borrow fields directly
    fn process_right(&mut self) @{
        let a = &mut self.field1;
        let b = &mut self.field2;  // OK: different fields
        // process(a, b);
    @}
@}
@end example

@subsubheading Preventing Data Races at Compile Time

The borrowing rules directly prevent data races in concurrent programs. Consider
this example that would cause a data race in other languages:

@example
@cindex thread safety
@cindex Send and Sync
use std::thread;

fn data_race_prevented() @{
    let mut data = vec![1, 2, 3];

    // This won't compile:
    // thread::spawn(|| @{
    //     data.push(4);  // Error: closure may outlive current function
    // @});
    // data.push(5);     // Would be a data race if allowed

    // Correct: Use message passing or Arc<Mutex<T>>
@}
@end example

@noindent
The borrow checker prevents the closure from capturing @code{&mut data} because
it cannot guarantee the closure won't outlive the function. This static analysis
eliminates entire classes of concurrency bugs that would only appear at runtime
in other languages---often intermittently and irreproducibly.

@subsubheading Connection to Chapter 3: State and Time

Returning to the themes of Chapter 3, we see how Rust's ownership system
addresses the challenges we identified with assignment and state:

@enumerate
@item
@strong{The substitution model:} By restricting mutation to exclusive mutable
borrows, Rust maintains local reasoning---within a scope with an immutable
reference, we know the value cannot change.

@item
@strong{Sameness and identity:} Ownership makes identity explicit. Two
references might point to the same data (@code{&}), or we might have two distinct
owned values. The type system prevents confusion between these cases.

@item
@strong{Pitfalls of imperative programming:} The borrow checker prevents the bugs
that plague imperative programs: use-after-free, double-free, data races,
iterator invalidation. These are not runtime errors to debug---they are
impossible by construction.
@end enumerate

@noindent
The borrow checker is strict, but its strictness serves a purpose: it transforms
the nebulous runtime concept of "who can access this data and when" into a
compile-time guarantee. The result is a language where we can use mutation and
shared state safely, without sacrificing the performance of direct memory access.

@quotation
@strong{@anchor{Exercise 3.15a}Exercise 3.15a:} Consider the following function
that attempts to find the longest common prefix of two strings:

@example
fn longest_common_prefix(s1: &str, s2: &str) -> &str @{
    let mut end = 0;
    for (c1, c2) in s1.chars().zip(s2.chars()) @{
        if c1 == c2 @{
            end += c1.len_utf8();
        @} else @{
            break;
        @}
    @}
    &s1[0..end]
@}
@end example

@enumerate a
@item
Will this function compile? If not, what is the error?
@item
Add appropriate lifetime annotations to make it compile.
@item
What does the lifetime annotation tell the caller about the returned reference?
@item
Why doesn't the function need to know which input string the result came from?
@end enumerate
@end quotation

@quotation
@strong{@anchor{Exercise 3.15b}Exercise 3.15b:} The following code attempts to
maintain a cache of computed values:

@example
struct Cache @{
    data: Vec<(String, i32)>,
@}

impl Cache @{
    fn get(&self, key: &str) -> Option<&i32> @{
        self.data
            .iter()
            .find(|(k, _)| k == key)
            .map(|(_, v)| v)
    @}

    fn get_or_insert(&mut self, key: String, value: i32) -> &i32 @{
        if let Some(v) = self.get(key.as_str()) @{
            return v;  // Error: cannot return value referencing self
        @}
        self.data.push((key, value));
        &self.data.last().unwrap().1
    @}
@}
@end example

@enumerate a
@item
Why does the borrow checker reject @code{get_or_insert}?
@item
Identify all the borrows and their lifetimes.
@item
Propose a solution that satisfies the borrow checker. (Hint: Avoid calling
@code{get} from @code{get_or_insert}.)
@item
Explain why this pattern is dangerous in languages without a borrow checker.
What runtime error might occur?
@end enumerate
@end quotation

@quotation
@strong{@anchor{Exercise 3.15c}Exercise 3.15c:} Create a function
@code{split_at_mut} that splits a mutable slice into two non-overlapping mutable
slices at a given index:

@example
fn split_at_mut<T>(slice: &mut [T], mid: usize)
    -> (&mut [T], &mut [T])
@{
    assert!(mid <= slice.len());

    // This naive approach doesn't work:
    // (&mut slice[..mid], &mut slice[mid..])
    // Error: cannot borrow slice as mutable more than once

    // Implement using unsafe code or slice methods
@}
@end example

@enumerate a
@item
Why does the naive approach of borrowing two slices from the same source fail?
@item
Implement @code{split_at_mut} using @code{slice::split_at_mut}.
@item
Explain how this function creates two mutable references from one. Does this
violate the borrowing rules?
@item
Bonus: Implement it using unsafe code with @code{std::ptr::slice_from_raw_parts_mut}.
What invariants must you uphold to maintain memory safety?
@end enumerate
@end quotation

The borrow checker may seem restrictive at first, but this restriction is
precisely its value. By encoding ownership and borrowing rules in the type
system, Rust provides memory safety and prevents data races without garbage
collection or manual memory management. The result is a language where we can
reason locally about code behavior, confident that the compiler has verified our
assumptions about ownership and access patterns.


@node	3.2, 3.3, 3.1.4, Chapter 3
@section 평가의 환경 모델 (The Environment Model of Evaluation)

우리가 @ref{Chapter 1}에서 복합 프로시저를 소개했을 때, 우리는 프로시저를 인자에 적용하는 것이 무엇을 의미하는지 정의하기 위해 치환 모델(@ref{1.1.5})을 사용했다:

@itemize @bullet

@item
복합 프로시저를 인자에 적용하려면, 각 형식 매개변수를 해당 인자로 교체하여 프로시저의 본문을 평가한다.

@end itemize

@noindent
일단 우리가 프로그래밍 언어에 할당을 허용하면, 그러한 정의는 더 이상 적절하지 않다.
특히, @ref{3.1.3}은 할당이 존재하는 경우 변수가 더 이상 단순히 값의 이름으로 간주될 수 없다고 주장했다.
오히려 변수는 값이 저장될 수 있는 ``장소(place)''를 지정해야 한다.
우리의 새로운 평가 모델에서, 이러한 장소는 @newterm{환경(environments)}이라고 불리는 구조에서 유지될 것이다.

환경은 @newterm{프레임(frames)}의 시퀀스이다.
각 프레임은 변수 이름과 해당 값을 연관시키는 @newterm{바인딩(bindings)}의 테이블(비어 있을 수 있음)이다. (단일 프레임은 어떤 변수에 대해서도 최대 하나의 바인딩을 포함할 수 있다.)
각 프레임은 또한 @newterm{감싸는 환경(enclosing environment)}에 대한 포인터를 갖는다. 단, 논의의 목적을 위해 해당 프레임이 @newterm{전역(global)}으로 간주되는 경우는 예외이다.
환경에 대한 @newterm{변수의 값(value of a variable)}은 그 환경에서 변수에 대한 바인딩을 포함하는 첫 번째 프레임의 바인딩에 의해 주어진 값이다.
시퀀스의 어떤 프레임도 변수에 대한 바인딩을 지정하지 않으면, 그 변수는 환경에서 @newterm{바인딩되지 않았다(unbound)}고 한다.

@ref{Figure 3.1}은 I, II, III으로 라벨이 붙은 세 개의 프레임으로 구성된 간단한 환경 구조를 보여준다.
다이어그램에서 A, B, C, D는 환경에 대한 포인터이다.
C와 D는 같은 환경을 가리킨다.
변수 @code{z}와 @code{x}는 프레임 II에 바인딩되어 있고, @code{y}와 @code{x}는 프레임 I에 바인딩되어 있다.
환경 D에서 @code{x}의 값은 3이다.
환경 B에 대한 @code{x}의 값도 3이다.
이것은 다음과 같이 결정된다: 우리는 시퀀스의 첫 번째 프레임(프레임 III)을 검사하고 @code{x}에 대한 바인딩을 찾지 못하므로, 감싸는 환경 D로 진행하여 프레임 I에서 바인딩을 찾는다.
반면에, 환경 A에서 @code{x}의 값은 7이다. 왜냐하면 시퀀스의 첫 번째 프레임(프레임 II)이 @code{x}를 7에 바인딩하는 것을 포함하기 때문이다.
환경 A에 대해, 프레임 II에서 @code{x}를 7에 바인딩한 것은 프레임 I에서 @code{x}를 3에 바인딩한 것을 @newterm{가린다(shadow)}고 말한다.

@float
@anchor{Figure 3.1}
@ifinfo
@quotation
@strong{Figure 3.1:} 간단한 환경 구조.

@example
           +--------+
           |      I |
           | x: 3   |
           | y: 5   |
           +--------+
              ^  ^
              |  |
            C |  | D
+---------+   |  |   +----------+
|      II |   |  |   |      III |
| z: 6    +---+  +---+ m: 1     |
| x: 7    |          | y: 2     |
+---------+          +----------+
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap3/Fig3.1b,69mm,,,.std.svg}
@caption{@strong{Figure 3.1:} 간단한 환경 구조.}
@end iftex
@end float

@noindent
환경은 평가 프로세스에 결정적인데, 왜냐하면 그것이 표현식이 평가되어야 할 컨텍스트를 결정하기 때문이다.
실제로 프로그래밍 언어의 표현식은 그 자체로는 아무런 의미가 없다고 말할 수 있다.
오히려 표현식은 그것이 평가되는 어떤 환경에 대해서만 의미를 획득한다.
@code{(+ 1 1)}처럼 간단한 표현식의 해석조차도 @code{+}가 덧셈을 위한 기호인 컨텍스트에서 작동하고 있다는 이해에 의존한다.
따라서 우리의 평가 모델에서 우리는 항상 어떤 환경에 대해 표현식을 평가하는 것을 말할 것이다.
인터프리터와의 상호 작용을 설명하기 위해, 우리는 (감싸는 환경이 없는) 단일 프레임으로 구성되고 원시 프로시저와 연관된 기호들에 대한 값을 포함하는 전역 환경이 있다고 가정할 것이다.
예를 들어, @code{+}가 덧셈을 위한 기호라는 아이디어는 기호 @code{+}가 전역 환경에서 원시 덧셈 프로시저에 바인딩되어 있다고 말함으로써 포착된다.

@menu
* 3.2.1::            The Rules for Evaluation
* 3.2.2::            Applying Simple Procedures
* 3.2.3::            Frames as the Repository of Local State
* 3.2.4::            Internal Definitions
@end menu

@node	3.2.1, 3.2.2, 3.2, 3.2
@subsection 평가 규칙 (The Rules for Evaluation)

인터프리터가 조합을 평가하는 방법에 대한 전체적인 명세는 우리가 @ref{1.1.3}에서 처음 소개했을 때와 동일하게 유지된다:

@itemize @bullet

@item
조합을 평가하려면:

@end itemize

@enumerate 1

@item
조합의 부분표현식을 평가한다.@footnote{할당은 평가 규칙의 1단계에 미묘함을 도입한다. @ref{Exercise 3.8}에서 보인 것처럼, 할당의 존재는 우리가 조합 내의 부분표현식이 평가되는 순서에 따라 다른 값을 생성하는 표현식을 작성할 수 있게 한다. 따라서 정확하게 하려면 우리는 1단계에서 평가 순서(예: 왼쪽에서 오른쪽 또는 오른쪽에서 왼쪽)를 지정해야 한다. 그러나 이 순서는 항상 구현 세부 사항으로 간주되어야 하며, 특정 순서에 의존하는 프로그램을 작성해서는 안 된다. 예를 들어, 정교한 컴파일러는 부분표현식이 평가되는 순서를 변경함으로써 프로그램을 최적화할 수 있다.}

@item
연산자 부분표현식의 값을 피연산자 부분표현식의 값에 적용한다.

@end enumerate

@noindent
평가의 환경 모델은 복합 프로시저를 인자에 적용하는 것이 무엇을 의미하는지 지정하는 데 있어 치환 모델을 대체한다.

평가의 환경 모델에서, 프로시저는 항상 어떤 코드와 환경에 대한 포인터로 구성된 쌍이다.
프로시저는 오직 한 가지 방법으로만 생성된다: 클로저 표현식을 평가함으로써.
이것은 코드가 클로저 표현식의 텍스트에서 얻어지고 환경이 프로시저를 생성하기 위해 클로저 표현식이 평가된 환경인 프로시저를 생성한다.
예를 들어, 다음 프로시저 정의를 고려해 보자

@example
fn square(x: i64) -> i64 @{
    x * x
@}
@end example

@noindent
이것이 전역 환경에서 평가된다. Rust에서 함수 정의는 함수 항목을 생성한다.
클로저를 사용한 동등한 형태는 다음과 같을 것이다:

@example
let square = |x: i64| -> i64 @{ x * x @};
@end example

@noindent
이것은 @code{|x| x * x}를 평가하고 결과 값을 @code{square}에 바인딩하며, 이 모든 것이 전역 환경에서 일어난다.

@ref{Figure 3.2}는 이 정의 표현식을 평가한 결과를 보여준다.
프로시저 객체는 프로시저가 하나의 형식 매개변수, 즉 @code{x}를 가지며 프로시저 본문이 @code{(* x x)}임을 명시하는 코드와 쌍을 이룬다.
프로시저의 환경 부분은 전역 환경에 대한 포인터인데, 왜냐하면 그것이 프로시저를 생성하기 위해 클로저 표현식이 평가된 환경이기 때문이다.
프로시저 객체를 기호 @code{square}와 연관시키는 새로운 바인딩이 전역 프레임에 추가되었다.
일반적으로, 정의는 프레임에 바인딩을 추가함으로써 정의를 생성한다.

@float
@anchor{Figure 3.2}
@ifinfo
@quotation
@strong{Figure 3.2:} 전역 환경에서 @code{fn square(x: i64) -> i64 @{ x * x @}}를 평가하여 생성된 환경 구조.

@example
           +----------------------+
           | other variables      |
global --->|                      |
env        | square: --+          |
           +-----------|----------+
                       |       ^
fn square(x: i64)      |       |
  -> i64 @{ x * x @}     V       |
                   .---.---.   |
                   | O | O-+---+
                   `-|-^---'
                     |
                     V
                   parameters: x: i64
                   body: x * x
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap3/Fig3.2b,81mm,,,.std.svg}
@caption{@strong{Figure 3.2:} 전역 환경에서 @code{fn square(x: i64) -> i64 @{ x * x @}}를 평가하여 생성된 환경 구조.}
@end iftex
@end float

@noindent
이제 프로시저가 어떻게 생성되는지 보았으므로, 프로시저가 어떻게 적용되는지 설명할 수 있다.
환경 모델은 다음과 같이 명시한다: 프로시저를 인자에 적용하려면, 매개변수를 인자의 값에 바인딩하는 프레임을 포함하는 새 환경을 생성하라.
이 프레임의 감싸는 환경은 프로시저가 지정한 환경이다.
이제, 이 새 환경 내에서 프로시저 본문을 평가하라.

이 규칙이 어떻게 따르는지 보여주기 위해, @ref{Figure 3.3}은 전역 환경에서 표현식 @code{square(5)}를 평가하여 생성된 환경 구조를 예시한다. 여기서 @code{square}는 @ref{Figure 3.2}에서 생성된 프로시저이다.
프로시저를 적용하면 그림에서 E1이라고 라벨이 붙은 새 환경이 생성되는데, 이는 프로시저의 형식 매개변수인 @code{x}가 인자 5에 바인딩된 프레임으로 시작한다.
이 프레임에서 위쪽으로 이어지는 포인터는 프레임의 감싸는 환경이 전역 환경임을 보여준다.
여기서 전역 환경이 선택된 이유는 이것이 @code{square} 프로시저 객체의 일부로 표시된 환경이기 때문이다.
E1 내에서, 우리는 프로시저의 본문 @code{(* x x)}를 평가한다.
E1에서 @code{x}의 값은 5이므로, 결과는 @code{(* 5 5)}, 즉 25이다.

@float
@anchor{Figure 3.3}
@ifinfo
@quotation
@strong{Figure 3.3:} 전역 환경에서 @code{square(5)}를 평가하여 생성된 환경.

@example
          +------------------------------------+
          | other variables                    |
global -->|                                    |
env       | square: --+                        |
          +-----------|---------------------+--+
                      |       ^             ^
(square 5)            |       |             |
                      V       |             |
                  .---.---.   |         +---+--+
                  | O | O-+---+   E1 -->| x: 5 |
                  `-|-^---'             +------+
                    |
                    V
                  parameters: x
                  body: (* x x)
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap3/Fig3.3b,129mm,,,.std.svg}
@caption{@strong{Figure 3.3:} 전역 환경에서 @code{square(5)}를 평가하여 생성된 환경.}
@end iftex
@end float

@noindent
프로시저 적용의 환경 모델은 두 가지 규칙으로 요약될 수 있다:

@itemize @bullet

@item
프로시저 객체는 프레임을 구성하고, 프로시저의 형식 매개변수를 호출의 인자에 바인딩한 다음, 구성된 새 환경의 컨텍스트에서 프로시저의 본문을 평가함으로써 인자 집합에 적용된다.
새 프레임은 적용되는 프로시저 객체의 환경 부분을 감싸는 환경으로 갖는다.

@item
프로시저는 주어진 환경에 대해 클로저 표현식을 평가함으로써 생성된다.
결과 프로시저 객체는 클로저 표현식의 텍스트와 프로시저가 생성된 환경에 대한 포인터로 구성된 쌍이다.

@end itemize

@noindent
우리는 또한 정의를 사용하여 기호를 정의하는 것이 현재 환경 프레임에 바인딩을 생성하고 기호에 지정된 값을 할당한다고 명시한다.@footnote{현재 프레임에 변수에 대한 바인딩이 이미 있다면, 바인딩이 변경된다. 이것은 기호의 재정의를 허용하기 때문에 편리하지만, 정의가 값을 변경하는 데 사용될 수 있음을 의미하기도 하며, 이는 명시적으로 @code{set!}을 사용하지 않고도 할당의 문제를 불러일으킨다. 이 때문에 어떤 사람들은 기존 기호의 재정의가 오류나 경고를 신호하는 것을 선호한다.} 마지막으로, 우리는 처음에 환경 모델을 도입하도록 강요했던 연산인 @code{set!}의 동작을 명시한다.
어떤 환경에서 표현식 @code{(set! ⟨@var{variable}⟩ ⟨@var{value}⟩)}를 평가하면 환경에서 변수의 바인딩을 찾아 그 바인딩을 새 값을 나타내도록 변경한다.
즉, 변수에 대한 바인딩을 포함하는 환경의 첫 번째 프레임을 찾아 그 프레임을 수정한다.
변수가 환경에서 바인딩되어 있지 않다면, @code{set!}은 오류를 신호한다.

이 평가 규칙들은 치환 모델보다 상당히 더 복잡하지만, 여전히 합리적으로 간단하다.
게다가 평가 모델은 추상적이지만 인터프리터가 표현식을 어떻게 평가하는지에 대한 정확한 설명을 제공한다.
@ref{Chapter 4}에서 우리는 이 모델이 작동하는 인터프리터를 구현하기 위한 청사진으로 어떻게 사용될 수 있는지 보게 될 것이다.
다음 절들은 몇 가지 예시적인 프로그램을 분석함으로써 모델의 세부 사항을 자세히 설명한다.

@node	3.2.2, 3.2.3, 3.2.1, 3.2
@subsection 단순 프로시저의 적용 (Applying Simple Procedures)

우리가 @ref{1.1.5}에서 치환 모델을 소개했을 때, 다음 프로시저 정의들이 주어졌을 때 조합 @code{f(5)}가 어떻게 136으로 평가되는지 보여주었다:

@example
fn square(x: i64) -> i64 @{
    x * x
@}

fn sum_of_squares(x: i64, y: i64) -> i64 @{
    square(x) + square(y)
@}

fn f(a: i64) -> i64 @{
    sum_of_squares(a + 1, a * 2)
@}
@end example

@noindent
우리는 환경 모델을 사용하여 같은 예제를 분석할 수 있다.
@ref{Figure 3.4}는 전역 환경에서 @code{f}, @code{square}, 그리고 @code{sum_of_squares}의 정의를 평가하여 생성된 세 개의 프로시저 객체를 보여준다.
각 프로시저 객체는 일부 코드와 전역 환경에 대한 포인터로 구성된다.

@float
@anchor{Figure 3.4}
@ifinfo
@strong{Figure 3.4:} 전역 프레임의 프로시저 객체들.

@example
          +--------------------------------------------+
          | sum-of-squares:                            |
global -->| square:                                    |
env       | f: --+                                     |
          +------|--------------+--------------+-------+
                 |     ^        |     ^        |     ^
                 |     |        |     |        |     |
                 V     |        V     |        V     |
             .---.---. |    .---.---. |    .---.---. |
             | O | O-+-+    | O | O-+-+    | O | O-+-+
             `-|-^---'      `-|-^---'      `-|-^---'
               |              |              |
               V              V              V
   parameters: a          parameters: x  parameters: x, y
   body: (sum-of-squares  body: (* x x)  body: (+ (square x)
           (+ a 1)                                (square y))
           (* a 2))
@end example
@end ifinfo
@iftex
@image{fig/chap3/Fig3.4b,132mm,,,.std.svg}
@caption{@strong{Figure 3.4:} 전역 프레임의 프로시저 객체들.}
@end iftex
@end float

@noindent
@ref{Figure 3.5}에서 우리는 표현식 @code{f(5)}를 평가하여 생성된 환경 구조를 본다.
@code{f}에 대한 호출은 @code{f}의 형식 매개변수인 @code{a}가 인자 5에 바인딩된 프레임으로 시작하는 새로운 환경 E1을 생성한다.
E1에서 우리는 @code{f}의 본문을 평가한다:

@example
sum_of_squares(a + 1, a * 2)
@end example

@float
@anchor{Figure 3.5}
@ifinfo
@strong{Figure 3.5:} @ref{Figure 3.4}의 프로시저를 사용하여 @code{f(5)}를 평가하여 생성된 환경들.

@example
          +-----------------------------------------------------+
global -->|                                                     |
env       +-----------------------------------------------------+
            ^              ^                ^               ^
(f 5)       |              |                |               |
        +------+       +-------+        +------+        +-------+
  E1 -->| a: 5 |  E2 ->| x: 6  |  E3 -->| x: 6 |  E4 -->| x: 10 |
        |      |       | y: 10 |        |      |        |       |
        +------+       +-------+        +------+        +-------+
   (sum-of-squares   (+ (square x)       (* x x)         (* x x)
     (+ a 1)            (square u))
     (+ a 2))
@end example
@end ifinfo
@iftex
@image{fig/chap3/Fig3.5b,142mm,,,.std.svg}
@caption{@strong{Figure 3.5:} @ref{Figure 3.4}의 프로시저를 사용하여 @code{f(5)}를 평가하여 생성된 환경들.}
@end iftex
@end float

@noindent
이 조합을 평가하기 위해, 우리는 먼저 부분표현식을 평가한다.
첫 번째 부분표현식 @code{sum_of_squares}는 프로시저 객체인 값을 갖는다.
(이 값이 어떻게 발견되는지 주목하라: 우리는 먼저 E1의 첫 번째 프레임에서 찾는데, 여기에는 @code{sum_of_squares}에 대한 바인딩이 없다. 그런 다음 감싸는 환경, 즉 전역 환경으로 진행하여 @ref{Figure 3.4}에 표시된 바인딩을 찾는다.)
다른 두 부분표현식은 원시 연산 @code{+}와 @code{*}를 적용하여 두 조합 @code{(+ a 1)}과 @code{(* a 2)}를 평가함으로써 각각 6과 10을 얻는다.

@noindent
이제 우리는 프로시저 객체 @code{sum_of_squares}를 인자 6과 10에 적용한다.
이것은 형식 매개변수 @code{x}와 @code{y}가 인자에 바인딩된 새로운 환경 E2를 초래한다.
E2 내에서 우리는 조합 @code{(+ (square x) (square y))}를 평가한다.
이것은 우리가 @code{(square x)}를 평가하도록 이끄는데, 여기서 @code{square}는 전역 프레임에서 발견되고 @code{x}는 6이다.
다시 한번, 우리는 @code{x}가 6에 바인딩된 새로운 환경 E3를 설정하고, 이 안에서 @code{square}의 본문인 @code{(* x x)}를 평가한다.
또한 @code{sum_of_squares}를 적용하는 것의 일부로, 우리는 부분표현식 @code{(square y)}를 평가해야 하는데, 여기서 @code{y}는 10이다.
이 @code{square}에 대한 두 번째 호출은 또 다른 환경 E4를 생성하는데, 여기서 @code{square}의 형식 매개변수 @code{x}는 10에 바인딩된다.
그리고 E4 내에서 우리는 @code{(* x x)}를 평가해야 한다.

관찰해야 할 중요한 점은 @code{square}에 대한 각 호출이 @code{x}에 대한 바인딩을 포함하는 새로운 환경을 생성한다는 것이다.
우리는 여기서 서로 다른 프레임이 모두 @code{x}라고 명명된 서로 다른 지역 변수를 분리하여 유지하는 역할을 하는 것을 볼 수 있다.
@code{square}에 의해 생성된 각 프레임이 전역 환경을 가리킨다는 점에 주목하라. 왜냐하면 이것이 @code{square} 프로시저 객체가 나타내는 환경이기 때문이다.

부분표현식이 평가된 후, 결과가 반환된다.
@code{square}에 대한 두 호출에 의해 생성된 값은 @code{sum_of_squares}에 의해 더해지고, 이 결과는 @code{f}에 의해 반환된다.
여기서 우리의 초점은 환경 구조에 있으므로, 우리는 이 반환된 값들이 호출에서 호출로 어떻게 전달되는지에 대해서는 자세히 설명하지 않을 것이다; 그러나 이것 또한 평가 프로세스의 중요한 측면이며, 우리는 @ref{Chapter 5}에서 이에 대해 자세히 다룰 것이다.

@quotation
@strong{@anchor{Exercise 3.9}연습문제 3.9:} @ref{1.2.1}에서 우리는 치환 모델을 사용하여 팩토리얼을 계산하는 두 프로시저, 재귀적 버전

@example
fn factorial(n: u64) -> u64 @{
    if n == 1 @{
        1
    @} else @{
        n * factorial(n - 1)
    @}
@}
@end example

@noindent
과 반복적 버전

@example
fn factorial(n: u64) -> u64 @{
    fact_iter(1, 1, n)
@}

fn fact_iter(product: u64, counter: u64, max_count: u64) -> u64 @{
    if counter > max_count @{
        product
    @} else @{
        fact_iter(counter * product, counter + 1, max_count)
    @}
@}
@end example

@noindent
을 분석했다.
@code{factorial} 프로시저의 각 버전을 사용하여 @code{(factorial 6)}을 평가할 때 생성되는 환경 구조를 보여라.@footnote{환경 모델은 우리가 @ref{1.2.1}에서 인터프리터가 꼬리 재귀를 사용하여 상수 공간에서 @code{fact_iter}와 같은 프로시저를 실행할 수 있다고 주장한 것을 명확히 해주지 않는다. 우리는 @ref{5.4}에서 인터프리터의 제어 구조를 다룰 때 꼬리 재귀를 논의할 것이다.}
@end quotation

@node	3.2.3, 3.2.4, 3.2.2, 3.2
@subsection 지역 상태의 저장소로서의 프레임 (Frames as the Repository of Local State)

우리는 프로시저와 할당이 지역 상태를 가진 객체를 표현하는 데 어떻게 사용될 수 있는지 보기 위해 환경 모델로 돌아갈 수 있다.
예를 들어, @ref{3.1.1}의 ``인출 처리기''가 다음 프로시저를 호출하여 생성되었다고 하자

@example
use std::cell::Cell;

fn make_withdraw(initial: i64) -> impl FnMut(i64) -> Result<i64, &'static str> @{
    let balance = Cell::new(initial);
    move |amount| @{
        let current = balance.get();
        if current >= amount @{
            balance.set(current - amount);
            Ok(balance.get())
        @} else @{
            Err("Insufficient funds")
        @}
    @}
@}
@end example

@noindent
다음의 평가를 설명해 보자

@example
let mut w1 = make_withdraw(100);
@end example

@noindent
그리고 뒤이어

@example
w1(50);
// => Ok(50)
@end example

@noindent
@ref{Figure 3.6}은 전역 환경에서 @code{make_withdraw} 프로시저를 정의한 결과를 보여준다.
이것은 전역 환경에 대한 포인터를 포함하는 프로시저 객체를 생성한다.
지금까지 이것은 우리가 이미 본 예제들과 다르지 않다. 단, 프로시저의 본문 자체가 클로저 표현식이라는 점만 빼고.

@float
@anchor{Figure 3.6}
@ifinfo
@quotation
@strong{Figure 3.6:} 전역 환경에서 @code{make_withdraw}를 정의한 결과.

@example
          +---------------------------+
global -->| make-withdraw: --+        |
env       +------------------|--------+
                             |      ^
                             V      |
                         .---.---.  |
                         | O | O-+--+
                         `-|-^---'
                           |
                           V
         parameters: balance
         body: |amount| @{
                 if balance >= amount @{
                     balance -= amount;
                     balance
                 @} else @{
                     "Insufficient funds"
                 @}
               @}
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap3/Fig3.6c,128mm,,,.std.svg}
@caption{@strong{Figure 3.6:} 전역 환경에서 @code{make_withdraw}를 정의한 결과.}
@end iftex
@end float

@noindent
계산의 흥미로운 부분은 우리가 @code{make_withdraw} 프로시저를 인자에 적용할 때 발생한다:

@example
let mut w1 = make_withdraw(100);
@end example

@noindent
우리는 여느 때처럼 형식 매개변수 @code{balance}가 인자 100에 바인딩된 환경 E1을 설정하는 것으로 시작한다.
이 환경 내에서, 우리는 @code{make_withdraw}의 본문, 즉 클로저 표현식을 평가한다.
이것은 @code{lambda}에 의해 지정된 코드와 @code{lambda}가 평가되어 프로시저를 생성한 환경인 E1을 환경으로 갖는 새로운 프로시저 객체를 구성한다.
결과 프로시저 객체는 @code{make_withdraw} 호출에 의해 반환된 값이다.
이것은 전역 환경에서 @code{W1}에 바인딩되는데, 왜냐하면 정의 자체가 전역 환경에서 평가되고 있기 때문이다.
@ref{Figure 3.7}은 결과적인 환경 구조를 보여준다.

@float
@anchor{Figure 3.7}
@ifinfo
@strong{Figure 3.7:} @code{let mut w1 = make_withdraw(100);}을 평가한 결과.

@example
          +-----------------------------------------------+
          | make-withdraw: -----------------------+       |
global -->|                                       |       |
          | W1: --+                               |       |
          +-------|-------------------------------|-------+
                  |                ^              |     ^
                  |                |              V     |
                  |        +-------+------+   .---.---. |
                  |  E1 -->| balance: 100 |   | O | O-+-+
                  |        +--------------+   `-|-^---'
                  V                ^            |
              .---.---.            |            V
            +-+-O | O-+------------+    parameters: balance
            | `---^---'                 body: ...
            V
    parameters: amount
    body: |amount| @{
              if balance.get() >= amount @{
                  balance.set(balance.get() - amount);
                  Ok(balance.get())
              @} else @{ Err("Insufficient funds") @}
          @}
@end example
@end ifinfo
@iftex
@image{fig/chap3/Fig3.7b,145mm,,,.std.svg}
@caption{@strong{Figure 3.7:} @code{let mut w1 = make_withdraw(100);}을 평가한 결과.}
@end iftex
@end float

이제 @code{W1}이 인자에 적용될 때 무슨 일이 일어나는지 분석할 수 있다:

@example
w1(50);
// => Ok(50)
@end example

@noindent
우리는 @code{W1}의 형식 매개변수인 @code{amount}가 인자 50에 바인딩된 프레임을 구성하는 것으로 시작한다.
관찰해야 할 중요한 점은 이 프레임이 감싸는 환경으로 전역 환경이 아니라 환경 E1을 갖는다는 것이다. 왜냐하면 이것이 @code{W1} 프로시저 객체에 의해 지정된 환경이기 때문이다.
이 새로운 환경 내에서, 우리는 프로시저의 본문을 평가한다:

@example
if balance.get() >= amount @{
    balance.set(balance.get() - amount);
    Ok(balance.get())
@} else @{
    Err("Insufficient funds")
@}
@end example

@noindent
결과적인 환경 구조는 @ref{Figure 3.8}에 나와 있다.
평가되는 표현식은 @code{amount}와 @code{balance}를 모두 참조한다.
@code{Amount}는 환경의 첫 번째 프레임에서 발견되는 반면, @code{balance}는 감싸는 환경 포인터를 따라 E1으로 이동하여 발견된다.

@float
@anchor{Figure 3.8}
@ifinfo
@strong{Figure 3.8:} 프로시저 객체 @code{W1}을 적용하여 생성된 환경.

@example
          +---------------------------------------------------+
          | make-withdraw: ...                                |
global -->|                                                   |
env       | W1: --+                                           |
          +-------|-------------------------------------------+
                  |               ^
                  |               |
                  |       +-------+------+ 여기가 변경될
                  | E1 -->| balance: 100 | 잔액이다.
                  |       +--------------+ set!에 의해.
                  V               ^   ^
              .---.---.           |   +----+
              | O | O-+-----------+        |
              `-|-^---'             +------+-----+
                |                   | amount: 50 |
                V                   +------------+
      parameters: amount   |amount| @{
      body: ...                if balance.get() >= amount @{
                                   balance.set(balance.get() - amount);
                                   Ok(balance.get())
                               @} else @{ Err("Insufficient funds") @}
                           @}
@end example
@end ifinfo
@iftex
@image{fig/chap3/Fig3.8c,145mm,,,.std.svg}
@caption{@strong{Figure 3.8:} 프로시저 객체 @code{W1}을 적용하여 생성된 환경.}
@end iftex
@end float

@code{set!}이 실행될 때, E1에 있는 @code{balance}의 바인딩이 변경된다.
@code{W1}에 대한 호출이 완료되면, @code{balance}는 50이고, @code{balance}를 포함하는 프레임은 여전히 프로시저 객체 @code{W1}에 의해 가리켜지고 있다.
@code{amount}를 바인딩하는 프레임(우리가 @code{balance}를 변경하는 코드를 실행한 곳)은 더 이상 관련이 없다. 왜냐하면 그것을 구성한 프로시저 호출이 종료되었고, 환경의 다른 부분에서 그 프레임에 대한 포인터가 없기 때문이다.
다음에 @code{W1}이 호출될 때, 이것은 @code{amount}를 바인딩하고 감싸는 환경이 E1인 새로운 프레임을 구축할 것이다.
우리는 E1이 프로시저 객체 @code{W1}에 대한 지역 상태 변수를 보유하는 ``장소'' 역할을 하는 것을 본다.
@ref{Figure 3.9}는 @code{W1}에 대한 호출 이후의 상황을 보여준다.

@float
@anchor{Figure 3.9}
@ifinfo
@strong{Figure 3.9:} @code{W1} 호출 후의 환경.

@example
           +------------------------------------+
           | make-withdraw: ...                 |
global --->|                                    |
env        | W1: --+                            |
           +-------|----------------------------+
                   |                   ^
                   |                   |
                   |            +------+------+
                   |     E1 --->| balance: 50 |
                   |            +-------------+
                   V                   ^
               .---.---.               |
               | O | O-+---------------+
               `-|-^---'
                 |
                 V
          parameters: amount
          body: ...
@end example
@end ifinfo
@iftex
@image{fig/chap3/Fig3.9b,147mm,,,.std.svg}
@caption{@strong{Figure 3.9:} @code{W1} 호출 후의 환경.}
@end iftex
@end float

우리가 @code{make_withdraw}를 한 번 더 호출하여 두 번째 ``인출'' 객체를 생성할 때 무슨 일이 일어나는지 관찰하라:

@example
let mut w2 = make_withdraw(100);
@end example

@noindent
이것은 @ref{Figure 3.10}의 환경 구조를 생성하는데, 이는 @code{W2}가 프로시저 객체, 즉 어떤 코드와 환경을 가진 쌍임을 보여준다.
@code{W2}를 위한 환경 E2는 @code{make_withdraw} 호출에 의해 생성되었다.
그것은 @code{balance}에 대한 자체 지역 바인딩을 가진 프레임을 포함한다.
반면에, @code{W1}과 @code{W2}는 같은 코드를 갖는다: @code{make_withdraw}의 본문에 있는 클로저 표현식에 의해 지정된 코드이다.@footnote{@code{W1}과 @code{W2}가 컴퓨터에 저장된 동일한 물리적 코드를 공유하는지, 아니면 각각 코드의 사본을 유지하는지는 구현의 세부 사항이다. 우리가 @ref{Chapter 4}에서 구현할 인터프리터의 경우, 코드는 사실 공유된다.}
우리는 여기서 왜 @code{W1}과 @code{W2}가 독립적인 객체로 행동하는지 본다.
@code{W1}에 대한 호출은 E1에 저장된 상태 변수 @code{balance}를 참조하는 반면, @code{W2}에 대한 호출은 E2에 저장된 @code{balance}를 참조한다.
따라서 한 객체의 지역 상태에 대한 변경은 다른 객체에 영향을 미치지 않는다.

@float
@anchor{Figure 3.10}
@ifinfo
@strong{Figure 3.10:} 두 번째 객체를 생성하기 위해 @code{let mut w2 = make_withdraw(100);} 사용하기.

@example
         +-------------------------------------------------+
         | make-withdraw: ...                              |
global ->| W2: ---------------------------+                |
env      | W1: --+                        |                |
         +-------|------------------------|----------------+
                 |              ^         |              ^
                 |              |         |              |
                 |       +------+------+  |       +------+-------+
                 |  E1 ->| balance: 50 |  |  E2 ->| balance: 100 |
                 |       +-------------+  |       +--------------+
                 V              ^         V              ^
             .---.---.          |     .---.---.          |
             | O | O-+----------+     | O | O-+----------+
             `-|-^---'                `-|-^---'
               | +----------------------+
               V V
        parameters: amount
        body: ...
@end example
@end ifinfo
@iftex
@image{fig/chap3/Fig3.10b,147mm,,,.std.svg}
@caption{@strong{Figure 3.10:} 두 번째 객체를 생성하기 위해 @code{let mut w2 = make_withdraw(100);} 사용하기.}
@end iftex
@end float

@quotation
@strong{@anchor{Exercise 3.10}연습문제 3.10:} @code{make_withdraw} 프로시저에서, 지역 변수 @code{balance}는 @code{make_withdraw}의 매개변수로 생성된다.
우리는 또한 다음과 같이 @code{let}을 사용하여 지역 상태 변수를 명시적으로 생성할 수 있다:

@example
fn make_withdraw(initial_amount: i64) -> impl FnMut(i64) -> Result<i64, &'static str> @{
    let balance = std::cell::Cell::new(initial_amount);
    move |amount| @{
        let current = balance.get();
        if current >= amount @{
            balance.set(current - amount);
            Ok(balance.get())
        @} else @{
            Err("Insufficient funds")
        @}
    @}
@}
@end example

Rust에서 @code{let} 바인딩은 Scheme의 @code{let}이 새 스코프에 바인딩을 생성하는 것과 유사하게 클로저에 의해 캡처되는 지역 변수를 생성한다:

@example
// Rust의 let 바인딩은 변수를 캡처한다
let balance = Cell::new(initial_amount);
move |amount| @{ /* balance 사용 */ @}
@end example

환경 모델을 사용하여 이 대안 버전의 @code{make_withdraw}를 분석하고, 위의 그림과 같은 그림을 그려 상호 작용을 예시하라

@example
let mut w1 = make_withdraw(100);
w1(50);
let mut w2 = make_withdraw(100);
@end example

@code{make_withdraw}의 두 버전이 동일한 동작을 하는 객체를 생성함을 보여라.
두 버전에 대한 환경 구조는 어떻게 다른가?
@end quotation

@node	3.2.4, 3.3, 3.1, 3.2
@subsection 내부 정의 (Internal Definitions)

@ref{1.1.8}절은 프로시저가 내부 정의를 가질 수 있다는 아이디어를 소개했으며, 이는 제곱근을 계산하는 다음 프로시저와 같은 블록 구조로 이어진다:

@example
fn sqrt(x: f64) -> f64 @{
    fn good_enough(guess: f64, x: f64) -> bool @{
        (guess * guess - x).abs() < 0.001
    @}

    fn improve(guess: f64, x: f64) -> f64 @{
        (guess + x / guess) / 2.0
    @}

    fn sqrt_iter(guess: f64, x: f64) -> f64 @{
        if good_enough(guess, x) @{
            guess
        @} else @{
            sqrt_iter(improve(guess, x), x)
        @}
    @}

    sqrt_iter(1.0, x)
@}
@end example

@noindent
이제 우리는 환경 모델을 사용하여 이 내부 정의들이 왜 원하는 대로 동작하는지 볼 수 있다.
@ref{Figure 3.11}은 표현식 @code{(sqrt 2)}를 평가하는 과정에서 내부 프로시저 @code{good_enough}가 @code{guess}를 1로 하여 처음 호출된 시점을 보여준다.

@float
@anchor{Figure 3.11}
@ifinfo
@strong{Figure 3.11:} 내부 정의가 있는 @code{Sqrt} 프로시저.

@example
          +--------------------------------------------------+
global -->| sqrt: --+                                        |
env       |         |                                        |
          +---------|----------------------------------------+
                    V       ^                   ^
                .---.---.   |                   |
     +----------+-O | O-+---+        +----------+------------+
     |          `---^---'            | x: 2                  |
     V                         E1 -->| good-enough?: -+      |
parameters: x                        | improve: ...   |      |
body: fn good_enough ...           | sqrt_iter: ... |      |
      fn improve ...                 +----------------|------+
      fn sqrt_iter ...                ^  ^            |     ^
      sqrt_iter(1.0)                  |  |            V     |
                            +---------++ |        .---.---. |
                      E2 -->| guess: 1 | |        | O | O-+-+
                            +----------+ |        `-|-^---'
                      call to sqrt-iter  |          |
                                         |          V
                               +---------++    parameters: guess
                         E3 -->| guess: 1 |    body: (< (abs ...)
                               +----------+             ...)
                         call to good-enough?
@end example
@end ifinfo
@iftex
@image{fig/chap3/Fig3.11b,147mm,,,.std.svg}
@caption{@strong{Figure 3.11:} 내부 정의가 있는 @code{Sqrt} 프로시저.}
@end iftex
@end float

환경의 구조를 관찰하라.
@code{Sqrt}는 전역 환경의 기호로, 연관된 환경이 전역 환경인 프로시저 객체에 바인딩되어 있다.
@code{sqrt}가 호출되었을 때, 전역 환경에 종속된 새로운 환경 E1이 형성되었으며, 여기에서 매개변수 @code{x}는 2에 바인딩된다.
그런 다음 @code{sqrt}의 본문이 E1에서 평가되었다.
@code{sqrt} 본문의 첫 번째 표현식은

@example
fn good_enough(guess: f64, x: f64) -> bool @{
    (guess * guess - x).abs() < 0.001
@}
@end example

@noindent
이므로, 이 표현식을 평가하면 환경 E1에 프로시저 @code{good_enough}가 정의된다.
더 정확하게 말하면, 기호 @code{good_enough}가 E1의 첫 번째 프레임에 추가되고, 연관된 환경이 E1인 프로시저 객체에 바인딩된다.
마찬가지로, @code{improve}와 @code{sqrt-iter}가 E1에서 프로시저로 정의되었다.
간결함을 위해, @ref{Figure 3.11}은 @code{good_enough}에 대한 프로시저 객체만 보여준다.

@noindent
지역 프로시저들이 정의된 후, 표현식 @code{(sqrt-iter 1.0)}이 여전히 환경 E1에서 평가되었다.
따라서 E1에서 @code{sqrt-iter}에 바인딩된 프로시저 객체가 1을 인자로 하여 호출되었다.
이것은 @code{sqrt-iter}의 매개변수 @code{guess}가 1에 바인딩된 환경 E2를 생성했다.
@code{Sqrt-iter}는 차례로 @code{good_enough}에 대한 인자로 (E2에서 온) @code{guess}의 값을 사용하여 @code{good_enough}를 호출했다.
이것은 또 다른 환경 E3를 설정했는데, 여기서 (@code{good_enough}의 매개변수) @code{guess}는 1에 바인딩된다.
@code{sqrt-iter}와 @code{good_enough}가 둘 다 @code{guess}라는 이름의 매개변수를 갖지만, 이것들은 서로 다른 프레임에 위치한 두 개의 별개의 지역 변수이다.
또한, E2와 E3는 둘 다 E1을 감싸는 환경으로 갖는데, 왜냐하면 @code{sqrt-iter}와 @code{good_enough} 프로시저가 둘 다 E1을 환경 부분으로 갖기 때문이다.
이것의 한 가지 결과는 @code{good_enough}의 본문에 나타나는 기호 @code{x}가 E1에 나타나는 @code{x}의 바인딩, 즉 원래 @code{sqrt} 프로시저가 호출되었을 때의 @code{x} 값을 참조한다는 것이다.

따라서 환경 모델은 지역 프로시저 정의를 프로그램 모듈화에 유용한 기술로 만드는 두 가지 주요 속성을 설명한다:

@itemize @bullet

@item
지역 프로시저의 이름은 감싸는 프로시저 외부의 이름과 간섭하지 않는다. 왜냐하면 지역 프로시저 이름은 전역 환경에 바인딩되는 것이 아니라 프로시저가 실행될 때 생성하는 프레임에 바인딩되기 때문이다.

@item
지역 프로시저는 단순히 매개변수 이름을 자유 변수로 사용함으로써 감싸는 프로시저의 인자에 접근할 수 있다.
이것은 지역 프로시저의 본문이 감싸는 프로시저에 대한 평가 환경에 종속된 환경에서 평가되기 때문이다.

@end itemize

@quotation
@strong{@anchor{Exercise 3.11}연습문제 3.11:} @ref{3.2.3}에서 우리는 환경 모델이 지역 상태를 가진 프로시저의 동작을 어떻게 설명하는지 보았다.
이제 우리는 내부 정의가 어떻게 작동하는지 보았다.
전형적인 메시지 전달 프로시저는 이 두 가지 측면을 모두 포함한다.
@ref{3.1.1}의 은행 계좌 프로시저를 고려해 보자:

@example
use std::cell::Cell;

struct Account @{
    balance: Cell<i64>,
@}

impl Account @{
    fn new(balance: i64) -> Self @{
        Account @{ balance: Cell::new(balance) @}
    @}

    fn withdraw(&self, amount: i64) -> Result<i64, &'static str> @{
        let current = self.balance.get();
        if current >= amount @{
            self.balance.set(current - amount);
            Ok(self.balance.get())
        @} else @{
            Err("Insufficient funds")
        @}
    @}

    fn deposit(&self, amount: i64) -> i64 @{
        self.balance.set(self.balance.get() + amount);
        self.balance.get()
    @}
@}
@end example

다음 상호 작용 시퀀스에 의해 생성된 환경 구조를 보여라

@example
let acc = Account::new(50);

acc.deposit(40);
// => 90

acc.withdraw(60);
// => Ok(30)
@end example

@code{acc}에 대한 지역 상태는 어디에 유지되는가?
우리가 또 다른 계좌를 정의한다고 가정해 보자

@example
let acc2 = Account::new(100);
@end example

두 계좌에 대한 지역 상태는 어떻게 분리되어 유지되는가?
환경 구조의 어떤 부분이 @code{acc}와 @code{acc2} 사이에 공유되는가?
@end quotation

@node	3.3, 3.4, 3.2, Chapter 3
@section 가변 데이터를 이용한 모델링 (Modeling with Mutable Data)

@ref{Chapter 2}는 실제 세계의 여러 측면을 가진 객체를 모델링하기 위해 여러 부분으로 구성된 계산 객체를 구축하는 수단으로서 복합 데이터를 다루었다.
그 장에서 우리는 데이터 구조가 데이터 객체를 생성하는 생성자와 복합 데이터 객체의 부분에 접근하는 선택자의 관점에서 지정되는 데이터 추상화 규율을 소개했다.
하지만 이제 우리는 2장이 다루지 않은 데이터의 또 다른 측면이 있다는 것을 안다.
상태가 변하는 객체로 구성된 시스템을 모델링하려는 욕구는 우리에게 복합 데이터 객체에서 선택하고 구성하는 것뿐만 아니라 수정할 필요성도 가져온다.
상태가 변하는 복합 객체를 모델링하기 위해, 우리는 데이터 추상화를 설계할 때 선택자와 생성자 외에도 데이터 객체를 수정하는 @newterm{변경자(mutators)}라고 불리는 연산을 포함할 것이다.
예를 들어, 은행 시스템을 모델링하려면 계좌 잔액을 변경해야 한다.
따라서 은행 계좌를 나타내는 데이터 구조는 다음과 같은 연산을 허용할 수 있다

@example
account.balance.set(new_value);
@end example

@noindent
이것은 지정된 계좌의 잔액을 지정된 새 값으로 변경한다.
변경자가 정의된 데이터 객체를 @newterm{가변 데이터 객체(mutable data objects)}라고 부른다.

2장은 복합 데이터를 합성하기 위한 범용 ``풀(glue)''로 쌍(pairs)을 소개했다.
우리는 쌍이 가변 데이터 객체를 구축하기 위한 구성 요소 역할을 할 수 있도록 쌍에 대한 기본 변경자를 정의함으로써 이 절을 시작한다.
이 변경자들은 쌍의 표현력을 크게 향상시켜, 우리가 @ref{2.2}에서 작업했던 시퀀스와 트리 이외의 데이터 구조를 구축할 수 있게 해준다.
우리는 또한 복잡한 시스템이 지역 상태를 가진 객체들의 컬렉션으로 모델링되는 시뮬레이션의 몇 가지 예를 제시한다.

@menu
* 3.3.1::            Mutable List Structure
* 3.3.2::            Representing Queues
* 3.3.3::            Representing Tables
* 3.3.4::            A Simulator for Digital Circuits
* 3.3.4a::           Arena Allocation for Graphs
* 3.3.5::            Propagation of Constraints
@end menu

@node	3.3.1, 3.3.2, 3.3, 3.3
@subsection 가변 리스트 구조 (Mutable List Structure)

쌍에 대한 기본 연산---@code{cons}, @code{car}, 그리고 @code{cdr}---은 리스트 구조를 구성하고 리스트 구조에서 부분을 선택하는 데 사용될 수 있지만, 리스트 구조를 수정할 수는 없다.
@code{append}와 @code{list}와 같이 우리가 지금까지 사용한 리스트 연산들도 마찬가지인데, 이는 이것들이 @code{cons}, @code{car}, 그리고 @code{cdr}의 관점에서 정의될 수 있기 때문이다.
리스트 구조를 수정하려면 새로운 연산이 필요하다.

쌍에 대한 원시 변경자는 @code{set_car}와 @code{set_cdr}이다.
@code{Set_car}는 두 개의 인자를 받는데, 첫 번째는 가변 쌍이어야 한다.
이것은 이 쌍을 수정하여 @code{car} 포인터를 두 번째 인자에 대한 포인터로 교체한다.@footnote{@code{set_car}와 @code{set_cdr}는 유닛 타입 @code{()}을 반환한다. 할당과 마찬가지로, 이것들은 오직 그 효과를 위해서만 사용되어야 한다.}

@noindent
예를 들어, @code{x}가 리스트 @code{((a b) c d)}에 바인딩되어 있고 @code{y}가 리스트 @code{(e f)}에 바인딩되어 있다고 가정하자(@ref{Figure 3.12} 참조).
표현식 @code{x.set_car(y)}를 평가하면 @code{x}가 바인딩된 쌍이 수정되어, 그 @code{car}가 @code{y}의 값으로 바뀐다.
연산의 결과는 @ref{Figure 3.13}에 나와 있다.
구조 @code{x}는 수정되었으며 이제 @code{((e f) c d)}로 출력될 것이다.
교체된 포인터에 의해 식별되던 리스트 @code{(a b)}를 나타내는 쌍들은 이제 원래 구조에서 분리되었다.@footnote{우리는 이것으로부터 리스트에 대한 변경 연산이 접근 가능한 구조의 일부가 아닌 ``쓰레기(garbage)''를 생성할 수 있음을 본다. 우리는 @ref{5.3.2}에서 동적 메모리 관리 시스템이 불필요한 쌍이 사용하는 메모리 공간을 식별하고 재활용하는 @newterm{가비지 컬렉터(garbage collector)}를 포함한다는 것을 보게 될 것이다.}

@float
@anchor{Figure 3.12}
@ifinfo
@quotation
@strong{Figure 3.12:} 리스트 @code{x}: @code{((a b) c d)} 그리고 @code{y}: @code{(e f)}.

@example
     +---+---+     +---+---+     +---+---+
x -->| * | *-+---->| * | *-+---->| * | / |
     +-|-+---+     +-|-+---+     +-|-+---+
       |             V             V
       |           +---+         +---+
       |           | c |         | d |
       |           +---+         +---+
       |           +---+---+     +---+---+
       +---------->| * | *-+---->| * | / |
                   +-|-+---+     +-|-+---+
                     V             V
                   +---+         +---+
                   | a |         | b |
                   +---+         +---+
                   +---+---+     +---+---+
              y -->| * | *-+---->| * | / |
                   +-|-+---+     +-|-+---+
                     V             V
                   +---+         +---+
                   | e |         | f |
                   +---+         +---+
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap3/Fig3.12b,123mm,,,.std.svg}
@caption{@strong{Figure 3.12:} 리스트 @code{x}: @code{((a b) c d)} 그리고 @code{y}: @code{(e f)}.}
@end iftex
@end float

@float
@anchor{Figure 3.13}
@ifinfo
@quotation
@strong{Figure 3.13:} @ref{Figure 3.12}의 리스트에 대한 @code{x.set_car(y)}의 효과.

@example
     +---+---+     +---+---+     +---+---+
x -->| * | *-+---->| * | *-+---->| * | / |
     +-|-+---+     +-|-+---+     +-|-+---+
       |             V             V
       |           +---+         +---+
       |           | c |         | d |
       |           +---+         +---+
       |           +---+---+     +---+---+
       |           | * | *-+---->| * | / |
       |           +-|-+---+     +-|-+---+
       |             V             V
       |           +---+         +---+
       |           | a |         | b |
       |           +---+         +---+
       +---------->+---+---+     +---+---+
                   | * | *-+---->| * | / |
              y -->+-|-+---+     +-|-+---+
                     V             V
                   +---+         +---+
                   | e |         | f |
                   +---+         +---+
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap3/Fig3.13b,123mm,,,.std.svg}
@caption{@strong{Figure 3.13:} @ref{Figure 3.12}의 리스트에 대한 @code{x.set_car(y)}의 효과.}
@end iftex
@end float

@ref{Figure 3.13}을 @ref{Figure 3.14}와 비교해 보라. @ref{Figure 3.14}는 @code{x}와 @code{y}가 @ref{Figure 3.12}의 원래 리스트에 바인딩된 상태에서 @code{let z = cons(y, x.cdr())}를 실행한 결과를 보여준다.
변수 @code{z}는 이제 @code{cons} 연산에 의해 생성된 새로운 쌍에 바인딩된다; @code{x}가 바인딩된 리스트는 변경되지 않았다.

@float
@anchor{Figure 3.14}
@ifinfo
@quotation
@strong{Figure 3.14:} @ref{Figure 3.12}의 리스트에 대한 @code{let z = cons(y, x.cdr())}의 효과.

@example
     +---+---+     +---+---+     +---+---+
x -->| * | *-+---->| * | *-+---->| * | / |
     +-|-+---+ +-->+-|-+---+     +-|-+---+
       |       |     V             V
       |       |   +---+         +---+
       |       |   | c |         | d |
       |       |   +---+         +---+
       |       |   +---+---+     +---+---+
       +-------+-->| * | *-+---->| * | / |
               |   +-|-+---+     +-|-+---+
     +---+---+ |     V             V
z -->| * | *-+-+   +---+         +---+
     +-|-+---+     | a |         | b |
       |           +---+         +---+
       +---------->+---+---+     +---+---+
                   | * | *-+---->| * | / |
              y -->+-|-+---+     +-|-+---+
                     V             V
                   +---+         +---+
                   | e |         | f |
                   +---+         +---+
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap3/Fig3.14b,123mm,,,.std.svg}
@caption{@strong{Figure 3.14:} @ref{Figure 3.12}의 리스트에 대한 @code{let z = cons(y, x.cdr())}의 효과.}
@end iftex
@end float

@code{set_cdr} (또는 유사한 변경자) 연산은 @code{set_car} (또는 유사한 변경자)와 유사하다.
유일한 차이점은 @code{car} 포인터가 아니라 쌍의 @code{cdr} 포인터가 교체된다는 것이다.
@ref{Figure 3.12}의 리스트에 대해 @code{(set-cdr! x y)}를 실행한 효과는 @ref{Figure 3.15}에 나와 있다.
여기서 @code{x}의 @code{cdr} 포인터는 @code{(e f)}를 가리키는 포인터로 교체되었다.
또한 @code{x}의 @code{cdr}였던 리스트 @code{(c d)}는 이제 구조에서 분리되었다.

@float
@anchor{Figure 3.15}
@ifinfo
@quotation
@strong{Figure 3.15:} @ref{Figure 3.12}의 리스트에 대한 @code{(set-cdr! x y)}의 효과.

@example
     +---+---+     +---+---+     +---+---+
x -->| * | * |     | * | *-+---->| * | / |
     +-|-+-|-+     +-|-+---+     +-|-+---+
       |   |         V             V
       |   |       +---+         +---+
       |   |       | c |         | d |
       |   |       +---+         +---+
       |   |       +---+---+     +---+---+
       +---+------>| * | *-+---->| * | / |
           |       +-|-+---+     +-|-+---+
           |         V             V
           |       +---+         +---+
           |       | a |         | b |
           |       +---+         +---+
           +------>+---+---+     +---+---+
                   | * | *-+---->| * | / |
              y -->+-|-+---+     +-|-+---+
                     V             V
                   +---+         +---+
                   | e |         | f |
                   +---+         +---+
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap3/Fig3.15b,123mm,,,.std.svg}
@caption{@strong{Figure 3.15:} @ref{Figure 3.12}의 리스트에 대한 @code{(set-cdr! x y)}의 효과.}
@end iftex
@end float

@noindent
@code{Cons}는 새로운 쌍을 생성하여 새로운 리스트 구조를 구축하는 반면, @code{set_car} (또는 유사한 변경자)와 @code{set_cdr} (또는 유사한 변경자)는 기존 쌍을 수정한다.
실제로 우리는 두 변경자와 기존 리스트 구조의 일부가 아닌 새 쌍을 반환하는 프로시저 @code{get-new-pair}의 관점에서 @code{cons}를 구현할 수 있다.
우리는 새 쌍을 얻고, 그 @code{car}와 @code{cdr} 포인터를 지정된 객체로 설정한 다음, @code{cons}의 결과로 새 쌍을 반환한다.@footnote{@code{Get-new-pair}는 Lisp 구현에 필요한 메모리 관리의 일부로 구현되어야 하는 연산 중 하나이다. 우리는 @ref{5.3.1}에서 이것을 논의할 것이다.}

@example
// Rust에서 튜플과 구조체는 자연스러운 등가물이다
fn cons<A, B>(x: A, y: B) -> (A, B) @{
    (x, y)
@}

// 또는 가변 쌍 구조를 사용하여:
struct Pair<T> @{
    car: T,
    cdr: Option<Box<Pair<T>>>,
@}
@end example

@quotation
@strong{@anchor{Exercise 3.12}연습문제 3.12:} 리스트를 연결하는 다음 프로시저는 @ref{2.2.1}에서 소개되었다:

@example
fn append<T: Clone>(x: &[T], y: &[T]) -> Vec<T> @{
    let mut result = x.to_vec();
    result.extend_from_slice(y);
    result
@}
@end example

@code{Append}는 @code{x}의 요소를 @code{y}에 순차적으로 @code{cons}하여 새로운 리스트를 형성한다.
@code{append_mut}는 @code{append}와 유사하지만, 생성자가 아니라 변경자이다.
이것은 @code{x}의 마지막 쌍을 수정하여 그 @code{cdr}가 @code{y}가 되도록 함으로써 리스트를 함께 접합한다. (@code{x}가 비어 있을 때 @code{append!}를 호출하는 것은 오류이다.)

@example
fn append_mut<T>(x: &mut Vec<T>, y: Vec<T>) @{
    x.extend(y);
@}
@end example

여기 @code{last}는 슬라이스의 마지막 요소를 반환하는 메서드이다:

@example
fn last<T>(x: &[T]) -> Option<&T> @{
    x.last()
@}
@end example

다음 상호 작용을 고려해 보자

@example
let x = vec!["a", "b"];
let y = vec!["c", "d"];
let z = append(&x, &y);

z
// => ["a", "b", "c", "d"]

&x[1..]
// ⟨response⟩  // 여전히 ["b"]

let mut w = x.clone();
append_mut(&mut w, y.clone());

w
// => ["a", "b", "c", "d"]

&x[1..]
// ⟨response⟩  // 여전히 ["b"] - x는 변경되지 않음
@end example

누락된 @code{⟨}@var{response}@code{⟩}는 무엇인가? 여러분의 답을 설명하기 위해 박스 앤 포인터 다이어그램을 그려라.
@end quotation

@quotation
@strong{@anchor{Exercise 3.13}연습문제 3.13:} @ref{Exercise 3.12}에서 정의된 @code{last-pair} 프로시저를 사용하는 다음 @code{make-cycle} 프로시저를 고려해 보자:

@example
// Rust는 의도적으로 소유된 데이터의 순환을 방지한다.
// 순환을 만들려면 아레나 할당이나 Rc<RefCell<T>>를 사용하라:
use std::rc::Rc;
use std::cell::RefCell;

struct Node<T> @{
    value: T,
    next: Option<Rc<RefCell<Node<T>>>>,
@}

fn make_cycle<T>(nodes: Vec<Rc<RefCell<Node<T>>>>) @{
    if let Some(last) = nodes.last() @{
        if let Some(first) = nodes.first() @{
            last.borrow_mut().next = Some(Rc::clone(first));
        @}
    @}
@}
@end example

다음에 의해 생성된 구조 @code{z}를 보여주는 박스 앤 포인터 다이어그램을 그려라

@example
// Rust에서 순환을 생성하려면 명시적인 공유 소유권이 필요하다
let a = Rc::new(RefCell::new(Node @{ value: "a", next: None @}));
let b = Rc::new(RefCell::new(Node @{ value: "b", next: None @}));
let c = Rc::new(RefCell::new(Node @{ value: "c", next: None @}));
a.borrow_mut().next = Some(Rc::clone(&b));
b.borrow_mut().next = Some(Rc::clone(&c));
c.borrow_mut().next = Some(Rc::clone(&a)); // 순환 생성
@end example

만약 우리가 @code{(last-pair z)}를 계산하려고 하면 어떤 일이 일어나는가?
@end quotation

@quotation
@strong{@anchor{Exercise 3.14}연습문제 3.14:} 다음 프로시저는 꽤 유용하지만, 이해하기 어렵다:

@example
// 이것은 제자리 리스트 반전(in-place list reversal)이다
fn mystery<T>(x: Vec<T>) -> Vec<T> @{
    let mut result = x;
    result.reverse();
    result
@}

// 연결 리스트의 경우, 변경 버전은 다음과 같을 것이다:
fn reverse_in_place<T>(mut x: Option<Box<Node<T>>>) -> Option<Box<Node<T>>> @{
    let mut prev = None;
    while let Some(mut node) = x @{
        x = node.next.take();
        node.next = prev;
        prev = Some(node);
    @}
    prev
@}
@end example

@code{Loop}는 ``임시'' 변수 @code{temp}를 사용하여 @code{x}의 @code{cdr}의 이전 값을 유지하는데, 왜냐하면 다음 줄의 @code{set_cdr} (또는 유사한 변경자)가 @code{cdr}을 파괴하기 때문이다.
@code{mystery}가 일반적으로 무엇을 하는지 설명하라.
@code{v}가 @code{let v = list("a", "b", "c", "d");}로 정의되었다고 가정하자. @code{v}가 바인딩된 리스트를 나타내는 박스 앤 포인터 다이어그램을 그려라.
이제 우리가 @code{let w = mystery(v);}를 평가한다고 가정하자. 이 표현식을 평가한 후의 구조 @code{v}와 @code{w}를 보여주는 박스 앤 포인터 다이어그램을 그려라.
@code{v}와 @code{w}의 값으로 무엇이 출력되겠는가?
@end quotation

@subsubheading 공유와 동일성 (Sharing and identity)

우리는 @ref{3.1.3}에서 할당의 도입으로 제기된 ``동일성''과 ``변화''의 이론적 문제들을 언급했다.
이러한 문제들은 개별 쌍이 서로 다른 데이터 객체 간에 @newterm{공유(shared)}될 때 실제로 발생한다.
예를 들어, 다음으로 형성된 구조를 고려해 보자

@example
let x = vec!["a", "b"];
let z1 = (x.clone(), x.clone());  // Rust에서는 독립적인 사본을 생성한다
// 공유하려면 Rc를 사용하라:
use std::rc::Rc;
let x = Rc::new(vec!["a", "b"]);
let z1 = (Rc::clone(&x), Rc::clone(&x));  // 둘 다 같은 데이터를 가리킨다
@end example

@noindent
@ref{Figure 3.16}에 표시된 것처럼, @code{z1}은 @code{car}와 @code{cdr}가 모두 같은 쌍 @code{x}를 가리키는 쌍이다.
@code{z1}의 @code{car}와 @code{cdr}에 의한 @code{x}의 공유는 @code{cons}가 구현되는 방식의 직접적인 결과이다.
일반적으로 @code{cons}를 사용하여 리스트를 구축하면 많은 개별 쌍이 많은 다른 구조에 의해 공유되는 상호 연결된 쌍 구조가 생성된다.

@float
@anchor{Figure 3.16}
@ifinfo
@quotation
@strong{Figure 3.16:} @code{(cons x x)}에 의해 형성된 리스트 @code{z1}.

@example
      +---+---+
z1 -->| * | * |
      +-|-+-|-+
        V   V
      +---+---+     +---+---+
 x -->| * | *-+---->| * | / |
      +-|-+---+     +-|-+---+
        V             V
      +---+         +---+
      | a |         | b |
      +---+         +---+
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap3/Fig3.16b,78mm,,,.std.svg}
@caption{@strong{Figure 3.16:} @code{(cons x x)}에 의해 형성된 리스트 @code{z1}.}
@end iftex
@end float

@ref{Figure 3.16}과 대조적으로, @ref{Figure 3.17}은 다음에 의해 생성된 구조를 보여준다

@example
let z2 = (vec!["a", "b"], vec!["a", "b"]);  // 두 개의 별개의 벡터
@end example

@float
@anchor{Figure 3.17}
@ifinfo
@quotation
@strong{Figure 3.17:} @code{(cons (list 'a 'b) (list 'a 'b))}에 의해 형성된 리스트 @code{z2}.

@example
      +---+---+     +---+---+     +---+---+
z2 -->| * | *-+---->| * | *-+---->| * | / |
      +-|-+---+     +-|-+---+     +-|-+---+
        |             V             V
        |           +---+         +---+
        |           | a |         | b |
        |           +---+         +---+
        |             ^             ^
        |             |             |
        |           +-|-+---+     +-|-+---+
        +---------->| * | *-+---->| * | / |
                    +---+---+     +---+---+
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap3/Fig3.17b,121mm,,,.std.svg}
@caption{@strong{Figure 3.17:} @code{(cons (list 'a 'b) (list 'a 'b))}에 의해 형성된 리스트 @code{z2}.}
@end iftex
@end float

@noindent
이 구조에서 두 @code{(a b)} 리스트의 쌍들은 구별되지만 실제 기호들은 공유된다.@footnote{두 쌍이 구별되는 이유는 @code{cons}에 대한 각 호출이 새로운 쌍을 반환하기 때문이다. 기호들은 공유된다; Scheme에는 주어진 이름을 가진 유일한 기호가 있다. Scheme은 기호를 변경하는 방법을 제공하지 않으므로 이 공유는 감지할 수 없다. 또한 이 공유 덕분에 우리가 포인터의 동등성을 단순히 확인하는 @code{eq?}를 사용하여 기호를 비교할 수 있다는 점에 주목하라.}

@noindent
리스트로 생각할 때, @code{z1}과 @code{z2}는 둘 다 ``같은'' 리스트 @code{((a b) a b)}를 나타낸다.
일반적으로, 만약 우리가 @code{cons}, @code{car}, 그리고 @code{cdr}만을 사용하여 리스트를 조작한다면 공유는 완전히 감지할 수 없다.
그러나 리스트 구조에 대한 변경자를 허용하면 공유는 중요해진다.
공유가 만들 수 있는 차이의 예로서, 적용된 구조의 @code{car}를 수정하는 다음 프로시저를 고려해 보자:

@example
// 공유 변경을 허용하기 위해 Rc<RefCell<Vec<&str>>> 사용
fn set_to_wow(x: &(Rc<RefCell<Vec<&str>>>, Rc<RefCell<Vec<&str>>>)) @{
    x.0.borrow_mut()[0] = "wow";
@}
@end example

@noindent
@code{z1}과 @code{z2}가 ``같은'' 구조일지라도, 그것들에 @code{set-to-wow!}를 적용하면 다른 결과가 나온다.
@code{z1}의 경우, @code{car}를 변경하면 @code{cdr}도 변경되는데, 왜냐하면 @code{z1}에서 @code{car}와 @code{cdr}는 같은 쌍이기 때문이다.
@code{z2}의 경우, @code{car}와 @code{cdr}는 구별되므로, @code{set-to-wow!}는 @code{car}만 수정한다:

@example
z1
// => (["a", "b"], ["a", "b"])  -- 동일한 기본 Rc

set_to_wow(&z1);
// => (["wow", "b"], ["wow", "b"])  -- 둘 다 변경됨!

z2
// => (["a", "b"], ["a", "b"])  -- 독립적인 벡터들

set_to_wow(&z2);
// => (["wow", "b"], ["a", "b"])  -- 첫 번째만 변경됨
@end example

@noindent
리스트 구조에서 공유를 감지하는 한 가지 방법은 우리가 @ref{2.3.1}에서 두 기호가 같은지 테스트하는 방법으로 소개한 술어 @code{eq?}를 사용하는 것이다.
더 일반적으로, @code{(eq? x y)}는 @code{x}와 @code{y}가 같은 객체인지(즉, @code{x}와 @code{y}가 포인터로서 같은지) 테스트한다.
따라서 @ref{Figure 3.16}과 @ref{Figure 3.17}에 정의된 @code{z1}과 @code{z2}에 대해, @code{(eq? (car z1) (cdr z1))}은 참이고 @code{(eq? (car z2) (cdr z2))}는 거짓이다.

다음 절들에서 볼 수 있듯이, 우리는 공유를 활용하여 쌍으로 표현될 수 있는 데이터 구조의 레퍼토리를 크게 확장할 수 있다.
반면에 공유는 위험할 수도 있는데, 왜냐하면 구조에 가해진 수정이 수정된 부분을 공유하는 다른 구조에도 영향을 미치기 때문이다.
변경 연산 @code{set_car} (또는 유사한 변경자)와 @code{set_cdr} (또는 유사한 변경자)는 주의해서 사용해야 한다; 데이터 객체가 어떻게 공유되는지 잘 이해하지 못한다면, 변경은 예상치 못한 결과를 초래할 수 있다.@footnote{가변 데이터 객체의 공유를 다루는 미묘함은 @ref{3.1.3}에서 제기된 ``동일성''과 ``변화''의 근본적인 문제를 반영한다.
우리는 거기서 우리 언어에 변화를 허용하는 것은 복합 객체가 그것을 구성하는 조각들과는 다른 ``정체성(identity)''을 가져야 함을 요구한다고 언급했다.
Lisp에서 우리는 이 ``정체성''을 @code{eq?}, 즉 포인터의 동등성에 의해 테스트되는 품질로 간주한다.
대부분의 Lisp 구현에서 포인터는 본질적으로 메모리 주소이므로, 우리는 데이터 객체 ``자체''가 컴퓨터의 특정 메모리 위치 집합에 저장된 정보라고 규정함으로써 객체의 정체성을 정의하는 ``문제를 해결''하고 있다.
이것은 간단한 Lisp 프로그램에는 충분하지만, 계산 모델에서 ``동일성'' 문제를 해결하는 일반적인 방법이라고 보기는 어렵다.}

@quotation
@strong{@anchor{Exercise 3.15}연습문제 3.15:} 위의 구조 @code{z1}과 @code{z2}에 대한 @code{set-to-wow!}의 효과를 설명하기 위해 박스 앤 포인터 다이어그램을 그려라.
@end quotation

@quotation
@strong{@anchor{Exercise 3.16}연습문제 3.16:} Ben Bitdiddle은 임의의 리스트 구조에 있는 쌍의 수를 세는 프로시저를 작성하기로 결정한다.
그는 ``쉽네,''라고 추론한다. ``어떤 구조의 쌍의 수는 @code{car}에 있는 수 더하기 @code{cdr}에 있는 수 더하기 현재 쌍을 세기 위한 1이야.''
그래서 Ben은 다음 프로시저를 작성한다:

@example
// 순진한 계산 - 공유를 올바르게 처리하지 않음
fn count_pairs<T>(x: &Node<T>) -> usize @{
    let car_count = match &x.car @{
        Some(node) => count_pairs(node),
        None => 0,
    @};
    let cdr_count = match &x.cdr @{
        Some(node) => count_pairs(node),
        None => 0,
    @};
    car_count + cdr_count + 1
@}
@end example

이 프로시저가 올바르지 않음을 보여라.
특히, 정확히 3개의 쌍으로 구성된 리스트 구조에 대해 Ben의 프로시저가 3을 반환하는 경우; 4를 반환하는 경우; 7을 반환하는 경우; 전혀 반환하지 않는 경우를 나타내는 박스 앤 포인터 다이어그램을 그려라.
@end quotation

@quotation
@strong{@anchor{Exercise 3.17}연습문제 3.17:} 어떤 구조에 있는 서로 다른 쌍의 수를 반환하는 @ref{Exercise 3.16}의 @code{count-pairs} 프로시저의 올바른 버전을 고안하라. (힌트: 구조를 순회하면서 이미 센 쌍들을 추적하는 데 사용되는 보조 데이터 구조를 유지하라.)
@end quotation

@quotation
@strong{@anchor{Exercise 3.18}연습문제 3.18:} 리스트를 검사하여 순환을 포함하는지, 즉 연속적인 @code{cdr}를 취하여 리스트의 끝을 찾으려는 프로그램이 무한 루프에 빠질지 여부를 결정하는 프로시저를 작성하라. @ref{Exercise 3.13}은 그러한 리스트를 구성했다.
@end quotation

@quotation
@strong{@anchor{Exercise 3.19}연습문제 3.19:} 상수 공간만 사용하는 알고리즘을 사용하여 @ref{Exercise 3.18}을 다시 수행하라. (이것은 매우 기발한 아이디어를 필요로 한다.)
@end quotation

@subsubheading 변경은 할당일 뿐이다 (Mutation is just assignment)

우리가 복합 데이터를 소개했을 때, @ref{2.1.3}에서 쌍이 순수하게 프로시저의 관점에서 표현될 수 있음을 관찰했다:

@example
// 열거형 값을 반환하는 클로저로 표현된 쌍
enum PairOp<T> @{
    Car,
    Cdr,
@}

fn cons<T: Clone>(x: T, y: T) -> impl Fn(PairOp<T>) -> T @{
    move |m| match m @{
        PairOp::Car => x.clone(),
        PairOp::Cdr => y.clone(),
    @}
@}

fn car<T>(z: impl Fn(PairOp<T>) -> T) -> T @{ z(PairOp::Car) @}
fn cdr<T>(z: impl Fn(PairOp<T>) -> T) -> T @{ z(PairOp::Cdr) @}
@end example

@noindent
동일한 관찰이 가변 데이터에 대해서도 사실이다.
우리는 할당과 지역 상태를 사용하여 가변 데이터 객체를 프로시저로 구현할 수 있다.
예를 들어, 우리는 @ref{3.1.1}에서 @code{Account::new}를 사용하여 은행 계좌를 구현한 방식과 유사하게 @code{set_car} (또는 유사한 변경자)와 @code{set_cdr} (또는 유사한 변경자)를 처리하도록 위의 쌍 구현을 확장할 수 있다:

@example
// 내부 가변성을 위해 Cell을 사용하는 가변 쌍
use std::cell::Cell;

struct MutablePair<T: Copy> @{
    car: Cell<T>,
    cdr: Cell<T>,
@}

impl<T: Copy> MutablePair<T> @{
    fn cons(x: T, y: T) -> Self @{
        MutablePair @{
            car: Cell::new(x),
            cdr: Cell::new(y),
        @}
    @}

    fn car(&self) -> T @{ self.car.get() @}
    fn cdr(&self) -> T @{ self.cdr.get() @}
    fn set_car(&self, v: T) @{ self.car.set(v); @}
    fn set_cdr(&self, v: T) @{ self.cdr.set(v); @}
@}
@end example

@noindent
이론적으로 가변 데이터의 동작을 설명하기 위해 필요한 것은 할당뿐이다.
우리 언어에 @code{set!}을 인정하자마자, 우리는 할당뿐만 아니라 가변 데이터 전반에 관한 모든 문제를 제기하게 된다.@footnote{반면에 구현의 관점에서 볼 때, 할당은 환경을 수정하는 것을 요구하며, 환경 자체도 가변 데이터 구조이다. 따라서 할당과 변경은 동등하다: 각각은 다른 것의 관점에서 구현될 수 있다.}

@quotation
@strong{@anchor{Exercise 3.20}연습문제 3.20:} 다음 표현식 시퀀스의 평가를 설명하기 위해 환경 다이어그램을 그려라

@example
let x = cons(1, 2);
let z = cons(x.clone(), x.clone());

z.cdr().set_car(17);

x.car()
@i{17}
@end example

@noindent
위에서 주어진 쌍의 절차적 구현을 사용하여. (@ref{Exercise 3.11}과 비교하라.)
@end quotation

@node	3.3.2, 3.3.3, 3.3.1, 3.3
@subsection 큐 표현 (Representing Queues)

변경자 @code{set_car} (또는 유사한 변경자)와 @code{set_cdr} (또는 유사한 변경자)는 우리가 @code{cons}, @code{car}, 그리고 @code{cdr}만으로는 구축할 수 없는 데이터 구조를 쌍을 사용하여 구축할 수 있게 해준다.
이 절에서는 큐라고 불리는 데이터 구조를 표현하기 위해 쌍을 사용하는 방법을 보여준다.
@ref{3.3.3} 절에서는 테이블이라고 불리는 데이터 구조를 표현하는 방법을 보여줄 것이다.

@newterm{큐(queue)}는 한쪽 끝(@newterm{뒤(rear)}라고 함)에서 항목이 삽입되고 다른 쪽 끝(@newterm{앞(front)})에서 항목이 삭제되는 시퀀스이다.
@ref{Figure 3.18}은 처음에 비어 있는 큐에 항목 @code{a}와 @code{b}가 삽입되는 것을 보여준다.
그 다음 @code{a}가 제거되고, @code{c}와 @code{d}가 삽입되고, @code{b}가 제거된다.
항목은 항상 삽입된 순서대로 제거되므로, 큐는 때때로 @newterm{FIFO} (선입 선출, first in, first out) 버퍼라고 불린다.

@float
@anchor{Figure 3.18}
@ifinfo
@quotation
@strong{Figure 3.18:} 큐 연산.

@example
Operation                Resulting Queue
let mut q = Queue::new();
q.push_back("a")         a
q.push_back("b")         a b
q.pop_front()            b
q.push_back("c")         b c
q.push_back("d")         b c d
q.pop_front()            c d
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap3/Fig3.18,119mm,,,.std.svg}
@caption{@strong{Figure 3.18:} 큐 연산.}
@end iftex
@end float

@noindent
데이터 추상화의 관점에서, 우리는 큐를 다음 연산 집합으로 정의된 것으로 간주할 수 있다:

@itemize @bullet

@item
생성자: @code{(make-queue)}는 빈 큐(항목이 없는 큐)를 반환한다.

@item
두 개의 선택자:

@example
queue.is_empty()
@end example

@noindent
큐가 비어 있는지 테스트한다.

@example
queue.front()
@end example

@noindent
큐의 맨 앞에 있는 객체를 반환하며, 큐가 비어 있으면 오류를 신호한다; 큐를 수정하지 않는다.

@item
두 개의 변경자:

@example
queue.push_back(item)
@end example

@noindent
항목을 큐의 뒤에 삽입하고 수정된 큐를 값으로 반환한다.

@example
queue.pop_front()
@end example

@noindent
큐의 맨 앞에 있는 항목을 제거하고 수정된 큐를 값으로 반환하며, 삭제 전에 큐가 비어 있으면 오류를 신호한다.

@end itemize

@noindent
큐는 항목의 시퀀스이므로, 우리는 확실히 큐를 일반 리스트로 표현할 수 있다; 큐의 앞은 리스트의 @code{car}가 될 것이고, 큐에 항목을 삽입하는 것은 리스트의 끝에 새 요소를 추가하는 것에 해당할 것이며, 큐에서 항목을 삭제하는 것은 단지 리스트의 @code{cdr}를 취하는 것일 것이다.
그러나 이 표현은 비효율적인데, 왜냐하면 항목을 삽입하기 위해 우리는 리스트의 끝에 도달할 때까지 리스트를 스캔해야 하기 때문이다.
리스트를 스캔하는 유일한 방법은 연속적인 @code{cdr} 연산이므로, 이 스캔은 @math{n}개의 항목이 있는 리스트에 대해 @math{{\Theta(n)}} 단계가 필요하다.
리스트 표현에 대한 간단한 수정은 큐 연산이 @math{{\Theta(1)}} 단계, 즉 필요한 단계 수가 큐의 길이에 독립적이도록 구현될 수 있게 함으로써 이 단점을 극복한다.

리스트 표현의 어려움은 리스트의 끝을 찾기 위해 스캔해야 할 필요성에서 비롯된다.
우리가 스캔해야 하는 이유는, 리스트를 쌍의 체인으로 표현하는 표준 방법이 우리에게 리스트의 시작 부분에 대한 포인터는 쉽게 제공하지만, 끝부분에 대한 쉽게 접근 가능한 포인터는 제공하지 않기 때문이다.

Rust에서 표준 라이브러리는 @code{std::collections::VecDeque}를 제공하는데, 이는 양쪽 끝에서의 삽입과 삭제를 @math{{\Theta(1)}} 시간에 효율적으로 처리한다. 이것은 수동 포인터 조작의 필요성을 대체한다. 그러나 기본 원리를 이해하기 위해, 우리는 큐를 리스트와 함께 리스트의 마지막 쌍을 가리키는 추가 포인터로 표현할 수 있다.

@noindent
그러면 큐는 일반 리스트의 첫 번째와 마지막 쌍을 각각 나타내는 포인터 쌍, @code{front_ptr}과 @code{rear_ptr}로 표현될 수 있다. 큐를 식별 가능한 객체로 만들고 싶으므로, 우리는 이것들을 구조체로 감쌀 수 있다. @ref{Figure 3.19}는 이 표현을 보여준다.

@float
@anchor{Figure 3.19}
@ifinfo
@quotation
@strong{Figure 3.19:} 전방 및 후방 포인터가 있는 리스트로서의 큐 구현.

@example
       +---+---+
  q -->| * | *-+-------------------+
       +-|-+---+                   |
         |                         |
         | front-ptr               | rear-ptr
         V                         V
     +---+---+    +---+---+    +---+---+
     | * | *-+--->| * | *-+--->| * | / |
     +-|-+---+    +-|-+---+    +-|-+---+
       V            V            V
     +---+        +---+        +---+
     | a |        | b |        | c |
     +---+        +---+        +---+
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap3/Fig3.19b,118mm,,,.std.svg}
@caption{@strong{Figure 3.19:} 전방 및 후방 포인터가 있는 리스트로서의 큐 구현.}
@end iftex
@end float

큐 연산을 정의하기 위해 우리는 큐의 전방 및 후방 포인터를 선택하고 수정할 수 있게 해주는 다음 프로시저들을 사용한다:

@example
use std::collections::VecDeque;

// Rust의 VecDeque는 양쪽 끝에서 효율적인 O(1) 연산을 제공한다
struct Queue<T> @{
    items: VecDeque<T>,
@}
@end example

@noindent
이제 우리는 실제 큐 연산을 구현할 수 있다.
우리는 전방 포인터가 빈 리스트이면 큐가 비어 있다고 간주할 것이다:

@example
fn is_empty(&self) -> bool @{
    self.items.is_empty()
@}
@end example

@noindent
@code{Queue::new} 생성자는 처음에는 비어 있는 큐로서 @code{car}와 @code{cdr}가 모두 빈 리스트인 쌍을 반환한다:

@example
fn new() -> Self @{
    Queue @{ items: VecDeque::new() @}
@}
@end example

@noindent
큐의 맨 앞에 있는 항목을 선택하기 위해, 우리는 전방 포인터가 가리키는 쌍의 @code{car}를 반환한다:

@example
fn front(&self) -> Option<&T> @{
    self.items.front()
@}
@end example

@noindent
큐에 항목을 삽입하기 위해, 우리는 그 결과가 @ref{Figure 3.20}에 표시된 방법을 따른다.
우리는 먼저 @code{car}가 삽입될 항목이고 @code{cdr}가 빈 리스트인 새 쌍을 생성한다.
만약 큐가 처음에 비어 있었다면, 우리는 큐의 전방 및 후방 포인터를 이 새 쌍으로 설정한다.
그렇지 않다면, 우리는 큐의 마지막 쌍이 새 쌍을 가리키도록 수정하고, 또한 후방 포인터를 새 쌍으로 설정한다.

@float
@anchor{Figure 3.20}
@ifinfo
@strong{Figure 3.20:} @ref{Figure 3.19}의 큐에 @code{q.push_back("d")}를 사용한 결과.

@example
       +---+---+
  q -->| * | *-+--------------------------------+
       +-|-+---+                                |
         |                                      |
         | front-ptr                            | rear-ptr
         V                                      V
     +---+---+    +---+---+    +---+---+    +---+---+
     | * | *-+--->| * | *-+--->| * | *-+--->| * | / |
     +-|-+---+    +-|-+---+    +-|-+---+    +-|-+---+
       V            V            V            V
     +---+        +---+        +---+        +---+
     | a |        | b |        | c |        | d |
     +---+        +---+        +---+        +---+
@end example
@end ifinfo
@iftex
@image{fig/chap3/Fig3.20c,141mm,,,.std.svg}
@caption{@strong{Figure 3.20:} @ref{Figure 3.19}의 큐에 @code{q.push_back("d")}를 사용한 결과.}
@end iftex
@end float

@example
fn push_back(&mut self, item: T) @{
    self.items.push_back(item);
@}
@end example

@noindent
큐의 맨 앞에 있는 항목을 삭제하기 위해, 우리는 단순히 전방 포인터가 큐의 두 번째 항목을 가리키도록 수정한다. 이 두 번째 항목은 첫 번째 항목의 @code{cdr} 포인터를 따라가면 찾을 수 있다(@ref{Figure 3.21} 참조):@footnote{만약 첫 번째 항목이 큐의 마지막 항목이라면, 삭제 후 전방 포인터는 빈 리스트가 되어 큐가 비어 있음을 표시할 것이다; 후방 포인터는 여전히 삭제된 항목을 가리키고 있겠지만, @code{empty-queue?}가 전방 포인터만 보므로 후방 포인터를 업데이트할 걱정은 할 필요가 없다.}

@example
fn pop_front(&mut self) -> Option<T> @{
    self.items.pop_front()
@}
@end example

@float
@anchor{Figure 3.21}
@ifinfo
@strong{Figure 3.21:} @ref{Figure 3.20}의 큐에 @code{q.pop_front()}을 사용한 결과.

@example
       +---+---+
  q -->| * | *-+--------------------------------+
       +-|-+---+                                |
         +------------+                         |
            front-ptr |                         | rear-ptr
                      V                         V
     +---+---+    +---+---+    +---+---+    +---+---+
     | * | *-+--->| * | *-+--->| * | *-+--->| * | / |
     +-|-+---+    +-|-+---+    +-|-+---+    +-|-+---+
       V            V            V            V
     +---+        +---+        +---+        +---+
     | a |        | b |        | c |        | d |
     +---+        +---+        +---+        +---+
@end example
@end ifinfo
@iftex
@image{fig/chap3/Fig3.21c,141mm,,,.std.svg}
@caption{@strong{Figure 3.21:} @ref{Figure 3.20}의 큐에 @code{q.pop_front()}을 사용한 결과.}
@end iftex
@end float

@quotation
@strong{@anchor{Exercise 3.21}연습문제 3.21:} Ben Bitdiddle은 위에서 설명한 큐 구현을 테스트하기로 결정한다.
그는 프로시저들을 Lisp 인터프리터에 입력하고 시도해 본다:

@example
let mut q1: Queue<&str> = Queue::new();

q1.push_back("a");
// q1 = ["a"]

q1.push_back("b");
// q1 = ["a", "b"]

q1.pop_front();
// => Some("a"), q1 = ["b"]

q1.pop_front();
// => Some("b"), q1 = []
@end example

``완전 틀렸어!'' 그가 불평한다. ``인터프리터의 응답은 마지막 항목이 큐에 두 번 삽입되었음을 보여줘. 그리고 두 항목을 삭제했을 때, 두 번째 @code{b}가 여전히 거기에 있어서 큐가 비어 있어야 하는데 비어 있지 않아.''
Eva Lu Ator는 Ben이 무슨 일이 일어나고 있는지 오해하고 있다고 제안한다.
``항목들이 큐에 두 번 들어가는 게 아니야,'' 그녀가 설명한다. ``단지 표준 Lisp 프린터가 큐 표현을 어떻게 이해해야 할지 모르는 거야. 만약 큐가 올바르게 출력되는 것을 보고 싶다면, 큐를 위한 너만의 출력 프로시저를 정의해야 할 거야.''
Eva Lu가 무슨 말을 하는지 설명하라.
특히, Ben의 예제가 왜 그런 출력 결과를 생성하는지 보여라.
큐를 입력으로 받아 큐에 있는 항목의 시퀀스를 출력하는 프로시저 @code{print-queue}를 정의하라.
@end quotation

@quotation
@strong{@anchor{Exercise 3.22}연습문제 3.22:} 포인터 쌍으로 큐를 표현하는 대신, 우리는 지역 상태를 가진 프로시저로 큐를 구축할 수 있다.
지역 상태는 일반 리스트의 시작과 끝에 대한 포인터로 구성될 것이다.
따라서 @code{Queue::new} 프로시저는 다음과 같은 형태를 가질 것이다

@example
struct Queue<T> @{
    items: VecDeque<T>,
@}

impl<T> Queue<T> @{
    fn new() -> Self @{ ... @}
    fn push_back(&mut self, item: T) @{ ... @}
    fn pop_front(&mut self) -> Option<T> @{ ... @}
    fn front(&self) -> Option<&T> @{ ... @}
    fn is_empty(&self) -> bool @{ ... @}
@}
@end example

@code{Queue::new}의 정의를 완성하고 이 표현을 사용하여 큐 연산의 구현을 제공하라.
@end quotation

@quotation
@strong{@anchor{Exercise 3.23}연습문제 3.23:} @newterm{덱(deque)} (``양끝 큐(double-ended queue)'')은 항목이 앞이나 뒤에서 삽입되고 삭제될 수 있는 시퀀스이다.
덱에 대한 연산은 생성자 @code{make-deque}, 술어 @code{empty-deque?}, 선택자 @code{front-deque}와 @code{rear-deque}, 그리고 변경자 @code{front-insert-deque!}, @code{rear-insert-deque!}, @code{front-delete-deque!}, @code{rear-delete-deque!}이다.
쌍을 사용하여 덱을 표현하는 방법을 보여주고, 연산의 구현을 제시하라.@footnote{인터프리터가 순환을 포함하는 구조를 출력하려고 시도하지 않도록 주의하라. (@ref{Exercise 3.13} 참조.)}
모든 연산은 @math{{\Theta(1)}} 단계에 완료되어야 한다.
@end quotation

@node	3.3.3, 3.3.4, 3.3.2, 3.3
@subsection 테이블 표현 (Representing Tables)

우리가 @ref{Chapter 2}에서 집합을 표현하는 다양한 방법을 공부했을 때, 우리는 @ref{2.3.3}에서 식별용 키로 인덱싱된 레코드 테이블을 유지하는 작업에 대해 언급했다.
@ref{2.4.3}에서 데이터 주도 프로그래밍을 구현할 때, 우리는 두 개의 키를 사용하여 정보를 저장하고 검색하는 2차원 테이블을 광범위하게 사용했다.
여기서는 가변 리스트 구조로 테이블을 구축하는 방법을 본다.

테이블은 키-값 쌍의 컬렉션으로 구현될 수 있다. Rust에서 @code{std::collections::HashMap}은 해시 테이블을 사용하여 효율적인 테이블 구현을 제공한다. 그러나 테이블의 구조를 이해하기 위해, 우리는 또한 각 레코드가 키와 연관된 값으로 구성된 쌍인 레코드들의 리스트로 테이블을 표현할 수도 있다.

@subsubheading 1차원 테이블 (One-dimensional tables)

1차원 테이블에서, 각 값은 단일 키 아래에 저장된다. Rust에서 우리는 @code{HashMap}을 사용하여 조회와 삽입을 쉽게 수행할 수 있다:

@example
use std::collections::HashMap;

fn lookup<K, V>(key: &K, table: &HashMap<K, V>) -> Option<&V>
where
    K: Eq + std::hash::Hash,
@{
    table.get(key)
@}

fn insert<K, V>(key: K, value: V, table: &mut HashMap<K, V>)
where
    K: Eq + std::hash::Hash,
@{
    table.insert(key, value);
@}
@end example

@noindent
해시 맵은 기본 메모리 관리를 처리하고 조회 및 삽입에 대해 @math{O(1)} 평균 시간을 제공한다.
만약 우리가 리스트 구조를 사용하여 수동으로 테이블을 구축한다면, 우리는 @ref{Figure 3.22}에 표시된 것처럼 @newterm{헤드 리스트(headed list)}로 표현할 것이다.

@float
@anchor{Figure 3.22}
@ifinfo
@quotation
@strong{Figure 3.22:} 헤드 리스트로 표현된 테이블.

@example
table
  |
  V
+---+---+   +---+---+   +---+---+   +---+---+
| * | *-+-->| * | *-+-->| * | *-+-->| * | / |
+-|-+---+   +-|-+---+   +-|-+---+   +-|-+---+
  V           V           V           V
+-------+   +---+---+   +---+---+   +---+---+
|*table*|   | * | *-+   | * | *-+   | * | *-+
+-------+   +-|-+-|-+   +-|-+-|-+   +-|-+-|-+
              V   V       V   V       V   V
             "a"  1      "b"  2      "c"  3
@end example
@end quotation
@end ifinfo
@iftex
@strong{Figure 3.22:} 헤드 리스트로 표현된 테이블.
@end iftex
@end float

@noindent
새 테이블을 구성하기 위해, 우리는 단순히 기호 @code{*table*}을 포함하는 리스트를 생성한다:

@example
fn make_table<K, V>() -> HashMap<K, V> @{
    HashMap::new()
@}
@end example

@subsubheading 2차원 테이블 (Two-dimensional tables)

2차원 테이블에서, 각 값은 두 개의 키로 인덱싱된다.
우리는 각 키가 서브테이블을 식별하는 1차원 테이블로서 그러한 테이블을 구성할 수 있다.
@ref{Figure 3.23}은 다음 테이블에 대한 박스 앤 포인터 다이어그램을 보여준다

@example
math:  +: 43    letters:  a: 97
       -: 45              b: 98
       *: 42
@end example

@noindent
이것은 두 개의 서브테이블을 갖는다. (서브테이블을 식별하는 키가 헤더 목적을 수행하므로 서브테이블에는 특별한 헤더 기호가 필요하지 않다.)

@float
@anchor{Figure 3.23}
@ifinfo
@strong{Figure 3.23:} 2차원 테이블.

@example
table
  |
  V
+---+---+   +---+---+   +---+---+
| * | *-+-->| * | *-+-->| * | / |
+-|-+---+   +-|-+---+   +-|-+---+
  V           |           V
+-------+     |         +---+---+   +---+---+   +---+---+
|*table*|     |         | * | *-+-->| * | *-+-->| * | / |
+-------+     |         +-|-+---+   +-|-+---+   +-|-+---+
              |           V           V           V
              |       +-------+     +---+---+   +---+---+
              |       |letters|     | * | * |   | * | * |
              |       +-------+     +-|-+-|-+   +-|-+-|-+
              |                       V   V       V   V
              |                    +---+ +---+ +---+ +---+
              |                    | a | | 97| | b | | 98|
              |                    +---+ +---+ +---+ +---+
              V
            +---+---+   +---+---+   +---+---+   +---+---+
            | * | *-+-->| * | *-+-->| * | *-+-->| * | / |
            +-|-+---+   +-|-+---+   +-|-+---+   +-|-+---+
              V           V           V           V
          +------+      +---+---+   +---+---+   +---+---+
          | math |      | * | * |   | * | * |   | * | * |
          +------+      +-|-+-|-+   +-|-+-|-+   +-|-+-|-+
                          V   V       V   V       V   V
                       +---+ +---+ +---+ +---+ +---+ +---+
                       | + | | 43| | - | | 45| | * | | 42|
                       +---+ +---+ +---+ +---+ +---+ +---+
@end example
@end ifinfo
@iftex
@image{fig/chap3/Fig3.23b,143mm,,,.std.svg}
@caption{@strong{Figure 3.23:} 2차원 테이블.}
@end iftex
@end float

@noindent
우리가 항목을 조회할 때, 첫 번째 키를 사용하여 올바른 서브테이블을 식별한다.
그런 다음 두 번째 키를 사용하여 서브테이블 내의 레코드를 식별한다.

@example
// 2차원 테이블: HashMap<K1, HashMap<K2, V>>
fn lookup_2d<K1, K2, V>(
    key1: &K1, key2: &K2,
    table: &HashMap<K1, HashMap<K2, V>>
) -> Option<&V>
where
    K1: Eq + std::hash::Hash,
    K2: Eq + std::hash::Hash,
@{
    table.get(key1).and_then(|subtable| subtable.get(key2))
@}
@end example

@noindent
키 쌍 아래에 새 항목을 삽입하기 위해, 우리는 @code{assoc}을 사용하여 첫 번째 키 아래에 저장된 서브테이블이 있는지 확인한다.
없다면, 우리는 단일 레코드(@code{key-2}, @code{value})를 포함하는 새 서브테이블을 구축하고 그것을 첫 번째 키 아래의 테이블에 삽입한다.
만약 첫 번째 키에 대한 서브테이블이 이미 존재한다면, 우리는 위에서 설명한 1차원 테이블에 대한 삽입 방법을 사용하여 새 레코드를 이 서브테이블에 삽입한다:

@example
fn insert_2d<K1, K2, V>(
    key1: K1, key2: K2, value: V,
    table: &mut HashMap<K1, HashMap<K2, V>>
)
where
    K1: Eq + std::hash::Hash,
    K2: Eq + std::hash::Hash,
@{
    table.entry(key1).or_insert_with(HashMap::new).insert(key2, value);
@}
@end example

@subsubheading 지역 테이블 생성 (Creating local tables)

위에서 정의한 @code{lookup}과 @code{insert} 연산은 테이블을 인자로 받는다.
이것은 우리가 하나 이상의 테이블에 접근하는 프로그램을 사용할 수 있게 해준다.
여러 테이블을 다루는 또 다른 방법은 각 테이블에 대해 별도의 @code{lookup}과 @code{insert} 프로시저를 갖는 것이다.
우리는 테이블을 절차적으로 표현함으로써, 즉 내부 테이블을 지역 상태의 일부로 유지하는 객체로서 표현함으로써 이를 수행할 수 있다.
적절한 메시지가 전송되면, 이 ``테이블 객체''는 내부 테이블에 대해 작동할 프로시저를 제공한다.
다음은 이런 방식으로 표현된 2차원 테이블 생성기이다:

@example
struct Table<K1, K2, V>
where
    K1: Eq + std::hash::Hash,
    K2: Eq + std::hash::Hash,
@{
    data: HashMap<K1, HashMap<K2, V>>,
@}

impl<K1, K2, V> Table<K1, K2, V>
where
    K1: Eq + std::hash::Hash,
    K2: Eq + std::hash::Hash,
@{
    fn new() -> Self @{
        Table @{ data: HashMap::new() @}
    @}

    fn lookup(&self, key1: &K1, key2: &K2) -> Option<&V> @{
        self.data.get(key1).and_then(|sub| sub.get(key2))
    @}

    fn insert(&mut self, key1: K1, key2: K2, value: V) @{
        self.data.entry(key1)
            .or_insert_with(HashMap::new)
            .insert(key2, value);
    @}
@}
@end example

@noindent
@code{Table::new}를 사용하여, 우리는 @ref{2.4.3}에서 데이터 주도 프로그래밍을 위해 사용된 @code{get}과 @code{put} 연산을 다음과 같이 구현할 수 있다:

@example
let mut operation_table: Table<&str, &str, fn(...)> = Table::new();
// 사용법:
operation_table.insert("math", "add", add_fn);
let op = operation_table.lookup(&"math", &"add");
@end example

@noindent
@code{Get}은 두 개의 키를 인자로 받고, @code{put}은 두 개의 키와 값을 인자로 받는다.
두 연산 모두 @code{Table::new} 호출에 의해 생성된 객체 내에 캡슐화된 동일한 지역 테이블에 접근한다.

@quotation
@strong{@anchor{Exercise 3.24}연습문제 3.24:} 위의 테이블 구현에서 키는 @code{equal?}(@code{assoc}에 의해 호출됨)을 사용하여 동등성을 테스트한다.
이것이 항상 적절한 테스트는 아니다.
예를 들어, 숫자 키를 가진 테이블에서 우리는 조회하는 숫자와 정확히 일치할 필요 없이 어떤 허용 오차 내에 있는 숫자만 있으면 될 수 있다.
키의 ``동등성''을 테스트하는 데 사용될 @code{same-key?} 프로시저를 인자로 받는 테이블 생성자 @code{Table::new}를 설계하라.
@code{Make-table}은 지역 테이블에 대한 적절한 @code{lookup}과 @code{insert} 프로시저에 접근하는 데 사용될 수 있는 @code{dispatch} 프로시저를 반환해야 한다.
@end quotation

@quotation
@strong{@anchor{Exercise 3.25}연습문제 3.25:} 1차원 및 2차원 테이블을 일반화하여, 값이 임의의 수의 키 아래에 저장되고 다른 값들이 다른 수의 키 아래에 저장될 수 있는 테이블을 구현하는 방법을 보여라.
@code{lookup}과 @code{insert} 프로시저는 테이블에 접근하는 데 사용되는 키들의 리스트를 입력으로 받아야 한다.
@end quotation

@quotation
@strong{@anchor{Exercise 3.26}연습문제 3.26:} 위에서 구현된 대로 테이블을 검색하려면 레코드 리스트를 스캔해야 한다.
이것은 기본적으로 @ref{2.3.3}의 비정렬 리스트 표현이다.
큰 테이블의 경우, 테이블을 다른 방식으로 구조화하는 것이 더 효율적일 수 있다.
키가 어떤 방식으로(예: 수치적으로 또는 알파벳순으로) 정렬될 수 있다고 가정할 때, (키, 값) 레코드가 이진 트리를 사용하여 조직된 테이블 구현을 설명하라. (@ref{Chapter 2}의 @ref{Exercise 2.66}과 비교하라.)
@end quotation

@quotation
@strong{@anchor{Exercise 3.27}연습문제 3.27:} @newterm{메모이제이션(Memoization)} (@newterm{도표화(tabulation)}라고도 함)은 프로시저가 이전에 계산된 값을 지역 테이블에 기록할 수 있게 해주는 기술이다.
이 기술은 프로그램의 성능에 큰 차이를 만들 수 있다.
메모이즈된 프로시저는 이전 호출의 값을 값을 생성한 인자를 키로 사용하여 테이블에 저장한다.
메모이즈된 프로시저가 값을 계산하라는 요청을 받으면, 먼저 테이블을 확인하여 값이 이미 있는지 보고, 그렇다면 그 값을 반환한다.
그렇지 않으면, 일반적인 방법으로 새 값을 계산하고 이것을 테이블에 저장한다.
메모이제이션의 예로서, 피보나치 수를 계산하기 위한 @ref{1.2.2}의 지수적 프로세스를 상기해 보자:

@example
fn fib(n: u64) -> u64 @{
    match n @{
        0 => 0,
        1 => 1,
        _ => fib(n - 1) + fib(n - 2),
    @}
@}
@end example

동일한 프로시저의 메모이즈된 버전은 다음과 같다

@example
use std::collections::HashMap;
use std::cell::RefCell;

// 내부 가변성을 사용한 메모이즈된 피보나치
thread_local! @{
    static MEMO: RefCell<HashMap<u64, u64>> = RefCell::new(HashMap::new());
@}

fn memo_fib(n: u64) -> u64 @{
    MEMO.with(|memo| @{
        if let Some(&result) = memo.borrow().get(&n) @{
            return result;
        @}
        let result = match n @{
            0 => 0,
            1 => 1,
            _ => memo_fib(n - 1) + memo_fib(n - 2),
        @};
        memo.borrow_mut().insert(n, result);
        result
    @})
@}
@end example

@noindent
여기서 메모이저는 다음과 같이 정의된다

@example
use std::collections::HashMap;
use std::hash::Hash;

/// 제네릭 메모이제이션 래퍼
struct Memoized<A, R, F>
where
    A: Eq + Hash + Clone,
    R: Clone,
    F: FnMut(A) -> R,
@{
    cache: HashMap<A, R>,
    func: F,
@}

impl<A, R, F> Memoized<A, R, F>
where
    A: Eq + Hash + Clone,
    R: Clone,
    F: FnMut(A) -> R,
@{
    fn new(func: F) -> Self @{
        Memoized @{ cache: HashMap::new(), func @}
    @}

    fn call(&mut self, arg: A) -> R @{
        if let Some(result) = self.cache.get(&arg) @{
            return result.clone();
        @}
        let result = (self.func)(arg.clone());
        self.cache.insert(arg, result.clone());
        result
    @}
@}
@end example

@code{(memo-fib 3)}의 계산을 분석하기 위해 환경 다이어그램을 그려라.
왜 @code{memo-fib}이 @math{n}에 비례하는 단계 수로 @math{n^{\text{th}}} 피보나치 수를 계산하는지 설명하라.
만약 우리가 단순히 @code{memo-fib}을 @code{(memoize fib)}로 정의했다면 이 계획이 여전히 작동할까?
@end quotation

@node	3.3.4, 3.3.4a, 3.3.3, 3.3
@subsection 디지털 회로 시뮬레이터 (A Simulator for Digital Circuits)

컴퓨터와 같은 복잡한 디지털 시스템을 설계하는 것은 중요한 공학 활동이다.
디지털 시스템은 단순한 요소들을 서로 연결하여 구성된다.
이러한 개별 요소들의 동작은 단순하지만, 그것들의 네트워크는 매우 복잡한 동작을 가질 수 있다.
제안된 회로 설계의 컴퓨터 시뮬레이션은 디지털 시스템 엔지니어가 사용하는 중요한 도구이다.
이 절에서 우리는 디지털 논리 시뮬레이션을 수행하기 위한 시스템을 설계한다.
이 시스템은 @newterm{이벤트 주도 시뮬레이션(event-driven simulation)}이라 불리는 프로그램 종류의 전형을 보여주는데, 여기서는 행동(``이벤트'')이 나중에 일어날 추가적인 이벤트를 트리거하고, 그것이 다시 더 많은 이벤트를 트리거하는 식으로 진행된다.

회로의 계산 모델은 회로가 구성되는 기본 요소들에 대응하는 객체들로 구성될 것이다.
@newterm{와이어(wires)}가 있으며, 이것들은 @newterm{디지털 신호(digital signals)}를 나른다.
디지털 신호는 어느 순간에든 0과 1이라는 두 가지 가능한 값 중 하나만 가질 수 있다.
또한 다양한 유형의 디지털 @newterm{함수 상자(function boxes)}가 있는데, 이것들은 입력 신호를 나르는 와이어를 다른 출력 와이어에 연결한다.
그러한 상자들은 입력 신호로부터 계산된 출력 신호를 생성한다.
출력 신호는 함수 상자의 유형에 따라 달라지는 시간만큼 지연된다.
예를 들어, @newterm{인버터(inverter)}는 입력을 반전시키는 원시 함수 상자이다.
인버터로의 입력 신호가 0으로 바뀌면, 1 @code{inverter-delay} 후에 인버터는 출력 신호를 1로 바꿀 것이다.
인버터로의 입력 신호가 1로 바뀌면, 1 @code{inverter-delay} 후에 인버터는 출력 신호를 0으로 바꿀 것이다.
우리는 @ref{Figure 3.24}와 같이 인버터를 기호로 그린다.
또한 그림 3.24에 표시된 @newterm{AND 게이트(and-gate)}는 두 개의 입력과 하나의 출력을 가진 원시 함수 상자이다.
이것은 출력 신호를 입력들의 @newterm{논리적 AND(logical and)} 값으로 구동한다.
즉, 두 입력 신호가 모두 1이 되면, 1 @code{and-gate-delay} 시간 후에 AND 게이트는 출력 신호를 1로 강제할 것이다; 그렇지 않으면 출력은 0이 될 것이다.
@newterm{OR 게이트(or-gate)}는 비슷한 두 입력 원시 함수 상자로, 출력 신호를 입력들의 @newterm{논리적 OR(logical or)} 값으로 구동한다.
즉, 입력 신호 중 적어도 하나가 1이면 출력이 1이 될 것이고; 그렇지 않으면 출력은 0이 될 것이다.

@float
@anchor{Figure 3.24}
@ifinfo
@quotation
@strong{Figure 3.24:} 디지털 논리 시뮬레이터의 원시 함수들.

@example
               __          ___
  |\        --|  \       --\  \
--| >o--      |   )--       )  >--
  |/        --|__/       --/__/

Inverter    And-gate     Or-gate
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap3/Fig3.24a,110mm,,,.std.svg}
@caption{@strong{Figure 3.24:} 디지털 논리 시뮬레이터의 원시 함수들.}
@end iftex
@end float

@noindent
우리는 원시 함수들을 서로 연결하여 더 복잡한 함수들을 구성할 수 있다.
이것을 달성하기 위해 우리는 어떤 함수 상자의 출력을 다른 함수 상자의 입력에 배선(wire)한다.
예를 들어, @ref{Figure 3.25}에 표시된 @newterm{반가산기(half-adder)} 회로는 하나의 OR 게이트, 두 개의 AND 게이트, 그리고 하나의 인버터로 구성된다.
이것은 두 개의 입력 신호 A와 B를 받고, 두 개의 출력 신호 S와 C를 가진다.
S는 A와 B 중 정확히 하나가 1일 때 1이 되고, C는 A와 B가 모두 1일 때 1이 된다.
우리는 그림에서 관련된 지연 때문에 출력이 서로 다른 시간에 생성될 수 있음을 볼 수 있다.
디지털 회로 설계의 많은 어려움은 이 사실에서 발생한다.

@float
@anchor{Figure 3.25}
@ifinfo
@quotation
@strong{Figure 3.25:} 반가산기 회로.

@example
    +--------------------------------------+
    |         ____                         |
A --------*---\   \ D               ___    |
    |     |    >   >---------------|   \   |
    |  +--|---/___/                |    )----- S
    |  |  |              |\  E  +--|___/   |
    |  |  |           +--| >o---+          |
    |  |  |    ___    |  |/                |
    |  |  +---|   \   |                    |
    |  |      |    )--*----------------------- C
B -----*------|___/                        |
    |                                      |
    +--------------------------------------+
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap3/Fig3.25c,122mm,,,.std.svg}
@caption{@strong{Figure 3.25:} 반가산기 회로.}
@end iftex
@end float

@noindent
우리는 이제 우리가 연구하고자 하는 디지털 논리 회로를 모델링하기 위한 프로그램을 구축할 것이다.
이 프로그램은 신호를 ``보유''할, 와이어를 모델링하는 계산 객체를 구성할 것이다.
함수 상자들은 신호들 사이의 올바른 관계를 강제하는 프로시저들에 의해 모델링될 것이다.

우리 시뮬레이션의 기본 요소 중 하나는 와이어를 구성하는 프로시저 @code{Simulator::make_wire}일 것이다.
예를 들어, 우리는 다음과 같이 6개의 와이어를 구성할 수 있다:

@example
let mut sim = Simulator::new();
let a = sim.make_wire();
let b = sim.make_wire();
let c = sim.make_wire();
let d = sim.make_wire();
let e = sim.make_wire();
let s = sim.make_wire();
@end example

@noindent
우리는 그 종류의 상자를 구성하는 프로시저를 호출함으로써 와이어 집합에 함수 상자를 부착한다.
생성자 프로시저에 대한 인자는 상자에 부착될 와이어들이다.
예를 들어, 우리가 AND 게이트, OR 게이트, 그리고 인버터를 구성할 수 있다고 가정하면, @ref{Figure 3.25}에 표시된 반가산기를 다음과 같이 배선할 수 있다:

@example
sim.or_gate(a, b, d);
sim.and_gate(a, b, c);
sim.inverter(c, e);
sim.and_gate(d, e, s);
@end example

@noindent
더 나아가, 우리는 이 회로를 구성하는 프로시저 @code{half_adder}를 정의함으로써 이 연산에 명시적으로 이름을 붙일 수 있다. 이 프로시저는 반가산기에 부착될 4개의 외부 와이어를 받는다:

@example
// 하프 애더 회로 (Half adder circuit).
pub fn half_adder(&mut self, a: WireId, b: WireId, sum: WireId, carry: WireId) @{
    let d = self.make_wire();
    let e = self.make_wire();

    self.or_gate(a, b, d);
    self.and_gate(a, b, carry);
    self.inverter(carry, e);
    self.and_gate(d, e, sum);
@}
@end example

@noindent
이 정의를 만드는 것의 장점은 더 복잡한 회로를 생성할 때 @code{half_adder} 자체를 구성 요소로 사용할 수 있다는 것이다.
예를 들어, @ref{Figure 3.26}은 두 개의 반가산기와 하나의 OR 게이트로 구성된 @newterm{전가산기(full-adder)}를 보여준다.@footnote{전가산기는 두 이진수를 더하는 데 사용되는 기본 회로 요소이다. 여기서 A와 B는 더해질 두 숫자의 대응하는 위치에 있는 비트들이고, @math{\rm C_{in}}은 오른쪽 한 자리에서 올라온 캐리 비트이다. 회로는 대응하는 위치의 합 비트인 SUM과 왼쪽으로 전파될 캐리 비트인 @math{\rm C_{out}}을 생성한다.}
우리는 다음과 같이 전가산기를 구성할 수 있다:

@example
// 풀 애더 회로 (Full adder circuit).
pub fn full_adder(
    &mut self,
    a: WireId,
    b: WireId,
    c_in: WireId,
    sum: WireId,
    c_out: WireId,
) @{
    let s = self.make_wire();
    let c1 = self.make_wire();
    let c2 = self.make_wire();

    self.half_adder(b, c_in, s, c1);
    self.half_adder(a, s, sum, c2);
    self.or_gate(c1, c2, c_out);
@}
@end example

@float
@anchor{Figure 3.26}
@ifinfo
@quotation
@strong{Figure 3.26:} 전가산기 회로.

@example
    +----------------------------------+
    |              +-------+           |
A -----------------+ half- +-------------- SUM
    |  +-------+   | adder |   ____    |
B -----+ half- +---+       +---\   \   |
    |  | adder |   +-------+    >or >----- Cout
C -----+       +---------------/___/   |
    |  +-------+                       |
    +----------------------------------+
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap3/Fig3.26,129mm,,,.std.svg}
@caption{@strong{Figure 3.26:} 전가산기 회로.}
@end iftex
@end float

@noindent
@code{full_adder}를 프로시저로 정의했으므로, 이제 우리는 그것을 더 복잡한 회로를 생성하기 위한 구성 요소로 사용할 수 있다. (예를 들어, @ref{Exercise 3.30}을 보라.)

본질적으로, 우리 시뮬레이터는 회로 언어를 구성하기 위한 도구를 제공한다.
우리가 @ref{1.1}에서 Lisp 연구에 접근했던 언어에 대한 일반적인 관점을 채택한다면, 우리는 원시 함수 상자들이 언어의 원시 요소들을 형성하고, 상자들을 함께 배선하는 것이 조합 수단을 제공하며, 배선 패턴을 프로시저로 지정하는 것이 추상화 수단으로 작용한다고 말할 수 있다.

@subsubheading 원시 함수 상자 (Primitive function boxes)

원시 함수 상자들은 한 와이어의 신호 변화가 다른 와이어의 신호에 영향을 미치는 ``힘''을 구현한다.
함수 상자를 구축하기 위해, 우리는 와이어에 대해 다음 연산들을 사용한다:

@itemize @bullet

@item @code{get_signal(wire)}

@noindent
와이어에 있는 신호의 현재 값을 반환한다.

@item @code{set_signal(wire, new_value)}

@noindent
와이어의 신호 값을 새 값으로 변경한다.

@item @code{add_action!(wire, procedure)}

@noindent
와이어의 신호가 값을 변경할 때마다 지정된 프로시저가 실행되어야 함을 주장한다.
그러한 프로시저들은 와이어의 신호 값 변경이 다른 와이어로 전달되는 수단이다.

@end itemize

@noindent
또한, 우리는 시간 지연과 실행될 프로시저를 받아 주어진 지연 후에 해당 프로시저를 실행하는 프로시저 @code{after_delay}를 사용할 것이다.

이러한 프로시저들을 사용하여, 우리는 원시 디지털 논리 함수들을 정의할 수 있다.
인버터를 통해 입력을 출력에 연결하기 위해, 우리는 @code{add_action!}을 사용하여 입력 와이어의 신호가 값을 변경할 때마다 실행될 프로시저를 입력 와이어와 연관시킨다.
이 프로시저는 입력 신호의 @code{logical_not}을 계산하고, 그 다음 1 @code{inverter_delay} 후에 출력 신호가 이 새 값이 되도록 설정한다:

@example
/// 인버터 게이트 (Inverter gate).
pub fn inverter(&mut self, input: WireId, output: WireId) @{
    let action_id = self.register_action(Box::new(move |sim: &mut Simulator| @{
        let new_value = Self::logical_not(sim.get_signal(input));
        sim.after_delay(
            INVERTER_DELAY,
            Box::new(move |sim2: &mut Simulator| @{
                sim2.set_signal(output, new_value);
            @}),
        );
    @}));
    self.add_action_to_wire(input, action_id);
    // 초기 액션 트리거 (Trigger initial action)
    self.run_action(action_id);
@}

pub fn logical_not(s: Signal) -> Signal @{
    if s == 0 @{ 1 @} else @{ 0 @}
@}
@end example

@noindent
AND 게이트는 조금 더 복잡하다. 액션 프로시저는 게이트의 입력 중 어느 하나라도 변경되면 실행되어야 한다.
이것은 입력 와이어들의 신호 값들의 @code{logical_and}(@code{logical_not}과 유사한 프로시저를 사용)를 계산하고 1 @code{and_gate_delay} 후에 출력 와이어에 새 값으로의 변경이 일어나도록 설정한다.

@example
/// AND 게이트 (AND gate).
pub fn and_gate(&mut self, a1: WireId, a2: WireId, output: WireId) @{
    let action_fn = move |sim: &mut Simulator| @{
        let new_value = Self::logical_and(sim.get_signal(a1), sim.get_signal(a2));
        sim.after_delay(
            AND_GATE_DELAY,
            Box::new(move |sim2: &mut Simulator| @{
                sim2.set_signal(output, new_value);
            @}),
        );
    @};

    let action_id1 = self.register_action(Box::new(action_fn));
    let action_id2 = self.register_action(Box::new(move |sim: &mut Simulator| @{
        let new_value = Self::logical_and(sim.get_signal(a1), sim.get_signal(a2));
        sim.after_delay(
            AND_GATE_DELAY,
            Box::new(move |sim2: &mut Simulator| @{
                sim2.set_signal(output, new_value);
            @}),
        );
    @}));

    self.add_action_to_wire(a1, action_id1);
    self.add_action_to_wire(a2, action_id2);
@}
@end example

@quotation
@strong{@anchor{Exercise 3.28}연습문제 3.28:} OR 게이트를 원시 함수 상자로 정의하라.
당신의 @code{or_gate} 생성자는 @code{and_gate}와 유사해야 한다.
@end quotation


@quotation
@strong{@anchor{Exercise 3.29}Exercise 3.29:} Another way to construct an
or-gate is as a compound digital logic device, built from and-gates and
inverters.  Define a procedure @code{or-gate} that accomplishes this.  What is
the delay time of the or-gate in terms of @code{and-gate-delay} and
@code{inverter-delay}?
@end quotation

@quotation
@strong{@anchor{Exercise 3.30}Exercise 3.30:} @ref{Figure 3.27} shows a
@newterm{ripple-carry adder} formed by stringing together @math{n} full-adders.
This is the simplest form of parallel adder for adding two @math{n}-bit binary
numbers.  The inputs @math{A_1}, @math{A_2}, @math{A_3}, @dots{}, @math{A_n} and 
@math{B_1}, @math{B_2}, @math{B_3},
@dots{}, @math{B_n} are the two binary numbers to be added (each @math{A_k} and
@math{B_k} is a 0 or a 1).  The circuit generates @math{S_1}, @math{S_2}, 
@math{S_3}, @dots{}, @math{S_n},
the @math{n} bits of the sum, and @math{C}, the carry from the addition.  Write a
procedure @code{ripple-carry-adder} that generates this circuit.  The procedure
should take as arguments three lists of @math{n} wires each---the @math{A_k}, the
@math{B_k}, and the @math{S_k}---and also another wire @math{C}.  The major drawback of the
ripple-carry adder is the need to wait for the carry signals to propagate.
What is the delay needed to obtain the complete output from an @math{n}-bit
ripple-carry adder, expressed in terms of the delays for and-gates, or-gates,
and inverters?
@end quotation

@float
@anchor{Figure 3.27}
@ifinfo
@quotation
@strong{Figure 3.27:} A ripple-carry adder for @math{n}-bit numbers.

@example
   :                                              :   :
   : A_1 B_1   C_1   A_2 B_2   C_2   A_3 B_3   C_3:   : A_n B_n C_n=0
   :  |   |   +---+   |   |   +---+   |   |   +-----  :  |   |   +-
   |  |   |   |   |   |   |   |   |   |   |   |   :   :  |   |   | 
   : ++---+---++  |  ++---+---++  |  ++---+---++  :   : ++---+---++
   : |   FA    |  |  |   FA    |  |  |   FA    |  :   : |   FA    |
   : +--+---+--+  |  +--+---+--+  |  +--+---+--+  :   : +--+---+--+
   :    |   |     |     |   |     |     |   |     :   :    |   |   
C ------+   |     +-----+   |     +-----+   |     :  ------+   |   
   :        |       C_1     |       C_2     |     :   :C_(n-1) |   
   :        |               |               |     :   :        |   
           S_1             S_2             S_3                S_n
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap3/Fig3.27b,132mm,,,.std.svg}
@caption{@strong{Figure 3.27:} A ripple-carry adder for @math{n}-bit numbers.}
@end iftex
@end float

@subsubheading Representing wires

A wire in our simulation will be a computational object with two local state
variables: a @code{signal-value} (initially taken to be 0) and a collection of
@code{action-procedures} to be run when the signal changes value.  We implement
the wire, using message-passing style, as a collection of local procedures
together with a @code{dispatch} procedure that selects the appropriate local
operation, just as we did with the simple bank-account object in 
@ref{3.1.1}:

@example
use std::cell::Cell;

#[derive(Clone, Copy, PartialEq, Eq)]
enum Signal @{ Low, High @}

struct Wire @{
    signal: Cell<Signal>,
    actions: Vec<Box<dyn Fn(&mut Circuit)>>,
@}

impl Wire @{
    fn new() -> Self @{
        Wire @{
            signal: Cell::new(Signal::Low),
            actions: Vec::new(),
        @}
    @}

    fn get_signal(&self) -> Signal @{
        self.signal.get()
    @}

    fn set_signal(&self, new_value: Signal, circuit: &mut Circuit) @{
        if self.signal.get() != new_value @{
            self.signal.set(new_value);
            for action in &self.actions @{
                action(circuit);
            @}
        @}
    @}

    fn add_action(&mut self, action: Box<dyn Fn(&mut Circuit)>) @{
        self.actions.push(action);
    @}
@}
@end example

@noindent
The local procedure @code{set-my-signal!} tests whether the new signal value
changes the signal on the wire.  If so, it runs each of the action procedures,
using the following procedure @code{call-each}, which calls each of the items
in a list of no-argument procedures:

@example
fn call_each<F>(procedures: &[F])
where
    F: Fn(),
@{
    for proc in procedures @{
        proc();
    @}
@}
@end example

@noindent
The local procedure @code{accept-action-procedure!} adds the given procedure to
the list of procedures to be run, and then runs the new procedure once.  (See
@ref{Exercise 3.31}.)

With the local @code{dispatch} procedure set up as specified, we can provide
the following procedures to access the local operations on
wires:@footnote{@anchor{Footnote 155} These procedures are simply
syntactic sugar that allow us to use ordinary procedural syntax to access the
local procedures of objects.  It is striking that we can interchange the role
of ``procedures'' and ``data'' in such a simple way.  For example, if we write
@code{(wire 'get-signal)} we think of @code{wire} as a procedure that is called
with the message @code{get_signal} as input.  Alternatively, writing
@code{(get-signal wire)} encourages us to think of @code{wire} as a data object
that is the input to a procedure @code{get_signal}.  The truth of the matter is
that, in a language in which we can deal with procedures as objects, there is
no fundamental difference between ``procedures'' and ``data,'' and we can
choose our syntactic sugar to allow us to program in whatever style we choose.}

@example
// In Rust, these are simply method calls on Wire:
// wire.get_signal()
// wire.set_signal(new_value, circuit)
// wire.add_action(action)
//
// The dispatch-based message passing is replaced by
// direct method calls on the Wire struct.
@end example

@noindent
Wires, which have time-varying signals and may be incrementally attached to
devices, are typical of mutable objects.  We have modeled them as procedures
with local state variables that are modified by assignment.  When a new wire is
created, a new set of state variables is allocated (by the @code{let}
expression in @code{Wire::new}) and a new @code{dispatch} procedure is
constructed and returned, capturing the environment with the new state
variables.

The wires are shared among the various devices that have been connected to
them.  Thus, a change made by an interaction with one device will affect all
the other devices attached to the wire.  The wire communicates the change to
its neighbors by calling the action procedures provided to it when the
connections were established.

@subsubheading The agenda

The only thing needed to complete the simulator is @code{after-delay}.  The
idea here is that we maintain a data structure, called an @newterm{agenda},
that contains a schedule of things to do.  The following operations are defined
for agendas:

@itemize @bullet

@item
@code{Agenda::new} returns a new empty agenda.

@item
@code{(empty-agenda? ⟨@var{agenda}⟩)} is true if the specified agenda is
empty.

@item
@code{(first-agenda-item ⟨@var{agenda}⟩)} returns the first item on the
agenda.

@item
@code{(remove-first-agenda-item! ⟨@var{agenda}⟩)} modifies the agenda by
removing the first item.

@item
@code{(add-to-agenda! ⟨@var{time}⟩ ⟨@var{action}⟩ ⟨@var{agenda}⟩)} 
modifies the agenda by adding the given action procedure to be run at the 
specified time.

@item
@code{(current-time ⟨@var{agenda}⟩)} returns the current simulation time.

@end itemize

@noindent
The particular agenda that we use is denoted by @code{the-agenda}.  The
procedure @code{after-delay} adds new elements to @code{the-agenda}:

@example
impl Circuit @{
    fn after_delay<F>(&mut self, delay: u64, action: F)
    where
        F: FnOnce(&mut Circuit) + 'static,
    @{
        let time = self.current_time() + delay;
        self.agenda.add(time, Box::new(action));
    @}
@}
@end example

@noindent
The simulation is driven by the procedure @code{propagate}, which operates on
@code{the-agenda}, executing each procedure on the agenda in sequence.  In
general, as the simulation runs, new items will be added to the agenda, and
@code{propagate} will continue the simulation as long as there are items on the
agenda:

@example
impl Circuit @{
    fn propagate(&mut self) @{
        while let Some((time, action)) = self.agenda.pop_first() @{
            self.time = time;
            action(self);
        @}
    @}
@}
@end example

@subsubheading 시뮬레이션 예제 (A sample simulation)

와이어에 ``프로브(probe)''를 배치하는 다음 프로시저는 시뮬레이터의 작동을 보여준다.
프로브는 와이어에게 신호가 값을 변경할 때마다 새 신호 값을 현재 시간 및 와이어를 식별하는 이름과 함께 출력해야 한다고 말한다:

@example
/// 프로브를 생성한다 (Creates a probe).
pub fn probe(&mut self, name: &str, connector: ConnectorId) -> ConstraintId @{
    let id = ConstraintId(self.constraints.len());
    self.constraints.push(ConstraintKind::Probe @{
        name: name.to_string(),
        connector,
    @});

    self.connectors[connector.0].constraints.push(id);
    id
@}
@end example

@noindent
우리는 아젠다를 초기화하고 원시 함수 상자의 지연 시간을 지정하는 것으로 시작한다:

@example
let mut sim = Simulator::new();
// 게이트 지연 (Gate delays).
pub const INVERTER_DELAY: Time = 2;
pub const AND_GATE_DELAY: Time = 3;
pub const OR_GATE_DELAY: Time = 5;
@end example

@noindent
이제 우리는 4개의 와이어를 정의하고 그중 두 개에 프로브를 배치한다:

@example
let input_1 = sim.make_wire();
let input_2 = sim.make_wire();
let sum = sim.make_wire();
let carry = sim.make_wire();

// Rust 구현에서는 프로브를 직접 추가하는 기능이 예제 코드에 없지만, 
// 개념적으로는 다음과 같이 동작한다:
// probe("sum", sum, &mut sim);
// => sum 0  New-value = 0
// probe("carry", carry, &mut sim);
// => carry 0  New-value = 0
@end example

@noindent
다음으로 우리는 반가산기 회로(@ref{Figure 3.25}와 같이)에 와이어들을 연결하고, @code{input_1}의 신호를 1로 설정한 다음 시뮬레이션을 실행한다:

@example
sim.half_adder(input_1, input_2, sum, carry);

sim.set_signal(input_1, 1);

sim.propagate();
// => sum 8  New-value = 1
@end example

@noindent
@code{sum} 신호는 시간 8에 1로 바뀐다. 우리는 이제 시뮬레이션 시작부터 8 시간 단위에 있다.
이 시점에서 우리는 @code{input_2}의 신호를 1로 설정하고 값이 전파되도록 할 수 있다:

@example
sim.set_signal(input_2, 1);

sim.propagate();
// => carry 11  New-value = 1
// => sum 16  New-value = 0
@end example

@noindent
@code{carry}는 시간 11에 1로 바뀌고 @code{sum}은 시간 16에 0으로 바뀐다.

@quotation
@strong{@anchor{Exercise 3.31}연습문제 3.31:} @code{Wire::new}에 정의된 내부 프로시저 @code{accept-action-procedure!}는 와이어에 새 액션 프로시저가 추가될 때 해당 프로시저가 즉시 실행되도록 지정한다.
이 초기화가 왜 필요한지 설명하라.
특히, 위의 반가산기 예제를 추적해 보고, 만약 우리가 @code{accept-action-procedure!}를 다음과 같이 정의했다면 시스템의 응답이 어떻게 달라질지 말하라.

@example
fn accept_action_procedure(&mut self, proc: Action) @{
    self.action_procedures.push(proc);
    // 참고: 즉시 호출이 빠져있다!
@}
@end example
@end quotation

@subsubheading 아젠다 구현 (Implementing the agenda)

마지막으로, 향후 실행을 위해 예약된 프로시저들을 보관하는 아젠다 데이터 구조에 대한 세부 사항을 제공한다.

아젠다는 @newterm{시간 세그먼트(time segments)}로 구성된다.
각 시간 세그먼트는 숫자(시간)와 그 시간 세그먼트 동안 실행되도록 예약된 프로시저들을 담고 있는 큐(@ref{Exercise 3.32} 참조)로 구성된 쌍이다.

@example
// Rust 구현에서는 BTreeMap<Time, VecDeque<ActionId>>를 사용하여
// 시간 세그먼트와 큐를 관리한다.
@end example

@noindent
우리는 @ref{3.3.2}에서 설명한 큐 연산을 사용하여 시간 세그먼트 큐를 조작할 것이다.

아젠다 자체는 시간 세그먼트의 1차원 테이블이다.
이것은 세그먼트들이 시간 증가 순서로 정렬된다는 점에서 @ref{3.3.3}에 설명된 테이블과 다르다.
또한, 우리는 @newterm{현재 시간(current time)}(즉, 가장 최근에 처리된 액션의 시간)을 아젠다의 헤드에 저장한다.
새로 생성된 아젠다는 시간 세그먼트가 없고 현재 시간이 0이다:@footnote{아젠다는 @ref{3.3.3}의 테이블과 같은 헤드 리스트이지만, 리스트가 시간으로 헤드되므로 추가적인 더미 헤더(테이블에 사용되는 @code{*table*} 기호 같은)가 필요하지 않다.}

@example
pub struct Simulator @{
    wires: Vec<Wire>,
    actions: Vec<Option<ActionFn>>,
    agenda: BTreeMap<Time, VecDeque<ActionId>>,
    current_time: Time,
@}

impl Simulator @{
    pub fn new() -> Self @{
        Simulator @{
            wires: Vec::new(),
            actions: Vec::new(),
            agenda: BTreeMap::new(),
            current_time: 0,
        @}
    @}
@}
@end example

@noindent
아젠다에 액션을 추가하기 위해, 우리는 먼저 아젠다가 비어 있는지 확인한다.
그렇다면 우리는 액션을 위한 시간 세그먼트를 생성하고 이것을 아젠다에 설치한다.
그렇지 않으면 우리는 아젠다를 스캔하여 각 세그먼트의 시간을 검사한다.
만약 우리가 지정된 시간에 대한 세그먼트를 찾으면, 우리는 그 액션을 관련된 큐에 추가한다.
만약 우리가 지정된 시간보다 늦은 시간에 도달하면, 우리는 아젠다의 그 바로 앞에 새 시간 세그먼트를 삽입한다.
만약 우리가 아젠다의 끝에 도달하면, 우리는 끝에 새 시간 세그먼트를 생성해야 한다.

Rust 구현에서는 @code{BTreeMap}을 사용하여 이 정렬 및 삽입 로직을 자동으로 처리한다:

@example
// BTreeMap은 자동으로 키(시간)에 따라 정렬된 상태를 유지한다.
self.agenda.entry(time).or_default().push_back(action_id);
@end example

@noindent
아젠다에서 첫 번째 항목을 제거하는 프로시저는 첫 번째 시간 세그먼트의 큐 앞쪽에서 항목을 삭제한다.
만약 이 삭제로 인해 시간 세그먼트가 비게 되면, 우리는 세그먼트 목록에서 그것을 제거한다:@footnote{이 프로시저의 @code{if} 표현식에는 @code{⟨}@var{alternative}@code{⟩} 표현식이 없다는 것을 관찰하라. 그러한 ``한 팔 @code{if} 문(one-armed @code{if} statement)''은 두 표현식 중 하나를 선택하는 것이 아니라 무언가를 할지 말지 결정하는 데 사용된다. @code{if} 표현식은 술어가 거짓이고 @code{⟨}@var{alternative}@code{⟩}가 없으면 지정되지 않은 값을 반환한다.}

@example
if let Some(mut queue) = self.agenda.remove(&time) @{
    while let Some(action_id) = queue.pop_front() @{
        self.run_action(action_id);
    @}
@}
@end example

@noindent
첫 번째 아젠다 항목은 첫 번째 시간 세그먼트의 큐 헤드에서 찾을 수 있다.
우리가 항목을 추출할 때마다, 우리는 또한 현재 시간을 업데이트한다:@footnote{이런 식으로, 현재 시간은 항상 가장 최근에 처리된 액션의 시간이 될 것이다. 이 시간을 아젠다의 헤드에 저장하는 것은 관련된 시간 세그먼트가 삭제되더라도 그것이 여전히 사용 가능함을 보장한다.}

@quotation
@strong{@anchor{Exercise 3.32}연습문제 3.32:} 아젠다의 각 시간 세그먼트 동안 실행될 프로시저들은 큐에 보관된다.
따라서 각 세그먼트의 프로시저들은 아젠다에 추가된 순서대로 호출된다(선입 선출).
왜 이 순서를 사용해야 하는지 설명하라.
특히, 입력이 같은 세그먼트에서 0, 1에서 1, 0으로 변하는 AND 게이트의 동작을 추적하고, 만약 우리가 세그먼트의 프로시저들을 일반 리스트에 저장하여 맨 앞에서만 프로시저를 추가하고 제거(후입 선출)했다면 동작이 어떻게 달라질지 말하라.
@end quotation


@node 3.3.4a, 3.3.5, 3.3.4, 3.3
@subsection 그래프를 위한 아레나 할당 (Arena Allocation for Graphs)
@cindex arena allocation
@cindex graph structures
@cindex cyclic references
@cindex index-based references
@cindex borrow checker escape hatch

이전 절의 디지털 회로 시뮬레이터는 시스템 프로그래밍의 일반적인 과제인 순환 참조를 가진 그래프 모양의 데이터 구조를 구축하는 것을 소개한다.
회로는 본질적으로 와이어가 여러 게이트에 연결되고, 게이트가 여러 와이어에 연결되는 그래프를 형성한다.
가비지 컬렉션이 있는 언어에서는 공유 참조를 자유롭게 사용할 수 있다.
하지만 Rust에서는 빌림 검사기가 동일한 데이터에 대한 다중 가변 참조를 가질 수 없다고 강제한다---이는 정확히 순환 그래프가 요구하는 것이다.

@newterm{아레나 패턴(arena pattern)}은 우아한 해결책을 제공한다: 참조를 사용하는 대신, 모든 노드를 연속적인 @code{Vec}에 저장하고 인덱스로 참조한다.
이것은 Rust의 컴파일 타임 안전성 보장을 런타임 인덱스 경계 검사와 교환하지만, 그 대가로 우리는 구축하기 쉽고, 순회하기 효율적이며, 자명하게 스레드 안전한 그래프 구조를 얻는다.

@subsubheading 문제: 순환과 빌림 검사기 (The Problem: Cycles and the Borrow Checker)

간단한 그래프 구조---각 노드가 전임자와 후임자를 모두 가리키는 이중 연결 리스트---를 고려해 보자:

@example
@cindex doubly-linked list
// 순진한 시도: 컴파일되지 않음
struct Node @{
    value: i32,
    prev: Option<&mut Node>,  // 오류: 수명 매개변수 누락
    next: Option<&mut Node>,  // 오류: 수명 매개변수 누락
@}
@end example

@noindent
우리는 즉시 문제에 봉착한다. 참조에는 수명 매개변수가 필요하지만, 어떤 수명을 사용해야 할까? 노드들은 서로 순환적으로 참조하므로, 명확한 소유권 계층 구조가 없다.

내부 가변성과 함께 공유 소유권을 얻기 위해 @code{Rc<RefCell<Node>>}를 사용하는 것을 시도해 볼 수 있다:

@example
@cindex Rc<RefCell<T>> pattern
use std::rc::Rc;
use std::cell::RefCell;

struct Node @{
    value: i32,
    prev: Option<Rc<RefCell<Node>>>,
    next: Option<Rc<RefCell<Node>>>,
@}

fn create_cycle() @{
    let node1 = Rc::new(RefCell::new(Node @{
        value: 1,
        prev: None,
        next: None,
    @}));

    let node2 = Rc::new(RefCell::new(Node @{
        value: 2,
        prev: Some(Rc::clone(&node1)),
        next: None,
    @}));

    // 순환 생성
    node1.borrow_mut().next = Some(Rc::clone(&node2));
@}
@end example

@noindent
이것은 컴파일되지만, 상당한 단점이 있다:

@enumerate
@item
@strong{런타임 오버헤드:} 모든 접근은 런타임 빌림 검사를 수행하는 @code{RefCell}을 거친다. 이것은 오버헤드를 추가하고 런타임에 빌림 규칙을 위반하면 패닉을 일으킬 수 있다.

@item
@strong{참조 카운팅 오버헤드:} @code{Rc}는 참조 카운트를 유지하므로 메모리 오버헤드와 원자적 연산(스레드 안전 변형인 @code{Arc}의 경우)을 추가한다.

@item
@strong{순환으로 인한 메모리 누수:} 순환을 만들고 모든 @code{Rc} 핸들을 해제하면, 참조 카운트가 0에 도달하지 않는다. 수동으로 순환을 끊지 않으면 메모리가 누수된다.

@item
@strong{스레드 안전하지 않음:} @code{Rc}는 @code{Send}가 아니므로 동시성 코드에서 작동하지 않는다. @code{Arc<RefCell<T>>}조차도 안전하지 않은데, @code{RefCell}이 @code{Sync}가 아니기 때문이다.

@item
@strong{나쁜 캐시 지역성:} 각 노드는 힙에 별도로 할당되어 메모리 전반에 흩어지며 캐시 성능을 파괴한다.
@end enumerate

@noindent
회로 시뮬레이터---그리고 일반적인 그래프---를 위해 우리는 더 나은 접근 방식이 필요하다.

@subsubheading 아레나 패턴: 인덱스 참조를 이용한 연속 저장 (The Arena Pattern: Contiguous Storage with Index References)

아레나 패턴은 간단한 통찰로 이 문제들을 해결한다: 포인터나 참조 카운트 핸들을 사용하는 대신, 모든 노드를 @code{Vec}에 저장하고 인덱스로 참조한다:

@example
@cindex arena pattern
struct Node @{
    value: i32,
    prev: Option<usize>,  // 아레나에 대한 인덱스
    next: Option<usize>,  // 아레나에 대한 인덱스
@}

struct Arena @{
    nodes: Vec<Node>,
@}

impl Arena @{
    fn new() -> Self @{
        Arena @{ nodes: Vec::new() @}
    @}

    fn alloc(&mut self, value: i32) -> usize @{
        let id = self.nodes.len();
        self.nodes.push(Node @{
            value,
            prev: None,
            next: None,
        @});
        id
    @}

    fn get(&self, id: usize) -> &Node @{
        &self.nodes[id]
    @}

    fn get_mut(&mut self, id: usize) -> &mut Node @{
        &mut self.nodes[id]
    @}
@}
@end example

@noindent
이제 우리는 순환 구조를 쉽게 구축할 수 있다:

@example
fn create_cycle() @{
    let mut arena = Arena::new();

    let id1 = arena.alloc(1);
    let id2 = arena.alloc(2);

    // 빌림 검사기와 싸우지 않고 링크 생성
    arena.get_mut(id1).next = Some(id2);
    arena.get_mut(id2).prev = Some(id1);
    arena.get_mut(id2).next = Some(id1);  // 순환
    arena.get_mut(id1).prev = Some(id2);
@}
@end example

@noindent
이점은 상당하다:

@enumerate
@item
@strong{연속 메모리:} 모든 노드가 @code{Vec}에 있어 캐시 지역성을 크게 향상시킨다. 그래프를 순회하는 것은 동일한 연속 배열에 대한 인덱스를 따라가는 것을 의미한다.

@item
@strong{참조 카운팅 없음:} 인덱스는 단지 정수일 뿐이다. 복사는 무료이며, 참조를 추적하는 오버헤드가 없다.

@item
@strong{자명하게 스레드 안전함:} 인덱스는 @code{Copy}, @code{Send}, 그리고 @code{Sync}이다. 아레나는 표준 동기화로 스레드 간에 공유될 수 있다.

@item
@strong{메모리 누수 없음:} 아레나가 해제되면, 순환 여부와 관계없이 모든 노드가 함께 해제된다.

@item
@strong{결정론적 할당 해제:} 가비지 컬렉션과 달리, 우리는 아레나가 언제 해제되는지 정확하게 제어한다.
@end enumerate

@subsubheading @code{ArenaId<T>}를 이용한 타입 안전 인덱스 (Type-Safe Indices with @code{ArenaId<T>})

기본 아레나 패턴에는 약점이 하나 있다: 인덱스가 단지 @code{usize}이므로, 실수로 잘못된 아레나의 인덱스를 사용하거나 서로 다른 노드 타입에 대한 인덱스를 섞어 쓸 수 있다. 우리는 Rust의 타입 시스템을 사용하여 @newterm{타입 안전 인덱스(type-safe index)}로 이 문제를 해결할 수 있다:

@example
@cindex type-safe indices
@cindex PhantomData
use std::marker::PhantomData;

/// Arena<T>에 대한 타입 안전 인덱스
struct ArenaId<T> @{
    index: usize,
    _marker: PhantomData<T>,  // 마커: 이것은 T에 대한 인덱스이다
@}

// T: Copy를 요구하지 않도록 Copy와 Clone을 수동으로 구현
impl<T> Copy for ArenaId<T> @{@}
impl<T> Clone for ArenaId<T> @{
    fn clone(&self) -> Self @{ *self @}
@}

impl<T> PartialEq for ArenaId<T> @{
    fn eq(&self, other: &Self) -> bool @{
        self.index == other.index
    @}
@}
impl<T> Eq for ArenaId<T> @{@}
@end example

@noindent
@code{PhantomData<T>} 마커는 중요한 역할을 한다: 이것은 @code{ArenaId}를 @code{T}에 대해 제네릭하게 만들어, @code{ArenaId<Wire>}가 예상되는 곳에 @code{ArenaId<Node>}를 사용하는 것을 방지한다. 하지만 @code{PhantomData}는 크기가 0인 타입이므로, 이 타입 안전성은 런타임 비용이 전혀 들지 않는다.

이제 우리 아레나는 다음과 같이 된다:

@example
struct Arena<T> @{
    items: Vec<T>,
@}

impl<T> Arena<T> @{
    fn new() -> Self @{
        Arena @{ items: Vec::new() @}
    @}

    fn alloc(&mut self, value: T) -> ArenaId<T> @{
        let index = self.items.len();
        self.items.push(value);
        ArenaId @{
            index,
            _marker: PhantomData,
        @}
    @}

    fn get(&self, id: ArenaId<T>) -> &T @{
        &self.items[id.index]
    @}

    fn get_mut(&mut self, id: ArenaId<T>) -> &mut T @{
        &mut self.items[id.index]
    @}
@}
@end example

@noindent
타입 안전성은 서로 다른 아레나를 섞는 것을 방지한다:

@example
@cindex type safety
fn demonstrate_type_safety() @{
    let mut nodes: Arena<Node> = Arena::new();
    let mut wires: Arena<Wire> = Arena::new();

    let node_id = nodes.alloc(Node @{ value: 1, prev: None, next: None @});
    let wire_id = wires.alloc(Wire @{ signal: 0 @});

    // 이것은 작동한다:
    let node = nodes.get(node_id);

    // 이것은 컴파일되지 않는다:
    // let wrong = nodes.get(wire_id);  // 타입 오류: ArenaId<Node>가 예상되나 ArenaId<Wire>가 발견됨
@}
@end example

@subsubheading 아레나로 회로 시뮬레이터 구현하기 (Implementing the Circuit Simulator with Arenas)

아레나 패턴을 회로 시뮬레이터에 적용해 보자. 각 와이어와 게이트는 아레나에 살며, 타입이 지정된 인덱스로 참조된다:

@example
@cindex circuit simulator
@cindex event-driven simulation
use std::collections::VecDeque;

type WireId = ArenaId<Wire>;
type GateId = ArenaId<Gate>;

struct Wire @{
    signal: u8,           // 0 또는 1
    gates: Vec<GateId>,   // 신호가 변경될 때 알림을 받을 게이트들
@}

enum GateType @{
    And(WireId, WireId, WireId),      // 입력1, 입력2, 출력
    Or(WireId, WireId, WireId),
    Inverter(WireId, WireId),         // 입력, 출력
@}

struct Gate @{
    gate_type: GateType,
    delay: usize,
@}

struct Circuit @{
    wires: Arena<Wire>,
    gates: Arena<Gate>,
    events: VecDeque<Event>,
    time: usize,
@}

struct Event @{
    time: usize,
    wire: WireId,
    new_signal: u8,
@}
@end example

@noindent
반가산기 회로를 생성하는 것은 간단해진다:

@example
impl Circuit @{
    fn new() -> Self @{
        Circuit @{
            wires: Arena::new(),
            gates: Arena::new(),
            events: VecDeque::new(),
            time: 0,
        @}
    @}

    fn new_wire(&mut self) -> WireId @{
        self.wires.alloc(Wire @{
            signal: 0,
            gates: Vec::new(),
        @})
    @}

    fn and_gate(&mut self, in1: WireId, in2: WireId, out: WireId) @{
        let gate_id = self.gates.alloc(Gate @{
            gate_type: GateType::And(in1, in2, out),
            delay: 3,
        @});

        // 이 게이트를 입력 와이어에 등록
        self.wires.get_mut(in1).gates.push(gate_id);
        self.wires.get_mut(in2).gates.push(gate_id);
    @}

    fn half_adder(&mut self) -> (WireId, WireId, WireId, WireId) @{
        let a = self.new_wire();
        let b = self.new_wire();
        let s = self.new_wire();
        let c = self.new_wire();
        let d = self.new_wire();
        let e = self.new_wire();

        self.or_gate(a, b, d);
        self.and_gate(a, b, c);
        self.inverter(c, e);
        self.and_gate(d, e, s);

        (a, b, s, c)
    @}

    fn set_signal(&mut self, wire: WireId, signal: u8) @{
        self.events.push_back(Event @{
            time: self.time,
            wire,
            new_signal: signal,
        @});
    @}

    fn propagate(&mut self) @{
        while let Some(event) = self.events.pop_front() @{
            if event.time > self.time @{
                self.time = event.time;
            @}

            let wire = self.wires.get_mut(event.wire);
            if wire.signal != event.new_signal @{
                wire.signal = event.new_signal;

                // 연결된 모든 게이트에 알림
                for gate_id in wire.gates.clone() @{
                    self.process_gate(gate_id);
                @}
            @}
        @}
    @}

    fn process_gate(&mut self, gate_id: GateId) @{
        let gate = self.gates.get(gate_id);
        let (output_wire, new_signal) = match &gate.gate_type @{
            GateType::And(in1, in2, out) => @{
                let s1 = self.wires.get(*in1).signal;
                let s2 = self.wires.get(*in2).signal;
                (*out, s1 & s2)
            @}
            GateType::Or(in1, in2, out) => @{
                let s1 = self.wires.get(*in1).signal;
                let s2 = self.wires.get(*in2).signal;
                (*out, s1 | s2)
            @}
            GateType::Inverter(input, out) => @{
                let s = self.wires.get(*input).signal;
                (*out, 1 - s)
            @}
        @};

        let delay = gate.delay;
        self.events.push_back(Event @{
            time: self.time + delay,
            wire: output_wire,
            new_signal,
        @});
    @}
@}
@end example

@noindent
아레나 패턴이 어떻게 우리가 빌림 검사기와 싸우지 않고 회로를 자유롭게 변경할 수 있게 해주는지 주목하라.
우리는 ID로 와이어와 게이트를 조회하고, 수정하고, 수명 명시 없이 복잡한 상호 연결된 구조를 구축할 수 있다.

@subsubheading 아레나를 사용하지 말아야 할 때 (When Not to Use Arenas)

아레나 패턴은 만능 해결책이 아니다. 이것은 컴파일 타임 안전성을 런타임 유연성과 교환하는 것으로, 어떤 상황에서는 적절하지만 다른 상황에서는 그렇지 않다:

@strong{아레나를 사용해야 할 때:}
@itemize @bullet
@item
순환 또는 복잡한 공유를 가진 그래프 구조를 구축할 때
@item
모든 노드가 동일한 수명을 가질 때 (함께 할당되고 해제됨)
@item
캐시 지역성이 중요할 때 (많은 노드를 순회함)
@item
인덱스를 사용한 스레드 안전성이 참조를 사용하는 것보다 간단할 때
@end itemize

@strong{아레나를 피해야 할 때:}
@itemize @bullet
@item
빌림 검사기의 해결책이 간단할 때 (참조 사용)
@item
노드가 개별적인 수명을 필요로 할 때 (@code{Box} 또는 @code{Rc} 사용)
@item
타입 안전성이 중요하고 인덱스가 너무 느슨하게 느껴질 때
@item
@code{Rc<RefCell<T>>}의 오버헤드가 용납될 수 있을 때
@end itemize

@noindent
핵심 통찰은 아레나가 빌림 검사기의 @emph{비상탈출구}이지 대체재가 아니라는 것이다.
가능하면 빌림 검사기를 사용하고, 대안이 몇 시간 동안 빌림 검사기와 싸우는 것일 때 아레나를 사용하라.

@subsubheading @code{sicp-common::arena} 모듈 (The @code{sicp-common::arena} Module)

SICP Rust 저장소는 @code{sicp-common} 크레이트에서 생산 준비된 아레나 구현을 제공한다. 전체 구현에는 추가 기능이 포함되어 있다:

@example
@cindex sicp-common crate
use sicp_common::arena::@{Arena, ArenaId@};

// 노드 타입을 위한 아레나 생성
let mut arena: Arena<Node> = Arena::new();

// 노드 할당
let id1 = arena.alloc(Node @{ value: 1, next: None @});
let id2 = arena.alloc(Node @{ value: 2, next: Some(id1) @});

// 노드 접근
let node = arena.get(id1);
arena.get_mut(id2).next = Some(id1);

// 모든 노드 순회
for node in arena.iter() @{
    println!("Value: @{@}", node.value);
@}

// ID와 함께 순회
for (id, node) in arena.iter_with_ids() @{
    println!("Node @{@}: @{@}", id.index(), node.value);
@}
@end example

@noindent
@code{rust-examples/sicp-common/src/arena.rs}의 구현은 견고한 제로 비용 추상화를 구축하는 방법을 보여준다.
타입 매개변수, 트레이트 구현, 그리고 신중한 API 설계가 본질적으로 화려한 @code{Vec}인 것에 대해 어떻게 안전하고 인체공학적인 인터페이스를 생성하는지 연구해 보라.

@quotation
@strong{@anchor{Exercise 3.28a}연습문제 3.28a:} 아레나 패턴을 사용하여 방향 그래프를 표현하는 @code{Graph} 구조체를 구현하라. 구현은 다음을 지원해야 한다:

@enumerate
@item
관련 데이터가 있는 노드 추가
@item
노드 간 방향 있는 간선 추가
@item
노드에서 이웃으로 순회
@item
깊이 우선 탐색을 사용하여 순환 감지
@end enumerate

@example
struct Node<T> @{
    data: T,
    edges: Vec<ArenaId<Node<T>>>,
@}

struct Graph<T> @{
    arena: Arena<Node<T>>,
@}

impl<T> Graph<T> @{
    fn new() -> Self @{ /* ... */ @}

    fn add_node(&mut self, data: T) -> ArenaId<Node<T>> @{ /* ... */ @}

    fn add_edge(&mut self, from: ArenaId<Node<T>>, to: ArenaId<Node<T>>) @{ /* ... */ @}

    fn neighbors(&self, node: ArenaId<Node<T>>) -> &[ArenaId<Node<T>>] @{ /* ... */ @}

    fn has_cycle(&self) -> bool @{ /* ... */ @}
@}
@end example

@noindent
순환이 있는 그래프를 생성하여 @code{has_cycle}이 감지하는지 확인하고, 비순환 그래프를 생성하여 거짓을 반환하는지 확인하여 구현을 테스트하라.
@end quotation

@quotation
@strong{@anchor{Exercise 3.28b}연습문제 3.28b:} 회로 시뮬레이터는 와이어 신호가 변경될 때 알림이 필요한 게이트를 추적하기 위해 @code{Wire} 구조체에서 @code{Vec<GateId>}를 사용한다. 이것은 반복 전에 벡터를 복제해야 한다(빌림 문제를 피하기 위해). 할당을 피하는 대안적인 설계를 제안하고 구현하라.

다음 접근 방식을 고려해 보라:

@enumerate a
@item
와이어가 연결된 게이트를 추적하는 대신, 게이트를 아레나에 저장하고 각 게이트에 출력 와이어 목록을 부여한다.

@item
와이어 신호 변경에 의해 채워지는, 처리할 게이트 ID를 저장하는 별도의 이벤트 큐를 사용한다.

@item
별도의 @code{Vec<(WireId, GateId)>} 연결 테이블에 대한 인덱스를 사용한다.
@end enumerate

@noindent
한 가지 접근 방식을 구현하고 원래 설계와 성능 특성(할당, 캐시 지역성, 코드 복잡성)을 비교하라. 생산 회로 시뮬레이터라면 어느 것을 선택하겠는가?
@end quotation

아레나 패턴은 시스템 프로그래밍의 기본 원칙을 보여준다: 때로는 올바른 추상화가 한 종류의 안전성을 다른 종류와 교환하는 것을 요구한다.
빌림 검사기의 안전성은 명확한 소유권 계층 구조를 가진 트리 모양의 구조에 대해 타의 추종을 불허한다.
하지만 소유권이 본질적으로 공유되고 순환적인 그래프의 경우, 아레나에 대한 인덱스는 다른 종류의 안전성을 제공한다: 경계 검사된 배열 접근, 결정론적 할당 해제, 그리고 Rust의 그래프 구조를 괴롭히는 수명 퍼즐로부터의 자유이다.

두 접근 방식을 모두 이해하고---각각을 언제 사용할지 앎으로써---우리는 타입 시스템이 도울 수 있는 곳에서는 도움을 받고 필요할 때는 신중하게 밖으로 나오며 안전하고 효율적인 복잡한 시스템을 구축할 유연성을 얻는다.

@node	3.3.5, 3.4, 3.2, 3.3
@subsection 제약 조건 전파 (Propagation of Constraints)

컴퓨터 프로그램은 전통적으로 미리 지정된 인자에 대해 연산을 수행하여 원하는 출력을 생성하는 단방향 계산으로 구성된다.
반면, 우리는 종종 양 사이의 관계의 관점에서 시스템을 모델링한다.
예를 들어, 기계 구조의 수학적 모델은 금속 막대의 처짐 @math{d}가 막대에 가해지는 힘 @math{F}, 막대의 길이 @math{L}, 단면적 @math{A}, 그리고 탄성 계수 @math{E}와 방정식
@ifinfo

@example
dAE = FL
@end example

@end ifinfo
@tex
\[ % :61:
  {dAE} \,=\, {FL.}  \]
@end tex
을 통해 관련되어 있다는 정보를 포함할 수 있다.
그러한 방정식은 단방향이 아니다.
다섯 가지 양 중 네 가지가 주어지면, 우리는 그것을 사용하여 다섯 번째를 계산할 수 있다.
그러나 방정식을 전통적인 컴퓨터 언어로 번역하면 나머지 네 가지의 관점에서 계산될 양 중 하나를 선택해야 한다.
따라서 면적 @math{A}를 계산하는 프로시저는 처짐 @math{d}를 계산하는 데 사용될 수 없다. 비록 @math{A}와 @math{d}의 계산이 같은 방정식에서 나오더라도 말이다.@footnote{제약 조건 전파는 Ivan @ref{Sutherland (1963)}의 믿을 수 없을 정도로 미래지향적인 @abbr{SKETCHPAD} 시스템에 처음 등장했다. Smalltalk 언어에 기반한 아름다운 제약 조건 전파 시스템은 제록스 팰로앨토 연구소의 Alan @ref{Borning (1977)}에 의해 개발되었다. Sussman, Stallman, 그리고 Steele은 제약 조건 전파를 전기 회로 분석에 적용했다(@ref{Sussman and Stallman 1975}; @ref{Sussman and Steele 1980}). TK!Solver(@ref{Konopasek and Jayaraman 1984})는 제약 조건에 기반한 광범위한 모델링 환경이다.}

이 절에서 우리는 관계 자체의 관점에서 작업할 수 있게 해주는 언어의 설계를 스케치한다.
언어의 기본 요소는 양들 사이에 특정 관계가 성립함을 명시하는 @newterm{원시 제약 조건(primitive constraints)}이다.
예를 들어, @code{(adder a b c)}는 양 @math{a}, @math{b}, 그리고 @math{c}가 방정식 @math{{a + b = c}}에 의해 관련되어야 함을 명시하고, @code{(multiplier x y z)}는 제약 조건 @math{{xy = z}}를 표현하며, @code{(constant 3.14 x)}는 @math{x}의 값이 3.14여야 한다고 말한다.

우리 언어는 더 복잡한 관계를 표현하기 위해 원시 제약 조건을 결합하는 수단을 제공한다.
우리는 제약 조건들이 @newterm{커넥터(connectors)}에 의해 결합되는 @newterm{제약 조건 네트워크(constraint networks)}를 구성함으로써 제약 조건을 결합한다.
커넥터는 하나 이상의 제약 조건에 참여할 수 있는 값을 ``보유''하는 객체이다.
예를 들어, 우리는 화씨온도와 섭씨온도 사이의 관계가 다음과 같음을 안다
@ifinfo

@example
9C = 5(F - 32)
@end example

@end ifinfo
@tex
\[ % :62:
  {9C} \,=\, {5(F - 32).}  \]
@end tex
그러한 제약 조건은 원시 덧셈기, 곱셈기, 그리고 상수 제약 조건으로 구성된 네트워크로 생각할 수 있다(@ref{Figure 3.28}).
그림에서, 우리는 왼쪽에 @math{{m1}}, @math{{m2}}, 그리고 @math{p}라고 라벨이 붙은 세 개의 터미널을 가진 곱셈기 상자를 본다.
이것들은 곱셈기를 네트워크의 나머지 부분과 다음과 같이 연결한다:
@math{{m1}} 터미널은 섭씨온도를 보유할 커넥터 @math{C}에 연결된다.
@math{{m2}} 터미널은 커넥터 @math{w}에 연결되는데, 이것은 또한 9를 보유하는 상수 상자에 연결된다.
곱셈기 상자가 @math{{m1}}과 @math{{m2}}의 곱이 되도록 제한하는 @math{p} 터미널은 다른 곱셈기 상자의 @math{p} 터미널에 연결되는데, 그 다른 곱셈기의 @math{{m2}}는 상수 5에 연결되고 @math{{m1}}은 합의 항 중 하나에 연결된다.

@float
@anchor{Figure 3.28}
@ifinfo
@strong{Figure 3.28:} 제약 조건 네트워크로 표현된 관계식 @math{9C = 5(F - 32)}.

@example
       +---------+     +---------+   v   +---------+
C -----+ m1      |  u  |      m1 +-------+ a1      |
       |    *  p +-----+ p  *    |       |    *  s +---- F
    +--+ m2      |     |      m2 +--+ +--+ a2      |
    |  +---------+     +---------+  | |  +---------+
  w |                              x| |y
    |    +-----+        +-----+     | |     +-----+
    +----+  9  |        |  5  +-----+ +-----+  32 |
         +-----+        +-----+             +-----+
@end example
@end ifinfo
@iftex
@image{fig/chap3/Fig3.28,142mm,,,.std.svg}
@caption{@strong{Figure 3.28:} 제약 조건 네트워크로 표현된 관계식 @math{{9C = 5(F - 32)}}.}
@end iftex
@end float

@noindent
그러한 네트워크에 의한 계산은 다음과 같이 진행된다: 커넥터가 (사용자나 연결된 제약 조건 상자에 의해) 값을 받으면, 값을 가졌음을 알리기 위해 연관된 모든 제약 조건(방금 그것을 깨운 제약 조건은 제외하고)을 깨운다.
각 깨어난 제약 조건 상자는 커넥터의 값을 결정하기 위한 충분한 정보가 있는지 확인하기 위해 자신의 커넥터들을 조사한다.
그렇다면, 상자는 그 커넥터를 설정하고, 이는 다시 연관된 모든 제약 조건을 깨우는 식으로 진행된다.
예를 들어, 섭씨와 화씨 사이의 변환에서, @math{w}, @math{x}, 그리고 @math{y}는 상수 상자에 의해 즉시 9, 5, 32로 설정된다.
커넥터들은 곱셈기와 덧셈기를 깨우는데, 이들은 진행하기에 충분한 정보가 없다고 판단한다.
만약 사용자(또는 네트워크의 다른 부분)가 @math{C}를 값(예를 들어 25)으로 설정하면, 가장 왼쪽의 곱셈기가 깨어나고, 이것은 @math{u}를 @math{{25 \cdot 9 = 225}}로 설정할 것이다.
그러면 @math{u}는 두 번째 곱셈기를 깨우고, 이것은 @math{v}를 45로 설정하며, @math{v}는 덧셈기를 깨워 @math{f}를 77로 설정한다.

@subsubheading 제약 조건 시스템 사용하기 (Using the constraint system)

제약 조건 시스템을 사용하여 위에서 설명한 온도 계산을 수행하기 위해, 우리는 먼저 생성자 @code{make_connector}를 호출하여 두 개의 커넥터 @code{C}와 @code{F}를 생성하고, 적절한 네트워크에서 @code{C}와 @code{F}를 연결한다:

@example
let mut network = ConstraintNetwork::new();
let c = network.make_connector();
let f = network.make_connector();
celsius_fahrenheit_converter(&mut network, c, f);
@end example

@noindent
네트워크를 생성하는 프로시저는 다음과 같이 정의된다:

@example
fn celsius_fahrenheit_converter(
    network: &mut ConstraintNetwork,
    c: ConnectorId,
    f: ConnectorId
) @{
    let u = network.make_connector();
    let v = network.make_connector();
    let w = network.make_connector();
    let x = network.make_connector();
    let y = network.make_connector();

    network.multiplier(c, w, u);  // c * w = u
    network.multiplier(v, x, u);  // v * x = u
    network.adder(v, y, f);       // v + y = f
    network.constant(9.0, w);
    network.constant(5.0, x);
    network.constant(32.0, y);
@}
@end example

@noindent
이 프로시저는 내부 커넥터 @code{u}, @code{v}, @code{w}, @code{x}, @code{y}를 생성하고, 원시 제약 조건 생성자 @code{adder}, @code{multiplier}, @code{constant}를 사용하여 @ref{Figure 3.28}과 같이 연결한다.
@ref{3.3.4}의 디지털 회로 시뮬레이터와 마찬가지로, 원시 요소들의 이러한 조합을 프로시저로 표현하는 것은 자동으로 우리 언어에 복합 객체를 위한 추상화 수단을 제공한다.

네트워크가 작동하는 것을 보려면, 우리는 @ref{3.3.4}에서 와이어를 모니터링하는 데 사용했던 것과 유사한 @code{probe} 프로시저를 사용하여 커넥터 @code{C}와 @code{F}에 프로브를 놓을 수 있다.
커넥터에 프로브를 놓으면 커넥터가 값을 받을 때마다 메시지가 출력될 것이다:

@example
network.probe("Celsius temp", c);
network.probe("Fahrenheit temp", f);
@end example

@noindent
다음으로 우리는 @code{C}의 값을 25로 설정한다. (@code{set-value!}의 세 번째 인자는 @code{C}에게 이 지시가 @code{user}로부터 온 것임을 알려준다.)

@example
network.set_value(c, 25.0, Informant::User)?;
// => Probe: Celsius temp = 25
// => Probe: Fahrenheit temp = 77
@end example

@noindent
@code{C}의 프로브가 깨어나서 값을 보고한다. @code{C}는 또한 위에서 설명한 대로 네트워크를 통해 값을 전파한다.
이것은 @code{F}를 77로 설정하며, 이는 @code{F}의 프로브에 의해 보고된다.

이제 우리는 @code{F}를 새로운 값, 예를 들어 212로 설정하려고 시도할 수 있다:

@example
network.set_value(f, 212.0, Informant::User);
// => Err(Contradiction @{ current: 77.0, new: 212.0 @})
@end example

@noindent
커넥터는 모순을 감지했다고 불평한다: 그 값은 77인데, 누군가 212로 설정하려고 한다.
만약 우리가 정말로 새로운 값으로 네트워크를 재사용하고 싶다면, 우리는 @code{C}에게 이전 값을 잊으라고 말할 수 있다:

@example
network.forget_value(c, Informant::User);
// => Probe: Celsius temp = ?
// => Probe: Fahrenheit temp = ?
@end example

@noindent
@code{C}는 원래 자신의 값을 설정했던 @code{user}가 이제 그 값을 철회하고 있음을 발견하므로, 프로브가 보여주듯이 자신의 값을 잃는 것에 동의하고, 이 사실을 네트워크의 나머지 부분에 알린다.
이 정보는 결국 @code{F}로 전파되는데, @code{F}는 이제 자신의 값이 77이라고 계속 믿을 이유가 없다는 것을 알게 된다.
따라서 @code{F}도 자신의 값을 포기하며, 이는 프로브에 의해 보여진다.

이제 @code{F}가 값을 가지고 있지 않으므로, 우리는 그것을 212로 설정할 수 있다:

@example
network.set_value(f, 212.0, Informant::User)?;
// => Probe: Fahrenheit temp = 212
// => Probe: Celsius temp = 100
@end example

@noindent
이 새로운 값은 네트워크를 통해 전파될 때 @code{C}가 100의 값을 갖도록 강제하며, 이것은 @code{C}의 프로브에 의해 등록된다.
바로 그 동일한 네트워크가 @code{F}가 주어졌을 때 @code{C}를 계산하고 @code{C}가 주어졌을 때 @code{F}를 계산하는 데 사용되고 있다는 점에 주목하라.
계산의 이 비방향성(nondirectionality)은 제약 조건 기반 시스템의 특징적인 기능이다.

@subsubheading 제약 조건 시스템 구현 (Implementing the constraint system)

제약 조건 시스템은 @ref{3.3.4}의 디지털 회로 시뮬레이터와 매우 유사한 방식으로 지역 상태를 가진 절차적 객체를 통해 구현된다.
제약 조건 시스템의 원시 객체가 다소 더 복잡하긴 하지만, 전체 시스템은 더 단순한데, 왜냐하면 아젠다나 논리 지연에 대한 걱정이 없기 때문이다.

커넥터에 대한 기본 연산은 다음과 같다:

@itemize @bullet

@item
@code{(has-value? ⟨@var{connector}⟩)}는 커넥터가 값을 가지고 있는지 알려준다.

@item
@code{(get-value ⟨@var{connector}⟩)}는 커넥터의 현재 값을 반환한다.

@item
@code{(set-value! ⟨@var{connector}⟩ ⟨@var{new-value}⟩ ⟨@var{informant}⟩)}는 정보 제공자가 커넥터에게 값을 새 값으로 설정하도록 요청하고 있음을 나타낸다.

@item
@code{(forget-value! ⟨@var{connector}⟩ ⟨@var{retractor}⟩)}는 커넥터에게 철회자가 값을 잊으라고 요청하고 있음을 알린다.

@item
@code{(connect ⟨@var{connector}⟩ ⟨@var{new-constraint}⟩)}는 커넥터에게 새 제약 조건에 참여하라고 말한다.

@end itemize

@noindent
커넥터는 @code{inform-about-value}(커넥터가 값을 가지고 있음을 주어진 제약 조건에 알림)와 @code{inform-about-no-value}(커넥터가 값을 잃었음을 제약 조건에 알림)라는 프로시저를 통해 제약 조건과 통신한다.

@code{Adder}는 피가산수 커넥터 @code{a1}과 @code{a2} 및 @code{sum} 커넥터 사이에 덧셈기 제약 조건을 구성한다.
덧셈기는 지역 상태를 가진 프로시저(아래의 @code{me} 프로시저)로 구현된다:

@example
struct Adder @{
    a1: ConnectorId,
    a2: ConnectorId,
    sum: ConnectorId,
@}

impl Constraint for Adder @{
    fn process_new_value(&self, network: &mut ConstraintNetwork) @{
        let a1_val = network.get_value(self.a1);
        let a2_val = network.get_value(self.a2);
        let sum_val = network.get_value(self.sum);

        match (a1_val, a2_val, sum_val) @{
            (Some(a1), Some(a2), None) => @{
                network.set_value(self.sum, a1 + a2, self.id());
            @}
            (Some(a1), None, Some(sum)) => @{
                network.set_value(self.a2, sum - a1, self.id());
            @}
            (None, Some(a2), Some(sum)) => @{
                network.set_value(self.a1, sum - a2, self.id());
            @}
            _ => @{@} // 정보가 충분하지 않음
        @}
    @}

    fn process_forget_value(&self, network: &mut ConstraintNetwork) @{
        network.forget_value(self.sum, self.id());
        network.forget_value(self.a1, self.id());
        network.forget_value(self.a2, self.id());
        self.process_new_value(network);
    @}
@}
@end example

@noindent
@code{Adder}는 새 덧셈기를 지정된 커넥터에 연결하고 그것을 값으로 반환한다.
덧셈기를 나타내는 프로시저 @code{me}는 지역 프로시저에 대한 디스패치 역할을 한다.
다음 ``문법 인터페이스''(@ref{3.3.4}의 @ref{Footnote 155} 참조)가 디스패치와 함께 사용된다:

@example
// Rust에서 제약 조건은 다음 메서드를 가진 트레이트를 구현한다:
trait Constraint @{
    fn process_new_value(&self, network: &mut ConstraintNetwork);
    fn process_forget_value(&self, network: &mut ConstraintNetwork);
@}
// 네트워크는 constraint.process_new_value() 또는
// constraint.process_forget_value()를 직접 호출한다.
@end example

@noindent
덧셈기의 지역 프로시저 @code{process-new-value}는 덧셈기가 커넥터 중 하나가 값을 가지고 있다고 통보받을 때 호출된다.
덧셈기는 먼저 @code{a1}과 @code{a2} 둘 다 값을 가지고 있는지 확인한다.
그렇다면, @code{sum}에게 그 값을 두 피가산수의 합으로 설정하라고 말한다.
@code{set-value!}에 대한 @code{informant} 인자는 @code{me}, 즉 덧셈기 객체 자체이다.
만약 @code{a1}과 @code{a2}가 둘 다 값을 가지고 있지 않다면, 덧셈기는 혹시 @code{a1}과 @code{sum}이 값을 가지고 있는지 확인한다.
그렇다면, @code{a2}를 이 둘의 차이로 설정한다.
마지막으로, @code{a2}와 @code{sum}이 값을 가지고 있다면, 이것은 덧셈기에게 @code{a1}을 설정할 충분한 정보를 제공한다.
만약 덧셈기가 커넥터 중 하나가 값을 잃었다고 통보받으면, 모든 커넥터에게 이제 값을 잃으라고 요청한다. (이 덧셈기에 의해 설정된 값들만 실제로 손실된다.)
그런 다음 @code{process-new-value}를 실행한다.
이 마지막 단계의 이유는 하나 이상의 커넥터가 여전히 값을 가지고 있을 수 있기 때문이며(즉, 커넥터가 덧셈기에 의해 원래 설정되지 않은 값을 가지고 있었을 수 있음), 이 값들이 덧셈기를 통해 다시 전파되어야 할 수 있기 때문이다.

곱셈기는 덧셈기와 매우 유사하다. 이것은 다른 인자가 알려지지 않았더라도 인자 중 하나가 0이면 @code{product}를 0으로 설정할 것이다.

@example
struct Multiplier @{
    m1: ConnectorId,
    m2: ConnectorId,
    product: ConnectorId,
@}

impl Constraint for Multiplier @{
    fn process_new_value(&self, network: &mut ConstraintNetwork) @{
        let m1_val = network.get_value(self.m1);
        let m2_val = network.get_value(self.m2);
        let prod_val = network.get_value(self.product);

        // 인자 중 하나가 0이면 곱은 0이다
        if m1_val == Some(0.0) || m2_val == Some(0.0) @{
            network.set_value(self.product, 0.0, self.id());
            return;
        @}

        match (m1_val, m2_val, prod_val) @{
            (Some(m1), Some(m2), None) => @{
                network.set_value(self.product, m1 * m2, self.id());
            @}
            (Some(m1), None, Some(p)) => @{
                network.set_value(self.m2, p / m1, self.id());
            @}
            (None, Some(m2), Some(p)) => @{
                network.set_value(self.m1, p / m2, self.id());
            @}
            _ => @{@}
        @}
    @}

    fn process_forget_value(&self, network: &mut ConstraintNetwork) @{
        network.forget_value(self.product, self.id());
        network.forget_value(self.m1, self.id());
        network.forget_value(self.m2, self.id());
        self.process_new_value(network);
    @}
@}
@end example

@noindent
@code{constant} 생성자는 단순히 지정된 커넥터의 값을 설정한다.
상수 상자로 전송된 @code{I-have-a-value} 또는 @code{I-lost-my-value} 메시지는 오류를 생성할 것이다.

@example
impl ConstraintNetwork @{
    fn constant(&mut self, value: f64, connector: ConnectorId) @{
        // 상수는 커넥터의 값을 즉시 설정하며
        // 변경될 수 없다 - 제약 조건 객체가 필요하지 않음
        self.set_value(connector, value, Informant::Constant);
    @}
@}
@end example

@noindent
마지막으로, 프로브는 지정된 커넥터의 설정 또는 설정 해제에 대한 메시지를 출력한다:

@example
struct Probe @{
    name: String,
    connector: ConnectorId,
@}

impl Constraint for Probe @{
    fn process_new_value(&self, network: &mut ConstraintNetwork) @{
        if let Some(value) = network.get_value(self.connector) @{
            println!("Probe: @{@} = @{@}", self.name, value);
        @}
    @}

    fn process_forget_value(&self, _network: &mut ConstraintNetwork) @{
        println!("Probe: @{@} = ?", self.name);
    @}
@}
@end example

@subsubheading 커넥터 표현 (Representing connectors)

커넥터는 지역 상태 변수 @code{value}(커넥터의 현재 값), @code{informant}(커넥터의 값을 설정한 객체), 그리고 @code{constraints}(커넥터가 참여하는 제약 조건들의 리스트)를 가진 절차적 객체로 표현된다.

@example
struct Connector @{
    value: Option<f64>,
    informant: Option<Informant>,
    constraints: Vec<ConstraintId>,
@}

impl Connector @{
    fn new() -> Self @{
        Connector @{
            value: None,
            informant: None,
            constraints: Vec::new(),
        @}
    @}

    fn has_value(&self) -> bool @{
        self.value.is_some()
    @}

    fn get_value(&self) -> Option<f64> @{
        self.value
    @}

    fn set_value(
        &mut self,
        new_val: f64,
        setter: Informant
    ) -> Result<(), Contradiction> @{
        match self.value @{
            None => @{
                self.value = Some(new_val);
                self.informant = Some(setter);
                Ok(())
            @}
            Some(current) if (current - new_val).abs() < 1e-10 => @{
                Ok(()) // 같은 값, 무시
            @}
            Some(current) => @{
                Err(Contradiction @{ current, new: new_val @})
            @}
        @}
    @}

    fn forget_value(&mut self, retractor: Informant) @{
        if self.informant == Some(retractor) @{
            self.value = None;
            self.informant = None;
        @}
    @}
@}
@end example

@noindent
커넥터의 지역 프로시저 @code{set-my-value}는 커넥터의 값을 설정하라는 요청이 있을 때 호출된다.
커넥터가 현재 값을 가지고 있지 않다면, 값을 설정하고 값을 설정하도록 요청한 제약 조건을 @code{informant}로 기억할 것이다.@footnote{@code{setter}가 제약 조건이 아닐 수도 있다. 온도 예제에서 우리는 @code{user}를 @code{setter}로 사용했다.}
그런 다음 커넥터는 값을 설정하도록 요청한 제약 조건을 제외한 모든 참여 제약 조건에 알릴 것이다.
이것은 주어진 항목을 제외한 리스트의 모든 항목에 지정된 프로시저를 적용하는 다음 반복자를 사용하여 달성된다:

@example
fn for_each_except<T, F>(exception: T, procedure: F, items: &[T])
where
    T: PartialEq,
    F: Fn(&T),
@{
    for item in items @{
        if item != &exception @{
            procedure(item);
        @}
    @}
@}
@end example

@noindent
커넥터가 값을 잊으라는 요청을 받으면, 지역 프로시저 @code{forget-my-value}를 실행하는데, 이것은 먼저 요청이 원래 값을 설정했던 것과 같은 객체에서 오는지 확인한다.
그렇다면, 커넥터는 연관된 제약 조건들에 값의 손실을 알린다.

지역 프로시저 @code{connect}는 지정된 새 제약 조건이 이미 리스트에 없다면 제약 조건 리스트에 추가한다.
그런 다음, 커넥터가 값을 가지고 있다면 새 제약 조건에 이 사실을 알린다.

커넥터의 프로시저 @code{me}는 다른 내부 프로시저에 대한 디스패치 역할을 하며 또한 커넥터를 객체로 나타낸다.
다음 프로시저들은 디스패치에 대한 문법 인터페이스를 제공한다:

@example
// Rust에서 이것들은 네트워크에 대한 메서드 호출이다:
impl ConstraintNetwork @{
    fn has_value(&self, conn: ConnectorId) -> bool @{
        self.connectors[conn].has_value()
    @}

    fn get_value(&self, conn: ConnectorId) -> Option<f64> @{
        self.connectors[conn].get_value()
    @}

    fn set_value(&mut self, conn: ConnectorId, val: f64, inf: Informant)
        -> Result<(), Contradiction>
    @{
        self.connectors[conn].set_value(val, inf)
    @}

    fn forget_value(&mut self, conn: ConnectorId, ret: Informant) @{
        self.connectors[conn].forget_value(ret);
    @}
@}
@end example

@quotation
@strong{@anchor{Exercise 3.33}연습문제 3.33:} 원시 곱셈기, 덧셈기, 그리고 상수 제약 조건을 사용하여, 세 커넥터 @code{a}, @code{b}, 그리고 @code{c}를 입력으로 받아 @code{c}의 값이 @code{a}와 @code{b} 값의 평균이라는 제약 조건을 설정하는 프로시저 @code{averager}를 정의하라.
@end quotation

@quotation
@strong{@anchor{Exercise 3.34}연습문제 3.34:} Louis Reasoner는 두 터미널을 가진 제약 장치인 제곱기(squarer)를 만들고 싶어 하는데, 두 번째 터미널의 커넥터 @code{b}의 값은 항상 첫 번째 터미널의 값 @code{a}의 제곱이 되도록 한다.
그는 곱셈기로 만든 다음의 간단한 장치를 제안한다:

@example
fn squarer(network: &mut ConstraintNetwork, a: ConnectorId, b: ConnectorId) @{
    network.multiplier(a, a, b);
@}
@end example

이 아이디어에는 심각한 결함이 있다. 설명하라.
@end quotation

@quotation
@strong{@anchor{Exercise 3.35}연습문제 3.35:} Ben Bitdiddle은 Louis에게 @ref{Exercise 3.34}의 문제를 피하는 한 가지 방법은 제곱기를 새로운 원시 제약 조건으로 정의하는 것이라고 말한다.
Ben의 윤곽에서 그러한 제약 조건을 구현하기 위한 프로시저의 누락된 부분을 채워라:

@example
struct Squarer @{
    a: ConnectorId,
    b: ConnectorId,
@}

impl Constraint for Squarer @{
    fn process_new_value(&self, network: &mut ConstraintNetwork) @{
        if let Some(b_val) = network.get_value(self.b) @{
            if b_val < 0.0 @{
                panic!("square less than 0: SQUARER @{@}", b_val);
            @}
            @r{<alternative1>}  // a를 sqrt(b)로 설정
        @} else @{
            @r{<alternative2>}  // a가 값을 가지면, b를 설정
        @}
    @}

    fn process_forget_value(&self, network: &mut ConstraintNetwork) @{
        @r{<body1>}
    @}
@}
@r{<rest of definition>}
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 3.36}연습문제 3.36:} 우리가 전역 환경에서 다음 표현식 시퀀스를 평가한다고 가정하자:

@example
let mut network = ConstraintNetwork::new();
let a = network.make_connector();
let b = network.make_connector();
network.set_value(a, 10.0, Informant::User)?;
@end example

@code{set-value!}의 평가 중 어느 시점에, 커넥터의 지역 프로시저에서 다음 표현식이 평가된다:

@example
for_each_except(setter, inform_about_value, &constraints);
@end example

위의 표현식이 평가되는 환경을 보여주는 환경 다이어그램을 그려라.
@end quotation

@quotation
@strong{@anchor{Exercise 3.37}연습문제 3.37:} @code{celsius-fahrenheit-converter} 프로시저는 다음과 같은 표현식 지향 스타일의 정의와 비교할 때 성가시다.

@example
fn celsius_fahrenheit_converter(
    network: &mut ConstraintNetwork,
    x: ConnectorId
) -> ConnectorId @{
    let nine = cv(network, 9.0);
    let five = cv(network, 5.0);
    let thirty_two = cv(network, 32.0);
    
    // (x * 9/5) + 32
    c_add(network,
        c_mul(network,
            c_div(network, nine, five),
            x),
        thirty_two)
@}

let mut network = ConstraintNetwork::new();
let c = network.make_connector();
let f = celsius_fahrenheit_converter(&mut network, c);
@end example

여기서 @code{c_add}, @code{c_mul} 등은 산술 연산의 ``제약 조건'' 버전이다.
예를 들어, @code{c_add}는 두 커넥터를 인자로 받아 덧셈기 제약 조건에 의해 이들과 관련된 커넥터를 반환한다:

@example
fn c_add(
    network: &mut ConstraintNetwork,
    x: ConnectorId,
    y: ConnectorId
) -> ConnectorId @{
    let z = network.make_connector();
    network.adder(x, y, z);
    z
@}
@end example

위의 변환기 예제에서처럼 복합 제약 조건을 정의할 수 있게 해주는 유사한 프로시저 @code{c_sub}, @code{c_mul}, @code{c_div}, 그리고 @code{cv}(상수 값)를 정의하라.@footnote{표현식 지향 형식은 계산의 중간 표현식에 이름을 붙일 필요를 피할 수 있기 때문에 편리하다. 우리의 원래 제약 언어 공식화는 복합 데이터에 대한 연산을 다룰 때 많은 언어가 성가신 것과 같은 방식으로 성가시다. 예를 들어, 변수가 벡터를 나타내는 경우 곱 @math{{(a + b) \cdot (c + d)}}를 계산하고 싶다면, 우리는 지정된 벡터 인자의 값을 설정하지만 벡터를 값으로 반환하지 않는 프로시저를 사용하여 ``명령형 스타일''로 작업할 수 있다:

@example
let temp1 = v_sum(&a, &b);
let temp2 = v_sum(&c, &d);
let answer = v_prod(&temp1, &temp2);
@end example

대안적으로, 우리는 벡터를 값으로 반환하는 프로시저를 사용하여 표현식을 다룰 수 있고, 따라서 @code{temp1}과 @code{temp2}를 명시적으로 언급하는 것을 피할 수 있다:

@example
let answer = v_prod(v_sum(&a, &b), v_sum(&c, &d));
@end example

Lisp는 우리가 프로시저의 값으로 복합 객체를 반환할 수 있게 해주기 때문에, 우리는 이 연습문제에서 보여준 것처럼 명령형 스타일의 제약 언어를 표현식 지향 스타일로 변환할 수 있다. Algol, Basic, Pascal과 같이 복합 객체를 다루는 데 빈약한 언어(Pascal 포인터 변수를 명시적으로 사용하지 않는 한)에서는 복합 객체를 조작할 때 대개 명령형 스타일에 갇히게 된다. 표현식 지향 형식의 이점을 감안할 때, 시스템에 명령형 스타일의 절차적 객체를 갖는 이유가 있는지 물을 수 있다. 그 이유는 @ref{3.1.3}에서 논의된 것과 같다: 프로시저가 단지 값을 반환하는 것이 아니라 내부 상태를 가져야 할 때 명령형 스타일이 필요해진다.}
@end quotation
implemented the system in imperative style, as we did in this section.  One
reason is that the non-expression-oriented constraint language provides a
handle on constraint objects (e.g., the value of the @code{adder} procedure) as
well as on connector objects.  This is useful if we wish to extend the system
with new operations that communicate with constraints directly rather than only
indirectly via operations on connectors.  Although it is easy to implement the
expression-oriented style in terms of the imperative implementation, it is very
difficult to do the converse.}
@end quotation

@node	3.4, 3.5, 3.3, Chapter 3
@section 동시성: 시간은 본질적인 요소이다 (Concurrency: Time Is of the Essence)

우리는 모델링 도구로서 지역 상태를 가진 계산 객체의 힘을 보았다.
그러나 @ref{3.1.3}에서 경고했듯이, 이 힘에는 대가가 따른다: 참조 투명성의 상실은 동일성과 변화에 대한 수많은 질문을 야기하고, 평가의 치환 모델을 포기하고 더 복잡한 환경 모델을 선호해야 할 필요성을 낳는다.

상태, 동일성, 그리고 변화의 복잡성 아래에 숨어 있는 중심 문제는 할당을 도입함으로써 우리가 계산 모델에 @newterm{시간(time)}을 받아들이도록 강요받는다는 것이다.
우리가 할당을 도입하기 전에는, 우리의 모든 프로그램은 시간을 초월한 것(timeless)이었다. 어떤 표현식이 값을 갖는다면 항상 같은 값을 갖는다는 의미에서 말이다.
대조적으로, @ref{3.1.1}의 시작 부분에서 소개된, 은행 계좌에서 인출하고 결과 잔액을 반환하는 모델링 예를 상기해 보자:

@example
withdraw(25);
// => 75

withdraw(25);
// => 50
@end example

@noindent
여기서 동일한 표현식의 연속적인 평가는 서로 다른 값을 산출한다.
이 동작은 할당 문(이 경우 변수 @code{balance}에 대한 할당)의 실행이 값이 변하는 @newterm{시간의 순간(moments in time)}을 묘사한다는 사실에서 비롯된다.
표현식을 평가한 결과는 표현식 자체뿐만 아니라 평가가 이 순간들 이전이나 이후에 일어나는지에 따라 달라진다.
지역 상태를 가진 계산 객체의 관점에서 모델을 구축하는 것은 우리가 프로그래밍에서 시간을 필수적인 개념으로 직면하게 만든다.

우리는 물리적 세계에 대한 우리의 인식과 일치하도록 계산 모델을 구조화하는 데 더 나아갈 수 있다.
세상의 객체들은 순차적으로 한 번에 하나씩 변하지 않는다.
오히려 우리는 그것들이 @newterm{동시적으로(concurrently)}---모두 한꺼번에---작용하는 것으로 인식한다.
그래서 시스템을 동시에 실행되는 계산 프로세스들의 컬렉션으로 모델링하는 것이 종종 자연스럽다.
우리가 별도의 지역 상태를 가진 객체들의 관점에서 모델을 조직함으로써 프로그램을 모듈화할 수 있는 것처럼, 계산 모델을 별도로 그리고 동시에 진화하는 부분들로 나누는 것이 종종 적절하다.
비록 프로그램이 순차적인 컴퓨터에서 실행되더라도, 마치 동시에 실행되는 것처럼 프로그램을 작성하는 관행은 프로그래머가 불필요한 타이밍 제약을 피하도록 강요하며 따라서 프로그램을 더 모듈화하게 만든다.

프로그램을 더 모듈화하게 만드는 것 외에도, 동시 계산은 순차 계산보다 속도상의 이점을 제공할 수 있다.
순차 컴퓨터는 한 번에 하나의 연산만 실행하므로, 작업을 수행하는 데 걸리는 시간은 수행된 총 연산 수에 비례한다.@footnote{대부분의 실제 프로세서는 @newterm{파이프라이닝(pipelining)}이라는 전략을 따라 한 번에 몇 가지 연산을 실제로 실행한다. 이 기술은 하드웨어의 효율적인 활용도를 크게 향상시키지만, 순차 프로그램의 동작을 유지하면서 순차 명령어 스트림의 실행 속도를 높이는 데에만 사용된다.}
그러나 문제를 상대적으로 독립적이고 드물게 통신할 필요가 있는 조각들로 분해할 수 있다면, 조각들을 별도의 컴퓨팅 프로세서에 할당하여 사용 가능한 프로세서 수에 비례하는 속도상의 이점을 얻을 수 있을 것이다.

불행히도, 할당에 의해 도입된 복잡성은 동시성이 있을 때 훨씬 더 문제가 된다.
세상이 병렬로 작동하기 때문이든 우리 컴퓨터가 그렇기 때문이든, 동시 실행이라는 사실은 시간에 대한 우리의 이해에 추가적인 복잡성을 수반한다.

@menu
* 3.4.1::            The Nature of Time in Concurrent Systems
* 3.4.2::            Mechanisms for Controlling Concurrency
* 3.4.3::            Fearless Concurrency
* 3.4.5::            Async/Await
@end menu

@node	3.4.1, 3.4.2, 3.4, 3.4
@subsection 동시성 시스템에서 시간의 성질 (The Nature of Time in Concurrent Systems)

표면적으로 시간은 간단해 보인다. 그것은 사건들에 부과된 순서이다.@footnote{케임브리지 건물 벽에서 본 낙서를 인용하자면: ``시간은 모든 것이 한꺼번에 일어나는 것을 막기 위해 발명된 장치이다.''}
어떤 사건 @math{A}와 @math{B}에 대해서도, @math{A}가 @math{B}보다 먼저 일어나거나, @math{A}와 @math{B}가 동시에 일어나거나, 또는 @math{A}가 @math{B}보다 나중에 일어난다.
예를 들어, 은행 계좌 예제로 돌아가서, Peter가 처음에 $100가 있는 공동 계좌에서 $10를 인출하고 Paul이 $25를 인출하여 계좌에 $65가 남는다고 가정하자.
두 인출의 순서에 따라, 계좌 잔액의 시퀀스는 $100 @math{\to} $90 @math{\to} $65 이거나 $100 @math{\to} $75 @math{\to} $65이다.
은행 시스템의 컴퓨터 구현에서, 이 변화하는 잔액 시퀀스는 변수 @code{balance}에 대한 연속적인 할당으로 모델링될 수 있다.

그러나 복잡한 상황에서는 그러한 관점이 문제가 될 수 있다.
Peter와 Paul, 그리고 그 외의 사람들이 전 세계에 분산된 은행 기계 네트워크를 통해 동일한 은행 계좌에 접근하고 있다고 가정하자.
계좌의 실제 잔액 시퀀스는 접근의 세부적인 타이밍과 기계 간 통신의 세부 사항에 결정적으로 의존할 것이다.

이 사건 순서의 불확정성은 동시성 시스템의 설계에 심각한 문제를 제기할 수 있다.
예를 들어, Peter와 Paul이 수행한 인출이 공통 변수 @code{balance}를 공유하는 두 개의 별도 프로세스로 구현되고, 각 프로세스가 @ref{3.1.1}에 주어진 프로시저에 의해 지정된다고 가정하자:

@example
use std::sync::Mutex;

static BALANCE: Mutex<i64> = Mutex::new(100);

fn withdraw(amount: i64) -> Result<i64, &'static str> @{
    let mut balance = BALANCE.lock().unwrap();
    if *balance >= amount @{
        *balance -= amount;
        Ok(*balance)
    @} else @{
        Err("잔액 부족 (Insufficient funds)")
    @}
@}
@end example

@noindent
만약 두 프로세스가 독립적으로 작동한다면, Peter는 잔액을 확인하고 합법적인 금액을 인출하려고 시도할 수 있다.
그러나 Paul은 Peter가 잔액을 확인한 시간과 Peter가 인출을 완료한 시간 사이에 자금을 인출하여 Peter의 확인을 무효화할 수 있다.

상황은 더 나빠질 수 있다. 다음 표현식을 고려해 보자

@example
*balance -= amount;
@end example

@noindent
이것은 각 인출 프로세스의 일부로서 실행된다. 이것은 세 단계로 구성된다: (1) @code{balance} 변수의 값에 접근한다; (2) 새 잔액을 계산한다; (3) @code{balance}를 이 새 값으로 설정한다.
만약 Peter와 Paul의 인출이 이 문장을 동시에 실행한다면, 두 인출은 그들이 @code{balance}에 접근하고 그것을 새 값으로 설정하는 순서를 @newterm{교차(interleave)}시킬 수 있다.

@noindent
@ref{Figure 3.29}의 타이밍 다이어그램은 @code{balance}가 100에서 시작하고, Peter가 10을 인출하고, Paul이 25를 인출하는데도 @code{balance}의 최종 값이 75가 되는 사건 순서를 묘사한다.
다이어그램에 표시된 것처럼, 이 이상 현상의 이유는 75를 @code{balance}에 할당하는 Paul의 작업이 감소될 @code{balance}의 값이 100이라는 가정하에 이루어졌기 때문이다.
그러나 그 가정은 Peter가 @code{balance}를 90으로 변경했을 때 무효가 되었다.
이것은 은행 시스템에 있어 재앙적인 실패인데, 왜냐하면 시스템의 총액이 보존되지 않기 때문이다.
거래 전에는 총액이 $100였다. 그 후에는 Peter가 $10, Paul이 $25, 그리고 은행이 $75를 갖는다.@footnote{만약 두 @code{set!} 연산이 동시에 잔액을 변경하려고 시도한다면 이 시스템에 더 나쁜 실패가 발생할 수 있다. 이 경우 메모리에 나타나는 실제 데이터는 두 프로세스가 쓴 정보의 무작위 조합이 될 수 있다. 대부분의 컴퓨터는 그러한 동시 접근을 방지하는 원시 메모리 쓰기 연산에 대한 인터록(interlocks)을 가지고 있다. 그러나 이 겉보기에 단순한 종류의 보호조차도 다중 처리 컴퓨터의 설계에서 구현상의 도전 과제를 제기한다. 여기서는 메모리 접근 속도를 높이기 위해 데이터가 다른 프로세서들 사이에 복제(``캐시'')될 수 있다는 사실에도 불구하고, 다양한 프로세서가 메모리 내용에 대한 일관된 뷰를 유지하도록 보장하기 위해 정교한 @newterm{캐시 일관성(cache-coherence)} 프로토콜이 필요하다.}

@float
@anchor{Figure 3.29}
@ifinfo
@strong{Figure 3.29:} 두 은행 인출의 사건 순서가 교차될 때 어떻게 잘못된 최종 잔액으로 이어질 수 있는지 보여주는 타이밍 다이어그램.

@example
 |           Peter              Bank              Paul
 |                              ____
 |                             /    \
 |             .--------------| $100 |-------------.
 |             |               \____/              |
 |             V                                   V
 |  .----------------------.            .----------------------.           
 |  | Access balance: $100 |            | Access balance: $100 |
 |  `----------+-----------'            `----------+-----------'
 |             V                                   V
 |  .----------------------.            .----------------------.           
 |  | new value: 100-10=90 |            | new value: 100-25=75 |
 |  `----------+-----------'            `----------+-----------'
 |             V                                   |
 |  .----------------------.                       |
 |  | balance.set(90)      |                       |
 |  `----------+-----------'    ____               |
 |             |               /    \              |
 |             `------------->| $ 90 |             V
 |                             \____/   .----------------------.
 |                                      | new value: 100-25=75 |
 |                              ____    `----------+-----------'
 |                             /    \              |
 |                            | $ 90 |<------------'
 V                             \____/
time
@end example
@end ifinfo
@iftex
@image{fig/chap3/Fig3.29b,147mm,,,.std.svg}
@caption{@strong{Figure 3.29:} 두 은행 인출의 사건 순서가 교차될 때 어떻게 잘못된 최종 잔액으로 이어질 수 있는지 보여주는 타이밍 다이어그램.}
@end iftex
@end float

여기서 설명된 일반적인 현상은 여러 프로세스가 공통 상태 변수를 공유할 수 있다는 것이다.
이것을 복잡하게 만드는 것은 하나 이상의 프로세스가 동시에 공유 상태를 조작하려고 시도할 수 있다는 것이다.
은행 계좌 예제의 경우, 각 거래 동안 각 고객은 마치 다른 고객이 존재하지 않는 것처럼 행동할 수 있어야 한다.
고객이 잔액에 의존하는 방식으로 잔액을 변경할 때, 그는 변경의 순간 직전에 잔액이 여전히 그가 생각했던 것과 같다고 가정할 수 있어야 한다.

@subsubheading 동시성 프로그램의 올바른 동작 (Correct behavior of concurrent programs)

위의 예제는 동시성 프로그램에 몰래 들어갈 수 있는 미묘한 버그의 전형이다.
이 복잡성의 근원은 다른 프로세스들 사이에 공유되는 변수에 대한 할당에 있다.
우리는 이미 @code{set!}을 사용하는 프로그램을 작성할 때 주의해야 함을 알고 있는데, 왜냐하면 계산 결과가 할당이 일어나는 순서에 따라 달라지기 때문이다.@footnote{@ref{3.1.3}의 팩토리얼 프로그램은 단일 순차 프로세스에 대해 이것을 보여준다.}
동시성 프로세스에서는 할당에 대해 특히 주의해야 한다. 왜냐하면 우리는 다른 프로세스들에 의해 수행되는 할당의 순서를 제어할 수 없을지도 모르기 때문이다.
만약 그러한 변경들이 동시에 일어날 수 있다면(공동 계좌에 접근하는 두 예금자처럼), 우리는 우리 시스템이 올바르게 동작하도록 보장할 어떤 방법이 필요하다.
예를 들어, 공동 은행 계좌에서 인출하는 경우, 우리는 돈이 보존되도록 보장해야 한다.
동시성 프로그램이 올바르게 동작하도록 만들기 위해, 우리는 동시 실행에 어떤 제한을 두어야 할 수도 있다.

@noindent
동시성에 대한 한 가지 가능한 제한은 공유 상태 변수를 변경하는 어떤 두 연산도 동시에 일어날 수 없다고 규정하는 것이다.
이것은 매우 엄격한 요구 사항이다.
분산 뱅킹의 경우, 시스템 설계자는 한 번에 하나의 거래만 진행될 수 있도록 보장해야 할 것이다.
이것은 비효율적이고 지나치게 보수적일 것이다.
@ref{Figure 3.30}은 Peter와 Paul이 은행 계좌를 공유하고 있으며, Paul이 개인 계좌도 가지고 있는 경우를 보여준다.
다이어그램은 공유 계좌에서의 두 번의 인출(Peter가 한 번, Paul이 한 번)과 Paul의 개인 계좌로의 입금을 보여준다.@footnote{열은 각 인출(W)과 입금(D) 전후의 Peter의 지갑, 공동 계좌(Bank1), Paul의 지갑, 그리고 Paul의 개인 계좌(Bank2) 내용을 보여준다. Peter는 Bank1에서 $10를 인출한다; Paul은 Bank2에 $5를 입금한 다음 Bank1에서 $25를 인출한다.}
공유 계좌에서의 두 인출은 동시에 일어나서는 안 되며(둘 다 같은 계좌에 접근하고 업데이트하므로), Paul의 입금과 인출은 동시에 일어나서는 안 된다(둘 다 Paul의 지갑에 있는 금액에 접근하고 업데이트하므로).
하지만 Paul의 개인 계좌로의 입금이 Peter의 공유 계좌 인출과 동시에 진행되는 것을 허용하는 데는 아무런 문제가 없어야 한다.

@float
@anchor{Figure 3.30}
@ifinfo
@strong{Figure 3.30:} Bank1의 공동 계좌와 Bank2의 개인 계좌에서의 동시 입금 및 인출.

@example
 |    Peter          Bank1          Paul           Bank2
 |    ____           ____           ____           ____  
 |   /    \         /    \         /    \         /    \ 
 |  |  $7  |--. .--| $100 |       |  $5  |--. .--| $300 |
 |   \____/   V V   \____/         \____/   V V   \____/ 
 |           +---+                         +---+         
 |           | W |                         | D |         
 |    ____   ++-++   ____           ____   ++-++   ____  
 |   /    \   | |   /    \         /    \   | |   /    \ 
 |  | $17  |<-' `->| $90  |--. .--|  $0  |<-' `->| $305 |
 |   \____/         \____/   V V   \____/         \____/ 
 |                          +---+
 |                          | W |
 |    ____           ____   ++-++   ____           ____  
 |   /    \         /    \   | |   /    \         /    \ 
 |  | $17  |       | $65  |<-' `->| $25  |       | $305 |
 |   \____/         \____/         \____/         \____/ 
 V
time
@end example
@end ifinfo
@iftex
@image{fig/chap3/Fig3.30c,147mm,,,.std.svg}
@caption{@strong{Figure 3.30:} Bank1의 공동 계좌와 Bank2의 개인 계좌에서의 동시 입금 및 인출.}
@end iftex
@end float

동시성에 대한 덜 엄격한 제한은 동시성 시스템이 프로세스들이 어떤 순서로 순차적으로 실행된 것과 같은 결과를 생성하도록 보장하는 것이다.
이 요구 사항에는 두 가지 중요한 측면이 있다.
첫째, 프로세스들이 실제로 순차적으로 실행될 것을 요구하지 않으며, 단지 마치 그들이 순차적으로 실행된 @emph{것처럼(as if)} 동일한 결과를 생성하기만 하면 된다.
@ref{Figure 3.30}의 예에서, 은행 계좌 시스템 설계자는 Paul의 입금과 Peter의 인출이 동시에 일어나는 것을 안전하게 허용할 수 있다. 왜냐하면 순 결과는 두 연산이 순차적으로 일어난 것과 같을 것이기 때문이다.
둘째, 동시성 프로그램에 의해 생성된 ``올바른'' 결과가 하나 이상 있을 수 있다. 왜냐하면 우리는 결과가 @emph{어떤} 순차적 순서에 대한 것과 같기만을 요구하기 때문이다.
예를 들어, Peter와 Paul의 공동 계좌가 $100로 시작하고, Peter가 $40를 입금하는 동안 Paul이 동시에 계좌 돈의 절반을 인출한다고 가정하자.
그러면 순차적 실행은 계좌 잔액이 $70 또는 $90가 되는 결과를 낳을 수 있다(@ref{Exercise 3.38} 참조).@footnote{@anchor{Footnote 167} 이 아이디어를 표현하는 더 형식적인 방법은 동시성 프로그램이 본질적으로 비결정론적(nondeterministic)이라고 말하는 것이다. 즉, 주어진 입력에 대해 하나 이상의 다른 결과를 가질 수 있다.}
어떤 순차적 실행과도 일치하지 않는 결과가 없다면 시스템은 올바른 것이다.

@quotation
@strong{@anchor{Exercise 3.38}연습문제 3.38:} Peter, Paul, 그리고 Mary가 $100가 있는 공동 은행 계좌를 공유한다고 가정하자.
동시성 행동을 정의하기 위해, 우리는 그들의 거래를 모델링하는 세 개의 독립된 프로세스(함수)를 생성할 수 있다:

@example
// Peter:
balance = balance + 10;
// Paul:
balance = balance - 20;
// Mary:
balance = balance - (balance / 2);
@end example

@enumerate a
@item
프로세스들이 어떤 순서로 순차적으로 실행된다면 이 세 거래 후 @code{balance}에 대해 가능한 모든 값을 나열하라.

@item
시스템이 프로세스들이 임의로 교차하는 것을 허용한다면 다른 어떤 값들이 생성될 수 있는가?
이것이 어떻게 일어날 수 있는지 설명하기 위해 타이밍 다이어그램을 그려라.
@end enumerate
@end quotation
@newterm{nondeterministic}. That is, they are described not by single-valued
functions, but by functions whose results are sets of possible values.  In
@ref{4.3} we will study a language for expressing nondeterministic
computations.}

There are still weaker requirements for correct execution of concurrent
programs.  A program for simulating diffusion (say, the flow of heat in an
object) might consist of a large number of processes, each one representing a
small volume of space, that update their values concurrently.  Each process
repeatedly changes its value to the average of its own value and its neighbors'
values.  This algorithm converges to the right answer independent of the order
in which the operations are done; there is no need for any restrictions on
concurrent use of the shared values.

@quotation
@strong{@anchor{Exercise 3.38}Exercise 3.38:} Suppose that Peter, Paul, and
Mary share a joint bank account that initially contains $100.  Concurrently,
Peter deposits $10, Paul withdraws $20, and Mary withdraws half the money in
the account, by executing the following commands:

@example
// Using AtomicI64 for shared mutable state:
Peter: balance.fetch_add(10, Ordering::SeqCst);
Paul:  balance.fetch_sub(20, Ordering::SeqCst);
Mary:  let cur = balance.load(Ordering::SeqCst);
       balance.store(cur - cur / 2, Ordering::SeqCst);
@end example

@enumerate a

@item
List all the different possible values for @code{balance} after these three
transactions have been completed, assuming that the banking system forces the
three processes to run sequentially in some order.

@item
What are some other values that could be produced if the system allows the
processes to be interleaved?  Draw timing diagrams like the one in @ref{Figure 3.29} 
to explain how these values can occur.

@end enumerate
@end quotation

@node	3.4.2, 3.4.3, 3.4.1, 3.4
@subsection Mechanisms for Controlling Concurrency

We've seen that the difficulty in dealing with concurrent processes is rooted
in the need to consider the interleaving of the order of events in the
different processes.  For example, suppose we have two processes, one with
three ordered events @math{{(a, b, c)}} and one with three ordered events
@math{{(x, y, z)}}.  If the two processes run concurrently, with no
constraints on how their execution is interleaved, then there are 20 different
possible orderings for the events that are consistent with the individual
orderings for the two processes:

@example
(a,b,c,x,y,z)  (a,x,b,y,c,z)  (x,a,b,c,y,z)  
(x,a,y,z,b,c)  (a,b,x,c,y,z)  (a,x,b,y,z,c)  
(x,a,b,y,c,z)  (x,y,a,b,c,z)  (a,b,x,y,c,z)  
(a,x,y,b,c,z)  (x,a,b,y,z,c)  (x,y,a,b,z,c)
(a,b,x,y,z,c)  (a,x,y,b,z,c)  (x,a,y,b,c,z)  
(x,y,a,z,b,c)  (a,x,b,c,y,z)  (a,x,y,z,b,c)  
(x,a,y,b,z,c)  (x,y,z,a,b,c)
@end example

@noindent
As programmers designing this system, we would have to consider the effects of
each of these 20 orderings and check that each behavior is acceptable.  Such an
approach rapidly becomes unwieldy as the numbers of processes and events
increase.

A more practical approach to the design of concurrent systems is to devise
general mechanisms that allow us to constrain the interleaving of concurrent
processes so that we can be sure that the program behavior is correct.  Many
mechanisms have been developed for this purpose.  In this section, we describe
one of them, the @newterm{serializer}.

@subsubheading 공유 상태에 대한 접근 직렬화 (Serializing access to shared state)

직렬화는 다음 아이디어를 구현한다: 프로세스들은 동시에 실행되지만, 동시에 실행될 수 없는 특정 프로시저 컬렉션들이 있다.
더 정확하게는, 직렬화는 각 직렬화된 집합 내의 프로시저가 한 번에 하나만 실행되도록 허용되는 구별된 프로시저 집합을 생성한다.
집합 내의 어떤 프로시저가 실행 중이면, 집합 내의 어떤 프로시저라도 실행하려고 시도하는 프로세스는 첫 번째 실행이 완료될 때까지 기다려야 한다.

우리는 공유 변수에 대한 접근을 제어하기 위해 직렬화를 사용할 수 있다.
예를 들어, 공유 변수의 이전 값에 기초하여 공유 변수를 업데이트하려면, 변수의 이전 값에 대한 접근과 변수에 대한 새 값의 할당을 동일한 프로시저에 넣는다.
그런 다음 우리는 동일한 직렬화기로 이 모든 프로시저를 직렬화함으로써 변수에 할당하는 다른 어떤 프로시저도 이 프로시저와 동시에 실행될 수 없도록 보장한다.
이것은 접근과 해당 할당 사이에 변수의 값이 변경될 수 없음을 보장한다.

@subsubheading Scheme의 직렬화기 (Serializers in Scheme)

위의 메커니즘을 더 구체적으로 만들기 위해, 우리가 Scheme을 확장하여 병렬 실행 프로시저를 포함했다고 가정하자:

@example
// Rust의 std::thread는 병렬 실행을 제공한다:
use std::thread;

let handles: Vec<_> = vec![p1, p2, /* ... */ pk]
    .into_iter()
    .map(|p| thread::spawn(p))
    .collect();

for h in handles @{
    h.join().unwrap();
@}
@end example

@noindent
각 @code{⟨}@var{p}@code{⟩}는 인자가 없는 프로시저여야 한다. @code{parallel-execute}는 각 @code{⟨}@var{p}@code{⟩}에 대해 별도의 프로세스를 생성하며, 이는 @code{⟨}@var{p}@code{⟩}를 (인자 없이) 적용한다. 이 프로세스들은 모두 동시에 실행된다.@footnote{@code{Parallel-execute}는 표준 Scheme의 일부가 아니지만, @abbr{MIT} Scheme에서 구현될 수 있다. 우리의 구현에서, 새로운 동시성 프로세스들은 또한 원래 Scheme 프로세스와 동시에 실행된다. 또한, 우리 구현에서 @code{parallel-execute}에 의해 반환된 값은 새로 생성된 프로세스들을 중단하는 데 사용될 수 있는 특별한 제어 객체이다.}

이것이 어떻게 사용되는지에 대한 예로, 다음을 고려해 보자

@noindent
Rust의 타입 시스템은 컴파일 타임에 데이터 레이스를 방지한다:
@example
use std::sync::@{Arc, Mutex@};
use std::thread;

let x = Arc::new(Mutex::new(10_i64));
let x1 = Arc::clone(&x);
let x2 = Arc::clone(&x);

let h1 = thread::spawn(move || @{
    let mut val = x1.lock().unwrap();
    *val = *val * *val;  // Mutex는 배타적 접근을 보장한다
@});

let h2 = thread::spawn(move || @{
    let mut val = x2.lock().unwrap();
    *val += 1;
@});

h1.join().unwrap();
h2.join().unwrap();
// 결과는 항상 101 또는 121이다 - 레이스 컨디션 없음!
@end example

@noindent
이것은 두 개의 동시성 프로세스를 생성한다---@math{P_1}은 @code{x}를 @code{x} 곱하기 @code{x}로 설정하고, @math{P_2}는 @code{x}를 증가시킨다.
실행이 완료된 후, @code{x}는 @math{P_1}과 @math{P_2}의 이벤트 교차에 따라 다섯 가지 가능한 값 중 하나를 갖게 될 것이다:

@example
101: @math{P_1}이 @code{x}를 100으로 설정하고 그 다음 @math{P_2}가
     @code{x}를 101로 증가시킨다.
121: @math{P_2}가 @code{x}를 11로 증가시키고 그 다음 @math{P_1}이
     @code{x}를 @code{x} 곱하기 @code{x}로 설정한다.
110: @math{P_2}가 @math{P_1}이 @code{(* x x)} 평가 중에 @code{x}의
     값에 접근하는 두 시점 사이에 @code{x}를 10에서 11로 변경한다.
 11: @math{P_2}가 @code{x}에 접근하고, 그 다음 @math{P_1}이 @code{x}를
     100으로 설정하고, 그 다음 @math{P_2}가 @code{x}를 설정한다.
100: @math{P_1}이 @code{x}에 (두 번) 접근하고, 그 다음 @math{P_2}가
     @code{x}를 11로 설정하고, 그 다음 @math{P_1}이 @code{x}를 설정한다.
@end example

@noindent
우리는 @newterm{직렬화기(serializers)}에 의해 생성된 직렬화된 프로시저를 사용하여 동시성을 제한할 수 있다.
직렬화기는 @code{Mutex::new}에 의해 구성되는데, 그 구현은 아래에 주어져 있다.
직렬화기는 프로시저를 인자로 받아 원래 프로시저처럼 동작하는 직렬화된 프로시저를 반환한다.
주어진 직렬화기에 대한 모든 호출은 동일한 집합 내의 직렬화된 프로시저를 반환한다.

따라서 위의 예제와 대조적으로, 다음을 실행하면

@example
use std::sync::@{Arc, Mutex@};
use std::thread;

let x = Arc::new(Mutex::new(10_i64));
let x1 = Arc::clone(&x);
let x2 = Arc::clone(&x);

// Mutex가 직렬화기 역할을 한다
let h1 = thread::spawn(move || @{
    let mut val = x1.lock().unwrap();
    *val = *val * *val;
@});

let h2 = thread::spawn(move || @{
    let mut val = x2.lock().unwrap();
    *val += 1;
@});

h1.join().unwrap();
h2.join().unwrap();
// 101 또는 121만 가능 - 직렬화된 접근!
@end example

@noindent
@code{x}에 대해 오직 두 가지 가능한 값, 101 또는 121만 생성할 수 있다.
다른 가능성들은 제거되는데, 왜냐하면 @math{P_1}과 @math{P_2}의 실행이 교차될 수 없기 때문이다.

다음은 입금과 인출이 직렬화된, @ref{3.1.1}의 @code{make-account} 프로시저 버전이다:

@example
use std::sync::Mutex;

struct Account @{
    balance: Mutex<i64>,
@}

impl Account @{
    fn new(initial_balance: i64) -> Self @{
        Account @{ balance: Mutex::new(initial_balance) @}
    @}

    fn withdraw(&self, amount: i64) -> Result<i64, &'static str> @{
        let mut balance = self.balance.lock().unwrap();
        if *balance >= amount @{
            *balance -= amount;
            Ok(*balance)
        @} else @{
            Err("잔액 부족 (Insufficient funds)")
        @}
    @}

    fn deposit(&self, amount: i64) -> i64 @{
        let mut balance = self.balance.lock().unwrap();
        *balance += amount;
        *balance
    @}

    fn get_balance(&self) -> i64 @{
        *self.balance.lock().unwrap()
    @}
@}
@end example

@noindent
이 구현으로, 두 프로세스는 단일 계좌에서 동시에 인출하거나 입금할 수 없다.
이것은 Peter가 Paul이 새 값을 계산하기 위해 잔액에 접근한 시간과 Paul이 실제로 할당을 수행한 시간 사이에 계좌 잔액을 변경하는 @ref{Figure 3.29}에 묘사된 오류의 원인을 제거한다.
반면에, 각 계좌는 자체 직렬화기를 가지고 있으므로, 서로 다른 계좌에 대한 입금과 인출은 동시에 진행될 수 있다.

@quotation
@strong{@anchor{Exercise 3.39}Exercise 3.39:} Which of the five possibilities
in the parallel execution shown above remain if we instead serialize execution
as follows:

@example
use std::sync::@{Arc, Mutex@};
use std::thread;

let x = Arc::new(Mutex::new(10_i64));
let x1 = Arc::clone(&x);
let x2 = Arc::clone(&x);

// Only the inner computation is serialized for thread 1
let h1 = thread::spawn(move || @{
    let square = @{
        let val = x1.lock().unwrap();
        *val * *val
    @};  // Lock released here
    let mut val = x1.lock().unwrap();
    *val = square;
@});

// Thread 2 is fully serialized
let h2 = thread::spawn(move || @{
    let mut val = x2.lock().unwrap();
    *val += 1;
@});
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 3.40}Exercise 3.40:} Give all possible values of
@code{x} that can result from executing

@example
// Without serialization - many possible outcomes
let x = Arc::new(AtomicI64::new(10));
let x1 = Arc::clone(&x);
let x2 = Arc::clone(&x);

thread::spawn(move || @{
    let val = x1.load(Ordering::SeqCst);
    x1.store(val * val, Ordering::SeqCst);
@});

thread::spawn(move || @{
    let val = x2.load(Ordering::SeqCst);
    x2.store(val * val * val, Ordering::SeqCst);
@});
@end example

Which of these possibilities remain if we instead use serialized procedures:

@example
// With Mutex serialization - only 100 or 1000000 possible
let x = Arc::new(Mutex::new(10_i64));
let x1 = Arc::clone(&x);
let x2 = Arc::clone(&x);

thread::spawn(move || @{
    let mut val = x1.lock().unwrap();
    *val = *val * *val;
@});

thread::spawn(move || @{
    let mut val = x2.lock().unwrap();
    *val = *val * *val * *val;
@});
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 3.41}Exercise 3.41:} Ben Bitdiddle worries that it
would be better to implement the bank account as follows (where the commented
line has been changed):

@example
use std::sync::Mutex;

struct Account @{
    balance: Mutex<i64>,
@}

impl Account @{
    fn new(initial: i64) -> Self @{
        Account @{ balance: Mutex::new(initial) @}
    @}

    fn withdraw(&self, amount: i64) -> Result<i64, &'static str> @{
        let mut balance = self.balance.lock().unwrap();
        if *balance >= amount @{
            *balance -= amount;
            Ok(*balance)
        @} else @{
            Err("Insufficient funds")
        @}
    @}

    fn deposit(&self, amount: i64) -> i64 @{
        let mut balance = self.balance.lock().unwrap();
        *balance += amount;
        *balance
    @}

    fn get_balance(&self) -> i64 @{
        // Also serialized - locks the mutex
        *self.balance.lock().unwrap()
    @}
@}
@end example

@noindent
직렬화되지 않은 은행 잔액 접근을 허용하면 이상 동작이 발생할 수 있기 때문이라고 한다.
동의하는가? Ben의 우려를 보여주는 시나리오가 있는가?
@end quotation

@quotation
@strong{@anchor{Exercise 3.42}연습문제 3.42:} Ben Bitdiddle은 모든 @code{withdraw}와 @code{deposit} 메시지에 대한 응답으로 새로운 직렬화된 프로시저를 생성하는 것은 시간 낭비라고 제안한다.
그는 @code{Account::new}를 변경하여 @code{protected}에 대한 호출이 @code{dispatch} 프로시저 외부에서 수행되도록 할 수 있다고 말한다.
즉, 계좌는 인출 프로시저를 요청받을 때마다 동일한 직렬화된 프로시저(계좌와 동시에 생성된)를 반환할 것이다.

@example
// Rust에서 Mutex 자체는 직렬화를 제공한다.
// 생성 시 래퍼 메서드를 만드는 것과 필요할 때 만드는 것 사이에는 차이가 없다
// - 둘 다 모든 연산을 직렬화하는 동일한 Mutex에 접근한다.

struct Account @{
    balance: Mutex<i64>,
@}

impl Account @{
    fn new(initial: i64) -> Self @{
        Account @{ balance: Mutex::new(initial) @}
    @}

    // 이 메서드들은 명시적 직렬화가 필요하지 않다 -
    // Mutex 락이 자동으로 제공한다
    fn withdraw(&self, amount: i64) -> Result<i64, &'static str> @{
        let mut balance = self.balance.lock().unwrap();
        if *balance >= amount @{
            *balance -= amount;
            Ok(*balance)
        @} else @{
            Err("잔액 부족 (Insufficient funds)")
        @}
    @}

    fn deposit(&self, amount: i64) -> i64 @{
        let mut balance = self.balance.lock().unwrap();
        *balance += amount;
        *balance
    @}
@}
@end example

이것은 안전한 변경인가? 특히, @code{Account::new}의 이 두 버전이 허용하는 동시성에 차이가 있는가?
@end quotation

@subsubheading 다중 공유 자원 사용의 복잡성 (Complexity of using multiple shared resources)

직렬화기는 동시성 프로그램의 복잡성을 격리하여 신중하고 (바라건대) 올바르게 처리할 수 있도록 돕는 강력한 추상화를 제공한다.
그러나 단일 공유 자원(예: 단일 은행 계좌)만 있는 경우 직렬화기를 사용하는 것이 비교적 간단한 반면, 다중 공유 자원이 있을 때 동시성 프로그래밍은 위험할 정도로 어려울 수 있다.

발생할 수 있는 어려움 중 하나를 설명하기 위해, 두 은행 계좌의 잔액을 교환(swap)하고 싶다고 가정하자.
우리는 각 계좌에 접근하여 잔액을 찾고, 잔액 간의 차이를 계산하고, 한 계좌에서 이 차이를 인출하여 다른 계좌에 입금한다.
우리는 이것을 다음과 같이 구현할 수 있다:@footnote{우리는 @code{deposit} 메시지가 음수 금액을 허용한다는 사실을 이용하여 @code{exchange}를 단순화했다. (이것은 우리 은행 시스템의 심각한 버그이다!)}

@example
fn exchange(account1: &Account, account2: &Account) @{
    let difference = account1.get_balance() - account2.get_balance();
    account1.withdraw(difference).ok();
    account2.deposit(difference);
@}
@end example

@noindent
이 프로시저는 단일 프로세스만 교환을 시도할 때는 잘 작동한다.
그러나 Peter와 Paul이 모두 계좌 @math{{a1}}, @math{{a2}}, @math{{a3}}에 접근할 수 있고, Peter가 @math{{a1}}과 @math{{a2}}를 교환하는 동안 Paul이 동시에 @math{{a1}}과 @math{{a3}}를 교환한다고 가정해 보자.
개별 계좌에 대해 계좌 입금과 인출이 직렬화되어 있더라도(이 절의 앞부분에 나온 @code{Account::new} 프로시저처럼), @code{exchange}는 여전히 잘못된 결과를 생성할 수 있다.
예를 들어, Peter가 @math{{a1}}과 @math{{a2}}의 잔액 차이를 계산할 수 있지만, Peter가 교환을 완료하기 전에 Paul이 @math{{a1}}의 잔액을 변경할 수 있다.@footnote{계좌 잔액이 $10, $20, $30으로 시작한다면, 동시 교환이 몇 번 일어나더라도 잔액은 어떤 순서로든 여전히 $10, $20, $30이어야 한다. 개별 계좌에 대한 입금을 직렬화하는 것만으로는 이것을 보장하기에 충분하지 않다. @ref{Exercise 3.43}을 참조하라.}
올바른 동작을 위해, 우리는 @code{exchange} 프로시저가 교환 전체 시간 동안 계좌에 대한 다른 어떤 동시 접근도 차단(lock out)하도록 조정해야 한다.

우리가 이것을 달성할 수 있는 한 가지 방법은 두 계좌의 직렬화기를 사용하여 전체 @code{exchange} 프로시저를 직렬화하는 것이다.
이를 위해, 우리는 계좌의 직렬화기에 접근하도록 조정할 것이다.
우리가 직렬화기를 노출함으로써 은행 계좌 객체의 모듈성을 의도적으로 깨고 있음에 주목하라.
다음 버전의 @code{Account::new}는 @ref{3.1.1}에 주어진 원본 버전과 동일하지만, 잔액 변수를 보호하기 위해 직렬화기가 제공되고, 직렬화기가 메시지 전달을 통해 내보내진다는 점이 다르다:

@example
use std::sync::@{Arc, Mutex@};

// 외부 직렬화를 위해 락을 노출하는 계좌
struct AccountWithSerializer @{
    balance: Arc<Mutex<i64>>,
@}

impl AccountWithSerializer @{
    fn new(initial_balance: i64) -> Self @{
        AccountWithSerializer @{
            balance: Arc::new(Mutex::new(initial_balance)),
        @}
    @}

    fn withdraw(&self, amount: i64) -> Result<i64, &'static str> @{
        let mut balance = self.balance.lock().unwrap();
        if *balance >= amount @{
            *balance -= amount;
            Ok(*balance)
        @} else @{
            Err("Insufficient funds")
        @}
    @}

    fn deposit(&self, amount: i64) -> i64 @{
        let mut balance = self.balance.lock().unwrap();
        *balance += amount;
        *balance
    @}

    fn get_balance(&self) -> i64 @{
        *self.balance.lock().unwrap()
    @}

    // 외부 직렬화를 위해 락 노출
    fn serializer(&self) -> Arc<Mutex<i64>> @{
        Arc::clone(&self.balance)
    @}
@}
@end example
    @}

    // Expose the lock for external serialization
    fn serializer(&self) -> Arc<Mutex<i64>> @{
        Arc::clone(&self.balance)
    @}
@}
@end example

@noindent
우리는 이것을 사용하여 직렬화된 입금과 인출을 수행할 수 있다.
그러나 우리의 초기 직렬화된 계좌와 달리, 이제 은행 계좌 객체의 각 사용자가 다음과 같이 직렬화를 명시적으로 관리할 책임이 있다:@footnote{@ref{Exercise 3.45}는 왜 입금과 인출이 더 이상 계좌에 의해 자동으로 직렬화되지 않는지 조사한다.}

@example
// Rust에서 Mutex는 이미 접근을 직렬화하므로, deposit은
// 동시 연산이 완료될 때까지 자동으로 대기한다.
fn deposit(account: &AccountWithSerializer, amount: i64) -> i64 @{
    account.deposit(amount)  // 내부적으로 락을 획득한다
@}
@end example

@noindent
직렬화기를 이런 식으로 내보내면 직렬화된 교환 프로그램을 구현할 만큼 충분한 유연성을 얻게 된다.
우리는 단순히 두 계좌의 직렬화기로 원래 @code{exchange} 프로시저를 직렬화한다:

@example
// 직렬화된 교환: 교환하기 전에 두 락을 모두 획득
fn serialized_exchange(
    account1: &AccountWithSerializer,
    account2: &AccountWithSerializer,
) @{
    // 두 계좌를 모두 잠금 (데드락을 피하기 위해 신중한 순서로)
    let (lock1, lock2) = if Arc::as_ptr(&account1.balance)
        < Arc::as_ptr(&account2.balance)
    @{
        (account1.balance.lock().unwrap(),
         account2.balance.lock().unwrap())
    @} else @{
        let l2 = account2.balance.lock().unwrap();
        let l1 = account1.balance.lock().unwrap();
        (l1, l2)
    @};

    // 두 락을 보유한 채로 교환 수행
    let difference = *lock1 - *lock2;
    drop(lock1);
    drop(lock2);

    account1.withdraw(difference).ok();
    account2.deposit(difference);
@}
@end example

@quotation
@strong{@anchor{Exercise 3.43}연습문제 3.43:} 세 계좌의 잔액이 $10, $20, $30으로 시작하고, 여러 프로세스가 실행되어 계좌의 잔액을 교환한다고 가정하자.
프로세스들이 순차적으로 실행된다면, 동시 교환 횟수에 관계없이 계좌 잔액은 어떤 순서로든 $10, $20, $30이어야 한다고 주장하라.
@ref{Figure 3.29}와 같은 타이밍 다이어그램을 그려서, 교환이 이 절의 첫 번째 버전의 계좌 교환 프로그램을 사용하여 구현될 경우 이 조건이 어떻게 위반될 수 있는지 보여라.
반면에, 이 @code{exchange} 프로그램으로도 계좌 잔액의 합계는 보존될 것이라고 주장하라.
만약 우리가 개별 계좌에 대한 거래를 직렬화하지 않았다면 이 조건조차 어떻게 위반될지 보여주는 타이밍 다이어그램을 그려라.
@end quotation

@quotation
@strong{@anchor{Exercise 3.44}연습문제 3.44:} 한 계좌에서 다른 계좌로 금액을 이체하는 문제를 고려해 보자.
Ben Bitdiddle은 입금과 인출 거래를 직렬화하는 계좌 메커니즘(예: 위 텍스트의 @code{Account::new} 버전)을 사용한다면, 여러 사람이 여러 계좌 간에 돈을 동시에 이체하더라도 다음 프로시저로 이체를 달성할 수 있다고 주장한다.

@example
fn transfer(
    from_account: &AccountWithSerializer,
    to_account: &AccountWithSerializer,
    amount: i64,
) @{
    from_account.withdraw(amount).unwrap();
    to_account.deposit(amount);
@}
@end example

Louis Reasoner는 여기에 문제가 있으며, 교환 문제를 다루는 데 필요한 것과 같은 더 정교한 방법이 필요하다고 주장한다.
Louis가 옳은가? 그렇지 않다면, 이체 문제와 교환 문제의 본질적인 차이점은 무엇인가?
(@code{from-account}의 잔액이 적어도 @code{amount}만큼 있다고 가정해야 한다.)
@end quotation

@quotation
@strong{@anchor{Exercise 3.45}연습문제 3.45:} Louis Reasoner는 입금과 인출이 자동으로 직렬화되지 않게 된 지금 우리 은행 계좌 시스템이 불필요하게 복잡하고 오류가 발생하기 쉽다고 생각한다.
그는 @code{make-account-and-serializer}가 @code{Account::new}가 했던 것처럼 계좌와 입금을 직렬화하는 데 사용하는 대신(대신이 아니라 추가로), 직렬화기를(@code{serialized-exchange}와 같은 프로시저에서 사용하기 위해) 내보냈어야 한다고 제안한다.
그는 다음과 같이 계좌를 재정의할 것을 제안한다:

@example
// Louis의 제안된 설계: 직렬화기를 노출하고 내부적으로도 사용함
// 이것은 withdraw/deposit이 이미 락을 보유하고 있는데
// serialized_exchange가 다시 락을 획득하려고 할 때 데드락을 일으킨다.
struct LouisAccount @{
    balance: Arc<Mutex<i64>>,
@}

impl LouisAccount @{
    fn new(initial_balance: i64) -> Self @{
        LouisAccount @{
            balance: Arc::new(Mutex::new(initial_balance)),
        @}
    @}

    // 문제: 이 메서드들은 내부적으로 락을 건다...
    fn withdraw(&self, amount: i64) -> Result<i64, &'static str> @{
        let mut balance = self.balance.lock().unwrap();
        if *balance >= amount @{
            *balance -= amount;
            Ok(*balance)
        @} else @{
            Err("잔액 부족 (Insufficient funds)")
        @}
    @}

    fn deposit(&self, amount: i64) -> i64 @{
        let mut balance = self.balance.lock().unwrap();
        *balance += amount;
        *balance
    @}

    // ...하지만 우리는 또한 외부 직렬화를 위해 락을 노출한다
    fn serializer(&self) -> Arc<Mutex<i64>> @{
        Arc::clone(&self.balance)
    @}
    // 만약 serialized_exchange가 락을 걸고 withdraw를 호출하면,
    // withdraw가 다시 락을 걸려고 시도하여 -> 데드락!
@}
@end example

그러면 입금은 원래 @code{Account::new}에서와 같이 처리된다:

@example
fn deposit(account: &LouisAccount, amount: i64) -> i64 @{
    account.deposit(amount)
@}
@end example

Louis의 추론에 무엇이 잘못되었는지 설명하라. 특히 @code{serialized-exchange}가 호출될 때 어떤 일이 일어나는지 고려하라.
@end quotation

@subsubheading 직렬화기 구현 (Implementing serializers)

우리는 @newterm{뮤텍스(mutex)}라고 불리는 더 원시적인 동기화 메커니즘의 관점에서 직렬화기를 구현한다.
뮤텍스는 두 가지 연산을 지원하는 객체이다---뮤텍스는 @newterm{획득(acquired)}될 수 있고, 뮤텍스는 @newterm{해제(released)}될 수 있다.
뮤텍스가 획득되면, 뮤텍스가 해제될 때까지 그 뮤텍스에 대한 다른 어떤 획득 연산도 진행될 수 없다.@footnote{``뮤텍스(mutex)''라는 용어는 @newterm{상호 배제(mutual exclusion)}의 줄임말이다. 동시성 프로세스가 자원을 안전하게 공유할 수 있도록 허용하는 메커니즘을 배열하는 일반적인 문제를 상호 배제 문제라고 한다. 우리의 뮤텍스는 @newterm{세마포어(semaphore)} 메커니즘(참조 @ref{Exercise 3.47})의 단순한 변형인데, 이는 에인트호번 공과대학교에서 개발된 ``THE'' 다중 프로그래밍 시스템에서 도입되었으며 대학의 네덜란드어 이니셜을 따서 명명되었다(@ref{Dijkstra 1968a}). 획득 및 해제 연산은 원래 P와 V라고 불렸는데, 이는 철도 시스템에서 사용되는 세마포어를 참조하여 네덜란드어 단어 @emph{passeren}(지나가다)과 @emph{vrijgeven}(해제하다)에서 유래했다. 다익스트라의 고전적인 설명(@ref{1968b})은 동시성 제어의 문제를 명확하게 제시한 최초의 것 중 하나였으며, 세마포어를 사용하여 다양한 동시성 문제를 처리하는 방법을 보여주었다.}
우리의 구현에서, 각 직렬화기는 연관된 뮤텍스를 갖는다.
프로시저 @code{p}가 주어지면, 직렬화기는 뮤텍스를 획득하고, @code{p}를 실행하고, 그런 다음 뮤텍스를 해제하는 프로시저를 반환한다.
이것은 직렬화기에 의해 생성된 프로시저 중 하나만 한 번에 실행될 수 있음을 보장하며, 이것이 바로 우리가 보장해야 할 직렬화 속성이다.

@example
use std::sync::Mutex;

// In Rust, Mutex<T> IS the serializer - it wraps the protected data
// and provides exclusive access via lock()
fn make_serializer<T>() -> Mutex<T>
where
    T: Default,
@{
    Mutex::new(T::default())
@}

// To serialize a procedure in Rust, we use MutexGuard's RAII:
fn serialized_operation<T, F, R>(mutex: &Mutex<T>, f: F) -> R
where
    F: FnOnce(&mut T) -> R,
@{
    let mut guard = mutex.lock().unwrap();  // Acquire
    let result = f(&mut *guard);             // Run procedure
    result                                    // Release on drop
@}
@end example

@noindent
The mutex is a mutable object (here we'll use a one-element list, which we'll
refer to as a @newterm{cell}) that can hold the value true or false.  When the
value is false, the mutex is available to be acquired.  When the value is true,
the mutex is unavailable, and any process that attempts to acquire the mutex
must wait.

Our mutex constructor @code{make-mutex} begins by initializing the cell
contents to false.  To acquire the mutex, we test the cell.  If the mutex is
available, we set the cell contents to true and proceed.  Otherwise, we wait in
a loop, attempting to acquire over and over again, until we find that the mutex
is available.@footnote{In most time-shared operating systems, processes that
are blocked by a mutex do not waste time ``busy-waiting'' as above.  Instead,
the system schedules another process to run while the first is waiting, and the
blocked process is awakened when the mutex becomes available.}  To release the
mutex, we set the cell contents to false.

@example
use std::sync::atomic::@{AtomicBool, Ordering@};

// Low-level mutex using atomic operations (spinlock)
struct SpinLock @{
    locked: AtomicBool,
@}

impl SpinLock @{
    fn new() -> Self @{
        SpinLock @{
            locked: AtomicBool::new(false),
        @}
    @}

    fn acquire(&self) @{
        // Spin until we acquire the lock
        while self.test_and_set() @{
            std::hint::spin_loop();  // CPU hint for spin-waiting
        @}
    @}

    fn release(&self) @{
        self.locked.store(false, Ordering::Release);
    @}

    fn test_and_set(&self) -> bool @{
        // Atomically: read old value, write true, return old
        self.locked.swap(true, Ordering::Acquire)
    @}
@}
@end example

@noindent
@code{Test-and-set!} tests the cell and returns the result of the test.  In
addition, if the test was false, @code{test-and-set!} sets the cell contents to
true before returning false.  We can express this behavior as the following
procedure:

@example
// NON-ATOMIC version - INCORRECT for concurrent use!
// This demonstrates the race condition problem
fn test_and_set_broken(cell: &Cell<bool>) -> bool @{
    if cell.get() @{
        true           // Already locked
    @} else @{
        cell.set(true);  // <-- Race condition here!
        false          // We "acquired" it
    @}
@}
// Between the read and write, another thread could also
// see false and think it acquired the lock
@end example

@noindent
However, this implementation of @code{test-and-set!} does not suffice as it
stands.  There is a crucial subtlety here, which is the essential place where
concurrency control enters the system: The @code{test-and-set!} operation must
be performed @newterm{atomically}.  That is, we must guarantee that, once a
process has tested the cell and found it to be false, the cell contents will
actually be set to true before any other process can test the cell.  If we do
not make this guarantee, then the mutex can fail in a way similar to the
bank-account failure in @ref{Figure 3.29}.  (See @ref{Exercise 3.46}.)

The actual implementation of @code{test-and-set!} depends on the details of how
our system runs concurrent processes.  For example, we might be executing
concurrent processes on a sequential processor using a time-slicing mechanism
that cycles through the processes, permitting each process to run for a short
time before interrupting it and moving on to the next process.  In that case,
@code{test-and-set!}  can work by disabling time slicing during the testing and
setting.@footnote{In @abbr{MIT} Scheme for a single processor, which uses a
time-slicing model, @code{test-and-set!} can be implemented as follows:

@example
use std::sync::atomic::@{AtomicBool, Ordering@};

// ATOMIC version using hardware support
fn test_and_set_atomic(cell: &AtomicBool) -> bool @{
    // compare_exchange atomically:
    // 1. Checks if current value equals `false`
    // 2. If so, sets to `true` and returns Ok(false)
    // 3. If not, returns Err(true)
    cell.compare_exchange(
        false,            // expected
        true,             // new value if expected matches
        Ordering::Acquire,
        Ordering::Relaxed,
    )
    .is_err()  // true if lock was already held
@}
@end example

@code{Without-interrupts} disables time-slicing interrupts while its procedure
ar@-gu@-ment is being executed.}  Alternatively, multiprocessing computers provide
instructions that support atomic operations directly in
hardware.@footnote{There are many variants of such instructions---including
test-and-set, test-and-clear, swap, compare-and-exchange, load-reserve, and
store-conditional---whose design must be carefully matched to the machine's
processor-memory interface.  One issue that arises here is to determine what
happens if two processes attempt to acquire the same resource at exactly the
same time by using such an instruction.  This requires some mechanism for
making a decision about which process gets control.  Such a mechanism is called
an @newterm{arbiter}.  Arbiters usually boil down to some sort of hardware
device.  Unfortunately, it is possible to prove that one cannot physically
construct a fair arbiter that works 100% of the time unless one allows the
arbiter an arbitrarily long time to make its decision.  The fundamental
phenomenon here was originally observed by the fourteenth-century French
philosopher Jean Buridan in his commentary on Aristotle's @i{De caelo}.
Buridan argued that a perfectly rational dog placed between two equally
attractive sources of food will starve to death, because it is incapable of
deciding which to go to first.}

@quotation
@strong{@anchor{Exercise 3.46}Exercise 3.46:} Suppose that we implement
@code{test-and-set!}  using an ordinary procedure as shown in the text, without
attempting to make the operation atomic.  Draw a timing diagram like the one in
@ref{Figure 3.29} to demonstrate how the mutex implementation can fail by
allowing two processes to acquire the mutex at the same time.
@end quotation

@quotation
@strong{@anchor{Exercise 3.47}Exercise 3.47:} A semaphore (of size @math{n}) is a
generalization of a mutex.  Like a mutex, a semaphore supports acquire and
release operations, but it is more general in that up to @math{n} processes can
acquire it concurrently.  Additional processes that attempt to acquire the
semaphore must wait for release operations.  Give implementations of semaphores

@enumerate a

@item
in terms of mutexes

@item
in terms of atomic @code{test-and-set!} operations.

@end enumerate
@end quotation

@subsubheading 데드락 (Deadlock)

이제 직렬화기를 구현하는 방법을 보았으므로, 우리는 위에서 본 @code{serialized-exchange} 프로시저가 있음에도 불구하고 계좌 교환에 여전히 문제가 있음을 알 수 있다.
Peter가 @math{{a1}}과 @math{{a2}}를 교환하려고 시도하는 동시에 Paul이 @math{{a2}}와 @math{{a1}}을 교환하려고 시도한다고 상상해 보자.
Peter의 프로세스가 @math{{a1}}을 보호하는 직렬화된 프로시저에 진입한 시점에 도달하고, 바로 그 직후에 Paul의 프로세스가 @math{{a2}}를 보호하는 직렬화된 프로시저에 진입했다고 가정하자.
이제 Peter는 Paul이 @math{{a2}}를 보호하는 직렬화된 프로시저를 빠져나올 때까지 (@math{{a2}}를 보호하는 직렬화된 프로시저에 진입하기 위해) 진행할 수 없다.
마찬가지로, Paul은 Peter가 @math{{a1}}을 보호하는 직렬화된 프로시저를 빠져나올 때까지 진행할 수 없다.
각 프로세스는 영원히 멈춰서 상대를 기다린다.
이 상황을 @newterm{데드락(deadlock)}이라고 한다.
데드락은 다중 공유 자원에 대한 동시 접근을 제공하는 시스템에서 항상 존재하는 위험이다.

이 상황에서 데드락을 피하는 한 가지 방법은 각 계좌에 고유 식별 번호를 부여하고, 프로세스가 항상 번호가 가장 낮은 계좌를 보호하는 프로시저에 먼저 진입하려고 시도하도록 @code{serialized-exchange}를 다시 작성하는 것이다.
이 방법은 교환 문제에는 잘 작동하지만, 더 정교한 데드락 회피 기술이 필요하거나 데드락을 전혀 피할 수 없는 다른 상황들이 있다. (@ref{Exercise 3.48}과 @ref{Exercise 3.49}를 참조하라.)@footnote{공유 자원에 번호를 매기고 순서대로 획득하여 데드락을 피하는 일반적인 기술은 @ref{Havender (1968)}에 기인한다. 데드락을 피할 수 없는 상황은 @newterm{데드락 복구(deadlock-recovery)} 방법을 필요로 하는데, 이는 프로세스가 데드락 상태에서 ``빠져나와(back out)'' 다시 시도하도록 하는 것을 수반한다. 데드락 복구 메커니즘은 데이터베이스 관리 시스템에서 널리 사용되는데, 이 주제는 @ref{Gray and Reuter 1993}에서 상세히 다루어진다.}

@quotation
@strong{@anchor{Exercise 3.48}연습문제 3.48:} 위에서 설명한 데드락 회피 방법(즉, 계좌에 번호가 매겨져 있고 각 프로세스가 더 작은 번호의 계좌를 먼저 획득하려고 시도함)이 교환 문제에서 데드락을 피하는 이유를 상세히 설명하라.
이 아이디어를 통합하도록 @code{serialized-exchange}를 다시 작성하라. (또한 각 계좌가 번호를 가지고 생성되고 적절한 메시지를 보내 접근할 수 있도록 @code{Account::new}를 수정해야 할 것이다.)
@end quotation

@quotation
@strong{@anchor{Exercise 3.49}연습문제 3.49:} 위에서 설명한 데드락 회피 메커니즘이 작동하지 않는 시나리오를 제시하라.
(힌트: 교환 문제에서, 각 프로세스는 접근해야 할 계좌들을 미리 알고 있다. 프로세스가 어떤 추가 공유 자원이 필요할지 알기 전에 일부 공유 자원에 접근해야 하는 상황을 고려하라.)
@end quotation

@subsubheading 동시성, 시간, 그리고 통신 (Concurrency, time, and communication)

우리는 동시성 시스템을 프로그래밍하는 데 있어 서로 다른 프로세스가 공유 상태에 접근할 때 이벤트의 순서를 제어하는 것이 필요함을 보았고, 직렬화기를 신중하게 사용하여 이 제어를 달성하는 방법을 보았다.
하지만 동시성의 문제는 이보다 더 깊은 곳에 있다. 왜냐하면 근본적인 관점에서 볼 때 ``공유 상태''가 무엇을 의미하는지 항상 명확하지 않기 때문이다.

@code{test-and-set!}과 같은 메커니즘은 프로세스가 임의의 시간에 전역 공유 플래그를 검사할 것을 요구한다.
이것은 파이프라이닝이나 캐시 메모리와 같은 최적화 기술로 인해 메모리 내용이 모든 순간에 일관된 상태가 아닐 수 있는 현대 고속 프로세서에서 구현하기에 문제가 있고 비효율적이다.
따라서 현대 다중 처리 시스템에서는 직렬화기 패러다임이 동시성 제어에 대한 새로운 접근 방식으로 대체되고 있다.@footnote{직렬화에 대한 그러한 대안 중 하나는 @newterm{장벽 동기화(barrier synchronization)}라고 불린다. 프로그래머는 동시성 프로세스들이 마음대로 실행되도록 허용하지만, 모든 프로세스가 장벽에 도달할 때까지 어떤 프로세스도 진행할 수 없는 특정 동기화 지점(``장벽'')을 설정한다. 현대 프로세서는 일관성이 필요한 곳에 동기화 지점을 설정할 수 있도록 하는 기계 명령어를 제공한다. 예를 들어 @abbr{PowerPC}는 이 목적을 위해 @abbr{SYNC}와 @abbr{EIEIO}(Enforced In-order Execution of Input/Output)라는 두 가지 명령어를 포함한다.}

공유 상태의 문제적인 측면은 대규모 분산 시스템에서도 발생한다.
예를 들어, 개별 지점 은행들이 은행 잔액에 대한 지역 값을 유지하고 주기적으로 이것들을 다른 지점이 유지하는 값과 비교하는 분산 은행 시스템을 상상해 보자.
그러한 시스템에서 ``계좌 잔액''의 값은 동기화 직후를 제외하고는 결정되지 않을 것이다.
Peter가 Paul과 공동으로 소유한 계좌에 돈을 입금한다면, 우리는 언제 계좌 잔액이 변했다고 말해야 하는가---지역 지점의 잔액이 변할 때인가, 아니면 동기화 후까지 아닌가?
그리고 Paul이 다른 지점에서 계좌에 접근한다면, 행동이 ``올바르다''고 하기 위해 은행 시스템에 부과해야 할 합리적인 제약 조건은 무엇인가?
정확성을 위해 중요한 유일한 것은 Peter와 Paul이 개별적으로 관찰한 행동과 동기화 직후 계좌의 ``상태''일 수 있다.
``실제'' 계좌 잔액이나 동기화 사이의 이벤트 순서에 대한 질문은 무의미하거나 의미 없을 수 있다.@footnote{이것은 이상한 관점처럼 보일 수 있지만, 이렇게 작동하는 시스템들이 있다. 예를 들어 신용카드 계좌에 대한 국제 청구는 보통 국가별로 정산되며, 다른 국가에서 이루어진 청구는 주기적으로 조정된다. 따라서 계좌 잔액은 다른 국가에서 다를 수 있다.}

여기서의 기본 현상은 서로 다른 프로세스를 동기화하거나, 공유 상태를 확립하거나, 이벤트에 순서를 부과하는 것이 프로세스 간의 통신을 필요로 한다는 것이다.
본질적으로, 동시성 제어에서 시간의 어떤 개념이든 통신과 밀접하게 연결되어야 한다.@footnote{분산 시스템에 대해, 이 관점은 @ref{Lamport (1978)}에 의해 추구되었는데, 그는 분산 시스템에서 이벤트에 순서를 확립하는 데 사용할 수 있는 ``전역 시계''를 확립하기 위해 통신을 사용하는 방법을 보여주었다.}
시간과 통신 사이의 유사한 연결이 상대성 이론에서도 나타난다는 것은 흥미로운데, 여기서 빛의 속도(이벤트를 동기화하는 데 사용할 수 있는 가장 빠른 신호)는 시간과 공간을 관련시키는 기본 상수이다.
우리가 계산 모델에서 시간과 상태를 다룰 때 마주치는 복잡성은 사실 물리적 우주의 근본적인 복잡성을 반영하는 것일 수 있다.

@node 3.4.3, 3.4.5, 3.4.2, 3.4
@subsection 두려움 없는 동시성 (Fearless Concurrency)
@cindex fearless concurrency
@cindex data races
@cindex Send trait
@cindex Sync trait

이전 절에서 우리는 직렬화(serialization)---특정 프로시저들이 동시에 실행되지 않도록 보장하는 것---를 통해 동시성을 제어하는 메커니즘을 탐구했다.
우리는 Scheme의 @code{make-serializer} 추상화가 경쟁 상태(race conditions)를 피하기 위해 프로그래머의 규율을 요구한다는 것을 보았다.
잊어버린 직렬화 호출은 특정 타이밍 조건에서만 나타나는 미묘하고 비결정적인 버그로 이어질 수 있다.

Rust는 근본적으로 다른 접근 방식을 취한다: @emph{컴파일러가 컴파일 타임에 동시성 안전성을 강제한다}.
소유권 시스템과 두 개의 특별한 트레이트---@code{Send}와 @code{Sync}---를 통해 Rust는 안전한 코드에서 데이터 레이스를 불가능하게 만든다.
이것이 우리가 @dfn{두려움 없는 동시성(fearless concurrency)}이라고 부르는 것이다:
@cindex fearless concurrency, definition
타입 시스템이 컴파일을 막기 때문에 데이터 레이스의 두려움 없이 동시성 프로그램을 작성할 수 있는 능력이다.

@subsubheading 문제: 데이터 레이스 (The Problem: Data Races)

@dfn{데이터 레이스(data race)}는 다음 경우에 발생한다:
@cindex data race, definition
@enumerate
@item
둘 이상의 스레드가 동일한 메모리 위치에 접근한다
@item
적어도 하나의 접근이 쓰기이다
@item
접근이 동기화되지 않았다
@end enumerate

다음의 가상적인 unsafe Rust 코드(컴파일되지 않음)를 고려해 보자:

@example
let mut counter = 0;

// 카운터를 증가시키는 두 스레드 생성
let handle1 = std::thread::spawn(|| @{
    for _ in 0..1000 @{
        counter += 1;  // 오류: `counter`를 캡처할 수 없음
    @}
@});

let handle2 = std::thread::spawn(|| @{
    for _ in 0..1000 @{
        counter += 1;  // 오류: `counter`를 캡처할 수 없음
    @}
@});

handle1.join().unwrap();
handle2.join().unwrap();
@end example

이 코드는 데이터 레이스를 가지고 있다: 두 스레드가 적절한 동기화 없이 @code{counter}를 읽고 쓴다.
최종 값은 예측할 수 없다---증가가 어떻게 섞이느냐에 따라 2000이 될 수도 있고 그보다 작은 값이 될 수도 있다.
설상가상으로, 현대 프로세서에서는 메모리 모델 위반으로 인해 동작이 정의되지 않을 수 있다(undefined behavior).

@strong{Rust는 이 코드의 컴파일을 거부한다.} 오류 메시지는 문제점을 정확히 지적한다: @code{counter}가 적절한 동기화 없이 여러 스레드에서 접근되고 있다.

@subsubheading Send 트레이트: 안전한 전송 (The Send Trait: Safe Transfer)

@code{Send} 트레이트는 스레드 경계를 넘어 @emph{소유권을 이전(transfer ownership)}하는 것이 안전한 타입을 표시한다.
@cindex Send trait
대부분의 타입은 @code{Send}이다: 정수, 문자열, 벡터, 그리고 @code{Send} 타입들로 구성된 사용자 정의 구조체 등이다.

@example
pub unsafe auto trait Send @{@}
@end example

@code{auto} 키워드는 컴파일러가 @code{Send} 구성 요소들로만 구성된 타입에 대해 자동으로 @code{Send}를 구현한다는 것을 의미한다.
@code{unsafe} 키워드는 @code{Send}를 수동으로 구현하려면 @code{unsafe impl} 블록이 필요하다는 것을 의미한다---이는 컴파일러가 검증할 수 없는 보장을 여러분이 하고 있다는 신호이다.

@code{Send}가 @emph{아닌} 타입은 다음과 같다:
@itemize @bullet
@item
@code{Rc<T>}: 비원자적 참조 카운팅을 사용하므로 전송하기에 안전하지 않다
@item
@code{*mut T}와 @code{*const T}: 원시 포인터는 소유권 의미론이 없다
@item
@code{Send}가 아닌 구성 요소를 포함하는 타입
@end itemize

@code{std::thread::spawn}을 호출할 때, 클로저는 반드시 @code{Send}여야 한다:

@example
use std::thread;

let data = vec![1, 2, 3];
let handle = thread::spawn(move || @{
    println!("Data: @{:?@}", data);  // `data`가 스레드로 이동됨
@});
handle.join().unwrap();
@end example

@code{move} 키워드는 @code{data}의 소유권을 새 스레드로 이전한다. @code{Vec<i32>}는 @code{Send}이므로, 이것은 성공적으로 컴파일된다.

@subsubheading Sync 트레이트: 안전한 공유 (The Sync Trait: Safe Sharing)

@code{Sync} 트레이트는 스레드 경계를 넘어 @emph{참조를 공유(share references)}하는 것이 안전한 타입을 표시한다.
@cindex Sync trait
타입 @code{T}는 만약 @code{&T}(@code{T}에 대한 불변 참조)가 @code{Send}라면 @code{Sync}이다.

@example
pub unsafe auto trait Sync @{@}
@end example

직관적으로:
@itemize @bullet
@item
@code{Send}: ``나는 다른 스레드로 이동될 수 있어''
@item
@code{Sync}: ``나는 스레드 간에 (@code{&T}를 통해) 공유될 수 있어''
@end itemize

@code{i32}, @code{bool}, @code{f64}와 같은 원시 타입은 @code{Sync}인데, 왜냐하면 그것들에 대한 불변 참조는 안전하게 공유될 수 있기 때문이다. 그러나:
@itemize @bullet
@item
@code{Cell<T>}와 @code{RefCell<T>}는 동기화 없는 내부 가변성을 제공하므로 @code{Sync}가 @emph{아니다}
@item
@code{Mutex<T>}는 동기화된 내부 가변성을 제공하므로 @code{Sync} @emph{이다} (만약 @code{T}가 @code{Send}라면)
@end itemize

@subsubheading 스레드 생성 (Spawning Threads)

@code{std::thread::spawn} 함수는 새로운 OS 스레드를 생성한다:
@cindex thread spawning

@example
use std::thread;
use std::time::Duration;

let handle = thread::spawn(|| @{
    for i in 1..10 @{
        println!("Thread: @{@}", i);
        thread::sleep(Duration::from_millis(1));
    @}
@});

for i in 1..5 @{
    println!("Main: @{@}", i);
    thread::sleep(Duration::from_millis(1));
@}

handle.join().unwrap();  // 스레드가 끝날 때까지 대기
@end example

@code{spawn}에 전달되는 클로저는 두 가지 제약 조건을 만족해야 한다:
@enumerate
@item
그것은 @code{Send}여야 한다 (다른 스레드로 이동할 수 있음)
@item
그것은 @code{'static} 수명을 가져야 한다 (지역 데이터를 빌릴 수 없음)
@end enumerate

@code{'static} 요구 사항은 중요하다. 다음을 고려해 보자:

@example
let v = vec![1, 2, 3];

let handle = thread::spawn(|| @{
    println!("@{:?@}", v);  // 오류: `v`가 충분히 오래 살지 않음
@});
@end example

생성된 스레드는 현재 스코프보다 오래 살 수 있지만, @code{v}는 스코프가 끝나면 해제될 것이다. Rust는 @code{'static} 바운드를 요구함으로써 이러한 해제 후 사용을 방지한다. 해결책은 소유권을 @code{move}하는 것이다:

@example
let v = vec![1, 2, 3];

let handle = thread::spawn(move || @{
    println!("@{:?@}", v);  // OK: 소유권 이전됨
@});
@end example

@subsubheading 스코프 스레드 (Scoped Threads)

@code{'static} 요구 사항은 때때로 너무 제한적이다.
@code{crossbeam} 크레이트는 지역 데이터를 안전하게 빌릴 수 있는 @dfn{스코프 스레드(scoped threads)}를 제공한다:
@cindex scoped threads

@example
use crossbeam::thread;

let mut arr = [1, 2, 3];

thread::scope(|s| @{
    s.spawn(|_| @{
        arr[0] += 1;  // 오류: 가변으로 빌릴 수 없음
    @});

    s.spawn(|_| @{
        println!("@{:?@}", arr);  // OK: 불변 빌림
    @});
@}).unwrap();
@end example

@code{scope} 함수는 모든 생성된 스레드가 반환하기 전에 완료됨을 보장한다. 이것은 스레드가 부모 스코프에서 빌리는 것을 허용한다.
그러나 Rust는 여전히 데이터 레이스를 방지한다: 다중 가변 빌림이나 불변 빌림과 함께 가변 빌림을 가질 수 없다.

@subsubheading 메시지 전달 (Message Passing)

스레드 간에 데이터를 공유하는 한 가지 접근 방식은 @emph{전혀 공유하지 않는 것}이다.
@cindex message passing
대신, 스레드는 채널을 통해 메시지를 보내 통신한다. Rust의 표준 라이브러리는 @code{std::sync::mpsc} (다중 생산자, 단일 소비자) 채널을 제공한다:

@example
use std::sync::mpsc;
use std::thread;

let (tx, rx) = mpsc::channel();

thread::spawn(move || @{
    let values = vec![
        String::from("hello"),
        String::from("from"),
        String::from("the"),
        String::from("thread"),
    ];

    for val in values @{
        tx.send(val).unwrap();
    @}
@});

for received in rx @{
    println!("Received: @{@}", received);
@}
@end example

@code{channel} 함수는 튜플을 반환한다: @code{tx} (송신자)와 @code{rx} (수신자).
송신자는 @code{Send}이지만 @code{Sync}는 아니어서, 여러 스레드가 메시지를 보낼 수 있다.
수신자는 @code{Send}도 @code{Sync}도 아니어서, 오직 한 스레드만이 메시지를 받을 수 있음을 보장한다.

@code{tx.send(val)}이 실행될 때, @code{val}의 소유권은 채널로 이전된다.
수신 스레드는 @code{rx.recv()}를 호출할 때 소유권을 가져간다.
이 @emph{소유권 이전}은 데이터 레이스를 방지한다: 어느 시점에서든 오직 하나의 스레드만이 데이터를 소유한다.

@code{crossbeam::channel} 크레이트는 더 발전된 채널을 제공한다:
@cindex crossbeam channels

@example
use crossbeam::channel;
use std::thread;
use std::time::Duration;

let (tx, rx) = channel::unbounded();

// 생산자 스레드
thread::spawn(move || @{
    for i in 0..10 @{
        tx.send(i).unwrap();
        thread::sleep(Duration::from_millis(100));
    @}
@});

// 채널과 타임아웃 사이에서 선택
loop @{
    select! @{
        recv(rx) -> msg => @{
            match msg @{
                Ok(i) => println!("Received: @{@}", i),
                Err(_) => break,
            @}
        @}
        default(Duration::from_millis(500)) => @{
            println!("Timeout - no message received");
        @}
    @}
@}
@end example

@code{select!} 매크로는 여러 채널 연산에 대해 대기할 수 있게 해주며, 이는 직렬화 장치의 제약 조건인 한 번에 하나의 연산만 진행된다는 것과 유사하다.

@subsubheading Arc와 Mutex를 이용한 공유 상태 (Shared State with Arc and Mutex)

메시지 전달이 관용적이지만, 때로는 공유된 가변 상태가 필요하다.
@cindex Arc
@cindex Mutex
Rust는 두 가지 도구를 제공한다:

@enumerate
@item
@code{Arc<T>} (Atomic Reference Counted): 스레드 안전한 공유 소유권
@item
@code{Mutex<T>}: 동기화된 접근을 위한 상호 배제
@end enumerate

다음은 올바르게 작성된 우리의 카운터 예제이다:

@example
use std::sync::@{Arc, Mutex@};
use std::thread;


let counter = Arc::new(Mutex::new(0));
let mut handles = vec![];

for _ in 0..10 @{
    let counter_clone = Arc::clone(&counter);
    let handle = thread::spawn(move || @{
        let mut num = counter_clone.lock().unwrap();
        *num += 1;
    @});
    handles.push(handle);
@}

for handle in handles @{
    handle.join().unwrap();
@}

println!("Result: @{@}", *counter.lock().unwrap());  // Result: 10
@end example

Let's dissect this:

@enumerate
@item
@code{Arc::new(Mutex::new(0))}: Creates a reference-counted pointer to
a mutex protecting the integer 0
@item
@code{Arc::clone(&counter)}: Increments the reference count, creating
a new pointer to the same data
@item
@code{counter_clone.lock().unwrap()}: Acquires the mutex, returning
a @code{MutexGuard}
@item
@code{*num += 1}: The guard dereferences to @code{&mut i32}, allowing
mutation
@item
When the guard goes out of scope, the mutex is @emph{automatically released}
@end enumerate

The type signature reveals the safety:
@example
impl<T: ?Sized + Send> Send for Arc<T>
impl<T: ?Sized + Send + Sync> Sync for Arc<T>
impl<T: ?Sized + Send> Send for Mutex<T>
impl<T: ?Sized + Send> Sync for Mutex<T>
@end example

@code{Arc<Mutex<T>>} is @code{Send} and @code{Sync} (if @code{T} is @code{Send}),
allowing it to be shared across threads. The @code{Mutex} ensures that only
one thread can access the data at a time, preventing data races.

@subsubheading Message Passing vs. Shared State

These two approaches represent different concurrency philosophies:
@cindex concurrency patterns

@strong{Message Passing} (``Share memory by communicating''):
@itemize @bullet
@item
@strong{Pros}: Clear ownership, fewer synchronization bugs, composable
@item
@strong{Cons}: Copying overhead, less intuitive for shared resources
@item
@strong{Use when}: Tasks are independent, data flow is unidirectional
@end itemize

@strong{Shared State} (``Communicate by sharing memory''):
@itemize @bullet
@item
@strong{Pros}: Zero-copy access, familiar to systems programmers
@item
@strong{Cons}: Deadlock risk, harder to reason about, contention issues
@item
@strong{Use when}: High-frequency updates, complex shared data structures
@end itemize

Consider a web server maintaining request statistics. Message passing works well:

@example
struct Stats @{
    requests: u64,
    errors: u64,
@}

enum Message @{
    Request,
    Error,
    GetStats(mpsc::Sender<Stats>),
@}

fn stats_actor(rx: mpsc::Receiver<Message>) @{
    let mut stats = Stats @{ requests: 0, errors: 0 @};

    for msg in rx @{
        match msg @{
            Message::Request => stats.requests += 1,
            Message::Error => stats.errors += 1,
            Message::GetStats(reply) => @{
                reply.send(stats.clone()).unwrap();
            @}
        @}
    @}
@}
@end example

The @code{stats_actor} owns the statistics, and other threads send messages
to update or query them. No locks required.

Conversely, a cache shared by multiple workers benefits from shared state:

@example
use std::sync::@{Arc, RwLock@};
use std::collections::HashMap;

type Cache = Arc<RwLock<HashMap<String, Vec<u8>>>>;

fn worker(cache: Cache, key: String) -> Option<Vec<u8>> @{
    // Try read lock first
    @{
        let read_guard = cache.read().unwrap();
        if let Some(value) = read_guard.get(&key) @{
            return Some(value.clone());
        @}
    @}  // Read lock released

    // Expensive computation
    let value = compute_value(&key);

    // Write lock to update cache
    let mut write_guard = cache.write().unwrap();
    write_guard.insert(key, value.clone());
    Some(value)
@}
@end example

The @code{RwLock} (read-write lock) allows multiple readers or one writer,
@cindex RwLock
reducing contention compared to @code{Mutex}.

@subsubheading The Compiler as Guardian

The key insight is that Rust's type system @emph{encodes concurrency invariants}.
@cindex type system, concurrency safety
You cannot write a data race in safe Rust because:

@enumerate
@item
Mutable references are exclusive (@code{&mut T})
@item
Shared references are immutable (@code{&T})
@item
@code{Send} and @code{Sync} control thread boundaries
@item
Lifetimes prevent use-after-free
@end enumerate

Compare this to Section 3.4's serializers in Scheme, which rely on programmer
discipline. In Rust, if your program compiles, you have a @emph{proof} that
it is free of data races.

This doesn't prevent @emph{all} concurrency bugs. Deadlocks are still possible:

@example
let m1 = Arc::new(Mutex::new(0));
let m2 = Arc::new(Mutex::new(0));

let m1_clone = Arc::clone(&m1);
let m2_clone = Arc::clone(&m2);

let t1 = thread::spawn(move || @{
    let _g1 = m1_clone.lock().unwrap();  // Acquire m1
    thread::sleep(Duration::from_millis(10));
    let _g2 = m2_clone.lock().unwrap();  // Wait for m2 (deadlock!)
@});

let t2 = thread::spawn(move || @{
    let _g2 = m2.lock().unwrap();        // Acquire m2
    thread::sleep(Duration::from_millis(10));
    let _g1 = m1.lock().unwrap();        // Wait for m1 (deadlock!)
@});
@end example

Both threads wait forever. The solution is @emph{lock ordering}: always
acquire locks in the same order. This is a runtime protocol, not enforced
by the type system.

However, data races---the most insidious class of concurrency bugs---are
@emph{impossible} in safe Rust. This is fearless concurrency: the confidence
to parallelize code without fear of undefined behavior.

@strong{@anchor{Exercise 3.45a}Exercise 3.45a:}
@quotation
The following code attempts to compute the sum of an array in parallel:

@example
fn parallel_sum(data: &[i32]) -> i32 @{
    let sum = 0;
    let handles: Vec<_> = data.chunks(100)
        .map(|chunk| @{
            thread::spawn(move || @{
                chunk.iter().sum::<i32>()
            @})
        @})
        .collect();

    for handle in handles @{
        sum += handle.join().unwrap();
    @}
    sum
@}
@end example

This code doesn't compile. Identify the two errors and fix them. Then,
rewrite the function using message passing instead of shared state.
@end quotation

@strong{@anchor{Exercise 3.46a}Exercise 3.46a:}
@quotation
Explain why @code{Rc<T>} is not @code{Send}, but @code{Arc<T>} is.
What operations does @code{Arc<T>} perform differently to ensure
thread safety? What is the performance cost?

Implement a simplified version of @code{Arc<T>} using @code{AtomicUsize}
for the reference count:

@example
use std::sync::atomic::@{AtomicUsize, Ordering@};
use std::ops::Deref;

struct SimpleArc<T> @{
    ptr: *const ArcInner<T>,
@}

struct ArcInner<T> @{
    ref_count: AtomicUsize,
    data: T,
@}

impl<T> SimpleArc<T> @{
    fn new(data: T) -> Self @{
        // Your implementation here
    @}
@}

impl<T> Clone for SimpleArc<T> @{
    fn clone(&self) -> Self @{
        // Your implementation here
    @}
@}

impl<T> Drop for SimpleArc<T> @{
    fn drop(&mut self) @{
        // Your implementation here
    @}
@}

impl<T> Deref for SimpleArc<T> @{
    type Target = T;
    fn deref(&self) -> &T @{
        // Your implementation here
    @}
@}
@end example

@emph{Hint}: Use @code{Ordering::Relaxed} for increments,
@code{Ordering::Release} for decrements, and @code{Ordering::Acquire}
for the final check before deallocation.
@end quotation

@strong{@anchor{Exercise 3.47a}Exercise 3.47a:}
@quotation
Design and implement a @dfn{reader-writer lock} using @code{Mutex} and
condition variables (or channels). The lock should allow:
@itemize @bullet
@item
Multiple readers simultaneously (if no writer)
@item
Exactly one writer (if no readers or other writers)
@item
Writers have priority over readers (prevent writer starvation)
@end itemize

@example
struct RwLock<T> @{
    // Your fields here
@}

impl<T> RwLock<T> @{
    fn new(data: T) -> Self @{
        // Your implementation
    @}

    fn read(&self) -> ReadGuard<T> @{
        // Acquire read access
    @}

    fn write(&self) -> WriteGuard<T> @{
        // Acquire write access
    @}
@}

struct ReadGuard<'a, T> @{
    // Your fields
@}

struct WriteGuard<'a, T> @{
    // Your fields
@}
@end example

Test your implementation with multiple threads performing mixed read/write
operations. Verify that:
@enumerate
@item
Multiple reads can occur simultaneously
@item
Writes are exclusive
@item
No data races occur (use @code{Arc<RwLock<Vec<i32>>>} and verify final state)
@end enumerate

@emph{Bonus}: Instrument your lock to track metrics (total reads, writes,
contentions, wait times). How does performance compare to @code{std::sync::RwLock}?
@end quotation

@node 3.4.5, 3.5, 3.4.3, 3.4
@subsection Async/Await: Cooperative Concurrency
@cindex async/await
@cindex futures
@cindex cooperative concurrency

In the previous section, we explored thread-based concurrency, where the
operating system schedules multiple threads of execution. Each thread has
its own stack and can be preempted at any time. This @dfn{preemptive
multitasking} works well for CPU-bound tasks, but creates overhead for
I/O-bound workloads.

Consider a web server handling 10,000 simultaneous connections. Creating
10,000 OS threads is expensive:
@itemize @bullet
@item
Each thread requires stack space (typically 2 MB on Linux)
@item
Context switching between thousands of threads degrades performance
@item
Most threads spend time waiting for I/O, not computing
@end itemize

Rust's @code{async/await} syntax provides an alternative: @dfn{cooperative
@cindex cooperative concurrency, definition
concurrency}, where tasks voluntarily yield control at specific points.
This allows thousands or millions of concurrent tasks on a single thread,
with minimal overhead.

@subsubheading Concurrency vs. Parallelism

Before diving into async, let's clarify terminology:
@cindex concurrency vs parallelism

@itemize @bullet
@item
@strong{Concurrency}: Managing multiple tasks that make progress over
overlapping time periods (``dealing with lots of things at once'')
@item
@strong{Parallelism}: Executing multiple tasks simultaneously on different
CPU cores (``doing lots of things at once'')
@end itemize

Threads can provide both: the OS may run threads in parallel on multiple
cores, or interleave them on a single core. Async provides @emph{concurrency
without parallelism}---tasks cooperatively share a single thread (though
async runtimes may use multiple threads internally).

@strong{Use threads when}:
@itemize @bullet
@item
Tasks are CPU-bound (image processing, cryptography, simulations)
@item
You need to utilize multiple CPU cores
@item
Interfacing with blocking system calls or C libraries
@end itemize

@strong{Use async when}:
@itemize @bullet
@item
Tasks are I/O-bound (network servers, databases, file systems)
@item
Managing thousands of concurrent connections
@item
Low latency is critical (microsecond-scale task switching)
@end itemize

@subsubheading Futures: Lazy Computations

At the heart of Rust's async system is the @code{Future} trait:
@cindex Future trait

@example
pub trait Future @{
    type Output;

    fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>)
        -> Poll<Self::Output>;
@}

pub enum Poll<T> @{
    Ready(T),
    Pending,
@}
@end example

A @code{Future} represents a value that may not be available yet. The
@code{poll} method asks: ``Are you done?'' It returns either:
@itemize @bullet
@item
@code{Poll::Ready(value)}: The computation completed with @code{value}
@item
@code{Poll::Pending}: Still working; poll again later
@end itemize

Crucially, futures are @dfn{lazy}: they do nothing until polled. Creating
@cindex lazy evaluation
a future merely constructs a state machine; no work happens until an
executor calls @code{poll}.

Here's a simple future that completes after being polled three times:

@example
use std::future::Future;
use std::pin::Pin;
use std::task::@{Context, Poll@};

struct CountdownFuture @{
    count: u32,
@}

impl Future for CountdownFuture @{
    type Output = ();

    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>)
        -> Poll<Self::Output>
    @{
        if self.count == 0 @{
            Poll::Ready(())
        @} else @{
            self.count -= 1;
            cx.waker().wake_by_ref();  // Schedule another poll
            Poll::Pending
        @}
    @}
@}
@end example

Each @code{poll} decrements the counter. When it reaches zero, the future
completes. The @code{cx.waker().wake_by_ref()} call tells the executor
to poll this future again.

@subsubheading Async Functions and Await

Manually implementing @code{Future} is tedious. The @code{async fn} syntax
@cindex async fn
generates futures automatically:

@example
async fn fetch_url(url: &str) -> Result<String, reqwest::Error> @{
    let response = reqwest::get(url).await?;
    let body = response.text().await?;
    Ok(body)
@}
@end example

This simple function hides sophisticated machinery:
@enumerate
@item
@code{async fn} transforms the function into a state machine implementing
@code{Future}
@item
Each @code{.await} is a potential suspension point
@item
When a future returns @code{Poll::Pending}, the state machine saves
local variables and yields control
@item
When polled again, it resumes from the last @code{.await}
@end enumerate

The @code{.await} keyword is postfix (like @code{?}) to emphasize that
@cindex .await keyword
it's an operation on a future, not a function call. Compare:

@example
// Synchronous (blocking)
fn fetch_sync(url: &str) -> String @{
    let response = blocking_get(url);  // Thread sleeps here
    response.text()
@}

// Asynchronous (non-blocking)
async fn fetch_async(url: &str) -> String @{
    let response = async_get(url).await;  // Task yields here
    response.text().await
@}
@end example

In the synchronous version, @code{blocking_get} halts the thread until
the network responds. In the async version, @code{.await} yields control
to the executor, which can run other tasks while waiting.

@subsubheading Async Runtimes

Futures need an @dfn{executor} to drive them to completion. Rust's standard
@cindex async runtime
@cindex executor
library defines the @code{Future} trait but @emph{does not provide an
executor}. This allows different runtimes to specialize:

@itemize @bullet
@item
@strong{Tokio}: Full-featured, multi-threaded work-stealing scheduler
@item
@strong{async-std}: Mirrors std library APIs, single- or multi-threaded
@item
@strong{smol}: Minimal, single-threaded, embeddable
@item
@strong{embassy}: Embedded systems, @code{no_std} compatible
@end itemize

Here's a Tokio example:

@example
use tokio;

#[tokio::main]
async fn main() @{
    let result = fetch_url("https://example.com").await;
    println!("Fetched: @{:?@}", result);
@}
@end example

The @code{#[tokio::main]} macro expands to:

@example
fn main() @{
    tokio::runtime::Runtime::new()
        .unwrap()
        .block_on(async @{
            let result = fetch_url("https://example.com").await;
            println!("Fetched: @{:?@}", result);
        @})
@}
@end example

@code{block_on} is the bridge between sync and async: it blocks the current
thread until the future completes. Inside the async block, you can use
@code{.await} freely.

@subsubheading Async Blocks and Async Move

Just as closures capture their environment, @code{async} blocks can too:
@cindex async blocks

@example
let url = String::from("https://example.com");

let future = async @{
    fetch_url(&url).await
@};

// `future` borrows `url`
@end example

To transfer ownership, use @code{async move}:
@cindex async move

@example
let url = String::from("https://example.com");

let future = async move @{
    fetch_url(&url).await  // `url` is moved into the future
@};

// `url` is no longer accessible here
@end example

This is essential when spawning tasks:

@example
use tokio;

#[tokio::main]
async fn main() @{
    let url = String::from("https://example.com");

    let handle = tokio::spawn(async move @{
        fetch_url(&url).await
    @});

    let result = handle.await.unwrap();
    println!("@{:?@}", result);
@}
@end example

@code{tokio::spawn} is the async equivalent of @code{std::thread::spawn}:
it runs a future on the runtime's thread pool. The future must be
@code{'static}, so we use @code{async move} to capture ownership.

@subsubheading Pin: Preventing Self-Referential Moves

One of async Rust's thorniest concepts is @code{Pin}. To understand why
@cindex Pin
@cindex self-referential structs
it's necessary, consider how async functions are compiled.

This async function:

@example
async fn example() @{
    let x = String::from("hello");
    let y = &x;
    some_async_call().await;
    println!("@{@}", y);
@}
@end example

Becomes a state machine like:

@example
enum ExampleFuture @{
    Start,
    AwaitingCall @{
        x: String,
        y: *const String,  // Pointer to x!
    @},
    Done,
@}
@end example

The problem: @code{y} points to @code{x}, which is stored @emph{inside
the same struct}. If we move @code{ExampleFuture} in memory, @code{y}
becomes a dangling pointer.

@code{Pin<&mut T>} is Rust's solution: it guarantees that @code{T} will
not move in memory. The @code{poll} method takes @code{Pin<&mut Self>},
ensuring the future stays put:

@example
fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>)
    -> Poll<Self::Output>;
@end example

For most users, @code{Pin} is transparent: the @code{async fn} syntax
handles it automatically. You only encounter @code{Pin} when:
@itemize @bullet
@item
Manually implementing @code{Future}
@item
Working with low-level async primitives
@item
Creating self-referential types
@end itemize

The key insight: @code{Pin} is a @emph{compile-time proof} that a value
won't move. This allows safe self-references in generated state machines.

@subsubheading Structured Concurrency

Just as spawning threads creates the risk of orphaned tasks, spawning
@cindex structured concurrency
async tasks requires careful management. Structured concurrency ensures
tasks are properly joined before their scope ends.

The @code{tokio::join!} macro waits for multiple futures concurrently:
@cindex tokio::join!

@example
use tokio;

async fn fetch_many() -> (String, String, String) @{
    let (a, b, c) = tokio::join!(
        fetch_url("https://example.com/a"),
        fetch_url("https://example.com/b"),
        fetch_url("https://example.com/c"),
    );

    (a.unwrap(), b.unwrap(), c.unwrap())
@}
@end example

All three fetches run concurrently (not sequentially!). If one completes,
the others continue. @code{join!} waits for all to finish before returning.

For dynamic collections, use @code{JoinSet}:

@example
use tokio::task::JoinSet;

async fn fetch_urls(urls: Vec<String>) -> Vec<String> @{
    let mut set = JoinSet::new();

    for url in urls @{
        set.spawn(async move @{
            fetch_url(&url).await.unwrap()
        @});
    @}

    let mut results = Vec::new();
    while let Some(res) = set.join_next().await @{
        results.push(res.unwrap());
    @}
    results
@}
@end example

The @code{tokio::select!} macro is the async equivalent of the @code{select!}
@cindex tokio::select!
we saw for channels:

@example
use tokio::time::@{sleep, Duration@};

async fn timeout_example() @{
    tokio::select! @{
        result = fetch_url("https://slow-server.com") => @{
            println!("Fetched: @{:?@}", result);
        @}
        _ = sleep(Duration::from_secs(5)) => @{
            println!("Timeout!");
        @}
    @}
@}
@end example

If the fetch completes first, the timeout is cancelled. If the timeout
fires, the fetch is cancelled. Only one branch executes.

@strong{Caution}: @code{select!} is not deterministic if multiple branches
are ready. For fairness, use @code{tokio::select! @{ biased; ... @}} to
prioritize branches in order.

@subsubheading When to Use Async vs. Threads

Async is not always the right choice. Consider:

@strong{Async Wins}:
@example
// Web server handling 100,000 concurrent connections
use tokio::net::TcpListener;

#[tokio::main]
async fn main() @{
    let listener = TcpListener::bind("127.0.0.1:8080")
        .await.unwrap();

    loop @{
        let (socket, _) = listener.accept().await.unwrap();
        tokio::spawn(async move @{
            handle_connection(socket).await;
        @});
    @}
@}
@end example

Each connection is a lightweight task. Spawning 100,000 threads would
exhaust memory; spawning 100,000 async tasks uses a few megabytes.

@strong{Threads Win}:
@example
// CPU-bound parallel computation
use rayon::prelude::*;

fn parallel_sum(data: &[i32]) -> i32 @{
    data.par_iter().sum()
@}
@end example

Async provides no benefit here---the task is CPU-bound, not I/O-bound.
Rayon's thread pool efficiently parallelizes across cores.

@strong{Hybrid Approach}:
@example
use tokio;

#[tokio::main]
async fn main() @{
    let data = load_data().await;

    let result = tokio::task::spawn_blocking(|| @{
        expensive_computation(data)  // Runs on dedicated thread pool
    @}).await.unwrap();

    save_result(result).await;
@}
@end example

@code{spawn_blocking} runs the synchronous, CPU-bound computation on a
separate thread pool, preventing it from blocking the async executor.

@subsubheading Zero-Cost Abstraction: State Machines

Async functions compile to state machines with zero runtime overhead
@cindex zero-cost abstraction
@cindex state machines
beyond what you'd write manually. Consider:

@example
async fn process() -> i32 @{
    let a = async_op_1().await;
    let b = async_op_2(a).await;
    let c = async_op_3(b).await;
    c
@}
@end example

The compiler generates (conceptually):

@example
enum ProcessFuture @{
    Start,
    AwaitingOp1 @{ fut1: impl Future<Output = i32> @},
    AwaitingOp2 @{ a: i32, fut2: impl Future<Output = i32> @},
    AwaitingOp3 @{ fut3: impl Future<Output = i32> @},
    Done,
@}

impl Future for ProcessFuture @{
    type Output = i32;

    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>)
        -> Poll<i32>
    @{
        loop @{
            match &mut *self @{
                ProcessFuture::Start => @{
                    let fut1 = async_op_1();
                    *self = ProcessFuture::AwaitingOp1 @{ fut1 @};
                @}
                ProcessFuture::AwaitingOp1 @{ fut1 @} => @{
                    match fut1.poll(cx) @{
                        Poll::Ready(a) => @{
                            let fut2 = async_op_2(a);
                            *self = ProcessFuture::AwaitingOp2 @{
                                a, fut2
                            @};
                        @}
                        Poll::Pending => return Poll::Pending,
                    @}
                @}
                ProcessFuture::AwaitingOp2 @{ a, fut2 @} => @{
                    match fut2.poll(cx) @{
                        Poll::Ready(b) => @{
                            let fut3 = async_op_3(b);
                            *self = ProcessFuture::AwaitingOp3 @{ fut3 @};
                        @}
                        Poll::Pending => return Poll::Pending,
                    @}
                @}
                ProcessFuture::AwaitingOp3 @{ fut3 @} => @{
                    match fut3.poll(cx) @{
                        Poll::Ready(c) => @{
                            *self = ProcessFuture::Done;
                            return Poll::Ready(c);
                        @}
                        Poll::Pending => return Poll::Pending,
                    @}
                @}
                ProcessFuture::Done => panic!("polled after completion"),
            @}
        @}
    @}
@}
@end example

This is a @emph{zero-cost abstraction}: the generated code is as efficient
as if you wrote the state machine by hand. Each @code{.await} becomes a
state transition. Local variables are stored in the enum.

The size of the future is the size of the largest variant (plus a
discriminant tag). Async code has minimal heap allocation---most futures
live on the stack or inline in their parent future.

@subsubheading Async and Cancellation Safety

Unlike preemptive threads, async tasks can be @emph{cancelled} at any
@cindex cancellation safety
@code{.await} point. This has subtle implications:

@example
async fn transfer_money(from: &Account, to: &Account, amount: u64) @{
    from.withdraw(amount).await;  // Cancellation here is a problem!
    to.deposit(amount).await;
@}
@end example

If this task is cancelled after the first @code{.await}, money disappears.
The solution is to make critical sections atomic:

@example
async fn transfer_money(from: &Account, to: &Account, amount: u64) @{
    let transaction = @{
        let tx = Transaction::new();
        tx.withdraw(from, amount);
        tx.deposit(to, amount);
        tx
    @};  // No .await in this block---cannot be cancelled mid-transaction

    transaction.commit().await;  // Atomic commit
@}
@end example

Alternatively, use a @code{tokio::sync::Mutex} guard:

@example
async fn critical_section(data: &Mutex<Vec<i32>>) @{
    let mut guard = data.lock().await;
    guard.push(1);
    guard.push(2);
    // If cancelled here, guard drops and releases lock
@}
@end example

The @code{MutexGuard} ensures the lock is released even if the task is
cancelled. Async code must be @dfn{cancellation-safe}: safe to abort at
any @code{.await}.

@subsubheading Comparison to SICP's Streams

Async programming shares deep connections with Chapter 3's streams. Recall
@cindex streams
the stream paradigm: lazy sequences computed on demand. The @code{cons-stream}
construct delays evaluation:

@example
(define (integers-starting-from n)
  (cons-stream n (integers-starting-from (+ n 1))))
@end example

In Rust, async functions and @code{Stream} (the async version of @code{Iterator})
@cindex Stream trait
provide similar lazy evaluation:

@example
use async_stream::stream;

fn integers_starting_from(n: i32) -> impl Stream<Item = i32> @{
    stream! @{
        let mut i = n;
        loop @{
            yield i;
            i += 1;
        @}
    @}
@}
@end example

The @code{yield} keyword produces values lazily, just like @code{cons-stream}.
The key difference: async streams can perform I/O or await other futures
between yields:

@example
async fn fetch_pages(urls: Vec<String>) -> impl Stream<Item = String> @{
    stream! @{
        for url in urls @{
            let page = fetch_url(&url).await;
            yield page.unwrap();
        @}
    @}
@}
@end example

This combines the laziness of streams with the concurrency of async/await.
You can process results as they arrive, without waiting for all fetches
to complete.

@strong{@anchor{Exercise 3.48a}Exercise 3.48a:}
@quotation
Implement an async function @code{parallel_map} that applies an async
function to every element of a vector, with a concurrency limit:

@example
async fn parallel_map<T, U, F>(
    items: Vec<T>,
    f: F,
    concurrency: usize,
) -> Vec<U>
where
    T: Send + 'static,
    U: Send + 'static,
    F: Fn(T) -> Pin<Box<dyn Future<Output = U> + Send>> + Send + Sync,
@{
    // Your implementation here
@}
@end example

For example, @code{parallel_map(urls, fetch_url, 10)} should fetch URLs
with at most 10 concurrent requests. Test your implementation with a
simulated async operation:

@example
async fn simulate_work(id: usize) -> usize @{
    tokio::time::sleep(Duration::from_millis(100)).await;
    id * 2
@}

#[tokio::main]
async fn main() @{
    let items: Vec<usize> = (0..20).collect();
    let results = parallel_map(
        items,
        |x| Box::pin(simulate_work(x)),
        5,
    ).await;
    assert_eq!(results, (0..20).map(|x| x * 2).collect::<Vec<_>>());
@}
@end example

@emph{Hint}: Use @code{futures::stream::FuturesUnordered} or a @code{JoinSet}
with manual buffering.

@strong{Bonus}: Modify your implementation to preserve input order in
the output, even though tasks may complete out of order.
@end quotation

@strong{@anchor{Exercise 3.49a}Exercise 3.49a:}
@quotation
The following code has a subtle bug related to cancellation safety:

@example
use tokio::fs::File;
use tokio::io::@{AsyncReadExt, AsyncWriteExt@};

async fn copy_file(src: &str, dst: &str) -> std::io::Result<()> @{
    let mut file = File::open(src).await?;
    let mut buffer = Vec::new();
    file.read_to_end(&mut buffer).await?;

    let mut out = File::create(dst).await?;
    out.write_all(&buffer).await?;
    out.sync_all().await?;
    Ok(())
@}

async fn process_files(files: Vec<(&str, &str)>) @{
    for (src, dst) in files @{
        tokio::select! @{
            result = copy_file(src, dst) => @{
                println!("Copied: @{:?@}", result);
            @}
            _ = tokio::time::sleep(Duration::from_secs(5)) => @{
                println!("Timeout on @{@} -> @{@}", src, dst);
            @}
        @}
    @}
@}
@end example

@enumerate
@item
Identify the cancellation safety issue. What can go wrong if a timeout occurs?
@item
Fix the bug by making @code{copy_file} cancellation-safe. Ensure that
if the operation is cancelled, no partial file is left on disk.
@item
Explain why @code{tokio::fs::File} doesn't implement @code{Drop} to
delete the file on cancellation. What would be the downsides?
@end enumerate

@emph{Hint}: Consider using a temporary file and atomic rename, or
checking for partial writes and cleaning up explicitly.
@end quotation

@node 3.5, Chapter 4, 3.4.5, Chapter 3
@section Streams

We've gained a good understanding of assignment as a tool in modeling, as well
as an appreciation of the complex problems that assignment raises. It is time
to ask whether we could have gone about things in a different way, so as to
avoid some of these problems.  In this section, we explore an alternative
approach to modeling state, based on data structures called @newterm{streams}.
As we shall see, streams can mitigate some of the complexity of modeling state.

Let's step back and review where this complexity comes from.  In an attempt to
model real-world phenomena, we made some apparently reasonable decisions: We
modeled real-world objects with local state by computational objects with local
variables.  We identified time variation in the real world with time variation
in the computer.  We implemented the time variation of the states of the model
objects in the computer with assignments to the local variables of the model
objects.

Is there another approach?  Can we avoid identifying time in the computer with
time in the modeled world?  Must we make the model change with time in order to
model phenomena in a changing world?  Think about the issue in terms of
mathematical functions.  We can describe the time-varying behavior of a
quantity @math{x} as a function of time @math{{x(t)}}.  If we concentrate on @math{x}
instant by instant, we think of it as a changing quantity.  Yet if we
concentrate on the entire time history of values, we do not emphasize
change---the function itself does not change.@footnote{Physicists sometimes
adopt this view by introducing the ``world lines'' of particles as a device for
reasoning about motion.  We've also already mentioned (@ref{2.2.3})
that this is the natural way to think about signal-processing systems.  We will
explore applications of streams to signal processing in @ref{3.5.3}.}

If time is measured in discrete steps, then we can model a time function as a
(possibly infinite) sequence.  In this section, we will see how to model change
in terms of sequences that represent the time histories of the systems being
modeled.  To accomplish this, we introduce new data structures called
@newterm{streams}.  From an abstract point of view, a stream is simply a
sequence.  However, we will find that the straightforward implementation of
streams as lists (as in @ref{2.2.1}) doesn't fully reveal the power of
stream processing.  As an alternative, we introduce the technique of
@newterm{delayed evaluation}, which enables us to represent very large (even
infinite) sequences as streams.

Stream processing lets us model systems that have state without ever using
assignment or mutable data.  This has important implications, both theoretical
and practical, because we can build models that avoid the drawbacks inherent in
introducing assignment.  On the other hand, the stream framework raises
difficulties of its own, and the question of which modeling technique leads to
more modular and more easily maintained systems remains open.

@menu
* 3.5.1::            Streams Are Delayed Lists
* 3.5.2::            Infinite Streams
* 3.5.3::            Exploiting the Stream Paradigm
* 3.5.4::            Streams and Delayed Evaluation
* 3.5.4a::           Lock-Free Data Structures
* 3.5.5::            Modularity of Functional Programs and Modularity of
                     Objects
@end menu

@node	3.5.1, 3.5.2, 3.5, 3.5
@subsection Streams Are Delayed Lists

As we saw in @ref{2.2.3}, sequences can serve as standard interfaces
for combining program modules.  We formulated powerful abstractions for
manipulating sequences, such as @code{map}, @code{filter}, and
@code{accumulate}, that capture a wide variety of operations in a manner that
is both succinct and elegant.

Unfortunately, if we represent sequences as lists, this elegance is bought at
the price of severe inefficiency with respect to both the time and space
required by our computations.  When we represent manipulations on sequences as
transformations of lists, our programs must construct and copy data structures
(which may be huge) at every step of a process.

To see why this is true, let us compare two programs for computing the sum of
all the prime numbers in an interval.  The first program is written in standard
iterative style:@footnote{Assume that we have a predicate @code{is_prime} (e.g.,
as in @ref{1.2.6}) that tests for primality.}

@example
fn sum_primes(a: u64, b: u64) -> u64 @{
    let mut accum = 0;
    for count in a..=b @{
        if is_prime(count) @{
            accum += count;
        @}
    @}
    accum
@}
@end example

@noindent
The second program performs the same computation using the sequence operations
of @ref{2.2.3}:

@example
fn sum_primes(a: u64, b: u64) -> u64 @{
    (a..=b)
        .filter(|&n| is_prime(n))
        .sum()
@}
@end example

@noindent
In carrying out the computation, the first program needs to store only the sum
being accumulated.  In contrast, the filter in the second program cannot do any
testing until @code{enumerate-interval} has constructed a complete list of the
numbers in the interval.  The filter generates another list, which in turn is
passed to @code{accumulate} before being collapsed to form a sum.  Such large
intermediate storage is not needed by the first program, which we can think of
as enumerating the interval incrementally, adding each prime to the sum as it
is generated.

The inefficiency in using lists becomes painfully apparent if we use the
sequence paradigm to compute the second prime in the interval from 10,000 to
1,000,000 by evaluating the expression

@example
(10_000..=1_000_000)
    .filter(|&n| is_prime(n))
    .nth(1)  // Second prime (0-indexed)
    .unwrap()
// => 10009
@end example

@noindent
This expression does find the second prime, but the computational overhead is
outrageous.  We construct a list of almost a million integers, filter this list
by testing each element for primality, and then ignore almost all of the
result.  In a more traditional programming style, we would interleave the
enumeration and the filtering, and stop when we reached the second prime.

Streams are a clever idea that allows one to use sequence manipulations without
incurring the costs of manipulating sequences as lists.  With streams we can
achieve the best of both worlds: We can formulate programs elegantly as
sequence manipulations, while attaining the efficiency of incremental
computation.  The basic idea is to arrange to construct a stream only
partially, and to pass the partial construction to the program that consumes
the stream.  If the consumer attempts to access a part of the stream that has
not yet been constructed, the stream will automatically construct just enough
more of itself to produce the required part, thus preserving the illusion that
the entire stream exists.  In other words, although we will write programs as
if we were processing complete sequences, we design our stream implementation
to automatically and transparently interleave the construction of the stream
with its use.

On the surface, streams are just lists with different names for the procedures
that manipulate them.  There is a constructor, @code{Stream::cons} (or similar constructor), and two
selectors, @code{head} and @code{tail}, which satisfy the
constraints

@example
// Iterator contract (Rust equivalent of stream axioms):
// iter.next()  =>  Some(first_element)  // on first call
// iter.next()  =>  Some(second_element) // on subsequent calls
// iter.next()  =>  None                 // when exhausted
@end example

@noindent
There is a distinguishable object, @code{the-empty-stream}, which cannot be the
result of any @code{cons-stream} operation, and which can be identified with
the predicate @code{stream-null?}.@footnote{In the @abbr{MIT}
implementation, @code{the-empty-stream} is the same as the empty list
@code{'()}, and @code{stream-null?} is the same as @code{null?}.}  Thus we can
make and use streams, in just the same way as we can make and use lists, to
represent aggregate data arranged in a sequence.  In particular, we can build
stream analogs of the list operations from @ref{Chapter 2}, such as
@code{list-ref}, @code{map}, and @code{for-each}:@footnote{This should bother
you.  The fact that we are defining such similar procedures for streams and
lists indicates that we are missing some underlying abstraction.
Unfortunately, in order to exploit this abstraction, we will need to exert
finer control over the process of evaluation than we can at present.  We will
discuss this point further at the end of @ref{3.5.4}.  In 
@ref{4.2}, we'll develop a framework that unifies lists and streams.}

@example
// Rust iterators are already lazy streams!
// These operations are built into Iterator trait:

// stream-ref => Iterator::nth
fn stream_ref<I: Iterator>(s: I, n: usize) -> Option<I::Item> @{
    s.skip(n).next()
@}

// stream-map => Iterator::map
fn stream_map<I, F, B>(s: I, proc: F) -> impl Iterator<Item = B>
where
    I: Iterator,
    F: FnMut(I::Item) -> B,
@{
    s.map(proc)
@}

// stream-for-each => Iterator::for_each
fn stream_for_each<I, F>(s: I, proc: F)
where
    I: Iterator,
    F: FnMut(I::Item),
@{
    s.for_each(proc);
@}
@end example

@noindent
@code{Stream-for-each} is useful for viewing streams:

@example
fn display_stream<I: Iterator>(s: I)
where
    I::Item: std::fmt::Display,
@{
    for x in s @{
        println!("@{@}", x);
    @}
@}
@end example

@noindent
To make the stream implementation automatically and transparently interleave
the construction of a stream with its use, we will arrange for the @code{cdr}
of a stream to be evaluated when it is accessed by the @code{tail}
procedure rather than when the stream is constructed by @code{cons-stream}.
This implementation choice is reminiscent of our discussion of rational numbers
in @ref{2.1.2}, where we saw that we can choose to implement rational
numbers so that the reduction of numerator and denominator to lowest terms is
performed either at construction time or at selection time.  The two
rational-number implementations produce the same data abstraction, but the
choice has an effect on efficiency.  There is a similar relationship between
streams and ordinary lists.  As a data abstraction, streams are the same as
lists.  The difference is the time at which the elements are evaluated.  With
ordinary lists, both the @code{car} and the @code{cdr} are evaluated at
construction time.  With streams, the @code{cdr} is evaluated at selection
time.

Our implementation of streams will be based on a special form called
@code{delay}.  Evaluating @code{(delay ⟨@var{exp}⟩)} does not evaluate the
expression @code{⟨}@var{exp}@code{⟩}, but rather returns a so-called 
@newterm{delayed object}, which we can think of as a ``promise'' to evaluate 
@code{⟨}@var{exp}@code{⟩} at some
future time.  As a companion to @code{delay}, there is a procedure called
@code{force} that takes a delayed object as argument and performs the
evaluation---in effect, forcing the @code{delay} to fulfill its promise.  We
will see below how @code{delay} and @code{force} can be implemented, but first
let us use these to construct streams.

@code{Cons-stream} is a special form defined so that

@example
std::iter::once(a).chain(b)
@end example

@noindent
is equivalent to

@example
// In Rust, iterators are lazy by default
// The "tail" is computed on demand when next() is called
std::iter::once(a).chain(/* b is evaluated lazily */)
@end example

@noindent
What this means is that we will construct streams using pairs.  However, rather
than placing the value of the rest of the stream into the @code{cdr} of the
pair we will put there a promise to compute the rest if it is ever requested.
@code{Stream-car} and @code{tail} can now be defined as procedures:

@example
// In Rust, Iterator::next() returns Option<Item>
// - Some(item) = stream-car (the first element)
// - Calling next() again = stream-cdr (rest of stream)
let mut stream = (1..=10).filter(|n| n % 2 == 0);
let first = stream.next();   // stream-car => Some(2)
let second = stream.next();  // stream-cdr then car => Some(4)
@end example

@noindent
@code{Stream-car} selects the @code{car} of the pair; @code{tail} selects
the @code{cdr} of the pair and evaluates the delayed expression found there to
obtain the rest of the stream.@footnote{Although @code{head} and
@code{tail} can be defined as procedures, @code{cons-stream} must be a
special form.  If @code{cons-stream} were a procedure, then, according to our
model of evaluation, evaluating @code{(cons-stream ⟨@var{a}⟩ ⟨@var{b}⟩)} would
automatically cause @code{⟨}@var{b}@code{⟩} to be evaluated, which is precisely what we do
not want to happen.  For the same reason, @code{delay} must be a special form,
though @code{force} can be an ordinary procedure.}

@subsubheading The stream implementation in action

To see how this implementation behaves, let us analyze the ``outrageous'' prime
computation we saw above, reformulated in terms of streams:

@example
// Lazy evaluation: only computes elements as needed
(10_000..=1_000_000)
    .filter(|&n| is_prime(n))
    .nth(1)  // Gets second prime without computing all
    .unwrap()
// Only tests primality until second prime is found!
@end example

@noindent
We will see that it does indeed work efficiently.

We begin by calling @code{stream-enumerate-interval} with the arguments 10,000
and 1,000,000.  @code{Stream-enumerate-interval} is the stream analog of
@code{enumerate-interval} (@ref{2.2.3}):

@example
// In Rust, ranges are already lazy iterators!
fn stream_enumerate_interval(low: u64, high: u64) -> impl Iterator<Item = u64> @{
    low..=high  // RangeInclusive is lazy - no allocation
@}
@end example

@noindent
and thus the result returned by @code{stream-enumerate-interval}, formed by the
@code{cons-stream}, is@footnote{The numbers shown here do not really appear in
the delayed expression.  What actually appears is the original expression, in
an environment in which the variables are bound to the appropriate numbers.
For example, @code{(+ low 1)} with @code{low} bound to 10,000 actually appears
where @code{10001} is shown.}

@example
// The Rust range iterator internally stores:
// RangeInclusive @{ start: 10000, end: 1000000 @}
// No elements are computed until next() is called
10_000..=1_000_000
@end example

@noindent
That is, @code{stream-enumerate-interval} returns a stream represented as a
pair whose @code{car} is 10,000 and whose @code{cdr} is a promise to enumerate
more of the interval if so requested.  This stream is now filtered for primes,
using the stream analog of the @code{filter} procedure (@ref{2.2.3}):

@example
// In Rust, Iterator::filter is already lazy
fn stream_filter<I, P>(stream: I, pred: P) -> impl Iterator<Item = I::Item>
where
    I: Iterator,
    P: FnMut(&I::Item) -> bool,
@{
    stream.filter(pred)
    // Returns a Filter adapter - no computation yet!
@}
@end example

@noindent
@code{Stream-filter} tests the @code{head} of the stream (the @code{car}
of the pair, which is 10,000).  Since this is not prime, @code{stream-filter}
examines the @code{tail} of its input stream.  The call to
@code{tail} forces evaluation of the delayed
@code{stream-enumerate-interval}, which now returns

@example
// After consuming 10000, the range's internal state becomes:
// RangeInclusive @{ start: 10001, end: 1000000 @}
// Still lazy - 10001 computed only when next() called
@end example

@noindent
@code{Stream-filter} now looks at the @code{head} of this stream, 10,001,
sees that this is not prime either, forces another @code{tail}, and so
on, until @code{stream-enumerate-interval} yields the prime 10,007, whereupon
@code{stream-filter}, according to its definition, returns

@example
// Filter yields matching element, continues lazily
// Internal state: Filter @{ iter: range, predicate @}
// Only advances when next element requested
@end example

@noindent
which in this case is

@example
// After finding first prime 10007:
// Filter @{ iter: 10008..=1000000, predicate: is_prime @}
// The 10007 is yielded, rest remains unevaluated
@end example

@noindent
This result is now passed to @code{tail} in our original expression.
This forces the delayed @code{stream-filter}, which in turn keeps forcing the
delayed @code{stream-enumerate-interval} until it finds the next prime, which
is 10,009.  Finally, the result passed to @code{head} in our original
expression is

@example
// After finding second prime 10009:
// Filter @{ iter: 10010..=1000000, predicate: is_prime @}
// nth(1) returns 10009, computation stops here
@end example

@noindent
@code{Stream-car} returns 10,009, and the computation is complete.  Only as
many integers were tested for primality as were necessary to find the second
prime, and the interval was enumerated only as far as was necessary to feed the
prime filter.

In general, we can think of delayed evaluation as ``demand-driven''
programming, whereby each stage in the stream process is activated only enough
to satisfy the next stage.  What we have done is to decouple the actual order
of events in the computation from the apparent structure of our procedures.  We
write procedures as if the streams existed ``all at once'' when, in reality,
the computation is performed incrementally, as in traditional programming
styles.

@subsubheading Implementing @code{delay} and @code{force}

Although @code{delay} and @code{force} may seem like mysterious operations,
their implementation is really quite straightforward.  @code{Delay} must
package an expression so that it can be evaluated later on demand, and we can
accomplish this simply by treating the expression as the body of a procedure.
@code{Delay} can be a special form such that

@example
|| exp  // A closure captures the expression
@end example

@noindent
is syntactic sugar for

@example
|| exp  // Equivalent: closure with no arguments
@end example

@noindent
@code{Force} simply calls the procedure (of no arguments) produced by
@code{delay}, so we can implement @code{force} as a procedure:

@example
fn force<T, F: FnOnce() -> T>(delayed_object: F) -> T @{
    delayed_object()  // Simply call the closure
@}
@end example

@noindent
This implementation suffices for @code{delay} and @code{force} to work as
advertised, but there is an important optimization that we can include.  In
many applications, we end up forcing the same delayed object many times.  This
can lead to serious inefficiency in recursive programs involving streams.  (See
@ref{Exercise 3.57}.)  The solution is to build delayed objects so that the
first time they are forced, they store the value that is computed.  Subsequent
forcings will simply return the stored value without repeating the computation.
In other words, we implement @code{delay} as a special-purpose memoized
procedure similar to the one described in @ref{Exercise 3.27}.  One way to
accomplish this is to use the following procedure, which takes as argument a
procedure (of no arguments) and returns a memoized version of the procedure.
The first time the memoized procedure is run, it saves the computed result.  On
subsequent evaluations, it simply returns the result.

@example
use std::cell::OnceCell;

// Memoized thunk using OnceCell for single initialization
struct MemoizedThunk<T, F: FnOnce() -> T> @{
    result: OnceCell<T>,
    proc: Option<F>,  // Option allows taking ownership
@}

impl<T, F: FnOnce() -> T> MemoizedThunk<T, F> @{
    fn new(proc: F) -> Self @{
        MemoizedThunk @{
            result: OnceCell::new(),
            proc: Some(proc),
        @}
    @}

    fn force(&mut self) -> &T @{
        self.result.get_or_init(|| @{
            (self.proc.take().unwrap())()
        @})
    @}
@}
@end example

@noindent
@code{Delay} is then defined so that @code{(delay ⟨@var{exp}⟩)} is equivalent
to

@example
// std::cell::Lazy provides this in Rust:
use std::cell::LazyCell;
let delayed = LazyCell::new(|| exp);
// First access computes; subsequent accesses return cached value
@end example

@noindent
and @code{force} is as defined previously.@footnote{There are many possible
implementations of streams other than the one described in this section.
Delayed evaluation, which is the key to making streams practical, was inherent
in Algol 60's @newterm{call-by-name} parameter-passing method.  The use of this
mechanism to implement streams was first described by @ref{Landin (1965)}.  Delayed
evaluation for streams was introduced into Lisp by @ref{Friedman and Wise (1976)}. In
their implementation, @code{cons} always delays evaluating its arguments, so
that lists automatically behave as streams.  The memoizing optimization is also
known as @newterm{call-by-need}.  The Algol community would refer to our
original delayed objects as @newterm{call-by-name thunks} and to the optimized
versions as @newterm{call-by-need thunks}.}

@quotation
@strong{@anchor{Exercise 3.50}Exercise 3.50:} Complete the following
definition, which generalizes @code{stream-map} to allow procedures that take
multiple arguments, analogous to @code{map} in @ref{2.2.1}.

@example
// Multi-iterator map using Iterator::zip
fn stream_map2<A, B, R, I1, I2, F>(
    mut s1: I1,
    mut s2: I2,
    mut proc: F,
) -> impl Iterator<Item = R>
where
    I1: Iterator<Item = A>,
    I2: Iterator<Item = B>,
    F: FnMut(A, B) -> R,
@{
    std::iter::from_fn(move || @{
        Some(proc(s1.next()?, s2.next()?))
    @})
@}
// Or simply: s1.zip(s2).map(|(a, b)| proc(a, b))
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 3.51}Exercise 3.51:} In order to take a closer look at
delayed evaluation, we will use the following procedure, which simply returns
its argument after printing it:

@example
fn show<T: std::fmt::Debug + Clone>(x: T) -> T @{
    println!("@{:?@}", x);
    x
@}
@end example

What does the interpreter print in response to evaluating each expression in
the following sequence?@footnote{Exercises such as @ref{Exercise 3.51} and
@ref{Exercise 3.52} are valuable for testing our understanding of how
@code{delay} works.  On the other hand, intermixing delayed evaluation with
printing---and, even worse, with assignment---is extremely confusing, and
instructors of courses on computer languages have traditionally tormented their
students with examination questions such as the ones in this section.  Needless
to say, writing programs that depend on such subtleties is odious programming
style.  Part of the power of stream processing is that it lets us ignore the
order in which events actually happen in our programs.  Unfortunately, this is
precisely what we cannot afford to do in the presence of assignment, which
forces us to be concerned with time and change.}

@example
let x = (0..=10).map(|n| show(n));
// Iterators in Rust are consumed on use, so we need collect or clone

// With inspect for side effects:
let mut x = (0..=10).inspect(|n| println!("@{@}", n));
x.nth(5);  // Prints 0,1,2,3,4,5 then returns Some(5)
x.nth(1);  // Continues from 6, prints 6,7 then returns Some(7)
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 3.52}Exercise 3.52:} Consider the sequence of
expressions

@example
use std::cell::Cell;

let sum = Cell::new(0_i64);

let accum = |x: i64| @{
    sum.set(sum.get() + x);
    sum.get()
@};

// Warning: this example shows problematic mutation with lazy eval!
// The order of forcing affects results due to shared mutable state
let seq = (1..=20).map(|x| accum(x));

let y = seq.clone().filter(|&x| x % 2 == 0);
let z = seq.clone().filter(|&x| x % 5 == 0);

// Results depend on evaluation order - this is the lesson:
// mixing lazy streams with mutation is confusing!
@end example

What is the value of @code{sum} after each of the above expressions is
evaluated?  What is the printed response to evaluating the @code{stream-ref}
and @code{display-stream} expressions?  Would these responses differ if we had
implemented @code{delay(⟨@var{exp}⟩)} simply as @code{|| ⟨@var{exp}⟩}
without using the optimization provided by @code{memo_proc}?  Explain.
@end quotation

@node	3.5.2, 3.5.3, 3.5.1, 3.5
@subsection 무한 스트림 (Infinite Streams)

우리는 실제로는 접근할 필요가 있는 만큼만 스트림을 계산함에도 불구하고, 스트림을 완전한 실체로 조작하는 환상을 지원하는 방법을 보았다.
우리는 시퀀스가 매우 길더라도, 이 기법을 활용하여 시퀀스를 스트림으로 효율적으로 표현할 수 있다.
더 놀라운 것은, 우리가 스트림을 사용하여 무한히 긴 시퀀스를 표현할 수 있다는 점이다.
예를 들어, 양의 정수 스트림에 대한 다음 정의를 고려해 보자:

@example
// 무한 정수 스트림
struct IntegersFrom @{
    current: i64,
@}

impl IntegersFrom @{
    fn new(start: i64) -> Self @{
        IntegersFrom @{ current: start @}
    @}
@}

impl Iterator for IntegersFrom @{
    type Item = i64;

    fn next(&mut self) -> Option<Self::Item> @{
        let value = self.current;
        self.current += 1;
        Some(value)
    @}
@}

// 사용법: let integers = IntegersFrom::new(1);
@end example

@noindent
이것이 말이 되는 이유는 @code{integers}가 @code{car}가 1이고 @code{cdr}이 2로 시작하는 정수를 생성하겠다는 약속인 쌍일 것이기 때문이다.
이것은 무한히 긴 스트림이지만, 주어진 어떤 시점에서도 우리는 오직 유한한 부분만 검사할 수 있다.
따라서 우리 프로그램은 전체 무한 스트림이 거기에 없다는 것을 결코 알지 못할 것이다.

@code{integers}를 사용하여 우리는 7로 나누어떨어지지 않는 정수들의 스트림과 같은 다른 무한 스트림을 정의할 수 있다:

@example
fn divisible(x: i64, y: i64) -> bool @{
    x % y == 0
@}

// 7로 나누어떨어지지 않는 정수들 - 지연, 무한
let no_sevens = (1..).filter(|&x| !divisible(x, 7));
@end example

@noindent
그러면 우리는 단순히 이 스트림의 요소에 접근함으로써 7로 나누어떨어지지 않는 정수들을 찾을 수 있다:

@example
(1..).filter(|&x| x % 7 != 0).nth(100)
// => Some(117)
@end example

@noindent
@code{integers}와 유사하게, 우리는 피보나치 수의 무한 스트림을 정의할 수 있다:

@example
// 무한 피보나치 반복자
struct Fibonacci @{
    current: u64,
    next: u64,
@}

impl Iterator for Fibonacci @{
    type Item = u64;
    fn next(&mut self) -> Option<u64> @{
        let result = self.current;
        self.current = self.next;
        self.next = result + self.next;
        Some(result)
    @}
@}

let fibs = Fibonacci @{ current: 0, next: 1 @};
// fibs.take(10).collect::<Vec<_>>()
// => [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]
@end example

@noindent
@code{Fibs}는 @code{car}가 0이고 @code{cdr}이 @code{(fibgen 1 1)}을 평가하겠다는 약속인 쌍이다.
이 지연된 @code{(fibgen 1 1)}을 평가하면, @code{car}가 1이고 @code{cdr}이 @code{(fibgen 1 2)}를 평가하겠다는 약속인 쌍이 생성될 것이고, 이런 식으로 계속된다.

더 흥미로운 무한 스트림을 살펴보기 위해, 우리는 @code{no-sevens} 예제를 일반화하여 @newterm{에라토스테네스의 체(sieve of Eratosthenes)}로 알려진 방법을 사용하여 소수(prime numbers)의 무한 스트림을 구성할 수 있다.@footnote{기원전 3세기 알렉산드리아의 그리스 철학자 에라토스테네스(Eratosthenes)는 하지 정오에 드리워진 그림자를 관측하여 지구의 둘레를 처음으로 정확하게 추정한 것으로 유명하다. 에라토스테네스의 체 방법은 고대의 것이지만, 최근까지 큰 소수를 찾는 데 존재하는 가장 강력한 도구였던 특수 목적 하드웨어 ``체''의 기초를 형성했다. 그러나 70년대 이후로 이 방법들은 @ref{1.2.6}에서 논의된 확률적 기술의 파생물로 대체되었다.}
우리는 첫 번째 소수인 2로 시작하는 정수들로 시작한다.
나머지 소수를 얻기 위해, 우리는 나머지 정수들에서 2의 배수를 걸러내는 것으로 시작한다.
그러면 다음 소수인 3으로 시작하는 스트림이 남는다.
이제 우리는 이 스트림의 나머지에서 3의 배수를 걸러낸다.
그러면 다음 소수인 5로 시작하는 스트림이 남고, 이런 식으로 계속된다.
즉, 우리는 다음과 같이 기술되는 체질(sieving) 프로세스에 의해 소수를 구성한다:
스트림 @code{S}를 체질하려면, @code{S}의 첫 번째 요소가 첫 번째 요소이고 나머지는 @code{S}의 나머지에서 @code{S}의 첫 번째 요소의 모든 배수를 걸러내고 그 결과를 체질하여 얻은 스트림을 형성하라.
이 프로세스는 스트림 연산으로 쉽게 설명된다:

@example
// 반복자로서의 에라토스테네스의 체
// 참고: 이 함수형 접근 방식은 중첩된 필터를 생성한다
fn sieve(stream: impl Iterator<Item = u64> + 'static)
    -> Box<dyn Iterator<Item = u64>>
@{
    let mut iter = stream.peekable();
    if let Some(&prime) = iter.peek() @{
        let prime = iter.next().unwrap();
        Box::new(
            std::iter::once(prime).chain(
                sieve(iter.filter(move |&x| x % prime != 0))
            )
        )
    @} else @{
        Box::new(std::iter::empty())
    @}
@}

let primes = sieve(2..);
@end example

@noindent
이제 특정 소수를 찾으려면 요청하기만 하면 된다:

@example
sieve(2..).nth(50)
// => Some(233)
@end example

@noindent
@code{sieve}에 의해 설정된 신호 처리 시스템을 생각해보는 것은 흥미로운데, 이는 @ref{Figure 3.31}의 ``헨더슨 다이어그램(Henderson diagram)''에 나와 있다.@footnote{우리는 스트림 처리에 대해 생각하는 방법으로 이런 종류의 다이어그램을 우리에게 처음 보여준 피터 헨더슨(Peter Henderson)의 이름을 따서 이 그림들의 이름을 지었다. 각 실선은 전송되는 값의 스트림을 나타낸다. @code{car}에서 @code{cons}와 @code{filter}로 가는 점선은 이것이 스트림이 아니라 단일 값임을 나타낸다.}
입력 스트림은 스트림의 첫 번째 요소를 나머지 스트림과 분리하는 ``un@code{cons}er''로 들어간다.
첫 번째 요소는 나누어떨어짐 필터를 구성하는 데 사용되며, 나머지는 이 필터를 통과하고, 필터의 출력은 다른 체 상자로 공급된다.
그런 다음 원래의 첫 번째 요소가 내부 체의 출력에 @code{cons}되어 출력 스트림을 형성한다.
따라서 스트림이 무한할 뿐만 아니라 신호 처리기 또한 무한한데, 왜냐하면 체가 그 안에 체를 포함하기 때문이다.

@float
@anchor{Figure 3.31}
@ifinfo
@strong{Figure 3.31:} 신호 처리 시스템으로 본 소수 체.

@example
  +---------------------------------------------------------------+
  | sieve                                                         |
  |                                                               |
  |        __/|                                        |\__       |
  |     __/car|........................................|   \__    |
  |   _/      |           :                            |      \_  |
----><_       |           V                            |  cons _>---->
  |    \__    |    +------------+    +------------+    |    __/   |
  |       \cdr|--->| filter:    |    | sieve      |--->| __/      |
  |          \|    |            |--->|            |    |/         |
  |                | not        |    |            |               |
  |                | divisible? |    |            |               |
  |                +------------+    +------------+               |
  +---------------------------------------------------------------+
@end example
@end ifinfo
@iftex
@image{fig/chap3/Fig3.31a,132mm,,,.std.svg}
@caption{@strong{Figure 3.31:} 신호 처리 시스템으로 본 소수 체.}
@end iftex
@end float

@subsubheading 스트림을 암시적으로 정의하기 (Defining streams implicitly)

위의 @code{integers}와 @code{fibs} 스트림은 스트림 요소를 하나씩 명시적으로 계산하는 ``생성'' 프로시저를 지정하여 정의되었다.
스트림을 지정하는 대안적인 방법은 지연 평가를 활용하여 스트림을 암시적으로 정의하는 것이다.
예를 들어, 다음 표현식은 @code{ones} 스트림을 1의 무한 스트림으로 정의한다:

@example
// 1의 무한 스트림
let ones = std::iter::repeat(1);
// 또는: std::iter::from_fn(|| Some(1))
@end example

@noindent
이것은 재귀 프로시저의 정의와 매우 유사하게 작동한다: @code{ones}는 @code{car}가 1이고 @code{cdr}이 @code{ones}를 평가하겠다는 약속인 쌍이다.
@code{cdr}을 평가하면 다시 1과 @code{ones}를 평가하겠다는 약속을 얻게 되고, 이런 식으로 계속된다.

우리는 두 개의 주어진 스트림의 요소별 합을 생성하는 @code{add_streams}와 같은 연산으로 스트림을 조작하여 더 흥미로운 일을 할 수 있다:@footnote{이것은 @ref{Exercise 3.50}의 @code{stream-map} 일반화 버전을 사용한다.}

@example
fn add_streams<I1, I2>(s1: I1, s2: I2) -> impl Iterator<Item = i64>
where
    I1: Iterator<Item = i64>,
    I2: Iterator<Item = i64>,
@{
    s1.zip(s2).map(|(a, b)| a + b)
@}
@end example

@noindent
이제 우리는 다음과 같이 정수를 정의할 수 있다:

@example
// Rust에서 더 간단한 접근 방식은 단지 범위를 사용하는 것이다:
let integers = 1_i64..;

// 자기 참조적 정의는 명시적인 상태를 필요로 한다:
let integers = std::iter::successors(Some(1_i64), |&n| Some(n + 1));
@end example

@noindent
이것은 @code{integers}를 첫 번째 요소가 1이고 나머지는 @code{ones}와 @code{integers}의 합인 스트림으로 정의한다.
따라서 @code{integers}의 두 번째 요소는 1 더하기 @code{integers}의 첫 번째 요소, 즉 2이다; @code{integers}의 세 번째 요소는 1 더하기 @code{integers}의 두 번째 요소, 즉 3이다; 이런 식으로 계속된다.
이 정의가 작동하는 이유는 어느 시점에서든 다음 정수를 생성하기 위해 정의로 다시 피드백할 수 있을 만큼 충분한 @code{integers} 스트림이 생성되었기 때문이다.

우리는 같은 스타일로 피보나치 수를 정의할 수 있다:

@example
// successors를 통한 자기 참조적 피보나치
let fibs = std::iter::successors(
    Some((0_u64, 1_u64)),
    |&(a, b)| Some((b, a + b))
).map(|(a, _)| a);

// 또는 unfold를 사용하여 (nightly):
// std::iter::unfold((0, 1), |(a, b)| @{
//     let next = (*a, *b);
//     *a = next.1;
//     *b = next.0 + next.1;
//     Some(next.0)
// @})
@end example

@noindent
이 정의는 @code{fibs}가 0과 1로 시작하는 스트림이며, 스트림의 나머지는 @code{fibs}를 한 자리 이동한 것과 자신을 더하여 생성될 수 있다고 말한다:

@example
    1 1 2 3 5  8 13 21 @r{…} = @code{(stream-cdr fibs)}
    0 1 1 2 3  5  8 13 @r{…} = @code{fibs}
0 1 1 2 3 5 8 13 21 34 @r{…} = @code{fibs}
@end example

@noindent
@code{Scale-stream}은 그러한 스트림 정의를 공식화하는 데 유용한 또 다른 프로시저이다.
이것은 스트림의 각 항목에 주어진 상수를 곱한다:

@example
fn scale_stream<I: Iterator<Item = i64>>(
    stream: I,
    factor: i64,
) -> impl Iterator<Item = i64> @{
    stream.map(move |x| x * factor)
@}
@end example

@noindent
예를 들어,

@example
// 2의 거듭제곱: 1, 2, 4, 8, 16, ...
let powers_of_2 = std::iter::successors(
    Some(1_i64),
    |&n| Some(n * 2)
);
@end example

@noindent
은 2의 거듭제곱 스트림을 생성한다: 1, 2, 4, 8, 16, 32, @dots{}.

소수 스트림의 대안적인 정의는 정수로 시작해서 소수성 테스트로 필터링하여 제공할 수 있다.
시작하려면 첫 번째 소수인 2가 필요하다:

@example
// 정수를 필터링하여 얻는 소수
fn primes() -> impl Iterator<Item = u64> @{
    std::iter::once(2).chain(
        (3..).filter(|&n| is_prime(n))
    )
@}
@end example

@noindent
이 정의는 보이는 것만큼 간단하지 않은데, 왜냐하면 우리는 숫자 @math{n}이 @math{\sqrt{n}}보다 작거나 같은 소수(단지 임의의 정수가 아니라)로 나누어떨어지는지 확인하여 소수인지 테스트할 것이기 때문이다:

@example
// 이전에 계산된 소수를 사용하여 소수성 테스트
fn is_prime_with_primes<I: Iterator<Item = u64>>(n: u64, primes: I) -> bool @{
    for p in primes @{
        if p * p > n @{
            return true;
        @}
        if n % p == 0 @{
            return false;
        @}
    @}
    true
@}
@end example

@noindent
이것은 재귀적 정의인데, @code{primes}가 @code{is_prime} 술어의 관점에서 정의되고, 이 술어 자체가 @code{primes} 스트림을 사용하기 때문이다.
이 프로시저가 작동하는 이유는 어느 시점에서든 우리가 다음에 확인해야 할 숫자의 소수성을 테스트하기에 충분한 @code{primes} 스트림이 생성되었기 때문이다.
즉, 우리가 소수성을 테스트하는 모든 @math{n}에 대해, @math{n}이 소수가 아니거나(이 경우 그것을 나누는 소수가 이미 생성됨) @math{n}이 소수이다(이 경우 이미 생성된 소수---즉, @math{n}보다 작은 소수---가 @math{\sqrt{n}}보다 크다).@footnote{이 마지막 점은 매우 미묘하며 @math{{p_{n+1} \le p_n^2}}이라는 사실에 의존한다. (여기서 @math{p_k}는 @math{k}번째 소수를 나타낸다.) 이와 같은 추정은 확립하기가 매우 어렵다. 소수가 무한히 많다는 유클리드의 고대 증명은 @math{p_{n+1} \le {p_1 p_2 \cdots p_n + 1}}임을 보여주며, 1851년 러시아 수학자 P. L. Chebyshev가 모든 @math{n}에 대해 @math{p_{n+1} \le 2p_n}임을 확립할 때까지 실질적으로 더 나은 결과는 증명되지 않았다. 원래 1845년에 추측된 이 결과는 @newterm{베르트랑의 가설(Bertrand's hypothesis)}로 알려져 있다. 증명은 @ref{Hardy and Wright 1960}의 22.3절에서 찾을 수 있다.}

@quotation
@strong{@anchor{Exercise 3.53}연습문제 3.53:} 프로그램을 실행하지 않고, 다음에 의해 정의된 스트림의 요소를 설명하라

@example
// 2의 거듭제곱: 1, 2, 4, 8, 16, ...
// 각 요소는 이전 요소의 두 배: s[n] = 2 * s[n-1]
let s = std::iter::successors(Some(1_i64), |&n| Some(n + n));
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 3.54}연습문제 3.54:} @code{add_streams}와 유사하게 두 입력 스트림의 요소별 곱을 생성하는 프로시저 @code{mul_streams}를 정의하라.
이것과 @code{integers} 스트림을 사용하여, @math{n}번째 요소(0부터 셈)가 @math{{n + 1}} 팩토리얼인 스트림의 다음 정의를 완성하라:

@example
// factorials: 1!, 2!, 3!, 4!, ... = 1, 2, 6, 24, ...
fn factorials() -> impl Iterator<Item = u64> @{
    (1..).scan(1_u64, |acc, n| @{
        *acc *= n;
        Some(*acc)
    @})
@}
// 또는: std::iter::successors(Some((1u64, 1u64)), |(f, n)| Some((f * n, n + 1)))
//     .map(|(f, _)| f)
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 3.55}연습문제 3.55:} 스트림 @math{S}를 인자로 받아 요소가 @math{S_0}, @math{{S_0 + S_1}}, @math{{S_0 + S_1} + {S_2, \dots}}인 스트림을 반환하는 프로시저 @code{partial_sums}를 정의하라.
예를 들어, @code{(partial-sums integers)}는 스트림 1, 3, 6, 10, 15, @dots{}여야 한다.
@end quotation

@quotation
@strong{@anchor{Exercise 3.56}연습문제 3.56:} R. Hamming이 처음 제기한 유명한 문제는 2, 3, 또는 5 이외의 소인수가 없는 모든 양의 정수를 중복 없이 오름차순으로 나열하는 것이다.
이를 수행하는 한 가지 분명한 방법은 각 정수를 차례로 테스트하여 2, 3, 5 이외의 인수가 있는지 확인하는 것이다.
하지만 정수가 커짐에 따라 요구 사항에 맞는 정수가 점점 적어지므로 이는 매우 비효율적이다.
대안으로, 필요한 숫자 스트림을 @code{S}라고 하고 그것에 대한 다음 사실에 주목하자.

@itemize @bullet

@item
@code{S}는 1로 시작한다.

@item
@code{scale_stream(S, 2)}의 요소들은 또한 @code{S}의 요소들이다.

@item
@code{scale_stream(S, 3)}과 @code{scale_stream(S, 5)}에 대해서도 마찬가지이다.

@item
이것들이 @code{S}의 모든 요소이다.

@end itemize

이제 우리는 이 소스들로부터 요소들을 결합하기만 하면 된다.
이를 위해 우리는 두 정렬된 스트림을 중복을 제거하며 하나의 정렬된 결과 스트림으로 결합하는 프로시저 @code{merge}를 정의한다:

@example
// 두 정렬된 반복자를 병합하고 중복 제거
fn merge<I1, I2>(s1: I1, s2: I2) -> impl Iterator<Item = u64>
where
    I1: Iterator<Item = u64>,
    I2: Iterator<Item = u64>,
@{
    let mut p1 = s1.peekable();
    let mut p2 = s2.peekable();

    std::iter::from_fn(move || @{
        match (p1.peek(), p2.peek()) @{
            (Some(&a), Some(&b)) if a < b => p1.next(),
            (Some(&a), Some(&b)) if a > b => p2.next(),
            (Some(_), Some(_)) => @{
                p2.next(); // 중복 건너뛰기
                p1.next()
            @}
            (Some(_), None) => p1.next(),
            (None, Some(_)) => p2.next(),
            (None, None) => None,
        @}
    @})
@}
@end example

그러면 필요한 스트림은 다음과 같이 @code{merge}로 구성될 수 있다:

@example
// 해밍 수: 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, ...
// (2, 3, 5만을 소인수로 갖는 수들)
// 채우기: merge(scale(S, 2), merge(scale(S, 3), scale(S, 5)))
@end example

위에서 @code{⟨??⟩}로 표시된 곳에 누락된 표현식을 채워라.
@end quotation

@quotation
@strong{@anchor{Exercise 3.57}연습문제 3.57:} @code{add_streams} 프로시저에 기초한 @code{fibs}의 정의를 사용하여 @math{n}번째 피보나치 수를 계산할 때 덧셈은 몇 번 수행되는가?
만약 우리가 @code{delay(⟨@var{exp}⟩)}를 @ref{3.5.1}에서 설명한 @code{memo_proc} 프로시저가 제공하는 최적화를 사용하지 않고 단순히 @code{|| ⟨@var{exp}⟩}로 구현했다면 덧셈의 횟수가 기하급수적으로 더 많았을 것임을 보여라.@footnote{이 연습문제는 필요 호출(call-by-need)이 @ref{Exercise 3.27}에서 설명한 일반 메모이제이션과 얼마나 밀접하게 관련되어 있는지 보여준다. 그 연습문제에서, 우리는 대입을 사용하여 명시적으로 지역 테이블을 구성했다. 우리의 필요 호출 스트림 최적화는 이전에 강제된 스트림 부분에 값을 저장함으로써 사실상 그러한 테이블을 자동으로 구성한다.}
@end quotation

@quotation
@strong{@anchor{Exercise 3.58}연습문제 3.58:} 다음 프로시저에 의해 계산되는 스트림에 대한 해석을 제시하라:

@example
// num/den의 십진(또는 다른 기수) 전개를 생성
fn expand(num: i64, den: i64, radix: i64) -> impl Iterator<Item = i64> @{
    std::iter::successors(Some(num), move |&n| @{
        Some((n * radix) % den)
    @})
    .map(move |n| (n * radix) / den)
@}
// expand(1, 7, 10) => 1, 4, 2, 8, 5, 7, 1, 4, ... (1/7 = 0.142857...)
// expand(3, 8, 10) => 3, 7, 5, 0, 0, 0, ... (3/8 = 0.375)
@end example

(@code{Quotient}는 두 정수의 정수 몫을 반환하는 원시 함수이다.)
@code{(expand 1 7 10)}에 의해 생성되는 연속적인 요소는 무엇인가?
@code{(expand 3 8 10)}에 의해 생성되는 것은 무엇인가?
@end quotation

@quotation
@strong{@anchor{Exercise 3.59}연습문제 3.59:} @ref{2.5.3}에서 우리는 다항식을 항의 리스트로 표현하는 다항식 산술 시스템을 구현하는 방법을 보았다.
비슷한 방식으로, 우리는 다음과 같은 @newterm{멱급수(power series)}를 다룰 수 있다
@ifinfo

@example
               x^2     x^3       x^4
e^x = 1 + x + ----- + ----- + --------- + ...
                2     3 * 2   4 * 3 * 2

             x^2       x^4
cos x = 1 - ----- + --------- - ...
              2     4 * 3 * 2

             x^3         x^5
sin x = x - ----- + ------------- - ...
            3 * 2   5 * 4 * 3 * 2
@end example

@end ifinfo
@tex
\[ % :63:
\begin{eqnarray}
  e^x 	  &=& 1 + x + \frac{1}{2} x^2  + \frac{1}{3 \cdot 2} x^3  + \frac{1}{4 \cdot 3 \cdot 2} x^4  + \dots, \\
  \cos x  &=& 1 - \frac{1}{2} x^2  + \frac{1}{4 \cdot 3 \cdot 2} x^4  - \dots, \\
  \sin x  &=& x - \frac{1}{3 \cdot 2} x^3  + \frac{1}{5 \cdot 4 \cdot 3 \cdot 2} x^5  - \dots
\end{eqnarray}
\]
@end tex
@noindent
이것들은 무한 스트림으로 표현된다.
우리는 급수 @math{{a_0 + a_1 x} + {a_2 x^2} + {a_3 x^3 + \dots}}를 요소가 계수 @math{a_0}, @math{a_1}, @math{a_2}, @math{a_3}, @dots{}인 스트림으로 표현할 것이다.

@enumerate a

@item
급수 @math{{a_0 + a_1 x} + {a_2 x^2} + {a_3 x^3 + \dots}}의 적분은 다음 급수이다
@ifinfo

@example
             1             1             1
c + a_0 x + --- a_1 x^2 + --- a_2 x^3 + --- a_3 x^4 + ...
             2             3             4
@end example

@end ifinfo
@tex
\[ % :64:
  c + {a_0 x} + {\frac{1}{2} a_1 x^2} + {\frac{1}{3} a_2 x^3} + {\frac{1}{4} a_3 x^4 + \dots,}  \]
@end tex
@noindent
여기서 @math{c}는 임의의 상수이다.
멱급수를 나타내는 스트림 @math{a_0}, @math{a_1}, @math{a_2}, @dots{}를 입력으로 받아 급수의 적분의 비상수 항들의 계수 스트림 @math{a_0}, @math{{{1\over2}a_1}}, @math{{{1\over3}a_2}}, @dots{}를 반환하는 프로시저 @code{integrate_series}를 정의하라. (결과에는 상수항이 없으므로, 멱급수를 나타내지 않는다; 우리가 @code{integrate_series}를 사용할 때, 우리는 적절한 상수를 @code{cons}할 것이다.)

@item
함수 @math{{x \mapsto e^x}}는 그 자신의 도함수이다. 이것은 @math{e^x}와 @math{e^x}의 적분이 상수항(@math{{e^0 = 1}})을 제외하고는 같은 급수임을 의미한다.
따라서 우리는 @math{e^x}에 대한 급수를 다음과 같이 생성할 수 있다

@example
// e^x에 대한 멱급수: 계수는 1/n!
fn exp_series() -> impl Iterator<Item = f64> @{
    std::iter::successors(Some((1.0_f64, 1_u64)), |(coef, n)| @{
        Some((coef / (*n as f64), n + 1))
    @})
    .map(|(coef, _)| coef)
@}
// => 1.0, 1.0, 0.5, 0.166..., 0.0416..., ...
@end example

사인의 도함수는 코사인이고 코사인의 도함수는 사인의 음수라는 사실로부터 시작하여 사인과 코사인에 대한 급수를 생성하는 방법을 보여라:

@example
// cos(x) = 1 - x^2/2! + x^4/4! - ...
fn cosine_series() -> impl Iterator<Item = f64> @{
    // 계수: 1, 0, -1/2, 0, 1/24, 0, -1/720, ...
    (0..).scan((1.0_f64, 1), |(coef, sign), n| @{
        let result = if n % 2 == 0 @{ *coef * (*sign as f64) @} else @{ 0.0 @};
        if n % 2 == 0 @{
            *coef /= ((n + 1) * (n + 2)) as f64;
            *sign *= -1;
        @}
        Some(result)
    @})
@}

// sin(x) = x - x^3/3! + x^5/5! - ...
fn sine_series() -> impl Iterator<Item = f64> @{
    // 계수: 0, 1, 0, -1/6, 0, 1/120, ...
    (0..).scan((1.0_f64, 1), |(coef, sign), n| @{
        let result = if n % 2 == 1 @{ *coef * (*sign as f64) @} else @{ 0.0 @};
        if n % 2 == 1 @{
            *coef /= ((n + 1) * (n + 2)) as f64;
            *sign *= -1;
        @}
        Some(result)
    @})
@}
@end example
@end enumerate
@end quotation

@quotation
@strong{@anchor{Exercise 3.60}연습문제 3.60:} @ref{Exercise 3.59}에서처럼 계수 스트림으로 표현된 멱급수에 대해, 급수 더하기는 @code{add_streams}로 구현된다.
급수를 곱하기 위한 다음 프로시저의 정의를 완성하라:

@example
// 두 멱급수 곱하기 (코시 곱)
// c_n = sum(a_i * b_(n-i)) for i = 0..n
fn mul_series<I1, I2>(s1: I1, s2: I2) -> impl Iterator<Item = f64>
where
    I1: Iterator<Item = f64>,
    I2: Iterator<Item = f64>,
@{
    let a: Vec<f64> = s1.collect();
    let b: Vec<f64> = s2.collect();
    (0..a.len().min(b.len())).map(move |n| @{
        (0..=n).map(|i| a[i] * b[n - i]).sum()
    @})
@}
@end example

@ref{Exercise 3.59}의 급수를 사용하여 @math{{\sin^2x + \cos^2x = 1}}임을 검증함으로써 여러분의 프로시저를 테스트할 수 있다.
@end quotation

@quotation
@strong{@anchor{Exercise 3.61}연습문제 3.61:} @math{S}를 상수항이 1인 멱급수(@ref{Exercise 3.59})라고 하자.
우리가 멱급수 @math{{1 / S}}, 즉 @math{{SX = 1}}인 급수 @math{X}를 찾고 싶다고 가정하자.
@math{{S = 1 + S_R}}이라고 쓰자. 여기서 @math{S_R}은 상수항 이후의 @math{S}의 부분이다.
그러면 우리는 @math{X}를 다음과 같이 풀 수 있다:
@ifinfo

@example
        S * X = 1
(1 + S_R) * X = 1
  X + S_R * X = 1
            X = 1 - S_R * X
@end example

@end ifinfo
@tex
\[ % :65:
\begin{eqnarray}
  S \cdot X           &=&   1, \\
  (1 + S_R) \cdot X   &=&   1, \\
  X + S_R \cdot X     &=&   1, \\
  X                   &=&   1 - S_R \cdot X.
\end{eqnarray}
\]
@end tex
즉, @math{X}는 상수항이 1이고 고차항이 @math{S_R}의 음수에 @math{X}를 곱한 것으로 주어지는 멱급수이다.
이 아이디어를 사용하여 상수항이 1인 멱급수 @math{S}에 대해 @math{{1 / S}}를 계산하는 프로시저 @code{invert_unit_series}를 작성하라.
@ref{Exercise 3.60}의 @code{mul_series}를 사용해야 할 것이다.
@end quotation

@quotation
@strong{@anchor{Exercise 3.62}연습문제 3.62:} @ref{Exercise 3.60}과 @ref{Exercise 3.61}의 결과를 사용하여 두 멱급수를 나누는 프로시저 @code{div_series}를 정의하라.
@code{Div-series}는 분모 급수가 0이 아닌 상수항으로 시작한다면 어떤 두 급수에 대해서도 작동해야 한다. (만약 분모의 상수항이 0이라면, @code{div_series}는 오류를 신호해야 한다.)
@code{div_series}를 @ref{Exercise 3.59}의 결과와 함께 사용하여 탄젠트에 대한 멱급수를 생성하는 방법을 보여라.
@end quotation

@node	3.5.3, 3.5.4, 3.5.2, 3.5
@subsection Exploiting the Stream Paradigm

Streams with delayed evaluation can be a powerful modeling tool, providing many
of the benefits of local state and assignment.  Moreover, they avoid some of
the theoretical tangles that accompany the introduction of assignment into a
programming language.

The stream approach can be illuminating because it allows us to build systems
with different module boundaries than systems organized around assignment to
state variables.  For example, we can think of an entire time series (or
signal) as a focus of interest, rather than the values of the state variables
at individual moments.  This makes it convenient to combine and compare
components of state from different moments.

@subsubheading Formulating iterations as stream processes

In section @ref{1.2.1}, we introduced iterative processes, which proceed by
updating state variables.  We know now that we can represent state as a
``timeless'' stream of values rather than as a set of variables to be updated.
Let's adopt this perspective in revisiting the square-root procedure from
@ref{1.1.7}.  Recall that the idea is to generate a sequence of better
and better guesses for the square root of @math{x} by applying over and over again
the procedure that improves guesses:

@example
fn sqrt_improve(guess: f64, x: f64) -> f64 @{
    (guess + x / guess) / 2.0
@}
@end example

@noindent
In our original @code{sqrt} procedure, we made these guesses be the successive
values of a state variable. Instead we can generate the infinite stream of
guesses, starting with an initial guess of 1:@footnote{We can't use @code{let}
to bind the local variable @code{guesses}, because the value of @code{guesses}
depends on @code{guesses} itself.  @ref{Exercise 3.63} addresses why we want a
local variable here.}

@example
fn sqrt_stream(x: f64) -> impl Iterator<Item = f64> @{
    std::iter::successors(Some(1.0), move |&guess| @{
        Some(sqrt_improve(guess, x))
    @})
@}

// sqrt_stream(2.0).take(5).collect::<Vec<_>>()
// => [1.0, 1.5, 1.4166666666666665,
//     1.4142156862745097, 1.4142135623746899]
@end example

@noindent
We can generate more and more terms of the stream to get better and better
guesses.  If we like, we can write a procedure that keeps generating terms
until the answer is good enough.  (See @ref{Exercise 3.64}.)

Another iteration that we can treat in the same way is to generate an
approximation to @math{\pi}, based upon the alternating series that we saw in
@ref{1.3.1}:
@ifinfo

@example
[pi]        1     1     1
---- = 1 - --- + --- - --- + ...
  4         3     5     7
@end example

@end ifinfo
@tex
\[ % :66:
  {\pi\over4} \,=\, 1 - {1\over3} + {1\over5} - {1\over7} + {\dots.}  \]
@end tex
We first generate the stream of summands of the series (the reciprocals of the
odd integers, with alternating signs).  Then we take the stream of sums of more
and more terms (using the @code{partial_sums} procedure of @ref{Exercise 3.55})
and scale the result by 4:

@example
// Leibniz series: pi/4 = 1 - 1/3 + 1/5 - 1/7 + ...
fn pi_summands() -> impl Iterator<Item = f64> @{
    (0..).map(|n| @{
        let sign = if n % 2 == 0 @{ 1.0 @} else @{ -1.0 @};
        sign / (2 * n + 1) as f64
    @})
@}

fn pi_stream() -> impl Iterator<Item = f64> @{
    pi_summands().scan(0.0, |acc, x| @{
        *acc += x;
        Some(*acc * 4.0)
    @})
@}

// pi_stream().take(8).collect::<Vec<_>>()
// => [4.0, 2.666..., 3.466..., 2.895...,
//     3.339..., 2.976..., 3.283..., 3.017...]
@end example

@noindent
This gives us a stream of better and better approximations to @math{\pi},
although the approximations converge rather slowly.  Eight terms of the
sequence bound the value of @math{\pi} between 3.284 and 3.017.

So far, our use of the stream of states approach is not much different from
updating state variables.  But streams give us an opportunity to do some
interesting tricks.  For example, we can transform a stream with a
@newterm{sequence accelerator} that converts a sequence of approximations to a
new sequence that converges to the same value as the original, only faster.

One such accelerator, due to the eighteenth-century Swiss mathematician
Leonhard Euler, works well with sequences that are partial sums of alternating
series (series of terms with alternating signs).  In Euler's technique, if
@math{S_n} is the @math{n^{\text{th}}} term of the original sum sequence, then the
accelerated sequence has terms
@ifinfo

@example
             (S_(n+1) - S_n)^2
S_(n+1) - ------------------------
          S_(n-1) - 2S_n + S_(n+1)
@end example

@end ifinfo
@tex
\[ % :67:
  S_{n+1} - {{(S_{n+1} - S_n)^2 \over S_{n-1} - 2S_n + S_{n+1}}.}  \]
@end tex
Thus, if the original sequence is represented as a stream of values, the
transformed sequence is given by

@example
// Euler's sequence accelerator for alternating series
fn euler_transform<I: Iterator<Item = f64>>(s: I) -> impl Iterator<Item = f64> @{
    let items: Vec<f64> = s.collect();
    (0..items.len().saturating_sub(2)).map(move |i| @{
        let s0 = items[i];
        let s1 = items[i + 1];
        let s2 = items[i + 2];
        let denom = s0 - 2.0 * s1 + s2;
        if denom.abs() < 1e-15 @{
            s2
        @} else @{
            s2 - (s2 - s1).powi(2) / denom
        @}
    @})
@}
@end example

@noindent
We can demonstrate Euler acceleration with our sequence of approximations to
@math{\pi}:

@example
// euler_transform(pi_stream().take(20)).take(8)
// => [3.166..., 3.133..., 3.145..., 3.139...,
//     3.142..., 3.140..., 3.142..., 3.141...]
// Converges much faster than the original series
@end example

@noindent
Even better, we can accelerate the accelerated sequence, and recursively
accelerate that, and so on.  Namely, we create a stream of streams (a structure
we'll call a @newterm{tableau}) in which each stream is the transform of the
preceding one:

@example
// Create tableau: stream of successively transformed streams
fn make_tableau<F>(transform: F, initial: Vec<f64>) -> Vec<Vec<f64>>
where
    F: Fn(Vec<f64>) -> Vec<f64>,
@{
    std::iter::successors(Some(initial), |s| @{
        let next = transform(s.clone());
        if next.is_empty() @{ None @} else @{ Some(next) @}
    @})
    .collect()
@}
@end example

@noindent
The tableau has the form
@ifinfo

@example
s_00   s_01   s_02   s_03   s_04   ...
       s_10   s_11   s_12   s_13   ...
              s_20   s_21   s_22   ...
                            ...
@end example

@end ifinfo
@tex
\[ % :68:

\begin{array}{cccccc}
 s_{00} 	&   s_{01}  	&   s_{02}  	&   s_{03}  	&   s_{04}  	&   \dots  \\
		&   s_{10}  	&   s_{11}  	&   s_{12}  	&   s_{13}  	&   \dots  \\
		& 		&   s_{20}  	&   s_{21}  	&   s_{22}  	&   \dots  \\
		& 		& 		&   \dots  	& 		&   
\end{array}
\]
@end tex
Finally, we form a sequence by taking the first term in each row of the
tableau:

@example
// Take first element from each row of tableau
fn accelerated_sequence<F>(transform: F, s: Vec<f64>) -> Vec<f64>
where
    F: Fn(Vec<f64>) -> Vec<f64>,
@{
    make_tableau(transform, s)
        .into_iter()
        .filter_map(|row| row.first().copied())
        .collect()
@}
@end example

@noindent
We can demonstrate this kind of ``super-acceleration'' of the @math{\pi}
sequence:

@example
// Super-acceleration: rapidly converges to pi
// accelerated_sequence(euler_vec_transform, pi_stream().take(30).collect())
// => [4.0, 3.166..., 3.142105..., 3.141599...,
//     3.14159271..., 3.14159265397..., 3.14159265359...]
// 8 terms yield 14 decimal places of pi!
@end example

@noindent
The result is impressive.  Taking eight terms of the sequence yields the
correct value of @math{\pi} to 14 decimal places.  If we had used only the
original @math{\pi} sequence, we would need to compute on the order of @math{10^{13}}
terms (i.e., expanding the series far enough so that the individual terms are
less than @math{10^{-13}}) to get that much accuracy!

We could have implemented these acceleration techniques without using streams.
But the stream formulation is particularly elegant and convenient because the
entire sequence of states is available to us as a data structure that can be
manipulated with a uniform set of operations.

@quotation
@strong{@anchor{Exercise 3.63}Exercise 3.63:} Louis Reasoner asks why the
@code{sqrt_stream} procedure was not written in the following more
straightforward way, without the local variable @code{guesses}:

@example
// Inefficient version: creates new iterator on each step
fn sqrt_stream_inefficient(x: f64) -> Box<dyn Iterator<Item = f64>> @{
    Box::new(std::iter::once(1.0).chain(
        sqrt_stream_inefficient(x).map(move |guess| sqrt_improve(guess, x))
    ))
@}
// Without memoization, this recomputes all previous values!
@end example

Alyssa P. Hacker replies that this version of the procedure is considerably
less efficient because it performs redundant computation.  Explain Alyssa's
answer.  Would the two versions still differ in efficiency if our
implementation of @code{delay} used only @code{|| ⟨@var{exp}⟩} without
using the optimization provided by @code{memo_proc} (@ref{3.5.1})?
@end quotation

@quotation
@strong{@anchor{Exercise 3.64}Exercise 3.64:} Write a procedure
@code{stream_limit} that takes as arguments a stream and a number (the
tolerance).  It should examine the stream until it finds two successive
elements that differ in absolute value by less than the tolerance, and return
the second of the two elements.  Using this, we could compute square roots up
to a given tolerance by

@example
fn sqrt(x: f64, tolerance: f64) -> f64 @{
    sqrt_stream(x)
        .tuple_windows()  // requires itertools
        .find(|(a, b)| (a - b).abs() < tolerance)
        .map(|(_, b)| b)
        .unwrap()
@}
// Or with manual window:
fn stream_limit<I: Iterator<Item = f64>>(stream: I, tolerance: f64) -> f64 @{
    let mut prev = None;
    for curr in stream @{
        if let Some(p) = prev @{
            if (curr - p).abs() < tolerance @{
                return curr;
            @}
        @}
        prev = Some(curr);
    @}
    prev.unwrap()
@}
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 3.65}Exercise 3.65:} Use the series
@ifinfo

@example
            1     1     1
ln 2 = 1 - --- + --- - --- + ...
            2     3     4
@end example

@end ifinfo
@tex
\[ % :69:
  \ln 2 \,=\, 1 - {1\over2} + {1\over3} - {1\over4} + \dots  \]
@end tex
@noindent
to compute three sequences of approximations to the natural logarithm of 2, in
the same way we did above for @math{\pi}.  How rapidly do these sequences
converge?
@end quotation

@subsubheading Infinite streams of pairs

In @ref{2.2.3}, we saw how the sequence paradigm handles traditional
nested loops as processes defined on sequences of pairs.  If we generalize this
technique to infinite streams, then we can write programs that are not easily
represented as loops, because the ``looping'' must range over an infinite set.

For example, suppose we want to generalize the @code{prime-sum-pairs} procedure
of @ref{2.2.3} to produce the stream of pairs of @emph{all} integers
@math{{(i, j)}} with @math{{i \le j}} such that @math{{i + j}} is prime.  If
@code{int_pairs} is the sequence of all pairs of integers @math{{(i, j)}} with
@math{{i \le j}}, then our required stream is simply@footnote{As in 
@ref{2.2.3}, we represent a pair of integers as a list rather than a Lisp
pair.}

@example
// Filter integer pairs (i, j) where i <= j and i + j is prime
fn prime_sum_pairs() -> impl Iterator<Item = (u64, u64)> @{
    (1..).flat_map(|j| (1..=j).map(move |i| (i, j)))
        .filter(|&(i, j)| is_prime(i + j))
@}
// => (1,1), (1,2), (1,4), (2,3), (1,6), (2,5), (3,4), ...
@end example

@noindent
Our problem, then, is to produce the stream @code{int_pairs}.  More generally,
suppose we have two streams @math{{S = (S_i)}} and @math{{T = (T_j)}},
and imagine the infinite rectangular array
@ifinfo

@example
(S_0, T_0)  (S_0, T_1)  (S_0, T_2)  ...
(S_1, T_0)  (S_1, T_1)  (S_1, T_2)  ...
(S_2, T_0)  (S_2, T_1)  (S_2, T_2)  ...
   ...
@end example

@end ifinfo
@tex
\[ % :70:

\begin{array}{cccc}
	 (S_0, T_0)  &  (S_0, T_1)  &  (S_0, T_2)  &  \dots  \\
	 (S_1, T_0)  &  (S_1, T_1)  &  (S_1, T_2)  &  \dots  \\
	 (S_2, T_0)  &  (S_2, T_1)  &  (S_2, T_2)  &  \dots  \\
	 \dots  & & & 
\end{array}
\]
@end tex
We wish to generate a stream that contains all the pairs in the array that lie
on or above the diagonal, i.e., the pairs
@ifinfo

@example
(S_0, T_0)  (S_0, T_1)  (S_0, T_2)  ...
            (S_1, T_1)  (S_1, T_2)  ...
                        (S_2, T_2)  ...
                                    ...
@end example

@end ifinfo
@tex
\[ % :71:

\begin{array}{cccc}
 (S_0, T_0)  	&  (S_0, T_1)  	&  (S_0, T_2)  	&  \dots  \\
		&  (S_1, T_1)  	&  (S_1, T_2)  	&  \dots  \\
		& 		&  (S_2, T_2)  	&  \dots  \\
		& 		& 		&  \dots 
\end{array}
\]
@end tex
@noindent
(If we take both @math{S} and @math{T} to be the stream of integers, then this will
be our desired stream @code{int_pairs}.)

Call the general stream of pairs @code{(pairs S T)}, and consider it to be
composed of three parts: the pair @math{{(S_0, T_0)}}, the rest of the pairs in
the first row, and the remaining pairs:@footnote{See @ref{Exercise 3.68} for
some insight into why we chose this decomposition.}
@ifinfo

@example
(S_0, T_0) | (S_0, T_1)  (S_0, T_2)  ...
-----------+-----------------------------
           | (S_1, T_1)  (S_1, T_2)  ...
           |             (S_2, T_2)  ...
           |                         ...
@end example

@end ifinfo
@tex
\[ % :72:

\begin{array}{c|ccc}
 (S_0, T_0)  	&  (S_0, T_1)  	&  (S_0, T_2)  	&  \dots  \\
\hline
		&  (S_1, T_1)  	&  (S_1, T_2)  	&  \dots  \\
		& 		&  (S_2, T_2)  	&  \dots  \\
		& 		& 		&  \dots  
\end{array}
\]
@end tex
Observe that the third piece in this decomposition (pairs that are not in the
first row) is (recursively) the pairs formed from @code{(stream-cdr S)} and
@code{(stream-cdr T)}.  Also note that the second piece (the rest of the first
row) is

@example
// Rest of first row: pair s0 with each element of t[1..]
t.skip(1).map(move |x| (s0.clone(), x))
@end example

@noindent
Thus we can form our stream of pairs as follows:

@example
// Generate pairs (s_i, t_j) where i <= j
// Structure: first element + first row + recursive remainder
fn pairs<S, T>(s: S, t: T) -> impl Iterator<Item = (i64, i64)>
where
    S: Iterator<Item = i64>,
    T: Iterator<Item = i64>,
@{
    // First element: (s_0, t_0)
    // First row rest: (s_0, t_1), (s_0, t_2), ...
    // Recursive: pairs(s[1..], t[1..])
    // Combine first_row_rest and recursive with some_combiner
    todo!("Need interleave to handle infinite streams")
@}
@end example

@noindent
In order to complete the procedure, we must choose some way to combine the two
inner streams.  One idea is to use the stream analog of the @code{append}
procedure from @ref{2.2.1}:

@example
// Stream append - unsuitable for infinite s1!
fn stream_append<I1, I2, T>(s1: I1, s2: I2) -> impl Iterator<Item = T>
where
    I1: Iterator<Item = T>,
    I2: Iterator<Item = T>,
@{
    s1.chain(s2)  // Exhausts s1 before yielding s2
@}
@end example

@noindent
This is unsuitable for infinite streams, however, because it takes all the
elements from the first stream before incorporating the second stream.  In
particular, if we try to generate all pairs of positive integers using

@example
// pairs((1..), (1..)) would get stuck on first row forever
// with chain/append - need interleaving
@end example

@noindent
our stream of results will first try to run through all pairs with the first
integer equal to 1, and hence will never produce pairs with any other value of
the first integer.

To handle infinite streams, we need to devise an order of combination that
ensures that every element will eventually be reached if we let our program run
long enough.  An elegant way to accomplish this is with the following
@code{interleave} procedure:@footnote{The precise statement of the required
property on the order of combination is as follows: There should be a function
@math{f} of two arguments such that the pair corresponding to element @math{i} of the
first stream and element @math{j} of the second stream will appear as element
number @math{{f(i, j)}} of the output stream.  The trick of using
@code{interleave} to accomplish this was shown to us by David Turner, who
employed it in the language KRC (@ref{Turner 1981}).}

@example
// Interleave two streams: take alternating elements
fn interleave<I1, I2, T>(s1: I1, s2: I2) -> impl Iterator<Item = T>
where
    I1: Iterator<Item = T>,
    I2: Iterator<Item = T>,
@{
    let mut it1 = s1.peekable();
    let mut it2 = s2.peekable();
    let mut take_first = true;

    std::iter::from_fn(move || @{
        if take_first @{
            take_first = false;
            it1.next().or_else(|| it2.next())
        @} else @{
            take_first = true;
            it2.next().or_else(|| it1.next())
        @}
    @})
@}
@end example

@noindent
Since @code{interleave} takes elements alternately from the two streams, every
element of the second stream will eventually find its way into the interleaved
stream, even if the first stream is infinite.

We can thus generate the required stream of pairs as

@example
// Generate all pairs (i, j) where i <= j
fn int_pairs() -> impl Iterator<Item = (u64, u64)> @{
    // Use diagonal enumeration to ensure all pairs are reached
    (1_u64..).flat_map(|sum| @{
        (1..sum).map(move |i| (i, sum - i))
    @})
    .filter(|&(i, j)| i <= j)
@}
// Or with explicit interleaving of rows
@end example

@quotation
@strong{@anchor{Exercise 3.66}Exercise 3.66:} Examine the stream @code{(pairs
integers integers)}. Can you make any general comments about the order in which
the pairs are placed into the stream? For example, approximately how many pairs precede
the pair (1, 100)?  the pair (99, 100)? the pair (100, 100)? (If you can make
precise mathematical statements here, all the better. But feel free to give
more qualitative answers if you find yourself getting bogged down.)
@end quotation

@quotation
@strong{@anchor{Exercise 3.67}Exercise 3.67:} Modify the @code{pairs} procedure
so that @code{(pairs integers integers)} will produce the stream of @emph{all}
pairs of integers @math{{(i, j)}} (without the condition @math{{i \le j}}).  Hint:
You will need to mix in an additional stream.
@end quotation

@quotation
@strong{@anchor{Exercise 3.68}Exercise 3.68:} Louis Reasoner thinks that
building a stream of pairs from three parts is unnecessarily complicated.
Instead of separating the pair @math{{(S_0, T_0)}} from the rest of the pairs in
the first row, he proposes to work with the whole first row, as follows:

@example
// Louis's broken pairs - infinite recursion!
fn pairs<I1, I2, T>(s: I1, t: I2) -> impl Iterator<Item = (T, T)>
where
    I1: Iterator<Item = T>,
    I2: Iterator<Item = T> + Clone,
@{
    // BUG: pairs() is called before interleave() can consume
    // any elements from the first iterator, causing infinite
    // recursion during construction (not lazy enough)
    interleave(
        t.clone().map(|x| (s.next()?, x)),  // First row
        pairs(s.skip(1), t.skip(1)),         // Recursive call
    )
@}
// This fails because Rust iterators are eager at construction
// time - we'd need true lazy evaluation (thunks) to make this
// pattern work. The correct approach uses explicit laziness.
@end example

Does this work?  Consider what happens if we evaluate @code{(pairs integers
integers)} using Louis's definition of @code{pairs}.
@end quotation

@quotation
@strong{@anchor{Exercise 3.69}Exercise 3.69:} Write a procedure @code{triples}
that takes three infinite streams, @math{S}, @math{T}, and @math{U}, and produces the
stream of triples @math{{(S_i, T_j, U_k)}} such that @math{{i \le j \le k}}.  
Use @code{triples} to generate the stream of all Pythagorean
triples of positive integers, i.e., the triples @math{{(i, j, k)}} such that
@math{{i \le j}} and @math{{i^2 + j^2 = k^2}}.
@end quotation

@quotation
@strong{@anchor{Exercise 3.70}Exercise 3.70:} It would be nice to be able to
generate streams in which the pairs appear in some useful order, rather than in
the order that results from an @emph{ad hoc} interleaving process.  We can use
a technique similar to the @code{merge} procedure of @ref{Exercise 3.56}, if we
define a way to say that one pair of integers is ``less than'' another.  One
way to do this is to define a ``weighting function'' @math{{W(i, j)}} and
stipulate that @math{{(i_1, j_1)}} is less than @math{{(i_2, j_2)}} if
@math{{W(i_1, j_1) <} {W(i_2, j_2)}}.  Write a procedure
@code{merge_weighted} that is like @code{merge}, except that
@code{merge_weighted} takes an additional argument @code{weight}, which is a
procedure that computes the weight of a pair, and is used to determine the
order in which elements should appear in the resulting merged
stream.@footnote{We will require that the weighting function be such that the
weight of a pair increases as we move out along a row or down along a column of
the array of pairs.}  Using this, generalize @code{pairs} to a procedure
@code{weighted_pairs} that takes two streams, together with a procedure that
computes a weighting function, and generates the stream of pairs, ordered
according to weight.  Use your procedure to generate

@enumerate a

@item
the stream of all pairs of positive integers @math{{(i, j)}} with @math{{i \le j}}
ordered according to the sum @math{{i + j}},

@item
the stream of all pairs of positive integers @math{{(i, j)}} with @math{{i \le j}},
where neither @math{i} nor @math{j} is divisible by 2, 3, or 5, and the pairs are
ordered according to the sum @math{{2i + 3j + 5ij}}.

@end enumerate
@end quotation

@quotation
@strong{@anchor{Exercise 3.71}Exercise 3.71:} Numbers that can be expressed as
the sum of two cubes in more than one way are sometimes called
@newterm{Ramanujan numbers}, in honor of the mathematician Srinivasa
Ramanujan.@footnote{To quote from G. H. Hardy's obituary of Ramanujan (@ref{Hardy 1921}): 
``It was Mr. Littlewood (I believe) who remarked that `every positive
integer was one of his friends.'  I remember once going to see him when he was
lying ill at Putney.  I had ridden in taxi-cab No. 1729, and remarked that the
number seemed to me a rather dull one, and that I hoped it was not an
unfavorable omen.  `No,' he replied, `it is a very interesting number; it is
the smallest number expressible as the sum of two cubes in two different ways.'
'' The trick of using weighted pairs to generate the Ramanujan numbers was
shown to us by Charles Leiserson.} Ordered streams of pairs provide an elegant
solution to the problem of computing these numbers.  To find a number that can
be written as the sum of two cubes in two different ways, we need only generate
the stream of pairs of integers @math{{(i, j)}} weighted according to the sum
@math{{i^3 + j^3}} (see @ref{Exercise 3.70}), then search the stream for two
consecutive pairs with the same weight.  Write a procedure to generate the
Ramanujan numbers.  The first such number is 1,729.  What are the next five?
@end quotation

@quotation
@strong{@anchor{Exercise 3.72}Exercise 3.72:} In a similar way to @ref{Exercise 3.71} 
generate a stream of all numbers that can be written as the sum of two
squares in three different ways (showing how they can be so written).
@end quotation

@subsubheading Streams as signals

We began our discussion of streams by describing them as computational analogs
of the ``signals'' in signal-processing systems.  In fact, we can use streams
to model signal-processing systems in a very direct way, representing the
values of a signal at successive time intervals as consecutive elements of a
stream.  For instance, we can implement an @newterm{integrator} or
@newterm{summer} that, for an input stream @math{{x = (x_i)}}, an initial
value @math{C}, and a small increment @math{{dt}}, accumulates the sum
@ifinfo

@example
           i
          ---
S_i = C + >   x_j dt
          ---
          j=1
@end example

@end ifinfo
@tex
\[ % :73:
  S_i \,=\, C + {\sum_{j=1}^i x_j \, dt}  \]
@end tex
@noindent
and returns the stream of values @math{{S = (S_i)}}.  The following
@code{integral} procedure is reminiscent of the ``implicit style'' definition
of the stream of integers (@ref{3.5.2}):

@example
fn integral(
    integrand: impl Iterator<Item = f64>,
    initial_value: f64,
    dt: f64,
) -> impl Iterator<Item = f64> @{
    // Use scan to accumulate the running sum
    std::iter::once(initial_value).chain(
        integrand.scan(initial_value, move |acc, x| @{
            *acc += x * dt;
            Some(*acc)
        @})
    )
@}
@end example

@noindent
@ref{Figure 3.32} is a picture of a signal-processing system that corresponds
to the @code{integral} procedure.  The input stream is scaled by @math{{dt}} and
passed through an adder, whose output is passed back through the same adder.
The self-reference in the definition of @code{int} is reflected in the figure
by the feedback loop that connects the output of the adder to one of the
inputs.

@float
@anchor{Figure 3.32}
@ifinfo
@strong{Figure 3.32:} The @code{integral} procedure viewed as a signal-processing system.

@example
                             initial-value
                                  |
       +-----------+              |   |\__
input  |           |      |\__    +-->|   \_  integral
------>| scale: dt +----->|   \_      |cons_>--*------->
       |           |      | add_>---->| __/    |
       +-----------+  +-->| __/       |/       |
                      |   |/                   |
                      |                        |
                      +------------------------+
@end example
@end ifinfo
@iftex
@image{fig/chap3/Fig3.32a,143mm,,,.std.svg}
@caption{@strong{Figure 3.32:} The @code{integral} procedure viewed as a signal-processing system.}
@end iftex
@end float

@quotation
@strong{@anchor{Exercise 3.73}Exercise 3.73:} We can model electrical circuits
using streams to represent the values of currents or voltages at a sequence of
times.  For instance, suppose we have an @newterm{RC circuit} consisting of a
resistor of resistance @math{R} and a capacitor of capacitance @math{C} in series.
The voltage response @math{v} of the circuit to an injected current @math{i} is
determined by the formula in @ref{Figure 3.33}, whose structure is shown by the
accompanying signal-flow diagram.

@float
@anchor{Figure 3.33}
@ifinfo
@strong{Figure 3.33:} An RC circuit and the associated signal-flow diagram.

@example
  +        v        -

 ->----'\/\/\,---| |---
  i       R         C


                  / t
               1  |
 v  =  v   +  --- |  i dt  +  R i
        0      C  |
                  / 0

         +--------------+
     +-->|   scale: R   |---------------------+   |\_
     |   +--------------+                     |   |  \_
     |                                        +-->|    \   v
  i  |   +--------------+     +------------+      | add >--->
 ----+-->|  scale: 1/C  |---->|  integral  |----->|   _/
         +--------------+     +------------+      | _/
                                    |             |/
				   v
				    0
@end example
@end ifinfo
@iftex
@image{fig/chap3/Fig3.33a,125mm,,,.std.svg}
@caption{@strong{Figure 3.33:} An RC circuit and the associated signal-flow diagram.}
@end iftex
@end float

Write a procedure @code{RC} that models this circuit.  @code{RC} should take as
inputs the values of @math{R}, @math{C}, and @math{{dt}} and should return a procedure
that takes as inputs a stream representing the current @math{i} and an initial
value for the capacitor voltage @math{v_0} and produces as output the stream of
voltages @math{v}.  For example, you should be able to use @code{RC} to model an
RC circuit with @math{R} = 5 ohms, @math{C} = 1 farad, and a 0.5-second time step by
evaluating @code{let rc1 = rc(5.0, 1.0, 0.5);}.  This defines @code{rc1} as a
procedure that takes a stream representing the time sequence of currents and an
initial capacitor voltage and produces the output stream of voltages.
@end quotation

@quotation
@strong{@anchor{Exercise 3.74}Exercise 3.74:} Alyssa P. Hacker is designing a
system to process signals coming from physical sensors.  One important feature
she wishes to produce is a signal that describes the @newterm{zero crossings}
of the input signal.  That is, the resulting signal should be @math{{+1}} whenever the
input signal changes from negative to positive, @math{{-1}} whenever the input signal
changes from positive to negative, and @math{0} otherwise.  (Assume that the sign of a
@math{0} input is positive.)  For example, a typical input signal with its associated
zero-crossing signal would be

@example
// Input signal and zero-crossing detection:
// ... 1.0  2.0  1.5  1.0  0.5 -0.1 -2.0 -3.0 -2.0 -0.5  0.2  3.0  4.0 ...
// ...   0    0    0    0    0   -1    0    0    0    0    1    0    0 ...
@end example

In Alyssa's system, the signal from the sensor is represented as a stream
@code{sense-data} and the stream @code{zero-crossings} is the corresponding
stream of zero crossings.  Alyssa first writes a procedure
@code{sign_change_detector} that takes two values as arguments and compares the
signs of the values to produce an appropriate @math{0}, @math{1}, or @math{{-1}}.  She then
constructs her zero-crossing stream as follows:

@example
fn sign_change_detector(current: f64, last: f64) -> i32 @{
    match (last < 0.0, current >= 0.0) @{
        (true, true) => 1,    // Negative to positive
        (false, false) if last >= 0.0 && current < 0.0 => -1,
        _ => 0,
    @}
@}

fn make_zero_crossings(
    input: impl Iterator<Item = f64>,
) -> impl Iterator<Item = i32> @{
    input.scan(0.0_f64, |last, current| @{
        let crossing = sign_change_detector(current, *last);
        *last = current;
        Some(crossing)
    @})
@}

let zero_crossings = make_zero_crossings(sense_data);
@end example

Alyssa's boss, Eva Lu Ator, walks by and suggests that this program is
approximately equivalent to the following one, which uses the generalized
version of @code{stream-map} from @ref{Exercise 3.50}:

@example
// Using zip to pair current with previous values
let zero_crossings = sense_data.clone()
    .zip(std::iter::once(0.0).chain(sense_data))
    .map(|(current, last)| sign_change_detector(current, last));
// The missing expression: prepend 0.0 to create the "last value" stream
@end example

Complete the program by supplying the indicated @code{⟨}@var{expression}@code{⟩}.
@end quotation

@quotation
@strong{@anchor{Exercise 3.75}Exercise 3.75:} Unfortunately, Alyssa's
zero-crossing detector in @ref{Exercise 3.74} proves to be insufficient,
because the noisy signal from the sensor leads to spurious zero crossings.  Lem
E.  Tweakit, a hardware specialist, suggests that Alyssa smooth the signal to
filter out the noise before extracting the zero crossings.  Alyssa takes his
advice and decides to extract the zero crossings from the signal constructed by
averaging each value of the sense data with the previous value.  She explains
the problem to her assistant, Louis Reasoner, who attempts to implement the
idea, altering Alyssa's program as follows:

@example
// Louis's buggy version - compares smoothed to previous raw value
fn make_zero_crossings_buggy(
    input: impl Iterator<Item = f64>,
) -> impl Iterator<Item = i32> @{
    input.scan(0.0_f64, |last_value, current| @{
        let avpt = (current + *last_value) / 2.0;
        // BUG: should compare avpt to *previous* avpt, not last_value
        let crossing = sign_change_detector(avpt, *last_value);
        *last_value = avpt;  // This compounds the error
        Some(crossing)
    @})
@}
// Fix: track both last_value AND last_avpt separately
@end example

This does not correctly implement Alyssa's plan.  Find the bug that Louis has
installed and fix it without changing the structure of the program.  (Hint: You
will need to increase the number of arguments to @code{make_zero_crossings}.)
@end quotation

@quotation
@strong{@anchor{Exercise 3.76}Exercise 3.76:} Eva Lu Ator has a criticism of
Louis's approach in @ref{Exercise 3.75}.  The program he wrote is not modular,
because it intermixes the operation of smoothing with the zero-crossing
extraction.  For example, the extractor should not have to be changed if Alyssa
finds a better way to condition her input signal.  Help Louis by writing a
procedure @code{smooth} that takes a stream as input and produces a stream in
which each element is the average of two successive input stream elements.
Then use @code{smooth} as a component to implement the zero-crossing detector
in a more modular style.
@end quotation

@node	3.5.4, 3.5.4a, 3.5.3, 3.5
@subsection 스트림과 지연 평가 (Streams and Delayed Evaluation)

이전 절의 끝에 있는 @code{integral} 프로시저는 피드백 루프를 포함하는 신호 처리 시스템을 모델링하기 위해 우리가 스트림을 어떻게 사용할 수 있는지 보여준다.
@ref{Figure 3.32}에 표시된 덧셈기에 대한 피드백 루프는 @code{integral}의 내부 스트림 @code{int}가 그 자체의 관점에서 정의된다는 사실에 의해 모델링된다:

@example
// 자기 참조적 스트림 정의 (암시적 스타일)
// Rust에서는 누적 패턴을 위해 scan을 사용한다:
let int = std::iter::once(initial_value).chain(
    integrand.scan(initial_value, move |acc, x| @{
        *acc += x * dt;
        Some(*acc)
    @})
);
@end example

@noindent
인터프리터가 그러한 암시적 정의를 처리할 수 있는 능력은 @code{cons-stream}에 통합된 @code{delay}에 의존한다.
이 @code{delay}가 없다면, 인터프리터는 @code{cons-stream}에 대한 두 인자를 모두 평가하기 전에 @code{int}를 구성할 수 없을 것이며, 이는 @code{int}가 이미 정의되어 있을 것을 요구할 것이다.
일반적으로 @code{delay}는 루프를 포함하는 신호 처리 시스템을 모델링하기 위해 스트림을 사용하는 데 결정적이다.
@code{delay}가 없다면, 우리 모델은 신호 처리 구성 요소에 대한 입력이 출력이 생성되기 전에 완전히 평가되도록 공식화되어야 할 것이다.
이것은 루프를 불법화할 것이다.

@noindent
불행히도, 루프가 있는 시스템의 스트림 모델은 @code{cons-stream}이 제공하는 ``숨겨진'' @code{delay}를 넘어 @code{delay}의 사용을 요구할 수 있다.
예를 들어, @ref{Figure 3.34}는 미분 방정식 @math{{dy / dt = f(y)}}를 해결하기 위한 신호 처리 시스템을 보여준다. 여기서 @math{f}는 주어진 함수이다.
그림은 입력 신호에 @math{f}를 적용하는 매핑 구성 요소를 보여주는데, 이것은 그러한 방정식을 해결하는 데 실제로 사용되는 아날로그 컴퓨터 회로와 매우 유사한 방식으로 적분기에 피드백 루프로 연결되어 있다.

@float
@anchor{Figure 3.34}
@ifinfo
@quotation
@strong{Figure 3.34:} 방정식 @math{{dy / dt = f(y)}}를 푸는 ``아날로그 컴퓨터 회로''.

@example
                            y_0
                             |
                             V
    +----------+  dy   +----------+     y
+-->|  map: f  +------>| integral +--*----->
|   +----------+       +----------+  |
|                                    |
+------------------------------------+
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap3/Fig3.34,110mm,,,.std.svg}
@caption{@strong{Figure 3.34:} 방정식 @math{{dy / dt = f(y)}}를 푸는 ``아날로그 컴퓨터 회로''.}
@end iftex
@end float

@math{y}에 대한 초기 값 @math{y_0}가 주어진다고 가정할 때, 우리는 이 시스템을 다음 프로시저를 사용하여 모델링하려고 시도할 수 있다

@example
// 이 순진한 접근 방식은 작동하지 않을 것이다 - dy가 아직 정의되지 않았다!
fn solve_broken<F>(f: F, y0: f64, dt: f64) -> impl Iterator<Item = f64>
where F: Fn(f64) -> f64
@{
    let y = integral(dy, y0, dt);   // 오류: dy가 정의되지 않음
    let dy = y.clone().map(f);      // y가 존재하기 전에 사용할 수 없음
    y
@}
@end example

@noindent
이 프로시저는 작동하지 않는데, 왜냐하면 @code{solve}의 첫 번째 줄에서 @code{integral} 호출이 입력 @code{dy}가 정의되어 있을 것을 요구하지만, 이것은 @code{solve}의 두 번째 줄까지 일어나지 않기 때문이다.

반면에, 우리 정의의 의도는 말이 되는데, 왜냐하면 우리는 원칙적으로 @code{dy}를 알지 못해도 @code{y} 스트림 생성을 시작할 수 있기 때문이다.
실제로 @code{integral}과 많은 다른 스트림 연산은 인자에 대한 부분적인 정보만 주어져도 답의 일부를 생성할 수 있다는 점에서 @code{cons-stream}과 유사한 속성을 갖는다.
@code{integral}의 경우, 출력 스트림의 첫 번째 요소는 지정된 @code{initial-value}이다.
따라서 우리는 피적분 함수 @code{dy}를 평가하지 않고도 출력 스트림의 첫 번째 요소를 생성할 수 있다.
일단 우리가 @code{y}의 첫 번째 요소를 알게 되면, @code{solve}의 두 번째 줄에 있는 @code{stream-map}이 @code{dy}의 첫 번째 요소를 생성하기 위해 작업을 시작할 수 있으며, 이것은 @code{y}의 다음 요소를 생성할 것이고, 이런 식으로 계속된다.

이 아이디어를 활용하기 위해, 우리는 피적분 함수 스트림이 @newterm{지연된 인자(delayed argument)}일 것으로 기대하도록 @code{integral}을 재정의할 것이다.
@code{Integral}은 출력 스트림의 첫 번째 요소보다 더 많은 것을 생성하는 데 필요할 때만 피적분 함수가 평가되도록 @code{force}할 것이다:

@example
// Rust에서는 피적분 함수를 위한 지연 클로저와 함께 successors를 사용한다
fn integral_delayed<F>(
    delayed_integrand: F,
    initial_value: f64,
    dt: f64,
) -> impl Iterator<Item = f64>
where
    F: FnOnce() -> Box<dyn Iterator<Item = f64>>,
@{
    let integrand = std::cell::OnceCell::new();
    std::iter::successors(
        Some((initial_value, 0_usize)),
        move |(acc, idx)| @{
            let stream = integrand.get_or_init(delayed_integrand);
            // 필요할 때만 평가를 강제한다
            stream.nth(*idx).map(|x| (*acc + x * dt, idx + 1))
        @}
    ).map(|(val, _)| val)
@}
@end example

@noindent
이제 우리는 @code{y}의 정의에서 @code{dy}의 평가를 지연시킴으로써 @code{solve} 프로시저를 구현할 수 있다:@footnote{이 프로시저는 모든 Scheme 구현에서 작동한다고 보장되지는 않지만, 어떤 구현에 대해서도 작동하는 간단한 변형이 있다. 문제는 Scheme 구현이 내부 정의를 처리하는 방식의 미묘한 차이와 관련이 있다. (@ref{4.1.6} 참조.)}

@example
// 자기 참조를 위해 successors를 사용하여 dy/dt = f(y) 풀기
fn solve<F>(f: F, y0: f64, dt: f64) -> impl Iterator<Item = f64>
where
    F: Fn(f64) -> f64,
@{
    std::iter::successors(Some(y0), move |&y| @{
        // dy = f(y), 그런 다음 적분: y_new = y + dy * dt
        Some(y + f(y) * dt)
    @})
@}
@end example

@noindent
일반적으로 @code{integral}의 모든 호출자는 이제 피적분 함수 인자를 @code{delay}해야 한다.
우리는 미분 방정식 @math{{dy / dt = y}}와 초기 조건 @math{{y(0) = 1}}의 해의 @math{{y = 1}}에서의 값을 계산하여 @math{{e \approx 2.718}}을 근사함으로써 @code{solve} 프로시저가 작동함을 시연할 수 있다:

@example
// y(0) = 1일 때 dy/dt = y를 풀어 e를 근사한다
let result = solve(|y| y, 1.0, 0.001).nth(1000).unwrap();
// => 2.716924 (e ~ 2.71828...을 근사함)
@end example

@quotation
@strong{@anchor{Exercise 3.77}연습문제 3.77:} 위에서 사용된 @code{integral} 프로시저는 @ref{3.5.2}의 무한 정수 스트림의 ``암시적'' 정의와 유사했다.
대안으로, 우리는 @code{integers-starting-from}(역시 @ref{3.5.2}에 있음)과 더 비슷한 @code{integral}의 정의를 줄 수 있다:

@example
// 명시적 재귀 스타일 적분
fn integral_explicit(
    mut integrand: impl Iterator<Item = f64>,
    initial_value: f64,
    dt: f64,
) -> impl Iterator<Item = f64> @{
    std::iter::once(initial_value).chain(
        std::iter::from_fn(move || @{
            integrand.next().map(|x| initial_value + x * dt)
        @})
    )
@}
// 참고: 이 버전도 루프를 위해 지연된 피적분 함수가 필요하다
@end example

루프가 있는 시스템에서 사용될 때, 이 프로시저는 @code{integral}의 원래 버전과 같은 문제를 갖는다.
프로시저가 @code{integrand}를 지연된 인자로 기대하고 따라서 위에 표시된 @code{solve} 프로시저에서 사용될 수 있도록 수정하라.
@end quotation

@quotation
@strong{@anchor{Exercise 3.78}연습문제 3.78:} 동차 2계 선형 미분 방정식
@ifinfo

@example
d^2 y        d y
-----  -  a -----  -  by  =  0
d t^2        d t
@end example

@end ifinfo
@tex
\[ % :74:
  \frac{d^2 y}{dt^2} - {a \frac{dy}{dt}} - {by} \,=\, {0.}  \]
@end tex
을 연구하기 위한 신호 처리 시스템을 설계하는 문제를 고려해 보자.
@math{y}를 모델링하는 출력 스트림은 루프를 포함하는 네트워크에 의해 생성된다.
왜냐하면 @math{{d^2 y / dt^2}}의 값은 @math{y}와 @math{{dy / dt}}의 값에 의존하고 이 둘 다 @math{{d^2 y / dt^2}}를 적분하여 결정되기 때문이다.
우리가 인코딩하고자 하는 다이어그램은 @ref{Figure 3.35}에 나와 있다.
상수 @math{a}, @math{b}, @math{{dt}}와 @math{y} 및 @math{{dy / dt}}에 대한 초기 값 @math{y_0}, @math{{dy_0}}를 인자로 받아 @math{y}의 연속적인 값의 스트림을 생성하는 프로시저 @code{solve-2nd}를 작성하라.
@end quotation

@float
@anchor{Figure 3.35}
@ifinfo
@quotation
@strong{Figure 3.35:} 2계 선형 미분 방정식의 해를 위한 신호 흐름 다이어그램.

@example
               dy_0                y_0
                |                   |
                V                   V
   ddy     +----------+    dy  +----------+    y
+--------->| integral +-----*--+ integral +--*--->
|          +----------+     |  +----------+  |
|                           |                |
|            +----------+   |                |
|     __/|<--+ scale: a |<--+                |
|   _/   |   +----------+                    |
+--<_add |                                   |
     \__ |   +----------+                    |
        \|<--+ scale: b |<-------------------+
             +----------+
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap3/Fig3.35b,116mm,,,.std.svg}
@caption{@strong{Figure 3.35:} 2계 선형 미분 방정식의 해를 위한 신호 흐름 다이어그램.}
@end iftex
@end float

@quotation
@strong{@anchor{Exercise 3.79}연습문제 3.79:} @ref{Exercise 3.78}의 @code{solve-2nd} 프로시저를 일반화하여 일반적인 2계 미분 방정식 @math{{d^2 y / dt^2} = {f(dy / dt, y)}}를 푸는 데 사용할 수 있도록 하라.
@end quotation

@float
@anchor{Figure 3.36}
@ifinfo
@quotation
@strong{Figure 3.36:} 직렬 RLC 회로.

@example
              + v_R -
        i_R
     +--->----'\/\/\,--------+
     |                       |  i_L
    \|/          R          \|/
  +  |  i_C                  |_   +
    -+-                       _)
v_C -+- C                     _)  v_L
     |                        _)
  -  |                       |    -
     +-----------------------+
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap3/Fig3.36,102mm,,,.std.svg}
@caption{@strong{Figure 3.36:} 직렬 RLC 회로.}
@end iftex
@end float

@quotation
@strong{@anchor{Exercise 3.80}연습문제 3.80:} @newterm{직렬 RLC 회로(series RLC circuit)}는 @ref{Figure 3.36}과 같이 직렬로 연결된 저항기, 커패시터, 인덕터로 구성된다.
만약 @math{R}, @math{L}, @math{C}가 저항, 인덕턴스, 커패시턴스라면, 세 구성 요소에 대한 전압 @math{{(v)}}와 전류 @math{{(i)}} 사이의 관계는 다음 방정식으로 설명된다
@ifinfo

@example
v_R = i_R R

         d i_L
v_L = L -------
          d t

         d v_C
i_C = C -------
          d t
@end example

@end ifinfo
@tex
\[ % :75:
\begin{eqnarray}
  v_R 	&=&   i_R R, \\
  v_L 	&=&   L\,{di_L \over dt}, \\
  i_C 	&=&   C\,{dv_C \over dt},
\end{eqnarray}
\]
@end tex
그리고 회로 연결은 다음 관계를 지시한다
@ifinfo

@example
i_R = i_L = -i_C

v_C = v_L + v_R
@end example

@end ifinfo
@tex
\[ % :76:
\begin{eqnarray}
  i_R 	&=&   i_L = -i_C, \\
  v_C 	&=&   v_L + v_R.
\end{eqnarray}
\]
@end tex
@noindent
이 방정식들을 결합하면 회로의 상태(커패시터 양단의 전압 @math{v_C}와 인덕터의 전류 @math{i_L}로 요약됨)가 다음 미분 방정식 쌍으로 설명됨을 알 수 있다
@ifinfo

@example
d v_C        i_L
-----  =  -  ---
 d t          C

d i_L      1           R
-----  =  --- v_C  -  --- i_L
 d t       L           L
@end example

@end ifinfo
@tex
\[ % :77:
\begin{eqnarray}
  {dv_C \over dt}   &=&   -{i_L \over C}\,, \\
  {di_L \over dt}   &=&    {1 \over L}\, v_C - {R \over L}\, i_L.
\end{eqnarray}
\]
@end tex
@noindent
이 미분 방정식 시스템을 나타내는 신호 흐름 다이어그램은 @ref{Figure 3.37}에 나와 있다.
@end quotation

@float
@anchor{Figure 3.37}
@ifinfo
@quotation
@strong{Figure 3.37:} 직렬 RLC 회로의 해를 위한 신호 흐름 다이어그램.

@example
                 +-------------+
+----------------+  scale: l/L |<--+
|                +-------------+   |
|                                  |
|                +-------------+   |  v_C
|       dv_C +-->|   integral  +---*------>
|            |   +-------------+
|            |        ^
|            |        | v_(C_0)
|            |
|            |   +-------------+
|            +---+ scale: -l/C |<--+
|                +-------------+   |
|  |\__                            |
+->|   \_  di_L  +-------------+   |  i_L
   | add_>------>|   integral  +---*------>
+->| __/         +-------------+   |
|  |/                 ^            |
|                     | i_(L_0)    |
|                                  |
|                +-------------+   |
+----------------+ scale: -R/L |<--+
                 +-------------+
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap3/Fig3.37,110mm,,,.std.svg}
@caption{@strong{Figure 3.37:} 직렬 RLC 회로의 해를 위한 신호 흐름 다이어그램.}
@end iftex
@end float

@quotation
회로의 매개변수 @math{R}, @math{L}, @math{C}와 시간 증분 @math{{dt}}를 인자로 받는 프로시저 @code{RLC}를 작성하라.
@ref{Exercise 3.73}의 @code{RC} 프로시저와 유사한 방식으로, @code{RLC}는 상태 변수의 초기 값 @math{v_{C_0}}와 @math{i_{L_0}}를 받아 상태 @math{v_C}와 @math{i_L}의 스트림 쌍(@code{cons} 사용)을 생성하는 프로시저를 반환해야 한다.
@code{RLC}를 사용하여, @math{R} = 1 옴, @math{C} = 0.2 패럿, @math{L} = 1 헨리, @math{{dt}} = 0.1 초, 그리고 초기 값 @math{i_{L_0}} = 0 암페어, @math{v_{C_0}} = 10 볼트인 직렬 RLC 회로의 동작을 모델링하는 스트림 쌍을 생성하라.
@end quotation

@subsubheading 정규 순서 평가 (Normal-order evaluation)

이 절의 예제들은 @code{delay}와 @code{force}의 명시적 사용이 어떻게 훌륭한 프로그래밍 유연성을 제공하는지 보여주지만, 동일한 예제들은 이것이 또한 우리 프로그램을 어떻게 더 복잡하게 만들 수 있는지도 보여준다.
예를 들어, 우리의 새로운 @code{integral} 프로시저는 루프가 있는 시스템을 모델링할 수 있는 능력을 제공하지만, 우리는 이제 @code{integral}이 지연된 피적분 함수와 함께 호출되어야 함을 기억해야 하고, @code{integral}을 사용하는 모든 프로시저는 이를 알고 있어야 한다.
사실상, 우리는 두 종류의 프로시저를 만들었다: 일반 프로시저와 지연된 인자를 받는 프로시저.
일반적으로, 별도의 프로시저 클래스를 만드는 것은 우리가 고차 프로시저의 별도 클래스 또한 만들도록 강요한다.@footnote{이것은 Pascal과 같은 전통적인 강타입 언어들이 고차 프로시저를 다루는 데 있어 겪는 어려움이 Lisp에 작게 반영된 것이다. 그러한 언어에서 프로그래머는 각 프로시저의 인자와 결과의 데이터 타입을 명시해야 한다: 숫자, 논리값, 시퀀스 등등. 결과적으로, 우리는 @code{stream-map}과 같은 단일 고차 프로시저로 ``주어진 프로시저 @code{proc}을 시퀀스의 모든 요소에 매핑하라''와 같은 추상화를 표현할 수 없다. 오히려, @code{proc}에 대해 지정될 수 있는 인자와 결과 데이터 타입의 각각의 다른 조합에 대해 다른 매핑 프로시저가 필요할 것이다. 고차 프로시저가 존재할 때 ``데이터 타입''의 실용적인 개념을 유지하는 것은 많은 어려운 문제를 제기한다. 이 문제를 다루는 한 가지 방법은 ML 언어(@ref{Gordon et al. 1979})에 의해 예시되는데, 그 ``다형성 데이터 타입(polymorphic data types)''은 데이터 타입 간의 고차 변환을 위한 템플릿을 포함한다. 게다가, ML의 대부분의 프로시저에 대한 데이터 타입은 프로그래머에 의해 명시적으로 선언되지 않는다. 대신, ML은 환경의 정보를 사용하여 새로 정의된 프로시저의 데이터 타입을 추론하는 @newterm{타입 추론(type-inferencing)} 메커니즘을 포함한다.}

두 가지 다른 종류의 프로시저가 필요한 것을 피하는 한 가지 방법은 모든 프로시저가 지연된 인자를 받도록 만드는 것이다.
우리는 프로시저에 대한 모든 인자가 자동으로 지연되고 인자가 실제로 필요할 때만(예를 들어, 원시 연산에 의해 요구될 때) 강제되는 평가 모델을 채택할 수 있다.
이것은 우리 언어를 정규 순서 평가(normal-order evaluation)를 사용하도록 변환할 것인데, 이는 우리가 @ref{1.1.5}에서 평가를 위한 치환 모델을 소개할 때 처음 설명했다.
정규 순서 평가로 전환하는 것은 지연 평가의 사용을 단순화하는 균일하고 우아한 방법을 제공하며, 만약 우리가 스트림 처리에만 관심이 있다면 이것은 채택하기에 자연스러운 전략일 것이다.
@ref{4.2}에서, 평가자를 공부한 후에, 우리는 우리 언어를 바로 이런 방식으로 변환하는 방법을 보게 될 것이다.
불행히도, 프로시저 호출에 지연을 포함시키는 것은 대입을 사용하거나, 데이터를 변경하거나, 입출력을 수행하는 프로그램과 같이 이벤트의 순서에 의존하는 프로그램을 설계하는 우리의 능력에 대혼란을 초래한다.
@code{cons-stream}에 있는 단일 @code{delay}조차도 @ref{Exercise 3.51}과 @ref{Exercise 3.52}에서 예시된 것처럼 큰 혼란을 일으킬 수 있다.
알려진 바로는, 변경 가능성과 지연 평가는 프로그래밍 언어에서 잘 섞이지 않으며, 이 둘을 동시에 다루는 방법을 고안하는 것은 활발한 연구 분야이다.

@node	3.5.4a, 3.5.5, 3.5.4, 3.5
@subsection 락 프리 데이터 구조 (Lock-Free Data Structures)
@cindex lock-free data structures
@cindex atomics
@cindex compare-and-swap
@cindex memory ordering

@ref{3.4}에서 우리는 스트림을 이용한 동시성 프로그래밍을 탐구했고 공유된 가변 상태가 어떻게 경쟁 상태(race conditions)로 이어질 수 있는지 보았다.
우리의 해결책은 @code{Mutex}와 @code{RwLock}과 같은 잠금(locks)을 사용하여 공유 데이터에 대한 독점적 접근을 보장하는 것이었다.
잠금은 직관적인 정확성 보장을 제공하지만, 상당한 비용이 든다: 잠금을 기다리는 스레드는 진행할 수 없고, @dfn{우선순위 역전(priority inversion)}이 발생할 수 있으며, 잠금 경합(lock contention)은 멀티 코어 시스템에서 성능을 크게 떨어뜨릴 수 있다.

락 프리 데이터 구조는 대안적인 접근 방식을 제공한다: 이것들은 원자적 연산(atomic operations)과 @dfn{비교 교환(compare-and-swap)} 원시 기능을 사용하여 스레드를 차단하지 않고 동시 접근을 조정한다.
이 절에서는 Rust에서 락 프리 프로그래밍의 기초를 탐구하며, 그 힘과 미묘함을 모두 드러낼 것이다.

@subsubheading 잠금의 비용 (The Cost of Locks)

스레드 간에 공유되는 간단한 카운터를 고려해 보자. 잠금을 사용하면 구현은 간단하다:

@example
use std::sync::@{Arc, Mutex@};
use std::thread;

let counter = Arc::new(Mutex::new(0_u64));
let mut handles = vec![];

for _ in 0..8 @{
    let counter = Arc::clone(&counter);
    let handle = thread::spawn(move || @{
        for _ in 0..1_000_000 @{
            *counter.lock().unwrap() += 1;
        @}
    @});
    handles.push(handle);
@}

for handle in handles @{
    handle.join().unwrap();
@}

assert_eq!(*counter.lock().unwrap(), 8_000_000);
@end example

이것은 올바르게 작동하지만, 각 증가는 잠금을 획득하고 해제하는 것을 필요로 하는데---이는 시스템 호출과 캐시 일관성 프로토콜을 포함하는 무거운 연산이다.
경합 상황에서, 스레드는 계산하는 것보다 기다리는 데 더 많은 시간을 소비한다.

@subsubheading 원자적 타입: 기초 (Atomic Types: The Foundation)

Rust는 중단 없이 실행됨이 보장되는 연산을 지원하는 @dfn{원자적 타입(atomic types)}을 제공한다.
이 타입들은 @code{std::sync::atomic}에 있으며 @code{AtomicBool}, @code{AtomicUsize}, @code{AtomicIsize}, 그리고 @code{AtomicPtr<T>}를 포함한다.

@cindex AtomicUsize
@cindex fetch_add

다음은 원자적 타입을 사용하여 다시 작성한 카운터이다:

@example
use std::sync::Arc;
use std::sync::atomic::@{AtomicU64, Ordering@};
use std::thread;

let counter = Arc::new(AtomicU64::new(0));
let mut handles = vec![];

for _ in 0..8 @{
    let counter = Arc::clone(&counter);
    let handle = thread::spawn(move || @{
        for _ in 0..1_000_000 @{
            counter.fetch_add(1, Ordering::Relaxed);
        @}
    @});
    handles.push(handle);
@}

for handle in handles @{
    handle.join().unwrap();
@}

assert_eq!(counter.load(Ordering::Relaxed), 8_000_000);
@end example

@code{fetch_add} 메서드는 현재 값을 원자적으로 읽고, 1을 더하고, 결과를 저장한다---이 모든 것이 단일한, 나눌 수 없는 연산으로 수행된다.
잠금도 없고, 차단도 없으며, 컨텍스트 전환도 없다.
현대 하드웨어에서, 이것은 x86의 @code{LOCK ADD} 명령어 또는 ARM의 @code{LDADD} 명령어로 컴파일된다.

@subsubheading 메모리 순서: 미묘함 (Memory Ordering: The Subtlety)

@cindex memory ordering
@cindex Ordering::Relaxed
@cindex Ordering::Acquire
@cindex Ordering::Release
@cindex Ordering::SeqCst

원자적 연산의 @code{Ordering} 매개변수는 메모리 연산이 컴파일러와 CPU에 의해 어떻게 재정렬되는지를 제어한다.
메모리 순서를 이해하는 것은 락 프리 프로그래밍의 정확성을 위해 매우 중요하다.

현대 프로세서는 성능을 위해 명령어를 비순차적으로 실행한다.
우리가 제약을 가하지 않으면 두 스레드는 메모리 연산을 다른 순서로 관찰할 수 있다.
Rust는 네 가지 순서 보장을 제공한다:

@itemize @bullet
@item
@code{Relaxed}: 순서 제약이 없다. 연산 자체의 원자성만 보장된다. 순서가 중요하지 않은 카운터에 사용한다.

@item
@code{Acquire}: 로드(load)할 때, 모든 후속 메모리 연산이 이 로드 이전으로 재정렬될 수 없다. 잠금을 획득하거나 다른 데이터를 보호하는 플래그를 읽을 때 사용된다.

@item
@code{Release}: 저장(store)할 때, 모든 이전 메모리 연산이 이 저장 이후로 재정렬될 수 없다. 잠금을 해제하거나 데이터를 게시할 때 사용된다.

@item
@code{SeqCst} (순차적 일관성, Sequentially Consistent): 가장 강력한 보장---모든 스레드가 모든 연산을 같은 순서로 관찰한다. 추론하기 가장 쉽지만 가장 비싸다.
@end itemize

핵심 통찰은 @dfn{이전 발생(happens-before)} 관계이다: 만약 연산 A가 Release 순서를 갖고 연산 B가 Acquire 순서를 가지며, B가 A에 의해 쓰인 값을 읽는다면, A 이전의 모든 것은 B 이후의 모든 것보다 @dfn{이전에 발생}한다.

@cindex synchronizes-with

다음은 데이터를 안전하게 게시하기 위해 @code{Acquire}와 @code{Release}를 사용하는 고전적인 예이다:

@example
use std::sync::atomic::@{AtomicBool, Ordering@};
use std::sync::Arc;
use std::thread;

let data = Arc::new(AtomicUsize::new(0));
let ready = Arc::new(AtomicBool::new(false));

let data_clone = Arc::clone(&data);
let ready_clone = Arc::clone(&ready);

let writer = thread::spawn(move || @{
    // 데이터를 먼저 쓴다
    data_clone.store(42, Ordering::Relaxed);
    // 데이터가 준비되었음을 알린다 (Release 순서)
    ready_clone.store(true, Ordering::Release);
@});

let reader = thread::spawn(move || @{
    // 데이터가 준비될 때까지 기다린다 (Acquire 순서)
    while !ready.load(Ordering::Acquire) @{
        std::hint::spin_loop();
    @}
    // 이제 데이터를 읽는 것이 안전하다
    assert_eq!(data.load(Ordering::Relaxed), 42);
@});

writer.join().unwrap();
reader.join().unwrap();
@end example

작성자의 @code{Release} 저장과 독자의 @code{Acquire} 로드는 @dfn{동기화(synchronizes-with)} 관계를 생성하여, 플래그가 설정되기 전에 쓰인 데이터를 독자가 볼 수 있도록 보장한다.

@subsubheading 비교 교환: 근본적인 원시 기능 (Compare-and-Swap: The Fundamental Primitive)

@cindex compare_exchange
@cindex CAS operation

가장 강력한 원자적 연산은 @dfn{비교 교환(compare-and-swap)} (CAS)이며, Rust에서는 @code{compare_exchange}로 노출된다.
이 연산은 원자적으로 다음을 수행한다:

@enumerate
@item
메모리에서 현재 값을 읽는다
@item
그것을 예상되는 값과 비교한다
@item
같으면, 새 값을 저장하고 성공을 반환한다
@item
같지 않으면, 실제 현재 값과 함께 실패를 반환한다
@end enumerate

CAS는 락 프리 알고리즘의 기초이다. 그 서명은 다음과 같다:

@example
pub fn compare_exchange(
    &self,
    current: T,
    new: T,
    success: Ordering,
    failure: Ordering,
) -> Result<T, T>
@end example

현재 값이 @code{current}와 일치하면 연산이 성공하고 @code{new}로 업데이트한다.
그렇지 않으면 실제 값을 반환한다.
결정적으로, 읽기와 조건부 쓰기 모두 원자적으로 발생한다.

CAS를 사용하여 간단한 스핀락(spinlock)을 구현해 보자:

@example
use std::sync::atomic::@{AtomicBool, Ordering@};
use std::cell::UnsafeCell;

pub struct SpinLock<T> @{
    locked: AtomicBool,
    data: UnsafeCell<T>,
@}

unsafe impl<T: Send> Sync for SpinLock<T> @{@}

impl<T> SpinLock<T> @{
    pub fn new(data: T) -> Self @{
        SpinLock @{
            locked: AtomicBool::new(false),
            data: UnsafeCell::new(data),
        @}
    @}

    pub fn lock(&self) -> SpinLockGuard<T> @{
        // 잠금을 획득할 때까지 회전(spin)
        while self.locked.compare_exchange(
            false,                   // 예상: 잠금 해제됨
            true,                    // 새 값: 잠김
            Ordering::Acquire,       // 성공: acquire 의미론
            Ordering::Relaxed,       // 실패: relaxed로 재시도
        ).is_err() @{
            // CPU에 우리가 회전 중임을 알림
            std::hint::spin_loop();
        @}
        SpinLockGuard @{ lock: self @}
    @}
@}

pub struct SpinLockGuard<'a, T> @{
    lock: &'a SpinLock<T>,
@}

impl<'a, T> std::ops::Deref for SpinLockGuard<'a, T> @{
    type Target = T;
    fn deref(&self) -> &T @{
        unsafe @{ &*self.lock.data.get() @}
    @}
@}

impl<'a, T> Drop for SpinLockGuard<'a, T> @{
    fn drop(&mut self) @{
        self.lock.locked.store(false, Ordering::Release);
    @}
@}
@end example

CAS 루프는 @code{locked}를 @code{false}에서 @code{true}로 성공적으로 변경할 때까지 회전한다.
@code{Acquire} 순서는 @code{data}에 대한 모든 후속 접근이 잠금을 획득한 후에 발생하도록 보장한다.

@subsubheading 락 프리 스택 (A Lock-Free Stack)

@cindex lock-free stack
@cindex Treiber stack

이제 더 정교한 구조를 구축해 보자: 락 프리 스택(@dfn{Treiber 스택}이라고도 함).
핵심 아이디어는 스택을 헤드 노드에 대한 원자적 포인터를 가진 연결 리스트로 표현하는 것이다.

@example
use std::sync::atomic::@{AtomicPtr, Ordering@};
use std::ptr;

struct Node<T> @{
    data: T,
    next: *mut Node<T>,
@}

pub struct LockFreeStack<T> @{
    head: AtomicPtr<Node<T>>,
@}

impl<T> LockFreeStack<T> @{
    pub fn new() -> Self @{
        LockFreeStack @{
            head: AtomicPtr::new(ptr::null_mut()),
        @}
    @}

    pub fn push(&self, data: T) @{
        let new_node = Box::into_raw(Box::new(Node @{
            data,
            next: ptr::null_mut(),
        @}));

        loop @{
            // 현재 헤드 읽기
            let old_head = self.head.load(Ordering::Relaxed);

            // 새 노드를 현재 헤드에 연결
            unsafe @{ (*new_node).next = old_head; @}

            // 새 노드를 헤드로 설치 시도
            match self.head.compare_exchange(
                old_head,
                new_node,
                Ordering::Release,  // 성공: 새 노드 게시
                Ordering::Relaxed,  // 실패: 재시도
            ) @{
                Ok(_) => return,  // 성공!
                Err(_) => @{
                    // 다른 스레드가 헤드를 수정함; 재시도
                    continue;
                @}
            @}
        @}
    @}

    pub fn pop(&self) -> Option<T> @{
        loop @{
            let old_head = self.head.load(Ordering::Acquire);

            if old_head.is_null() @{
                return None;  // 스택이 비었음
            @}

            // 헤드 노드에서 다음 포인터 읽기
            let next = unsafe @{ (*old_head).next @};

            // 다음을 새 헤드로 설치 시도
            match self.head.compare_exchange(
                old_head,
                next,
                Ordering::Release,  // 성공: 새 헤드 게시
                Ordering::Acquire,  // 실패: acquire로 재시도
            ) @{
                Ok(_) => @{
                    // 헤드 제거 성공
                    let result = unsafe @{
                        Box::from_raw(old_head).data
                    @};
                    return Some(result);
                @}
                Err(_) => @{
                    // 다른 스레드가 헤드를 수정함; 재시도
                    continue;
                @}
            @}
        @}
    @}
@}
@end example

@code{push}와 @code{pop} 모두 동일한 패턴을 따른다: 현재 상태를 읽고, 새 상태를 계산하고, 아무것도 변경되지 않았다면 CAS를 사용하여 원자적으로 업데이트한다.
만약 그 사이에 다른 스레드가 헤드를 수정했다면, CAS는 실패하고 우리는 새 값으로 재시도한다.

이것은 @dfn{낙관적 동시성(optimistic concurrency)}이다: 우리는 성공을 가정하고 충돌 시 재시도하며, 잠금으로 비관적으로 차단하지 않는다.

@subsubheading ABA 문제 (The ABA Problem)

@cindex ABA problem
@cindex tagged pointers

우리 스택에는 미묘한 버그가 있다. 다음 시나리오를 고려해 보자:

@enumerate
@item
스레드 1이 헤드 포인터를 읽는다 (노드 A를 가리킴)
@item
스레드 2가 A를 팝하고, B를 팝한 다음, A를 다시 푸시한다
@item
스레드 1의 CAS는 헤드가 다시 A를 가리키므로 성공한다
@item
하지만 A의 @code{next} 포인터는 이제 손상되었을 수 있다!
@end enumerate

이것이 악명 높은 @dfn{ABA 문제}이다: 값은 A에서 B로 갔다가 다시 A로 돌아왔지만, CAS는 포인터가 재사용되었음을 감지할 수 없다.
해결책은 포인터에 버전 카운터 태그를 붙이는 것이다:

@example
use std::sync::atomic::@{AtomicU64, Ordering@};

#[repr(C)]
struct TaggedPtr<T> @{
    ptr: *mut T,
    tag: u64,
@}

// 포인터와 태그를 단일 128비트 값으로 묶음
// 128비트 CAS에 대한 플랫폼 지원 필요
pub struct VersionedStack<T> @{
    head: AtomicU128,  // 개념적; 플랫폼 지원 필요
@}
@end example

x86-64에서, 우리는 @code{CMPXCHG16B} 명령어를 사용하여 포인터와 버전을 모두 인코딩하는 128비트를 원자적으로 교환할 수 있다.
대안으로, 포인터 자체에서 비트를 훔쳐올 수 있다 (포인터는 일반적으로 정렬되어 있어 하위 비트가 사용되지 않음).

실제로, @strong{대부분의 프로그래머는 자신의 락 프리 구조를 작성해서는 안 된다}.
미묘함이 심오하며, 버그는 재현하거나 디버그하기가 거의 불가능할 수 있다.
대신 @code{crossbeam}과 같이 전투 테스트를 거친 라이브러리를 사용하라.

@subsubheading 생산용 락 프리: Crossbeam 크레이트 (Production Lock-Free: The Crossbeam Crate)

@cindex crossbeam
@cindex epoch-based reclamation

@code{crossbeam} 크레이트는 생산 품질의 락 프리 구조를 제공한다:

@itemize @bullet
@item
@code{crossbeam::queue::SegQueue}: 락 프리 다중 생산자, 다중 소비자 큐

@item
@code{crossbeam::deque::Worker/Stealer}: 작업 훔치기 덱 (@code{rayon}에서 사용됨)

@item
@code{crossbeam::channel}: 선택(select)을 지원하는 락 프리 채널

@item
@code{crossbeam::epoch}: 락 프리 구조를 위한 안전한 메모리 회수
@end itemize

@cindex memory reclamation

락 프리 프로그래밍에서 가장 어려운 문제는 @dfn{안전한 메모리 회수(safe memory reclamation)}이다:
다른 스레드가 여전히 접근하고 있을 수 있는 노드를 언제 안전하게 할당 해제할 수 있는가?
Crossbeam은 @dfn{에포크 기반 회수(epoch-based reclamation)}로 이를 해결한다:

@example
use crossbeam::epoch::@{self, Atomic, Owned@};
use std::sync::atomic::Ordering;

pub struct CrossbeamStack<T> @{
    head: Atomic<Node<T>>,
@}

impl<T> CrossbeamStack<T> @{
    pub fn push(&self, data: T) @{
        let new = Owned::new(Node @{
            data,
            next: Atomic::null(),
        @});

        let guard = epoch::pin();  // 에포크 진입

        loop @{
            let head = self.head.load(Ordering::Acquire, &guard);
            new.next.store(head, Ordering::Relaxed);

            match self.head.compare_exchange(
                head,
                new,
                Ordering::Release,
                Ordering::Acquire,
                &guard,
            ) @{
                Ok(_) => return,
                Err(e) => new = e.new,
            @}
        @}
    @}
@}
@end example

@code{guard}는 우리가 읽는 모든 포인터가 가드를 해제할 때까지 유효함을 보장한다.
Crossbeam은 전역적으로 에포크를 추적하며, 해당 에포크의 모든 가드가 해제될 때까지 할당 해제를 지연한다.
이것은 리눅스 커널의 RCU(read-copy-update)와 유사하다.

@subsubheading 락 프리를 사용해야 할 때 (When to Use Lock-Free)

@cindex when to use lock-free

락 프리 프로그래밍은 만병통치약이 아니다. 다음과 같은 경우에 락 프리 구조를 사용하라:

@itemize @bullet
@item
경합이 높고 잠금 오버헤드가 지배적일 때
@item
보장된 진행(교착 상태나 우선순위 역전 없음)이 필요할 때
@item
구조가 단순할 때 (큐, 스택, 카운터)
@item
@code{crossbeam}과 같은 입증된 라이브러리를 사용할 수 있을 때
@end itemize

다음과 같은 경우 잠금을 사용하라:

@itemize @bullet
@item
경합이 낮을 때
@item
임계 구역이 복잡할 때 (다중 연산, 조건문)
@item
정확성이 가장 중요하고 락 프리의 미묘함이 위험할 때
@item
읽기-쓰기 패턴이 필요할 때 (@code{RwLock}이 매우 효율적일 수 있음)
@end itemize

@strong{기본적으로 잠금을 사용하라}. 프로파일링 결과 잠금 경합이 병목 현상임을 보여줄 때만 락 프리에 손을 뻗고, 직접 만들기보다는 기존 라이브러리를 사용하라.

@subsubheading 진행 보장 (Progress Guarantees)

@cindex wait-free
@cindex lock-free
@cindex obstruction-free

락 프리 알고리즘은 다양한 @dfn{진행 보장(progress guarantees)}을 제공한다:

@itemize @bullet
@item
@strong{대기 없음(Wait-free)}: 모든 스레드가 다른 스레드의 동작과 관계없이 제한된 단계 내에 연산을 완료한다. 가장 강력한 보장이지만 달성하기 가장 어렵다.

@item
@strong{락 프리(Lock-free)}: 적어도 하나의 스레드가 제한된 단계 내에 진행한다. 우리 스택은 락 프리이다: 일부 스레드가 CAS 루프를 재시도하더라도, 적어도 하나의 스레드는 성공한다.

@item
@strong{방해 없음(Obstruction-free)}: 스레드가 고립되어 실행된다면 진행한다. 가장 약한 보장: 경합 하에서만 진행이 멈춘다.
@end itemize

대부분의 실용적인 락 프리 구조는 락 프리이지만 대기 없지는 않다.
대기 없음 알고리즘은 일반적으로 스레드별 도움 메커니즘을 필요로 하며, 복잡성을 더한다.

@subsubheading 스트림과의 연결 (Connection to Streams)

@ref{3.5.3}의 스트림 기반 동시성 시스템을 상기해 보라. 락 프리 구조는 생산자-소비자 시나리오에서 빛을 발한다:

@example
use crossbeam::channel::unbounded;
use std::thread;

let (sender, receiver) = unbounded();

// 생산자 스레드 (락 프리 push)
for i in 0..4 @{
    let sender = sender.clone();
    thread::spawn(move || @{
        for j in 0..1000 @{
            sender.send((i, j)).unwrap();
        @}
    @});
@}
drop(sender);  // 생산자가 끝나면 채널 닫기

// 소비자 스레드 (락 프리 pop)
let consumer = thread::spawn(move || @{
    let mut count = 0;
    while let Ok(_) = receiver.recv() @{
        count += 1;
    @}
    count
@});

assert_eq!(consumer.join().unwrap(), 4000);
@end example

@code{crossbeam::channel}은 내부적으로 락 프리 알고리즘을 사용하여 경합 하에서도 높은 처리량을 제공한다.
이 패턴---락 프리 큐를 통해 흐르는 데이터 스트림---은 Tokio의 작업 스케줄러와 Rayon의 작업 훔치기와 같은 현대 동시성 시스템의 기초이다.

락 프리 프로그래밍은 @dfn{시간을 통한 상태 관리}라는 SICP의 주제를 구현한다.
잠금으로 시간을 동결하는 대신, 우리는 동시 수정을 수용하고 충돌을 중재하기 위해 원자적 연산을 사용한다.
그 결과는 많은 코어로 우아하게 확장되는 시스템이며, 애플리케이션이 요구할 때 성능을 위해 단순성을 희생한다.

@quotation
@strong{@anchor{Exercise 3.81a}연습문제 3.81a:} @code{AtomicUsize}에 대해 값을 현재 값과 주어진 값 중 최소값으로 원자적으로 업데이트하는 락 프리 @code{fetch_min} 연산을 구현하라.
구현은 루프에서 @code{compare_exchange}를 사용해야 하며 이전 값을 반환해야 한다.
그런 다음 동시 호출이 전역 최소값을 올바르게 계산함을 보여주는 테스트를 작성하라.

@example
impl AtomicMinimum @{
    pub fn fetch_min(&self, val: usize) -> usize @{
        // 여기에 구현
    @}
@}
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 3.82a}연습문제 3.82a:} ABA 문제는 신중한 스레드 스케줄링으로 시연될 수 있다.
ABA 버그를 노출하는 (버전 태깅 없는) 순진한 @code{LockFreeStack}에 대한 테스트를 작성하라.
A를 팝하는 스레드, B를 팝하고 A를 푸시하는 스레드, 그리고 원래 A에 대해 CAS를 시도하는 스레드, 이 세 스레드의 정확한 타이밍을 조율하기 위해 @code{std::sync::Barrier}와 같은 동기화 원시 기능을 사용해야 할 것이다.

힌트: 포인터 재사용을 관찰하기 위해 지연이나 출력 문을 삽입하라.
@end quotation

@quotation
@strong{@anchor{Exercise 3.83a}연습문제 3.83a:} 두 개의 원자적 포인터 @code{head} (디큐용)와 @code{tail} (엔큐용)을 사용하는 락 프리 큐를 설계하라.
여러분의 설계 속성을 락 프리 스택과 비교하라:

@itemize @bullet
@item
@code{enqueue}와 @code{dequeue}가 서로 간섭하지 않고 동시에 진행될 수 있는가?

@item
큐가 비어 있으면 어떻게 되는가? @code{head == tail}인 경우를 어떻게 처리하는가?

@item
빈 큐와 단일 요소 큐를 구별하기 위해 더미 노드가 필요한가?

@item
CAS 연산에 어떤 메모리 순서가 필요하며 그 이유는 무엇인가?
@end itemize

전체 큐를 구현할 필요는 없지만, 엣지 케이스를 처리하고 정확성을 보장하는 방법을 설명하는 의사 코드가 포함된 상세한 설계를 제공하라.
@end quotation

@node 3.5.5, Chapter 4, 3.5.4a, 3.5
@subsection 함수형 프로그램의 모듈성과 객체의 모듈성 (Modularity of Functional Programs and Modularity of Objects)

@ref{3.1.2}에서 보았듯이, 대입을 도입하는 것의 주요 이점 중 하나는 큰 시스템 상태의 일부를 지역 변수 내에 캡슐화하거나 ``숨김''으로써 시스템의 모듈성을 높일 수 있다는 것이다.
스트림 모델은 대입을 사용하지 않고도 동등한 모듈성을 제공할 수 있다.
예를 들어, 우리는 @ref{3.1.2}에서 살펴본 @math{\pi}의 몬테카를로 추정을 스트림 처리 관점에서 재구현할 수 있다.

핵심 모듈성 문제는 난수 생성기의 내부 상태를 난수를 사용하는 프로그램으로부터 숨기고 싶다는 것이었다.
우리는 연속적인 값이 난수의 공급을 제공하는 @code{rand-update} 프로시저로 시작하여, 이것을 사용하여 난수 생성기를 만들었다:

@example
// Cell을 사용한 상태를 가진 난수 생성기
fn make_rand(random_init: u64) -> impl FnMut() -> u64 @{
    let x = std::cell::Cell::new(random_init);
    move || @{
        let next = rand_update(x.get());
        x.set(next);
        next
    @}
@}
@end example

@noindent
스트림 공식화에서는 난수 생성기 자체가 없고, 단지 @code{rand-update}에 대한 연속적인 호출에 의해 생성된 난수의 스트림만 있다:

@example
// successors를 사용한 난수 스트림
fn random_numbers(random_init: u64) -> impl Iterator<Item = u64> @{
    std::iter::successors(Some(random_init), |&x| Some(rand_update(x)))
@}
@end example

@noindent
우리는 이것을 사용하여 @code{random-numbers} 스트림의 연속적인 쌍에 대해 수행된 체자로(Ces@`aro) 실험의 결과 스트림을 구성한다:

@example
fn gcd(a: u64, b: u64) -> u64 @{
    if b == 0 @{ a @} else @{ gcd(b, a % b) @}
@}

// 스트림의 연속적인 쌍에 대해 매핑
fn map_successive_pairs<T, U, I, F>(mut stream: I, f: F) -> impl Iterator<Item = U>
where
    I: Iterator<Item = T>,
    F: Fn(T, T) -> U,
@{
    std::iter::from_fn(move || @{
        let r1 = stream.next()?;
        let r2 = stream.next()?;
        Some(f(r1, r2))
    @})
@}

let cesaro_stream = map_successive_pairs(
    random_numbers(random_init),
    |r1, r2| gcd(r1, r2) == 1
);
@end example

@noindent
@code{cesaro-stream}은 이제 @code{monte-carlo} 프로시저로 공급되어 확률 추정치의 스트림을 생성한다.
그런 다음 결과는 @math{\pi}의 추정치 스트림으로 변환된다.
이 버전의 프로그램은 얼마나 많은 시행을 수행할지 알려주는 매개변수가 필요하지 않다.
(더 많은 실험을 수행하여 얻은) @math{\pi}의 더 나은 추정치는 @code{pi} 스트림을 더 멀리 들여다봄으로써 얻어진다:

@example
// 실행 중인 확률 스트림으로서의 몬테카를로
fn monte_carlo(
    experiment_stream: impl Iterator<Item = bool>,
) -> impl Iterator<Item = f64> @{
    experiment_stream.scan((0_u64, 0_u64), |(passed, failed), result| @{
        if result @{
            *passed += 1;
        @} else @{
            *failed += 1;
        @}
        Some(*passed as f64 / (*passed + *failed) as f64)
    @})
@}

// pi 추정치 스트림
let pi_stream = monte_carlo(cesaro_stream)
    .map(|p| (6.0 / p).sqrt());
@end example

@noindent
이 접근 방식에는 상당한 모듈성이 있는데, 왜냐하면 우리는 여전히 임의의 실험을 다룰 수 있는 일반적인 @code{monte-carlo} 프로시저를 공식화할 수 있기 때문이다.
그러나 대입이나 지역 상태는 없다.

@quotation
@strong{@anchor{Exercise 3.81}연습문제 3.81:} @ref{Exercise 3.6}은 반복 가능한 ``난수'' 시퀀스를 생성하도록 난수 시퀀스를 재설정할 수 있게 함으로써 난수 생성기를 일반화하는 것에 대해 논의했다.
새로운 난수를 @code{generate}하거나 시퀀스를 지정된 값으로 @code{reset}하라는 요청의 입력 스트림에 대해 작동하고 원하는 난수 스트림을 생성하는 동일한 생성기의 스트림 공식화를 생성하라.
해결책에 대입을 사용하지 마라.
@end quotation

@quotation
@strong{@anchor{Exercise 3.82}연습문제 3.82:} 몬테카를로 적분에 대한 @ref{Exercise 3.5}를 스트림의 관점에서 다시 수행하라.
@code{estimate-integral}의 스트림 버전은 얼마나 많은 시행을 수행할지 알려주는 인자를 갖지 않을 것이다.
대신, 이것은 연속적으로 더 많은 시행에 기초한 추정치 스트림을 생성할 것이다.
@end quotation

@subsubheading 시간에 대한 함수형 프로그래밍 관점 (A functional-programming view of time)

이제 이 장의 시작 부분에서 제기된 객체와 상태의 문제로 돌아가 새로운 시각으로 검토해 보자.
우리는 상태를 가진 시스템을 모델링하는 프로그램의 모듈식 구성을 위한 메커니즘을 제공하기 위해 대입과 가변 객체를 도입했다.
우리는 지역 상태 변수를 가진 계산 객체를 구성하고 대입을 사용하여 이러한 변수를 수정했다.
우리는 세계에 있는 객체의 시간적 동작을 해당 계산 객체의 시간적 동작으로 모델링했다.

이제 우리는 스트림이 지역 상태를 가진 객체를 모델링하는 대안적인 방법을 제공한다는 것을 보았다.
우리는 연속적인 상태의 시간 이력을 나타내는 스트림을 사용하여, 어떤 객체의 지역 상태와 같은 변화하는 양을 모델링할 수 있다.
본질적으로, 우리는 스트림을 사용하여 시간을 명시적으로 표현하므로, 시뮬레이션된 세계의 시간을 평가 중에 일어나는 이벤트의 시퀀스와 분리한다.
실제로, @code{delay}의 존재 때문에 모델의 시뮬레이션된 시간과 평가 중의 이벤트 순서 사이에는 거의 관계가 없을 수 있다.

모델링에 대한 이 두 가지 접근 방식을 대조하기 위해, 은행 계좌의 잔액을 모니터링하는 ``인출 처리기''의 구현을 다시 고려해 보자.
@ref{3.1.3}에서 우리는 그러한 처리기의 단순화된 버전을 구현했다:

@example
// 내부 가변성을 위해 Cell을 사용하는 상태를 가진 인출
fn make_simplified_withdraw(initial_balance: i64) -> impl FnMut(i64) -> i64 @{
    let balance = std::cell::Cell::new(initial_balance);
    move |amount| @{
        balance.set(balance.get() - amount);
        balance.get()
    @}
@}
@end example

@noindent
@code{make-simplified-withdraw}에 대한 호출은 계산 객체를 생성하는데, 각 객체는 객체에 대한 연속적인 호출에 의해 감소하는 지역 상태 변수 @code{balance}를 갖는다.
객체는 @code{amount}를 인자로 받아 새 잔액을 반환한다.
우리는 은행 계좌 사용자가 그러한 객체에 입력 시퀀스를 입력하고 디스플레이 화면에 표시되는 반환된 값의 시퀀스를 관찰하는 것을 상상할 수 있다.

대안으로, 우리는 인출 처리기를 잔액과 인출할 금액의 스트림을 입력으로 받아 계좌의 연속적인 잔액 스트림을 생성하는 프로시저로 모델링할 수 있다:

@example
// 함수형 스트림 기반 인출 - 변경 없음!
fn stream_withdraw(
    initial_balance: i64,
    amount_stream: impl Iterator<Item = i64>,
) -> impl Iterator<Item = i64> @{
    std::iter::once(initial_balance).chain(
        amount_stream.scan(initial_balance, |balance, amount| @{
            *balance -= amount;
            Some(*balance)
        @})
    )
@}
// 각 잔액은 입력에 의해 완전히 결정된다 - 순수 함수!
@end example

@noindent
@code{Stream-withdraw}는 출력이 입력에 의해 완전히 결정되는 잘 정의된 수학적 함수를 구현한다.
그러나 입력 @code{amount-stream}이 사용자가 입력한 연속적인 값의 스트림이고 결과 잔액 스트림이 표시된다고 가정해 보자.
그러면 값을 입력하고 결과를 지켜보는 사용자의 관점에서 볼 때, 스트림 프로세스는 @code{make-simplified-withdraw}에 의해 생성된 객체와 동일한 동작을 갖는다.
하지만 스트림 버전에서는 대입도 없고, 지역 상태 변수도 없으며, 결과적으로 우리가 @ref{3.1.3}에서 마주쳤던 이론적인 어려움도 없다.
그런데도 시스템은 상태를 가지고 있다!

이것은 정말 놀라운 일이다.
@code{stream-withdraw}가 동작이 변하지 않는 잘 정의된 수학적 함수를 구현함에도 불구하고, 여기서 사용자의 인식은 변화하는 상태를 가진 시스템과 상호 작용하는 것이다.
이 역설을 해결하는 한 가지 방법은 시스템에 상태를 부과하는 것이 사용자의 시간적 존재라는 것을 깨닫는 것이다.
만약 사용자가 상호 작용에서 물러나 개별 거래보다는 잔액의 스트림 관점에서 생각할 수 있다면, 시스템은 상태가 없는 것처럼 보일 것이다.@footnote{물리학에서도 비슷하게, 움직이는 입자를 관찰할 때 우리는 입자의 위치(상태)가 변하고 있다고 말한다. 그러나 시공간에서 입자의 세계선(world line) 관점에서는 변화가 포함되지 않는다.}

복잡한 프로세스의 한 부분의 관점에서 볼 때, 다른 부분들은 시간에 따라 변하는 것처럼 보인다.
그것들은 숨겨진 시간 가변적 지역 상태를 가지고 있다.
만약 우리가 우리 세계의 이런 종류의 자연스러운 분해(우리가 그 세계의 일부로서 우리의 관점에서 보는 대로)를 우리 컴퓨터의 구조로 모델링하는 프로그램을 작성하고 싶다면, 우리는 기능적이지 않은 계산 객체를 만든다---그것들은 시간과 함께 변해야 한다.
우리는 지역 상태 변수로 상태를 모델링하고, 그 변수에 대한 대입으로 상태의 변화를 모델링한다.
이렇게 함으로써 우리는 계산의 실행 시간을 우리가 속한 세계의 시간 모델로 만들고, 따라서 우리 컴퓨터에 ``객체''를 갖게 된다.

객체로 모델링하는 것은 강력하고 직관적인데, 주로 이것이 우리가 속한 세계와 상호 작용하는 인식과 일치하기 때문이다.
그러나 우리가 이 장 전체에서 반복해서 보았듯이, 이러한 모델은 이벤트의 순서를 제약하고 여러 프로세스를 동기화하는 골치 아픈 문제를 제기한다.
이러한 문제를 피할 수 있는 가능성은 대입이나 가변 데이터에 대한 어떤 규정도 포함하지 않는 @newterm{함수형 프로그래밍 언어(functional programming languages)}의 개발을 자극했다.
그러한 언어에서 모든 프로시저는 동작이 변하지 않는 인자의 잘 정의된 수학적 함수를 구현한다.
함수형 접근 방식은 동시성 시스템을 다루는 데 매우 매력적이다.@footnote{Fortran의 발명가인 John Backus는 1978년 @abbr{ACM} 튜링상을 수상했을 때 함수형 프로그래밍에 큰 가시성을 부여했다. 그의 수락 연설(@ref{Backus 1978})은 함수형 접근 방식을 강력하게 옹호했다. 함수형 프로그래밍에 대한 좋은 개요는 @ref{Henderson 1980}과 @ref{Darlington et al. 1982}에 나와 있다.}

반면에 자세히 살펴보면, 우리는 시간 관련 문제가 함수형 모델에도 스며드는 것을 볼 수 있다.
특히 골치 아픈 영역 중 하나는 대화형 시스템, 특히 독립적인 개체 간의 상호 작용을 모델링하는 시스템을 설계하고자 할 때 발생한다.
예를 들어, 공동 은행 계좌를 허용하는 은행 시스템의 구현을 다시 한 번 고려해 보자.
대입과 객체를 사용하는 전통적인 시스템에서, 우리는 @ref{3.1.3}에서 본 것처럼 Peter와 Paul이 모두 자신의 거래 요청을 동일한 은행 계좌 객체로 보냄으로써 Peter와 Paul이 계좌를 공유한다는 사실을 모델링할 것이다.
``객체'' 자체가 없는 스트림 관점에서, 우리는 은행 계좌가 거래 요청 스트림에 대해 작동하여 응답 스트림을 생성하는 프로세스로 모델링될 수 있음을 이미 나타냈다.
따라서 우리는 @ref{Figure 3.38}에 표시된 것처럼 Peter의 거래 요청 스트림과 Paul의 요청 스트림을 병합하고 그 결과를 은행 계좌 스트림 프로세스에 공급함으로써 Peter와 Paul이 공동 은행 계좌를 가지고 있다는 사실을 모델링할 수 있다.

@float
@anchor{Figure 3.38}
@ifinfo
@strong{Figure 3.38:} 두 거래 요청 스트림을 병합하여 모델링된 공동 은행 계좌.

@example
Peter's requests   +---------+     +---------+
------------------>|         |     |         |
Paul's requests    |  merge  |---->| bank    |---->
------------------>|         |     | account |
                   +---------+     +---------+
@end example
@end ifinfo
@iftex
@image{fig/chap3/Fig3.38a,143mm,,,.std.svg}
@caption{@strong{Figure 3.38:} 두 거래 요청 스트림을 병합하여 모델링된 공동 은행 계좌.}
@end iftex
@end float

@noindent
이 공식화의 문제는 @newterm{병합(merge)}이라는 개념에 있다.
단순히 Peter의 요청 하나와 Paul의 요청 하나를 번갈아 가며 취하는 것으로는 두 스트림을 병합할 수 없다. Paul이 계좌에 아주 드물게만 접근한다고 가정해 보자.
우리는 Peter가 두 번째 거래를 발행하기 전에 Paul이 계좌에 접근할 때까지 기다리도록 강요할 수 없다.
병합이 어떻게 구현되든, 그것은 Peter와 Paul이 인식하는 ``실시간''에 의해 제약되는 방식으로 두 거래 스트림을 인터리빙해야 한다. 만약 Peter와 Paul이 만난다면, 그들은 특정 거래가 회의 전에 처리되었고 다른 거래는 회의 후에 처리되었다는 것에 동의할 수 있다는 의미에서다.@footnote{어떤 두 스트림에 대해서도 일반적으로 하나 이상의 허용 가능한 인터리빙 순서가 있음을 관찰하라. 따라서 엄밀히 말하면 ``병합''은 함수라기보다는 관계(relation)이다---답은 입력의 결정론적 함수가 아니다. 우리는 이미 (@ref{Footnote 167}) 동시성을 다룰 때 비결정론이 필수적이라고 언급했다. 병합 관계는 함수형 관점에서 동일한 필수적인 비결정론을 보여준다. @ref{4.3}에서 우리는 또 다른 관점에서 비결정론을 살펴볼 것이다.}
이것은 정확히 우리가 @ref{3.4.1}에서 다루어야 했던 것과 동일한 제약 조건이며, 거기서 우리는 상태를 가진 객체의 동시 처리에서 ``올바른'' 이벤트 순서를 보장하기 위해 명시적인 동기화를 도입할 필요성을 발견했다.
따라서 함수형 스타일을 지원하려는 시도에서, 서로 다른 에이전트로부터의 입력을 병합해야 하는 필요성은 함수형 스타일이 제거하고자 했던 바로 그 문제를 다시 도입한다.

우리는 우리가 모델링하려는 실제 세계에 대한 우리의 인식과 구조가 일치하는 계산 모델을 구축하겠다는 목표로 이 장을 시작했다.
우리는 세계를 상태를 가진 별개의, 시간 제한적인, 상호 작용하는 객체들의 컬렉션으로 모델링할 수도 있고, 세계를 단일한, 시간을 초월한, 상태 없는 통일체로 모델링할 수도 있다.
각 관점은 강력한 장점을 가지고 있지만, 어느 한 관점만으로는 완전히 만족스럽지 않다.
대통합은 아직 나타나지 않았다.@footnote{객체 모델은 세계를 별개의 조각으로 나눔으로써 근사한다. 함수형 모델은 객체 경계를 따라 모듈화하지 않는다. 객체 모델은 ``객체''의 공유되지 않은 상태가 그들이 공유하는 상태보다 훨씬 클 때 유용하다. 객체 관점이 실패하는 곳의 예는 양자 역학인데, 여기서 사물을 개별 입자로 생각하는 것은 역설과 혼란으로 이어진다. 객체 관점과 함수형 관점을 통합하는 것은 프로그래밍보다는 근본적인 인식론적 문제와 관련이 있을 수 있다.}

@node    Chapter 4, 4.1, 3.5, Top
@chapter 메타언어적 추상화 (Metalinguistic Abstraction)

@quotation
@dots{} 마법은 단어 속에 있다---아브라카다브라, 열려라 참깨, 그리고 나머지도---하지만 한 이야기 속의 마법의 단어는 다음 이야기에서는 마법이 아니다.
진짜 마법은 어떤 단어가 작동하는지, 언제, 그리고 무엇을 위해 작동하는지 이해하는 것이다; 요령은 그 요령을 배우는 것이다.

@dots{} 그리고 그 단어들은 우리 알파벳의 글자들로 만들어졌다: 펜으로 그릴 수 있는 몇 십 개의 구불구불한 선들.
이것이 열쇠다! 그리고 보물도, 우리가 손에 넣을 수만 있다면! 그것은 마치---마치 보물로 가는 열쇠가 보물 @emph{인} 것처럼!

---존 바스(John Barth), @cite{키메라(Chimera)}
@end quotation


@noindent
프로그램 설계에 대한 우리의 연구에서, 우리는 전문 프로그래머들이 모든 복잡한 시스템의 설계자들이 사용하는 것과 동일한 일반적인 기술로 설계의 복잡성을 제어한다는 것을 보았다.
그들은 원시 요소를 결합하여 복합 객체를 형성하고, 복합 객체를 추상화하여 더 높은 수준의 구성 요소를 형성하며, 시스템 구조에 대한 적절한 거시적 관점을 채택하여 모듈성을 보존한다.
이러한 기술을 설명하면서, 우리는 현실 세계의 복잡한 현상을 모델링하기 위한 프로세스를 설명하고 계산 데이터 객체와 프로세스를 구성하기 위한 언어로 Lisp을 사용했다.
그러나 점점 더 복잡한 문제에 직면함에 따라, 우리는 Lisp이나 사실상 어떤 고정된 프로그래밍 언어도 우리의 필요에 충분하지 않다는 것을 알게 될 것이다.
우리는 아이디어를 더 효과적으로 표현하기 위해 끊임없이 새로운 언어로 눈을 돌려야 한다.
새로운 언어를 확립하는 것은 엔지니어링 설계에서 복잡성을 제어하기 위한 강력한 전략이다; 우리는 종종 당면한 문제에 특히 잘 맞는 원시 요소, 결합 수단, 추상화 수단을 사용하여 문제를 다른 방식으로 설명(하고 따라서 생각)할 수 있게 해주는 새로운 언어를 채택함으로써 복잡한 문제를 다루는 능력을 향상시킬 수 있다.@footnote{동일한 아이디어가 공학의 모든 분야에 퍼져 있다. 예를 들어, 전기 기술자는 회로를 설명하기 위해 많은 다른 언어를 사용한다. 이 중 두 가지는 전기 @newterm{네트워크(networks)} 언어와 전기 @newterm{시스템(systems)} 언어이다. 네트워크 언어는 이산 전기 소자의 관점에서 장치의 물리적 모델링을 강조한다. 네트워크 언어의 원시 객체는 저항, 커패시터, 인덕터, 트랜지스터와 같은 원시 전기 부품이며, 이들은 전압과 전류라는 물리적 변수의 관점에서 특징지어진다. 네트워크 언어로 회로를 설명할 때, 엔지니어는 설계의 물리적 특성에 관심을 갖는다. 대조적으로, 시스템 언어의 원시 객체는 필터와 증폭기와 같은 신호 처리 모듈이다. 모듈의 기능적 동작만이 관련이 있으며, 신호는 전압과 전류로서의 물리적 구현에 대한 고려 없이 조작된다. 시스템 언어는 신호 처리 시스템의 요소가 전기 네트워크로 구성된다는 의미에서 네트워크 언어 위에 세워진다. 그러나 여기서 관심사는 주어진 응용 문제를 해결하기 위한 전기 장치의 대규모 조직에 있으며, 부품의 물리적 타당성은 가정된다. 이 계층화된 언어 모음은 @ref{2.2.4}의 그림 언어로 설명된 계층화된 설계 기술의 또 다른 예이다.}

프로그래밍에는 수많은 언어가 부여되어 있다.
특정 컴퓨터를 위한 기계어와 같은 물리적 언어가 있다.
이러한 언어는 개별 저장 비트와 원시 기계 명령어의 관점에서 데이터와 제어의 표현에 관심을 갖는다.
기계어 프로그래머는 자원이 제한된 계산의 효율적인 구현을 위해 주어진 하드웨어를 사용하여 시스템과 유틸리티를 구축하는 데 관심을 갖는다.
기계어 기판 위에 세워진 고급 언어는 비트 모음으로서의 데이터 표현과 원시 명령어 시퀀스로서의 프로그램 표현에 대한 우려를 숨긴다.
이러한 언어는 프로시저 정의와 같이 시스템의 대규모 조직에 적합한 결합 및 추상화 수단을 가지고 있다.

@newterm{메타언어적 추상화(Metalinguistic abstraction)}---새로운 언어 확립---는 엔지니어링 설계의 모든 분야에서 중요한 역할을 한다.
이것은 컴퓨터 프로그래밍에서 특히 중요한데, 프로그래밍에서는 우리가 새로운 언어를 공식화할 수 있을 뿐만 아니라 평가자를 구성하여 이러한 언어를 구현할 수도 있기 때문이다.
프로그래밍 언어에 대한 @newterm{평가자(evaluator)}(또는 @newterm{인터프리터(interpreter)})는 언어의 표현식에 적용될 때 해당 표현식을 평가하는 데 필요한 작업을 수행하는 프로시저이다.

이것을 프로그래밍에서 가장 근본적인 아이디어로 간주하는 것은 과장이 아니다:

@quotation
프로그래밍 언어에서 표현식의 의미를 결정하는 평가자는 단지 또 다른 프로그램일 뿐이다.
@end quotation

@noindent
이 점을 이해하는 것은 프로그래머로서의 우리 자신의 이미지를 바꾸는 것이다.
우리는 타인이 설계한 언어의 사용자일 뿐만 아니라 언어의 설계자로서 자신을 보게 된다.

사실, 우리는 거의 모든 프로그램을 어떤 언어에 대한 평가자로 간주할 수 있다.
예를 들어, @ref{2.5.3}의 다항식 조작 시스템은 다항식 산술 규칙을 구현하며 리스트 구조 데이터에 대한 연산으로 이를 구현한다.
이 시스템을 다항식 표현식을 읽고 인쇄하는 프로시저로 보강하면, 기호 수학의 문제를 다루기 위한 특수 목적 언어의 핵심을 갖게 된다.
@ref{3.3.4}의 디지털 논리 시뮬레이터와 @ref{3.3.5}의 제약 조건 전파기는 그 자체로 합법적인 언어이며, 각각 고유한 원시 요소, 결합 수단, 추상화 수단을 가지고 있다.
이 관점에서 보면, 대규모 컴퓨터 시스템을 다루는 기술은 새로운 컴퓨터 언어를 구축하는 기술과 합쳐지며, 컴퓨터 과학 자체는 적절한 설명 언어를 구성하는 학문에 지나지 않게 된다(그 이상도 그 이하도 아니다).

이제 우리는 다른 언어의 관점에서 언어가 확립되는 기술을 둘러보는 여행을 시작한다.
이 장에서 우리는 Lisp을 기반으로 사용하여 평가자를 Lisp 프로시저로 구현할 것이다.
Lisp은 기호 표현식을 표현하고 조작하는 능력 때문에 이 작업에 특히 적합하다.
우리는 Lisp 자체에 대한 평가자를 구축함으로써 언어가 어떻게 구현되는지 이해하는 첫 걸음을 내딛을 것이다.
우리 평가자가 구현할 언어는 이 책에서 사용하는 Lisp의 Scheme 방언의 하위 집합이 될 것이다.
이 장에서 설명하는 평가자는 Lisp의 특정 방언을 위해 작성되었지만, 순차적 기계를 위한 프로그램을 작성하기 위해 설계된 모든 표현식 중심 언어에 대한 평가자의 본질적인 구조를 포함하고 있다.
(사실 대부분의 언어 처리기는 그 깊은 곳에 작은 ``Lisp'' 평가자를 포함하고 있다.)
평가자는 설명과 토론의 목적으로 단순화되었으며, 상용 품질의 Lisp 시스템에 포함되어야 할 중요한 일부 기능이 생략되었다.
그럼에도 불구하고 이 간단한 평가자는 이 책의 대부분의 프로그램을 실행하기에 충분하다.@footnote{우리 평가자가 생략한 가장 중요한 기능은 오류 처리 및 디버깅 지원 메커니즘이다. 평가자에 대한 더 광범위한 논의는 @ref{Friedman et al. 1992}를 참조하라. 이 책은 Scheme으로 작성된 일련의 평가자를 통해 프로그래밍 언어를 설명한다.}

평가자를 Lisp 프로그램으로 접근 가능하게 만드는 것의 중요한 이점은 이러한 평가자 프로그램에 대한 수정으로 설명하여 대체 평가 규칙을 구현할 수 있다는 것이다.
우리가 이 힘을 잘 활용할 수 있는 한 곳은 계산 모델이 시간 개념을 구현하는 방식에 대해 추가적인 제어를 얻는 것인데, 이는 @ref{Chapter 3}의 논의에서 매우 중심적이었다.
거기서 우리는 스트림을 사용하여 세계의 시간 표현을 컴퓨터의 시간과 분리함으로써 상태와 대입의 복잡성 중 일부를 완화했다.
그러나 우리의 스트림 프로그램은 때때로 번거로웠는데, Scheme의 적용 순서 평가(applicative-order evaluation)에 의해 제약받았기 때문이다.
@ref{4.2}에서 우리는 평가자를 수정하여 @newterm{정규 순서 평가(normal-order evaluation)}를 제공함으로써 더 우아한 접근 방식을 제공하도록 기본 언어를 변경할 것이다.

@ref{4.3}절은 더 야심 찬 언어적 변화를 구현하는데, 여기서 표현식은 단일 값이 아니라 많은 값을 갖는다.
이 @newterm{비결정적 컴퓨팅(nondeterministic computing)} 언어에서는 표현식에 대한 모든 가능한 값을 생성한 다음 특정 제약 조건을 만족하는 값을 찾는 프로세스를 표현하는 것이 자연스럽다.
계산과 시간의 모델 측면에서, 이것은 시간이 일련의 ``가능한 미래''로 분기한 다음 적절한 시간 선을 검색하는 것과 같다.
우리의 비결정적 평가자에서는 여러 값을 추적하고 검색을 수행하는 것이 언어의 기본 메커니즘에 의해 자동으로 처리된다.

@ref{4.4}에서 우리는 지식이 입력과 출력이 있는 계산의 관점이 아니라 관계(relations)의 관점에서 표현되는 @newterm{논리 프로그래밍(logic-programming)} 언어를 구현한다.
비록 이것이 언어를 Lisp이나 사실상 어떤 기존 언어와도 근본적으로 다르게 만들지만, 우리는 논리 프로그래밍 평가자가 Lisp 평가자의 본질적인 구조를 공유한다는 것을 보게 될 것이다.

@node	4.1, 4.2, Chapter 4, Chapter 4
@section 메타순환 평가자 (The Metacircular Evaluator)

Lisp을 위한 우리의 평가자는 Lisp 프로그램으로 구현될 것이다.
Lisp으로 구현된 평가자를 사용하여 Lisp 프로그램을 평가한다는 생각은 순환적인 것처럼 보일 수 있다.
그러나 평가는 프로세스이므로, 프로세스를 설명하기 위한 도구인 Lisp을 사용하여 평가 프로세스를 설명하는 것은 적절하다.@footnote{그렇다고 해도, 우리의 평가자로 명확히 밝혀지지 않는 평가 프로세스의 중요한 측면들이 여전히 남아 있다. 이 중 가장 중요한 것은 프로시저가 다른 프로시저를 호출하고 호출자에게 값을 반환하는 세부 메커니즘이다. 우리는 @ref{Chapter 5}에서 평가자를 단순 레지스터 기계로 구현함으로써 평가 프로세스를 더 자세히 살펴볼 때 이 문제를 다룰 것이다.}
자신이 평가하는 것과 같은 언어로 작성된 평가자를 @newterm{메타순환(metacircular)}이라고 한다.

메타순환 평가자는 본질적으로 @ref{3.2}에서 설명한 평가의 환경 모델을 Scheme으로 공식화한 것이다.
모델에는 두 가지 기본 부분이 있음을 상기하라:

@enumerate 1

@item
조합(특수 형식이 아닌 복합 표현식)을 평가하려면, 하위 표현식을 평가한 다음 연산자 하위 표현식의 값을 피연산자 하위 표현식의 값에 적용한다.

@item
복합 프로시저를 인자 집합에 적용하려면, 새 환경에서 프로시저의 본문을 평가한다.
이 환경을 구성하기 위해, 프로시저 객체의 환경 부분을 프로시저의 형식 매개변수가 프로시저가 적용되는 인자에 바인딩되는 프레임으로 확장한다.

@end enumerate

@noindent
이 두 규칙은 평가 프로세스의 본질을 설명한다. 평가 프로세스는 환경에서 평가될 표현식이 인자에 적용될 프로시저로 축소되고, 이것이 다시 새 환경에서 평가될 새 표현식으로 축소되는 기본 주기를 반복하며, 결국 환경에서 값을 찾는 기호와 직접 적용되는 원시 프로시저에 도달할 때까지 계속된다(@ref{Figure 4.1} 참조).@footnote{만약 우리에게 원시 프로시저를 적용할 능력이 주어진다면, 평가자에서 구현해야 할 것은 무엇이 남는가? 평가자의 임무는 언어의 원시 프로시저를 지정하는 것이 아니라, 원시 프로시저 모음을 묶어 언어를 형성하는 결합 조직---조합 수단과 추상화 수단---을 제공하는 것이다. 구체적으로:

@itemize @bullet

@item
평가자는 우리가 중첩된 표현식을 다룰 수 있게 해준다. 예를 들어, 단순히 원시 프로시저를 적용하는 것만으로는 @code{(+ 1 6)} 표현식을 평가하기에 충분할지 모르지만, @code{(+ 1 (* 2 3))}을 처리하기에는 적절하지 않다. 원시 프로시저 @code{+}에 관한 한, 그 인자는 숫자여야 하며, @code{(* 2 3)}이라는 표현식을 인자로 전달하면 질식할 것이다. 평가자의 중요한 역할 중 하나는 @code{(* 2 3)}이 @code{+}에 인자로 전달되기 전에 6으로 축소되도록 프로시저 합성을 안무하는 것이다.

@item
평가자는 우리가 변수를 사용할 수 있게 해준다. 예를 들어, 덧셈을 위한 원시 프로시저는 @code{(+ x 1)}과 같은 표현식을 처리할 방법이 없다. 우리는 변수를 추적하고 원시 프로시저를 호출하기 전에 그 값을 얻기 위해 평가자가 필요하다.

@item
평가자는 우리가 복합 프로시저를 정의할 수 있게 해준다. 이것은 프로시저 정의를 추적하고, 표현식을 평가할 때 이 정의를 사용하는 방법을 알고, 프로시저가 인자를 받을 수 있게 하는 메커니즘을 제공하는 것을 포함한다.

@item
평가자는 프로시저 호출과는 다르게 평가되어야 하는 특수 형식을 제공한다.

@end itemize
}
이 평가 주기는 평가자의 두 가지 핵심 프로시저인 @code{eval}과 @code{apply} 사이의 상호 작용으로 구현될 것이며, 이는 @ref{4.1.1}에서 설명된다(@ref{Figure 4.1} 참조).

@float
@anchor{Figure 4.1}
@ifinfo
@strong{Figure 4.1:} @code{eval}-@code{apply} 주기는 컴퓨터 언어의 본질을 드러낸다.

@example
                           .,ad88888888baa,
                  _    ,d8P"""        ""9888ba.      _
                 /  .a8"          ,ad88888888888a   |\
               /   aP'          ,88888888888888888a   \
              /  ,8"           ,88888888888888888888,  \
             |  ,8'            (888888888888888888888, |
            /  ,8'             `8888888888888888888888  \
            |  8)               `888888888888888888888, |
Procedure,  |  8                  "88888 Apply 8888888) | Expression
Arguments   |  8     Eval          `888888888888888888) | Environment
            |  8)                    "8888888888888888  |
            \  (b                     "88888888888888'  /
             | `8,                     8888888888888)  |
             \  "8a                   ,888888888888)  /
              \   V8,                 d88888888888"  /
              _\| `8b,             ,d8888888888P' _/
                     `V8a,       ,ad8888888888P'
                        ""88888888888888888P"
                             """"""""""""

                               [graphic by Normand Veillux, modified]
@end example
@end ifinfo
@iftex
@image{fig/chap4/Fig4.1a,147mm,,,.std.svg}
@caption{@strong{Figure 4.1:} @code{eval}-@code{apply} 주기는 컴퓨터 언어의 본질을 드러낸다.}
@end iftex
@end float

평가자의 구현은 평가될 표현식의 @newterm{구문(syntax)}을 정의하는 프로시저에 의존할 것이다.
우리는 평가자가 언어의 표현과 독립적이 되도록 데이터 추상화를 사용할 것이다.
예를 들어, 대입이 기호 @code{set!}으로 시작하는 리스트로 표현된다는 선택에 전념하는 대신, 우리는 대입을 테스트하기 위해 추상 술어 @code{is_assignment}를 사용하고, 대입의 부분에 접근하기 위해 추상 선택자 @code{assignment_variable}과 @code{assignment_value}를 사용한다.
표현식의 구현은 @ref{4.1.2}에서 자세히 설명될 것이다.
또한 @ref{4.1.3}에서 설명된 프로시저와 환경의 표현을 지정하는 연산들도 있다.
예를 들어, @code{make_procedure}는 복합 프로시저를 생성하고, @code{lookup_variable_value}는 변수의 값에 접근하며, @code{apply_primitive_procedure}는 주어진 인자 리스트에 원시 프로시저를 적용한다.

@menu
* 4.1.1::            The Core of the Evaluator
* 4.1.2::            Representing Expressions
* 4.1.3::            Evaluator Data Structures
* 4.1.4::            Running the Evaluator as a Program
* 4.1.5::            Data as Programs
* 4.1.6::            Internal Definitions
* 4.1.7::            Separating Syntactic Analysis from Execution
* 4.1.8::            Declarative Macros
@end menu

@node	4.1.1, 4.1.2, 4.1, 4.1
@subsection 평가자의 핵심 (The Core of the Evaluator)

평가 프로세스는 두 프로시저 @code{eval}과 @code{apply} 사이의 상호 작용으로 설명될 수 있다.

@subsubheading Eval

@code{Eval}은 표현식과 환경을 인자로 받는다.
이것은 표현식을 분류하고 평가를 지시한다.
@code{Eval}은 평가될 표현식의 구문 유형에 대한 사례 분석(case analysis)으로 구조화되어 있다.
프로시저를 일반적인 상태로 유지하기 위해, 우리는 표현식 유형의 결정을 추상적으로 표현하며, 다양한 유형의 표현식에 대한 특정 표현에 전념하지 않는다.
각 유형의 표현식은 그것을 테스트하는 술어와 그 부분을 선택하는 추상적인 수단을 갖는다.
이 @newterm{추상 구문(abstract syntax)}은 동일한 평가자를 사용하지만 다른 구문 프로시저 모음을 사용하여 언어의 구문을 변경할 수 있는 방법을 쉽게 볼 수 있게 해준다.

@noindent
@b{원시 표현식 (Primitive expressions)}

@itemize @bullet

@item
숫자와 같은 자체 평가 표현식의 경우, @code{eval}은 표현식 자체를 반환한다.

@item
@code{Eval}은 변수의 값을 찾기 위해 환경에서 변수를 조회해야 한다.

@end itemize

@noindent
@b{특수 형식 (Special forms)}

@itemize @bullet

@item
인용된(quoted) 표현식의 경우, @code{eval}은 인용된 표현식을 반환한다.

@item
변수에 대한 대입(또는 정의)은 변수와 연관될 새 값을 계산하기 위해 @code{eval}을 재귀적으로 호출해야 한다.
환경은 변수의 바인딩을 변경(또는 생성)하기 위해 수정되어야 한다.

@item
@code{if} 표현식은 술어가 참이면 결과절(consequent)을 평가하고, 그렇지 않으면 대안절(alternative)을 평가하도록 그 부분에 대한 특별한 처리를 요구한다.

@item
@code{lambda} 표현식은 @code{lambda} 표현식에 의해 지정된 매개변수 및 본문을 평가 환경과 함께 묶어 적용 가능한 프로시저로 변환되어야 한다.

@item
@code{begin} 표현식은 표현식의 시퀀스를 나타나는 순서대로 평가하는 것을 요구한다.

@item
사례 분석(@code{cond})은 @code{if} 표현식의 중첩으로 변환된 다음 평가된다.

@end itemize

@noindent
@b{조합 (Combinations)}

@itemize @bullet

@item
프로시저 적용의 경우, @code{eval}은 조합의 연산자 부분과 피연산자들을 재귀적으로 평가해야 한다.
결과 프로시저와 인자들은 @code{apply}로 전달되며, 이것이 실제 프로시저 적용을 처리한다.

@end itemize

@noindent
다음은 @code{eval}의 정의이다:

@noindent
@b{Rust:} 열거형에 대한 패턴 매칭은 철저한 디스패치를 제공한다. 평가는 값과 잠재적으로 업데이트된 환경을 모두 반환한다(상태를 함수적으로 스레딩함):
@example
pub fn eval(
    expr: &Expr,
    env: Environment<Value>,
) -> Result<(Value, Environment<Value>), EvalError> @{
    match expr @{
        // 자체 평가 표현식
        Expr::Number(n) => Ok((Value::Number(*n), env)),
        Expr::String(s) => Ok((Value::String(s.clone()), env)),

        // 변수 조회
        Expr::Symbol(name) => @{
            let value = env
                .lookup(name)
                .ok_or_else(|| EvalError::UnboundVariable(name.clone()))?
                .clone();
            Ok((value, env))
        @}

        // 인용: 표현식을 평가하지 않고 반환
        Expr::Quote(quoted) => @{
            let value = expr_to_value(quoted)?;
            Ok((value, env))
        @}

        // If: 술어를 평가한 다음, 결과절 또는 대안절 평가
        Expr::If @{ predicate, consequent, alternative @} => @{
            let (pred_value, env) = eval(predicate, env)?;
            if is_true(&pred_value) @{
                eval(consequent, env)
            @} else @{
                eval(alternative, env)
            @}
        @}

        // Lambda: 현재 환경을 캡처하는 클로저 생성
        Expr::Lambda @{ params, body @} => @{
            let closure = Value::Closure @{
                params: params.clone(),
                body: body.clone(),
                env: env.clone(), // O(1) 복제로 캡처
                self_name: None,
            @};
            Ok((closure, env))
        @}

        // Define: 값을 평가하고 새 환경에 바인딩
        Expr::Define @{ name, value @} => @{
            let (val, env) = eval(value, env)?;
            let new_env = env.define(name.clone(), val);
            Ok((Value::Void, new_env))
        @}

        // 적용: 연산자와 피연산자를 평가한 다음 적용
        Expr::Application @{ operator, operands @} => @{
            let (proc, env) = eval(operator, env)?;
            let (args, env) = eval_list(operands, env)?;
            let result = apply(proc, args)?;
            Ok((result, env))
        @}
        _ => Err(EvalError::InvalidSyntax(format!("Unknown: @{:?@}", expr))),
    @}
@}
@end example

@noindent
명확성을 위해, @code{eval}은 @code{match}를 사용한 사례 분석으로 구현되었다.
이것의 단점은 우리의 프로시저가 구별 가능한 몇 가지 유형의 표현식만 처리하며, @code{eval}의 정의를 편집하지 않고는 새로운 유형을 정의할 수 없다는 것이다.
대부분의 Lisp 구현에서, 표현식 유형에 따른 디스패치는 데이터 주도 스타일로 수행된다.
이것은 사용자가 @code{eval} 자체의 정의를 수정하지 않고도 @code{eval}이 구별할 수 있는 새로운 유형의 표현식을 추가할 수 있게 해준다. (@ref{Exercise 4.3} 참조.)

@subsubheading Apply

@code{Apply}는 두 개의 인자, 프로시저와 프로시저가 적용되어야 할 인자 리스트를 받는다.
@code{Apply}는 프로시저를 두 종류로 분류한다: 원시 프로시저를 적용하기 위해 @code{apply_primitive_procedure}를 호출한다; 복합 프로시저는 프로시저의 본문을 구성하는 표현식들을 순차적으로 평가함으로써 적용한다.
복합 프로시저의 본문 평가를 위한 환경은 프로시저가 전달한 기본 환경을 확장하여 프로시저의 형식 매개변수가 프로시저가 적용되는 인자에 바인딩되는 프레임을 포함함으로써 구성된다.
다음은 @code{apply}의 정의이다:

@noindent
@b{Rust:}
@example
pub fn apply(procedure: Value, args: Vec<Value>) -> Result<Value, EvalError> @{
    match procedure @{
        Value::Primitive(_, func) => func(&args),
        Value::Closure @{ params, body, env, .. @} => @{
            // 매개변수 바인딩으로 확장
            let bindings: Vec<(String, Value)> =
                params.into_iter().zip(args).collect();
            let new_env = env.extend(bindings);

            // 본문 평가; apply에서는 최종 환경을 무시함
            let (result, _) = eval_sequence(&body, new_env)?;
            Ok(result)
        @}
        _ => Err(EvalError::TypeError(format!("Not a procedure: @{:?@}", procedure))),
    @}
@}
@end example

@subsubheading 프로시저 인자 (Procedure arguments)

@code{eval}이 프로시저 적용을 처리할 때, 프로시저가 적용될 인자 리스트를 생성하기 위해 @code{eval_list}를 사용한다.
@code{Eval_list}는 조합의 피연산자를 인자로 받는다.
이것은 각 피연산자를 차례로 평가하며, 평가를 통해 환경을 스레딩하고, 해당 값의 리스트를 반환한다:

@example
fn eval_list(
    exprs: &[Expr],
    mut env: Environment<Value>,
) -> Result<(Vec<Value>, Environment<Value>), EvalError> @{
    let mut values = Vec::with_capacity(exprs.len());
    for expr in exprs @{
        let (val, new_env) = eval(expr, env)?;
        values.push(val);
        env = new_env;
    @}
    Ok((values, env))
@}
@end example

@subsubheading 조건문 (Conditionals)

@code{Eval_if}는 주어진 환경에서 @code{if} 표현식의 술어 부분을 평가한다.
결과가 참이면, @code{eval_if}는 결과절을 평가하고, 그렇지 않으면 대안절을 평가한다.
환경이 평가를 통해 어떻게 스레딩되는지 주목하라:

@example
fn eval_if(
    predicate: &Expr,
    consequent: &Expr,
    alternative: &Expr,
    env: Environment<Value>,
) -> Result<(Value, Environment<Value>), EvalError> @{
    let (pred_value, env) = eval(predicate, env)?;
    if is_true(&pred_value) @{
        eval(consequent, env)
    @} else @{
        eval(alternative, env)
    @}
@}
@end example

@noindent
@code{eval_if}에서 @code{is_true}의 사용은 구현된 언어와 구현 언어 사이의 연결 문제를 강조한다.
@code{predicate}는 구현되는 언어에서 평가되므로 그 언어에서의 값을 산출한다.
인터프리터 술어 @code{is_true}는 그 값을 구현 언어의 @code{if}에 의해 테스트될 수 있는 값으로 변환한다: 진실의 메타순환적 표현은 기본 Rust의 표현과 같지 않을 수 있다.@footnote{이 경우, 구현되는 언어와 구현 언어는 동일하다. 여기서 @code{is_true}의 의미에 대한 사색은 약물 남용 없이 의식의 확장을 낳는다.}

@subsubheading 시퀀스 (Sequences)

@code{Eval_sequence}는 프로시저 본문의 표현식 시퀀스를 평가하기 위해 @code{apply}에 의해 사용되고, @code{begin} 표현식의 표현식 시퀀스를 평가하기 위해 @code{eval}에 의해 사용된다.
이것은 표현식의 시퀀스와 환경을 인자로 받아, 표현식을 나타나는 순서대로 평가한다.
각 평가는 새 환경을 반환할 수 있으며 이는 다음 단계로 전달된다:

@example
fn eval_sequence(
    exprs: &[Expr],
    mut env: Environment<Value>,
) -> Result<(Value, Environment<Value>), EvalError> @{
    if exprs.is_empty() @{
        return Ok((Value::Void, env));
    @}

    let mut result = Value::Void;
    for expr in exprs @{
        let (val, new_env) = eval(expr, env)?;
        result = val;
        env = new_env;
    @}
    Ok((result, env))
@}
@end example

@subsubheading 대입과 정의 (Assignments and definitions)

다음 프로시저는 변수의 정의를 처리한다.
이것은 할당될 값을 찾기 위해 @code{eval}을 호출하고 바인딩이 설치된 새 환경을 반환한다:

@example
fn eval_definition(
    var: String,
    value_expr: &Expr,
    env: Environment<Value>,
) -> Result<(Value, Environment<Value>), EvalError> @{
    let (value, env) = eval(value_expr, env)?;
    let new_env = env.define(var, value);
    Ok((Value::Void, new_env))
@}
@end example

@noindent
우리는 여기서 정의의 값으로 @code{Value::Void}를 반환하기로 선택했다.@footnote{우리가 정의와 @code{set!}을 소개할 때 말했듯이, 이 값들은 Scheme에서 구현 의존적이다---즉, 구현자가 어떤 값을 반환할지 선택할 수 있다.}
우리는 함수형 상태 스레딩 모델을 사용하고 있으므로, 여기서 전통적인 가변 @code{eval_assignment}를 제공하지 않는다; 대신, @code{eval_definition}(또는 유사한 @code{set!} 구현)에 의해 반환된 업데이트된 환경이 후속 평가에 사용될 것이다.

@quotation
@strong{@anchor{Exercise 4.1}연습문제 4.1:} @code{eval_list}의 우리 Rust 구현에서, 우리는 피연산자들의 평가를 통해 환경을 스레딩함으로써 왼쪽에서 오른쪽으로의 평가 순서를 명시적으로 선택했음에 주목하라.

만약 우리가 변경이 있는 환경 모델을 사용하고 있었다면(따라서 환경을 스레딩하지 않는다면), 우리는 @code{map}이나 유사한 구성을 사용하여 @code{eval_list}를 작성했을 수도 있다.
기본 언어의 인자 평가 순서와 관계없이 피연산자를 왼쪽에서 오른쪽으로 평가하는 @code{eval_list} 버전을 작성하라.
또한 피연산자를 오른쪽에서 왼쪽으로 평가하는 @code{eval_list} 버전을 작성하라.
@end quotation

@node	4.1.2, 4.1.3, 4.1.1, 4.1
@subsection 표현식 표현하기 (Representing Expressions)

평가자는 @ref{2.3.2}에서 논의된 기호 미분 프로그램을 상기시킨다.
두 프로그램 모두 기호 표현식에 대해 작동한다.
두 프로그램 모두에서, 복합 표현식에 대해 작동한 결과는 표현식의 조각들에 대해 재귀적으로 작동하고 표현식의 유형에 따라 달라지는 방식으로 결과를 결합함으로써 결정된다.
두 프로그램 모두에서 우리는 작동의 일반적인 규칙을 표현식이 표현되는 방식의 세부 사항으로부터 분리하기 위해 데이터 추상화를 사용했다.
미분 프로그램에서 이것은 동일한 미분 프로시저가 전위 형식, 중위 형식 또는 다른 형식의 대수 표현식을 다룰 수 있음을 의미했다.
평가자의 경우, 이것은 평가되는 언어의 구문이 오로지 표현식의 조각을 분류하고 추출하는 프로시저에 의해서만 결정된다는 것을 의미한다.

다음은 우리 언어 구문의 명세이다:

@itemize

@item
자체 평가 항목은 숫자, 문자열, 그리고 불리언이다:

@example
enum Expr @{
    Number(i64),
    String(String),
    Bool(bool),
    // ...
@}
@end example

@item
변수는 기호로 표현된다:

@example
enum Expr @{
    Symbol(String),
    // ...
@}
@end example

@item
인용(Quotations)은 @code{(quote ⟨@var{text_of_quotation}⟩)} 형식을 갖는다:

@example
enum Expr @{
    Quote(Box<Expr>),
    // ...
@}
@end example

@item
정의(Definitions)는 @code{let ⟨@var{var}⟩ = ⟨@var{value}⟩;} 형식을 갖는다 (@code{(define ⟨@var{var}⟩ ⟨@var{value}⟩)}에서 탈설탕(desugared)됨):
@example
enum Expr @{
    Define @{ name: String, value: Box<Expr> @},
    // ...
@}
@end example

@item
@code{Lambda} 표현식은 익명 함수 @code{|⟨@var{params}⟩| @{ ⟨@var{body}⟩ @}}를 나타낸다:

@example
enum Expr @{
    Lambda @{ params: Vec<String>, body: Vec<Expr> @},
    // ...
@}
@end example

@item
조건문(Conditionals)은 @code{if}로 시작하며 술어, 결과절, 그리고 대안절을 갖는다:

@example
enum Expr @{
    If @{
        predicate: Box<Expr>,
        consequent: Box<Expr>,
        alternative: Box<Expr>,
    @},
    // ...
@}
@end example

@item
@code{Begin}은 표현식 시퀀스를 단일 표현식으로 포장한다:

@example
enum Expr @{
    Begin(Vec<Expr>),
    // ...
@}
@end example

@item
프로시저 적용(procedure application)은 연산자와 피연산자로 구성된다:

@example
enum Expr @{
    Application @{
        operator: Box<Expr>,
        operands: Vec<Expr>,
    @},
@}
@end example

@end itemize

@subsubheading 파생된 표현식 (Derived expressions)

우리 언어의 일부 특수 형식은 직접 구현되는 대신 다른 특수 형식을 포함하는 표현식의 관점에서 정의될 수 있다.
한 가지 예는 @code{cond}인데, 이는 @code{if} 표현식의 중첩으로 구현될 수 있다.
Rust에서, 우리는 절(clauses)의 리스트를 포함하는 @code{Cond} 변형으로 이를 표현한다:

@example
enum Expr @{
    Cond(Vec<CondClause>),
    // ...
@}

struct CondClause @{
    predicate: Expr,
    actions: Vec<Expr>,
@}
@end example

프로시저 @code{cond_to_if}는 이 절들을 @code{if} 표현식의 체인으로 변환한다:

@example
fn cond_to_if(clauses: &[CondClause]) -> Result<Expr, EvalError> @{
    if clauses.is_empty() @{
        return Ok(Expr::Bool(false));
    @}
    let first = &clauses[0];
    let rest = &clauses[1..];
    if let Expr::Symbol(s) = &first.predicate && s == "else" @{
        return Ok(make_sequence(&first.actions));
    @}
    let consequent = make_sequence(&first.actions);
    let alternative = cond_to_if(rest)?;
    Ok(Expr::If @{
        predicate: Box::new(first.predicate.clone()),
        consequent: Box::new(consequent),
        alternative: Box::new(alternative),
    @})
@}
@end example
@code{cond}의 평가를 이런 방식으로 구현하면 평가 프로세스가 명시적으로 지정되어야 하는 특수 형식의 수를 줄이기 때문에 평가자를 단순화한다.

우리는 @code{cond} 표현식의 부분을 추출하는 구문 프로시저와 @code{cond} 표현식을 @code{if} 표현식으로 변환하는 프로시저 @code{cond_to_if}를 포함한다.
사례 분석은 @code{cond}로 시작하며 술어-행동 절의 리스트를 갖는다.
절은 그 술어가 기호 @code{else}이면 @code{else} 절이다.@footnote{모든 술어가 거짓이고 @code{else} 절이 없을 때 @code{cond} 표현식의 값은 Scheme에서 지정되지 않았다; 우리는 여기서 거짓이 되도록 선택했다.}

@example
// Rust에서 cond는 일반적으로 match 표현식으로 대체된다.
// 만약 인터프리터에서 cond를 if로 탈설탕해야 한다면:
fn cond_to_if(clauses: &[(Expr, Vec<Expr>)]) -> Expr @{
    clauses.iter().rev().fold(
        Expr::Bool(false),  // else 절 없으면 거짓 반환
        |acc, (pred, actions)| @{
            if matches!(pred, Expr::Symbol(s) if s == "else") @{
                sequence_to_exp(actions.clone())
            @} else @{
                make_if(pred.clone(), sequence_to_exp(actions.clone()), acc)
            @}
        @}
    )
@}
@end example

@noindent
우리가 구문 변환으로 구현하기로 선택한 표현식(@code{cond}와 같은)을 @newterm{파생된 표현식(derived expressions)}이라고 부른다.
@code{Let} 표현식도 파생된 표현식이다(@ref{Exercise 4.6} 참조).@footnote{실용적인 Lisp 시스템은 사용자가 새로운 파생된 표현식을 추가하고 평가자를 수정하지 않고도 구문 변환으로서 그 구현을 지정할 수 있는 메커니즘을 제공한다. 그러한 사용자 정의 변환을 @newterm{매크로(macro)}라고 부른다. 매크로를 정의하기 위한 초보적인 메커니즘을 추가하는 것은 쉽지만, 결과 언어는 미묘한 이름 충돌 문제를 갖는다. 이러한 어려움을 일으키지 않는 매크로 정의 메커니즘에 대한 많은 연구가 있었다. 예를 들어, @ref{Kohlbecker 1986}, @ref{Clinger and Rees 1991}, 그리고 @ref{Hanson 1991}을 보라.}

@quotation
@strong{@anchor{Exercise 4.2}연습문제 4.2:} Louis Reasoner는 프로시저 적용에 대한 절이 대입에 대한 절보다 먼저 나타나도록 @code{eval}의 @code{cond} 절을 재배열할 계획이다.
그는 이것이 인터프리터를 더 효율적으로 만들 것이라고 주장한다: 프로그램은 보통 대입, 정의 등보다 더 많은 적용을 포함하므로, 그의 수정된 @code{eval}은 표현식의 유형을 식별하기 전에 원래 @code{eval}보다 더 적은 절을 확인할 것이다.

@enumerate a

@item
Louis의 계획에 무엇이 잘못되었는가? (힌트: Louis의 평가자는 표현식 @code{let x = 3;}으로 무엇을 할 것인가?)

@item
Louis는 자신의 계획이 효과가 없어서 화가 났다. 그는 평가자가 다른 종류의 표현식을 확인하기 전에 프로시저 적용을 인식하게 만들기 위해 어떤 대가라도 치를 의향이 있다.
프로시저 적용이 @code{call}로 시작하도록 평가되는 언어의 구문을 변경하여 그를 도워라.
예를 들어, @code{(factorial 3)} 대신 우리는 이제 @code{(call factorial 3)}을 써야 할 것이고 @code{(+ 1 2)} 대신 @code{(call + 1 2)}를 써야 할 것이다.

@end enumerate
@end quotation

@quotation
@strong{@anchor{Exercise 4.3}연습문제 4.3:} 디스패치가 데이터 주도 스타일로 수행되도록 @code{eval}을 다시 작성하라.
이것을 @ref{Exercise 2.73}의 데이터 주도 미분 프로시저와 비교하라. (이 절에서 구현된 구문에 적합한 대로, 복합 표현식의 @code{car}를 표현식의 유형으로 사용할 수 있다.)
@end quotation

@quotation
@strong{@anchor{Exercise 4.4}연습문제 4.4:} @ref{Chapter 1}의 특수 형식 @code{and}와 @code{or}의 정의를 상기해 보자:

@itemize @bullet

@item
@code{and}: 표현식들은 왼쪽에서 오른쪽으로 평가된다.
어떤 표현식이 거짓으로 평가되면, 거짓이 반환된다; 남은 표현식들은 평가되지 않는다.
모든 표현식이 참 값으로 평가되면, 마지막 표현식의 값이 반환된다.
표현식이 없으면 참이 반환된다.

@item
@code{or}: 표현식들은 왼쪽에서 오른쪽으로 평가된다.
어떤 표현식이 참 값으로 평가되면, 그 값이 반환된다; 남은 표현식들은 평가되지 않는다.
모든 표현식이 거짓으로 평가되거나, 표현식이 없으면 거짓이 반환된다.

@end itemize

적절한 구문 프로시저와 평가 프로시저 @code{eval-and} 및 @code{eval-or}를 정의하여 @code{and}와 @code{or}를 평가자의 새로운 특수 형식으로 설치하라.
대안으로, @code{and}와 @code{or}를 파생된 표현식으로 구현하는 방법을 보여라.
@end quotation

@quotation
@strong{@anchor{Exercise 4.5}연습문제 4.5:} Scheme은 @code{cond} 절에 대한 추가 구문 @code{(⟨@var{test}⟩ => ⟨@var{recipient}⟩)}를 허용한다.
만약 @code{⟨}@var{test}@code{⟩}가 참 값으로 평가되면, @code{⟨}@var{recipient}@code{⟩}가 평가된다.
그 값은 하나의 인자를 받는 프로시저여야 한다; 이 프로시저는 @code{⟨}@var{test}@code{⟩}의 값에 대해 호출되며, 그 결과가 @code{cond} 표현식의 값으로 반환된다.
예를 들어

@example
match assoc("b", list(list("a", 1), list("b", 2))) @{
    Some(val) => cadr(val),
    None => false,
@}
@end example

@noindent
은 2를 반환한다. 이 확장된 구문을 지원하도록 @code{cond} 처리를 수정하라.
@end quotation

@quotation
@strong{@anchor{Exercise 4.6}연습문제 4.6:} @code{Let} 표현식은 파생된 표현식인데, 왜냐하면

@example
@{
    let @var{var1} = @var{exp1};
    // ...
    let @var{varn} = @var{expn};
    @var{body}
@}
@end example

@noindent
은 다음과 동등하기 때문이다

@example
// 즉시 실행 함수 표현식(IIFE):
(|@var{var1}, ..., @var{varn}| @{
    @var{body}
@})(@var{exp1}, ..., @var{expn})
@end example

@code{let} 표현식 평가를 위에 표시된 유형의 조합 평가로 축소하는 구문 변환 @code{let_to_combination}을 구현하고, @code{let} 표현식을 처리하기 위해 @code{eval}에 적절한 절을 추가하라.
@end quotation

@quotation
@strong{@anchor{Exercise 4.7}연습문제 4.7:} @code{Let*}는 @code{let}과 유사한데, @code{let*} 변수의 바인딩이 왼쪽에서 오른쪽으로 순차적으로 수행되고, 각 바인딩이 선행하는 모든 바인딩이 보이는 환경에서 만들어진다는 점이 다르다.
예를 들어

@example
// let*는 Rust에서 순차적인 let 바인딩이다:
@{
    let x = 3;
    let y = x + 2;      // x를 사용할 수 있다
    let z = x + y + 5;  // x와 y를 사용할 수 있다
    x * z               // => 39
@}
@end example

@noindent
은 39를 반환한다.
@code{let*} 표현식이 중첩된 @code{let} 표현식 집합으로 어떻게 다시 쓰일 수 있는지 설명하고, 이 변환을 수행하는 프로시저 @code{let*->nested-lets}를 작성하라.
우리가 이미 @code{let}을 구현했고(@ref{Exercise 4.6}) @code{let*}를 처리하도록 평가자를 확장하고 싶다면, @code{eval}에 다음과 같은 행동을 하는 절을 추가하는 것으로 충분한가

@example
eval(&let_star_to_nested_lets(exp), env)
@end example

@noindent
아니면 파생되지 않은 표현식의 관점에서 @code{let*}를 명시적으로 확장해야 하는가?
@end quotation

@quotation
@strong{@anchor{Exercise 4.8}연습문제 4.8:} ``이름 있는 @code{let}(Named @code{let})''은 다음과 같은 형식을 가진 @code{let}의 변형이다

@example
// Rust에서 이름 있는 let은 초기 값이 있는 루프이다:
loop @{
    // 바인딩은 가변 루프 변수가 된다
    // 본문은 continue를 통해 새 값으로 재귀적으로 호출할 수 있다
@}
@end example

@code{⟨}@var{bindings}@code{⟩}와 @code{⟨}@var{body}@code{⟩}는 일반 @code{let}과 같지만, @code{⟨}@var{var}@code{⟩}가 @code{⟨}@var{body}@code{⟩} 내에서 본문이 @code{⟨}@var{body}@code{⟩}이고 매개변수가 @code{⟨}@var{bindings}@code{⟩}의 변수인 프로시저에 바인딩된다는 점이 다르다.
따라서 @code{⟨}@var{var}@code{⟩}라는 이름의 프로시저를 호출하여 @code{⟨}@var{body}@code{⟩}를 반복적으로 실행할 수 있다.
예를 들어, 반복적 피보나치 프로시저(@ref{1.2.2})는 이름 있는 @code{let}을 사용하여 다음과 같이 다시 쓸 수 있다:

@example
fn fib(n: u64) -> u64 @{
    let (mut a, mut b, mut count) = (1, 0, n);
    loop @{
        if count == 0 @{
            return b;
        @}
        (a, b, count) = (a + b, a, count - 1);
    @}
@}
@end example

이름 있는 @code{let}도 지원하도록 @ref{Exercise 4.6}의 @code{let->combination}을 수정하라.
@end quotation

@quotation
@strong{@anchor{Exercise 4.9}연습문제 4.9:} 많은 언어는 @code{do}, @code{for}, @code{while}, @code{until}과 같은 다양한 반복 구성을 지원한다.
Scheme에서 반복 프로세스는 일반 프로시저 호출의 관점에서 표현될 수 있으므로, 특수 반복 구성은 계산 능력에서 본질적인 이득을 제공하지 않는다.
반면에, 그러한 구성은 종종 편리하다.
일부 반복 구성을 설계하고, 그 사용 예제를 제시하고, 파생된 표현식으로 구현하는 방법을 보여라.
@end quotation

@quotation
@strong{@anchor{Exercise 4.10}연습문제 4.10:} 데이터 추상화를 사용함으로써, 우리는 평가될 언어의 특정 구문에 독립적인 @code{eval} 프로시저를 작성할 수 있었다.
이를 설명하기 위해, @code{eval}이나 @code{apply}를 변경하지 않고 이 절의 프로시저를 수정하여 Scheme을 위한 새로운 구문을 설계하고 구현하라.
@end quotation

@node	4.1.3, 4.1.4, 4.1.2, 4.1
@subsection 평가자 데이터 구조 (Evaluator Data Structures)

언어의 외부 구문을 정의하는 것 외에도, 평가자 구현은 평가자가 내부적으로 조작하는 데이터 구조를 정의해야 한다. 예를 들어 프로시저와 환경의 표현, 그리고 참과 거짓의 표현 등이다.

@subsubheading 술어의 테스트 (Testing of predicates)

조건문의 경우, 우리는 불리언 상수 @code{false}를 제외한 모든 값을 참으로 받아들인다.

@example
fn is_true(value: &Value) -> bool @{
    !matches!(value, Value::Bool(false))
@}
@end example

@subsubheading 프로시저 표현하기 (Representing procedures)

원시(primitives)를 처리하기 위해, 우리는 다음 프로시저들을 사용할 수 있다고 가정한다:

@itemize @bullet

@item
@code{apply_primitive_procedure(⟨@var{proc}⟩, ⟨@var{args}⟩)}

주어진 원시 프로시저를 리스트 @code{⟨}@var{args}@code{⟩}에 있는 인자 값들에 적용하고 적용 결과를 반환한다.

@item
@code{is_primitive_procedure(⟨@var{proc}⟩)}

@code{⟨}@var{proc}@code{⟩}이 원시 프로시저인지 테스트한다.

@end itemize

@noindent
원시를 처리하는 이러한 메커니즘은 @ref{4.1.4}에서 더 자세히 설명된다.

복합 프로시저는 매개변수, 프로시저 본문, 그리고 환경으로부터 구성된다. Rust에서, 우리는 이것들을 @code{Value} 열거형의 변형으로 표현한다:

@example
#[derive(Clone)]
pub enum Value @{
    Number(i64),
    Bool(bool),
    String(String),
    Symbol(String),
    Closure @{
        params: Vec<String>,
        body: Vec<Expr>,
        env: Environment<Value>,
        self_name: Option<String>,
    @},
    Primitive(String, fn(&[Value]) -> Result<Value, EvalError>),
    Pair(Box<Value>, Box<Value>),
    Nil,
    Void,
@}
@end example

@subsubheading 환경에 대한 연산 (Operations on Environments)

평가자는 환경을 조작하기 위한 연산이 필요하다.
@ref{3.2}에서 설명했듯이, 환경은 프레임의 시퀀스이며, 각 프레임은 변수와 해당 값을 연관시키는 바인딩 테이블이다.
우리는 효율성을 위해 구조적 공유(structural sharing)를 사용하는 영속적(persistent) @code{Environment} 구조체를 사용한다:

@example
use im::HashMap as ImHashMap;

#[derive(Clone)]
pub struct Environment<V> @{
    bindings: ImHashMap<String, V>,
    parent: Option<Box<Environment<V>>>,
@}

impl<V: Clone> Environment<V> @{
    pub fn new() -> Self @{
        Self @{ bindings: ImHashMap::new(), parent: None @}
    @}

    pub fn lookup(&self, name: &str) -> Option<&V> @{
        self.bindings.get(name)
            .or_else(|| self.parent.as_ref().and_then(|p| p.lookup(name)))
    @}

    pub fn define(&self, name: String, value: V) -> Self @{
        Self @{
            bindings: self.bindings.update(name, value),
            parent: self.parent.clone(),
        @}
    @}

    pub fn extend(&self, bindings: impl IntoIterator<Item = (String, V)>) -> Self @{
        Self @{
            bindings: bindings.into_iter().collect(),
            parent: Some(Box::new(self.clone())),
        @}
    @}
@}
@end example

@noindent
여기서 설명된 방법은 구조적 공유를 통해 @math{O(\log n)} 연산을 제공하기 위해 @code{im::HashMap}을 사용한다.
이것은 환경을 프레임의 리스트로 표현하는 전통적인 Lisp 표현을 대체하는데, 전통적인 방식은 선형 시간 조회를 요구할 것이다.
Rust에서, 이 함수형 접근 방식은 클로저가 참조 카운팅이나 내부 가변성 없이 자신의 환경의 스냅샷을 소유할 수 있게 해준다.

@code{im::HashMap}의 사용은 우리가 환경을 ``정의''하거나 ``확장''할 때 기존 데이터를 변경하는 것이 아니라 이전 버전과 구조의 대부분을 공유하는 새 버전을 생성하도록 보장한다.
이것은 Rust와 같이 엄격한 소유권 규칙을 가진 언어에서 환경 모델을 올바르게 구현하는 데 중요하다.

@quotation
@strong{@anchor{Exercise 4.11}연습문제 4.11:} 우리의 @code{Environment} 구조체는 각 프레임에 대해 @code{HashMap}을 사용한다.
이것을 프레임을 리스트의 쌍으로 표현하는 원래 Lisp 표현과 비교하라.
특히 (프로시저 호출에서처럼) 많은 작은 환경을 생성할 때 성능과 메모리 사용 측면에서 해시 맵을 사용하는 것의 장단점은 무엇인가?
@end quotation

@quotation
@strong{@anchor{Exercise 4.12}연습문제 4.12:} 프로시저 @code{define}과 @code{lookup}은 환경 구조를 순회하기 위한 더 추상적인 프로시저의 관점에서 표현될 수 있다.
우리의 Rust 구현에서, 우리는 @code{parent} 링크와 @code{HashMap} 메서드에 의존한다.
순회를 명시적으로 만드는 함수형 폴드(fold)나 재귀적 도우미를 사용하여 @code{lookup}을 재정의하라.
@end quotation

@quotation
@strong{@anchor{Exercise 4.13}연습문제 4.13:} Scheme은 정의를 통해 변수에 대한 새 바인딩을 생성할 수 있게 해주지만, 바인딩을 제거하는 방법은 제공하지 않는다.
현재 프레임에서 주어진 기호의 바인딩이 제거된 새 환경을 반환하는 특수 형식 @code{make_unbound}를 평가자를 위해 구현하라. (힌트: @code{HashMap::without}을 사용하라).
@end quotation

@node   4.1.4, 4.1.5, 4.1.3, 4.1
@subsection 프로그램으로서의 평가자 실행 (Running the Evaluator as a Program)

평가자가 주어지면, 우리는 표현식이 평가되는 과정에 대한 (Rust로 표현된) 설명을 손에 쥐게 된다.
평가자를 프로그램으로 표현하는 것의 한 가지 이점은 그 프로그램을 실행할 수 있다는 것이다.
이것은 우리에게 Rust 내에서 실행되는, 언어 자체가 표현식을 어떻게 평가하는지에 대한 작동 모델을 제공한다.
이것은 우리가 이 장의 나중에 할 것처럼 평가 규칙을 실험하기 위한 프레임워크 역할을 할 수 있다.

우리의 평가자 프로그램은 표현식을 궁극적으로 원시 프로시저의 적용으로 축소한다.
따라서 평가자를 실행하기 위해 필요한 것은 원시 프로시저의 적용을 모델링하기 위해 기본 Rust 시스템을 호출하는 메커니즘을 만드는 것뿐이다.

각 원시 프로시저 이름에 대한 바인딩이 있어야 하는데, 그래야 @code{eval}이 원시의 적용에 대한 연산자를 평가할 때 @code{apply}에 전달할 객체를 찾을 수 있기 때문이다.
따라서 우리는 평가할 표현식에 나타날 수 있는 원시 프로시저의 이름과 고유한 객체를 연관시키는 전역 환경을 설정한다.
전역 환경은 또한 기호 @code{true}와 @code{false}에 대한 바인딩을 포함한다.

@example
pub fn setup_environment() -> Environment<Value> @{
    let env = Environment::new();

    // 산술 원시
    let env = env.define("+".to_string(), 
                         Value::Primitive("+".into(), prim_add));
    let env = env.define("-".to_string(), 
                         Value::Primitive("-".into(), prim_sub));
    let env = env.define("*".to_string(), 
                         Value::Primitive("*".into(), prim_mul));
    let env = env.define("/".to_string(), 
                         Value::Primitive("/".into(), prim_div));

    // 불리언 상수
    let env = env.define("true".to_string(), Value::Bool(true));
    let env = env.define("false".to_string(), Value::Bool(false));

    env
@}
@end example

@noindent
@code{apply}가 원시 프로시저 객체를 식별하고 적용할 수 있는 한, 우리가 그것들을 어떻게 표현하는지는 중요하지 않다.
우리의 @code{Value} 열거형에서, 우리는 원시 프로시저를 이름과 함께 함수 포인터로 표현한다:

@example
// Value::Primitive(String, fn(&[Value]) -> Result<Value, EvalError>)
@end example

@noindent
메타순환 평가자를 실행할 때의 편의를 위해, 우리는 읽기-평가-출력 루프(read-eval-print loop)를 모델링하는 @newterm{드라이버 루프(driver loop)}를 제공한다.
이것은 @newterm{프롬프트(prompt)}를 출력하고, 입력 표현식을 읽고, 전역 환경에서 그것을 평가하고, 결과를 출력한다.
@code{driver_loop}가 정의를 허용하기 위해 각 반복을 통해 환경을 스레딩하는 방식에 주목하라:

@example
const INPUT_PROMPT: &str = ";;; Eval input:";
const OUTPUT_PROMPT: &str = ";;; Eval value:";

fn driver_loop(mut env: Environment<Value>) @{
    loop @{
        println!("\n@{@}", INPUT_PROMPT);
        let input = read_and_parse(); // 가상의 파서
        match eval(&input, env) @{
            Ok((output, new_env)) => @{
                env = new_env;
                println!("@{@}", OUTPUT_PROMPT);
                user_print(&output);
            @}
            Err(e) => eprintln!("Error: @{:?@}", e),
        @}
    @}
@}
@end example

@noindent
우리는 복합 프로시저의 전체 환경 부분을 출력하는 것을 피하기 위해 특수 출력 프로시저 @code{user_print}를 사용한다:

@example
fn user_print(object: &Value) @{
    match object @{
        Value::Closure @{ params, .. @} => @{
            println!("#<procedure (@{@})>", params.join(" "));
        @}
        other => println!("@{@}", other),
    @}
@}
@end example

@noindent
이제 평가자를 실행하기 위해 해야 할 일은 전역 환경을 초기화하고 드라이버 루프를 시작하는 것뿐이다.
다음은 샘플 상호 작용이다:

@example
fn main() @{
    let env = setup_environment();
    driver_loop(env);
@}

// ;;; Eval input:
// fn append(x, y) @{ if x.is_null() @{ y @} else @{ cons(x.car(), append(x.cdr(), y)) @} @}
// ;;; Eval value:
// #<procedure (x y)>

// ;;; Eval input:
// append(list(1, 2, 3), list(4, 5, 6))
// ;;; Eval value:
// (1 2 3 4 5 6)
@end example

@quotation
@strong{@anchor{Exercise 4.14}연습문제 4.14:} Eva Lu Ator와 Louis Reasoner는 각자 메타순환 평가자를 실험하고 있다.
Eva는 @code{map}의 정의를 입력하고 그것을 사용하는 몇 가지 테스트 프로그램을 실행한다. 잘 작동한다.
반면 Louis는 @code{map}의 시스템 버전을 메타순환 평가자를 위한 원시로 설치했다.
그가 그것을 시도했을 때, 일이 끔찍하게 잘못되었다.
Eva의 @code{map}은 작동하는데 Louis의 @code{map}은 실패하는 이유를 설명하라.
@end quotation

@node	4.1.5, 4.1.6, 4.1.4, 4.1
@subsection Data as Programs

In thinking about a Lisp program that evaluates Lisp expressions, an analogy
might be helpful.  One operational view of the meaning of a program is that a
program is a description of an abstract (perhaps infinitely large) machine.
For example, consider the familiar program to compute factorials:

@example
fn factorial(n: i64) -> i64 @{
    if n == 1 @{
        1
    @} else @{
        factorial(n - 1) * n
    @}
@}
@end example

@noindent
We may regard this program as the description of a machine containing parts
that decrement, multiply, and test for equality, together with a two-position
switch and another factorial machine. (The factorial machine is infinite
because it contains another factorial machine within it.)  @ref{Figure 4.2} is
a flow diagram for the factorial machine, showing how the parts are wired
together.

@float
@anchor{Figure 4.2}
@ifinfo
@strong{Figure 4.2:} The factorial program, viewed as an abstract machine.

@example
    +-----------------------------------+
    | factorial                   |1    |
    |              |1             V     |
    |              |           +-----+  |
    |              V           | #   |  |
    |           +-----+        |     |  |
6 --------*-----|  =  |------->|   #-+-----> 720
    |     |     +-----+        |  /  |  |
    |     |                    | #   |  |
    |     |                    +-----+  |
    |     |                       ^     |
    |     |                       |     |
    |     |                    +--+--+  |
    |     *------------------->|  *  |  |
    |     |                    +-----+  |
    |     V                       ^     |
    |  +-----+    +-----------+   |     |
    |  |  -  +--->| factorial +---+     |
    |  +-----+    +-----------+         |
    |     ^                             |
    |     |1                            |
    +-----------------------------------+
@end example
@end ifinfo
@iftex
@image{fig/chap4/Fig4.2a,143mm,,,.std.svg}
@caption{@strong{Figure 4.2:} The factorial program, viewed as an abstract machine.}
@end iftex
@end float

In a similar way, we can regard the evaluator as a very special machine that
takes as input a description of a machine.  Given this input, the evaluator
configures itself to emulate the machine described.  For example, if we feed
our evaluator the definition of @code{factorial}, as shown in @ref{Figure 4.3},
the evaluator will be able to compute factorials.

@float
@anchor{Figure 4.3}
@ifinfo
@strong{Figure 4.3:} The evaluator emulating a factorial machine.

@example
                   +--------+
            6 ---->|  eval  |----> 720
                   +--------+
                       /
             . . .    /  . . .
       . . .       ../. .      .
     .                           ..
    .   fn factorial(n: i64) -> i64 @{      . . .
   .      if n == 1 @{                   . .
    .         1                            .
    .      @} else @{ factorial(n - 1) * n @}   .
      . .                       . .        .
          . .  . .      . . . .     . . . .
                   . ..
@end example
@end ifinfo
@iftex
@image{fig/chap4/Fig4.3,117mm,,,.std.svg}
@caption{@strong{Figure 4.3:} The evaluator emulating a factorial machine.}
@end iftex
@end float

From this perspective, our evaluator is seen to be a @newterm{universal machine}.  
It mimics other machines when these are described as Rust
programs.@footnote{The fact that the machines are described in Rust is
inessential.  If we give our evaluator a Rust program that behaves as an
evaluator for some other language, say C, the Rust evaluator will emulate the C
evaluator, which in turn can emulate any machine described as a C program.
Similarly, writing a Rust evaluator in C produces a C program that can execute
any Rust program.  The deep idea here is that any evaluator can emulate any
other.  Thus, the notion of ``what can in principle be computed'' (ignoring
practicalities of time and memory required) is independent of the language or
the computer, and instead reflects an underlying notion of
@newterm{computability}.  This was first demonstrated in a clear way by Alan
M. Turing (1912-1954), whose 1936 paper laid the foundations for theoretical
computer science.  In the paper, Turing presented a simple computational
model---now known as a @newterm{Turing machine}---and argued that any
``effective process'' can be formulated as a program for such a machine.  (This
argument is known as the @newterm{Church-Turing thesis}.)  Turing then
implemented a universal machine, i.e., a Turing machine that behaves as an
evaluator for Turing-machine programs.  He used this framework to demonstrate
that there are well-posed problems that cannot be computed by Turing machines
(see @ref{Exercise 4.15}), and so by implication cannot be formulated as
``effective processes.''  Turing went on to make fundamental contributions to
practical computer science as well.  For example, he invented the idea of
structuring programs using general-purpose subroutines.  See @ref{Hodges 1983} for a
biography of Turing.} This is striking. Try to imagine an analogous evaluator
for electrical circuits.  This would be a circuit that takes as input a signal
encoding the plans for some other circuit, such as a filter.  Given this input,
the circuit evaluator would then behave like a filter with the same
description.  Such a universal electrical circuit is almost unimaginably
complex.  It is remarkable that the program evaluator is a rather simple
program.@footnote{Some people find it counterintuitive that an evaluator, which
is implemented by a relatively simple procedure, can emulate programs that are
more complex than the evaluator itself.  The existence of a universal evaluator
machine is a deep and wonderful property of computation.  @newterm{Recursion theory}, 
a branch of mathematical logic, is concerned with logical limits of
computation.  Douglas Hofstadter's beautiful book @cite{G@"odel, Escher, Bach}
explores some of these ideas (@ref{Hofstadter 1979}).}

@noindent
Another striking aspect of the evaluator is that it acts as a bridge between
the data objects that are manipulated by our programming language and the
programming language itself.  Imagine that the evaluator program (implemented
in Rust) is running, and that a user is typing expressions to the evaluator and
observing the results.  From the perspective of the user, an input expression
such as @code{x * x} is an expression in the programming language, which the
evaluator should execute.  From the perspective of the evaluator, however, the
expression is simply a data structure (in our case, an @code{Application}
variant of the @code{Expr} enum) that is to be manipulated according to a
well-defined set of rules.

That the user's programs are the evaluator's data need not be a source of
confusion.  In fact, it is sometimes convenient to ignore this distinction, and
to give the user the ability to explicitly evaluate a data object as an
expression, by making @code{eval} available for use in programs.  Many
languages provide a primitive @code{eval} procedure that takes as arguments an
expression and an environment and evaluates the expression relative to the
environment.@footnote{Warning: This @code{eval} primitive is not identical to
the @code{eval} procedure we implemented in @ref{4.1.1}, because it
uses @emph{actual} language environments rather than the sample environment
structures we built in @ref{4.1.3}.  Similarly, the @code{apply} primitive
we saw earlier is not identical to the metacircular @code{apply}, because it
uses actual Rust procedures rather than the procedure objects we constructed
in @ref{4.1.3} and @ref{4.1.4}.} Thus,

@example
// In Rust, eval takes an expression and environment reference
let expr = Expr::Application @{
    operator: Box::new(Expr::Symbol("*".into())),
    operands: vec![Expr::Number(5), Expr::Number(5)],
@};
let result = eval(&expr, &global_env)?;
// => Value::Number(25)
@end example

@noindent
and

@example
// Building the expression programmatically
let op = Expr::Symbol("*".into());
let args = vec![Expr::Number(5), Expr::Number(5)];
let expr = Expr::Application @{
    operator: Box::new(op),
    operands: args,
@};
eval(&expr, &global_env)?
// => Value::Number(25)
@end example

@noindent
will both return 25.@footnote{The @abbr{MIT} implementation of Scheme
includes @code{eval}, as well as a symbol @code{user_initial_environment} that
is bound to the initial environment in which the user's input expressions are
evaluated.}

@quotation
@strong{@anchor{Exercise 4.15}Exercise 4.15:} Given a one-argument procedure
@code{p} and an object @code{a}, @code{p} is said to ``halt'' on @code{a} if
evaluating the expression @code{(p a)} returns a value (as opposed to
terminating with an error message or running forever).  Show that it is
impossible to write a procedure @code{halts?} that correctly determines whether
@code{p} halts on @code{a} for any procedure @code{p} and object @code{a}.  Use
the following reasoning: If you had such a procedure @code{halts?}, you could
implement the following program:

@example
fn run_forever() -> ! @{
    loop @{@}  // Infinite loop, never returns
@}

fn try_halting<F>(p: F) -> &'static str
where
    F: Fn(&F) -> bool,
@{
    if halts(&p, &p) @{
        run_forever()  // If p halts on p, loop forever
    @} else @{
        "halted"       // If p doesn't halt, return
    @}
@}
@end example

Now consider evaluating the expression @code{(try try)} and show that any
possible outcome (either halting or running forever) violates the intended
behavior of @code{halts?}.@footnote{Although we stipulated that @code{halts?}
is given a procedure object, notice that this reasoning still applies even if
@code{halts?} can gain access to the procedure's text and its environment.
This is Turing's celebrated @newterm{Halting Theorem}, which gave the first
clear example of a @newterm{non-computable} problem, i.e., a well-posed task
that cannot be carried out as a computational procedure.}
@end quotation

@node	4.1.6, 4.1.7, 4.1.5, 4.1
@subsection Internal Definitions

Our environment model of evaluation and our metacircular evaluator execute
definitions in sequence, extending the environment frame one definition at a
time.  This is particularly convenient for interactive program development, in
which the programmer needs to freely mix the application of procedures with the
definition of new procedures.  However, if we think carefully about the
internal definitions used to implement block structure (introduced in 
@ref{1.1.8}), we will find that name-by-name extension of the environment may
not be the best way to define local variables.

Consider a procedure with internal definitions, such as

@example
fn f(x: i64) -> /* result */ @{
    // Rust allows mutually recursive inner functions
    fn is_even(n: i64) -> bool @{
        if n == 0 @{
            true
        @} else @{
            is_odd(n - 1)
        @}
    @}
    fn is_odd(n: i64) -> bool @{
        if n == 0 @{
            false
        @} else @{
            is_even(n - 1)
        @}
    @}
    // @r{rest of body of @code{f}}
@}
@end example

@noindent
Our intention here is that the name @code{is_odd} in the body of the procedure
@code{is_even} should refer to the procedure @code{is_odd} that is defined after
@code{is_even}.  The scope of the name @code{is_odd} is the entire body of
@code{f}, not just the portion of the body of @code{f} starting at the point
where the definition for @code{is_odd} occurs.  Indeed, when we consider that
@code{is_odd} is itself defined in terms of @code{is_even}---so that @code{is_even}
and @code{is_odd} are mutually recursive procedures---we see that the only
satisfactory interpretation of the two definitions is to regard them as if
the names @code{is_even} and @code{is_odd} were being added to the environment
simultaneously.  More generally, in block structure, the scope of a local name
is the entire procedure body in which the definition is evaluated.

As it happens, our interpreter will evaluate calls to @code{f} correctly, but
for an ``accidental'' reason: Since the definitions of the internal procedures
come first, no calls to these procedures will be evaluated until all of them
have been defined.  Hence, @code{is_odd}  will have been defined by the time
@code{is_even} is executed.  In fact, our sequential evaluation mechanism will
give the same result as a mechanism that directly implements simultaneous
definition for any procedure in which the internal definitions come first in a
body and evaluation of the value expressions for the defined variables doesn't
actually use any of the defined variables.  (For an example of a procedure that
doesn't obey these restrictions, so that sequential definition isn't equivalent
to simultaneous definition, see @ref{Exercise 4.19}.)@footnote{Wanting programs
to not depend on this evaluation mechanism is the reason for the ``management
is not responsible'' remark in @ref{Footnote 28} of @ref{Chapter 1}.  By
insisting that internal definitions come first and do not use each other while
the definitions are being evaluated, the @abbr{IEEE} standard for Scheme
leaves implementors some choice in the mechanism used to evaluate these
definitions.  The choice of one evaluation rule rather than another here may
seem like a small issue, affecting only the interpretation of ``badly formed''
programs.  However, we will see in @ref{5.5.6} that moving to a model
of simultaneous scoping for internal definitions avoids some nasty difficulties
that would otherwise arise in implementing a compiler.}

There is, however, a simple way to treat definitions so that internally defined
names have truly simultaneous scope---just create all local variables that will
be in the current environment before evaluating any of the value expressions.
One way to do this is by a syntax transformation on @code{lambda} expressions.
Before evaluating the body of a @code{lambda} expression, we ``scan out'' and
eliminate all the internal definitions in the body.  The internally defined
variables will be created with a @code{let} and then set to their values by
assignment.  For example, the procedure

@example
|@var{vars}| @{
    let u = @var{e1};
    let v = @var{e2};
    @var{e3}
@}
@end example

@noindent
would be transformed into

@example
|@var{vars}| @{
    // Conceptual transformation to support simultaneous scope:
    let u = "*unassigned*";
    let v = "*unassigned*";
    u = @var{e1};
    v = @var{e2};
    @var{e3}
@}
@end example

@noindent
where @code{"*unassigned*"} is a special value that causes looking up a variable
to signal an error if an attempt is made to use the value of the
not-yet-assigned variable. In our functional evaluator, this assignment
would be implemented by returning updated environments during the evaluation
of the body.

An alternative strategy for scanning out internal definitions is shown in
@ref{Exercise 4.18}.  Unlike the transformation shown above, this enforces the
restriction that the defined variables' values can be evaluated without using
any of the variables' values.@footnote{The @abbr{IEEE} standard for Scheme
allows for different implementation strategies by specifying that it is up to
the programmer to obey this restriction, not up to the implementation to
enforce it.}

@quotation
@strong{@anchor{Exercise 4.16}Exercise 4.16:} In this exercise we implement the
method just described for interpreting internal definitions.  We assume that
the evaluator supports @code{let} (see @ref{Exercise 4.6}).

@enumerate a

@item
Change @code{lookup_variable_value} (@ref{4.1.3}) to signal an error if
the value it finds is the symbol @code{*unassigned*}.

@item
Write a procedure @code{scan_out_defines} that takes a procedure body and
returns an equivalent one that has no internal definitions, by making the
transformation described above.

@item
Install @code{scan_out_defines} in the interpreter, either in
@code{make_procedure} or in @code{procedure_body} (see @ref{4.1.3}).
Which place is better?  Why?

@end enumerate
@end quotation

@quotation
@strong{@anchor{Exercise 4.17}Exercise 4.17:} Draw diagrams of the environment
in effect when evaluating the expression @code{⟨}@var{e3}@code{⟩} in the procedure in the
text, comparing how this will be structured when definitions are interpreted
sequentially with how it will be structured if definitions are scanned out as
described.  Why is there an extra frame in the transformed program?  Explain
why this difference in environment structure can never make a difference in the
behavior of a correct program.  Design a way to make the interpreter implement
the ``simultaneous'' scope rule for internal definitions without constructing
the extra frame.
@end quotation

@quotation
@strong{@anchor{Exercise 4.18}Exercise 4.18:} Consider an alternative strategy
for scanning out definitions that translates the example in the text to

@example
// Alternative transformation with temporary bindings:
|@var{vars}| @{
    let u;
    let v;
    @{
        // Evaluate expressions before any assignment
        let a = @var{e1};  // Neither u nor v visible here
        let b = @var{e2};  // Neither u nor v visible here
        u = a;
        v = b;
    @}
    @var{e3}
@}
@end example

Here @code{a} and @code{b} are meant to represent new variable names, created
by the interpreter, that do not appear in the user's program.  Consider the
@code{solve} procedure from @ref{3.5.4}:

@example
fn solve<F>(f: F, y0: f64, dt: f64) -> impl Iterator<Item = f64>
where
    F: Fn(f64) -> f64,
@{
    // In Rust, we use std::iter::successors for self-referential iteration
    std::iter::successors(Some(y0), move |&y| @{
        Some(y + f(y) * dt)
    @})
@}
@end example

Will this procedure work if internal definitions are scanned out as shown in
this exercise?  What if they are scanned out as shown in the text?  Explain.
@end quotation

@quotation
@strong{@anchor{Exercise 4.19}Exercise 4.19:} Ben Bitdiddle, Alyssa P. Hacker,
and Eva Lu Ator are arguing about the desired result of evaluating the
expression

@example
@{
    let a = 1;
    fn f(x: i64) -> i64 @{
        // In Rust, inner 'a' shadows outer 'a'
        // Order of let bindings matters
        let b = a + x;  // Which 'a' does this refer to?
        let a = 5;      // This 'a' shadows outer 'a'
        a + b
    @}
    f(10)
@}
// Rust's shadowing rules: b uses outer a (1), result = 5 + 11 = 16
@end example

Ben asserts that the result should be obtained using the sequential rule for
definition: @code{b} is defined to be 11, then @code{a} is defined to be 5,
so the result is 16.  Alyssa objects that mutual recursion requires the
simultaneous scope rule for internal procedure definitions, and that it is
unreasonable to treat procedure names differently from other names.  Thus, she
argues for the mechanism implemented in @ref{Exercise 4.16}.  This would lead
to @code{a} being unassigned at the time that the value for @code{b} is to be
computed.  Hence, in Alyssa's view the procedure should produce an error.  Eva
has a third opinion.  She says that if the definitions of @code{a} and @code{b}
are truly meant to be simultaneous, then the value 5 for @code{a} should be
used in evaluating @code{b}.  Hence, in Eva's view @code{a} should be 5,
@code{b} should be 15, and the result should be 20.  Which (if any) of these
viewpoints do you support?  Can you devise a way to implement internal
definitions so that they behave as Eva prefers?@footnote{The @abbr{MIT}
implementors of Scheme support Alyssa on the following grounds: Eva is in
principle correct---the definitions should be regarded as simultaneous.  But
it seems difficult to implement a general, efficient mechanism that does what
Eva requires.  In the absence of such a mechanism, it is better to generate an
error in the difficult cases of simultaneous definitions (Alyssa's notion) than
to produce an incorrect answer (as Ben would have it).}
@end quotation

@quotation
@strong{@anchor{Exercise 4.20}Exercise 4.20:} Because internal definitions look
sequential but are actually simultaneous, some people prefer to avoid them
entirely, and use the special form @code{letrec} instead.  @code{Letrec} looks
like @code{let}, so it is not surprising that the variables it binds are bound
simultaneously and have the same scope as each other.  The sample procedure
@code{f} above can be written without internal definitions, but with exactly
the same meaning, as

@example
fn f(x: i64) -> /* result */ @{
    // Rust's inner functions are naturally mutually recursive
    fn is_even(n: i64) -> bool @{
        if n == 0 @{
            true
        @} else @{
            is_odd(n - 1)
        @}
    @}
    fn is_odd(n: i64) -> bool @{
        if n == 0 @{
            false
        @} else @{
            is_even(n - 1)
        @}
    @}
    // @r{rest of body of @code{f}}
@}
@end example

@code{Letrec} expressions, which have the form

@example
// Rust equivalent: inner functions with mutual recursion
fn @var{var_1}(@dots{}) -> T @{ @var{exp_1} @}
@dots{}
fn @var{var_n}(@dots{}) -> T @{ @var{exp_n} @}
@var{body}
@end example

@noindent
are a variation on @code{let} in which the expressions
@math{{⟨\kern0.1em exp_k⟩}} that provide the initial values for the
variables @math{{⟨\kern0.06em var_k⟩}} are evaluated in an environment
that includes all the @code{letrec} bindings.  This permits recursion in the
bindings, such as the mutual recursion of @code{is_even} and @code{is_odd} in the
example above, or the evaluation of 10 factorial with

@example
@{
    // Recursive local function
    fn fact(n: i64) -> i64 @{
        if n == 1 @{
            1
        @} else @{
            n * fact(n - 1)
        @}
    @}
    fact(10)
@}
// => 3628800
@end example

@enumerate a

@item
Implement @code{letrec} as a derived expression, by transforming a
@code{letrec} expression into a @code{let} expression as shown in the text
above or in @ref{Exercise 4.18}.  That is, the @code{letrec} variables should
be created with a @code{let} and then be assigned their values with
@code{set!}.

@item
Louis Reasoner is confused by all this fuss about internal definitions.  The
way he sees it, if you don't like to use definition inside a procedure, you
can just use @code{let}.  Illustrate what is loose about his reasoning by
drawing an environment diagram that shows the environment in which the
@code{⟨}@var{rest of body of @code{f}}@code{⟩} is evaluated during evaluation of the
expression @code{f(5)}, with @code{f} defined as in this exercise.  Draw an
environment diagram for the same evaluation, but with @code{let} in place of
@code{letrec} in the definition of @code{f}.

@end enumerate
@end quotation

@quotation
@strong{@anchor{Exercise 4.21}Exercise 4.21:} Amazingly, Louis's intuition in
@ref{Exercise 4.20} is correct.  It is indeed possible to specify recursive
procedures without using @code{letrec} (or even definition), although the
method for accomplishing this is much more subtle than Louis imagined.  The
following expression computes 10 factorial by applying a recursive factorial
procedure:@footnote{This example illustrates a programming trick for
formulating recursive procedures without using definition.  The most general
trick of this sort is the @math{Y} @newterm{operator}, which can be used to give a
``pure λ-calculus'' implementation of recursion.  (See @ref{Stoy 1977} for
details on the λ-calculus, and @ref{Gabriel 1988} for an exposition of the
@math{Y} operator in Scheme.)}

@example
// Y combinator style: passing the function to itself
(|n: i64| @{
    // fact takes itself as first argument
    let fact = |ft: &dyn Fn(&dyn Fn(&dyn Fn(&_, i64) -> i64, i64) -> i64, i64) -> i64,
                k: i64| -> i64 @{
        if k == 1 @{
            1
        @} else @{
            k * ft(ft, k - 1)
        @}
    @};
    // Simpler approach using a recursive closure via Cell
    fn factorial(n: i64) -> i64 @{
        if n == 1 @{ 1 @} else @{ n * factorial(n - 1) @}
    @}
    factorial(n)
@})(10)
// => 3628800
@end example

@enumerate a

@item
Check (by evaluating the expression) that this really does compute factorials.
Devise an analogous expression for computing Fibonacci numbers.

@item
Consider the following procedure, which includes mutually recursive internal
definitions:

@example
fn f(x: i64) -> bool @{
    fn is_even(n: i64) -> bool @{
        if n == 0 @{
            true
        @} else @{
            is_odd(n - 1)
        @}
    @}
    fn is_odd(n: i64) -> bool @{
        if n == 0 @{
            false
        @} else @{
            is_even(n - 1)
        @}
    @}
    is_even(x)
@}
@end example

Fill in the missing expressions to complete an alternative definition of
@code{f}, which uses neither internal definitions nor @code{letrec}:

@example
fn f(x: i64) -> bool @{
    // Pass functions to themselves for recursion
    type EvenOdd = fn(fn(i64) -> bool, fn(i64) -> bool, i64) -> bool;

    let is_even: EvenOdd = |ev, od, n| @{
        if n == 0 @{ true @} else @{ od(ev, od, n - 1) @}
    @};
    let is_odd: EvenOdd = |ev, od, n| @{
        if n == 0 @{ false @} else @{ ev(ev, od, n - 1) @}
    @};

    is_even(is_even, is_odd, x)
@}
@end example
@end enumerate
@end quotation

@node	4.1.7, 4.1.8, 4.1.6, 4.1
@subsection Separating Syntactic Analysis from Execution

The evaluator implemented above is simple, but it is very inefficient, because
the syntactic analysis of expressions is interleaved with their execution.
Thus if a program is executed many times, its syntax is analyzed many times.
Consider, for example, evaluating @code{(factorial 4)} using the following
definition of @code{factorial}:

@example
fn factorial(n: i64) -> i64 @{
    if n == 1 @{
        1
    @} else @{
        factorial(n - 1) * n
    @}
@}
@end example

@noindent
Each time @code{factorial} is called, the evaluator must determine that the
body is an @code{if} expression and extract the predicate.  Only then can it
evaluate the predicate and dispatch on its value.  Each time it evaluates the
expression @code{(* (factorial (- n 1)) n)}, or the subexpressions
@code{(factorial (- n 1))} and @code{(- n 1)}, the evaluator must perform the
case analysis in @code{eval} to determine that the expression is an
application, and must extract its operator and operands.  This analysis is
expensive.  Performing it repeatedly is wasteful.

We can transform the evaluator to be significantly more efficient by arranging
things so that syntactic analysis is performed only once.@footnote{This
technique is an integral part of the compilation process, which we shall
discuss in @ref{Chapter 5}.  Jonathan Rees wrote a Scheme interpreter like this
in about 1982 for the T project (@ref{Rees and Adams 1982}).  Marc @ref{Feeley (1986)} (see
also @ref{Feeley and Lapalme 1987}) independently invented this technique in his
master's thesis.} We split @code{eval}, which takes an expression and an
environment, into two parts.  The procedure @code{analyze} takes only the
expression.  It performs the syntactic analysis and returns a new procedure,
the @newterm{execution procedure}, that encapsulates the work to be done in
executing the analyzed expression.  The execution procedure takes an
environment as its argument and completes the evaluation.  This saves work
because @code{analyze} will be called only once on an expression, while the
execution procedure may be called many times.

With the separation into analysis and execution, @code{eval} now becomes

@example
// Analyze returns a closure that takes and returns an environment
fn eval(exp: &Expr, env: Environment<Value>) 
    -> Result<(Value, Environment<Value>), EvalError> 
@{
    let executor = analyze(exp)?;
    executor(env)
@}
@end example

@noindent
The result of calling @code{analyze} is the execution procedure to be applied
to the environment.  The @code{analyze} procedure is the same case analysis as
performed by the original @code{eval} of @ref{4.1.1}, except that the
procedures to which we dispatch perform only analysis, not full evaluation.
The @code{Executor} type now threads the environment functionally:

@example
type Executor = Box<dyn Fn(Environment<Value>) 
    -> Result<(Value, Environment<Value>), EvalError>>;

fn analyze(exp: &Expr) -> Result<Executor, EvalError> @{
    match exp @{
        Expr::Number(n) => analyze_self_evaluating(*n),
        Expr::String(s) => analyze_self_evaluating_string(s.clone()),
        Expr::Quote(quoted) => analyze_quoted(quoted),
        Expr::Symbol(var) => analyze_variable(var.clone()),
        Expr::Define @{ name, value @} => 
            analyze_definition(name.clone(), value),
        Expr::If @{ predicate, consequent, alternative @} =>
            analyze_if(predicate, consequent, alternative),
        Expr::Lambda @{ params, body @} =>
            analyze_lambda(params.clone(), body),
        Expr::Begin(actions) => analyze_sequence(actions),
        Expr::Application @{ operator, operands @} =>
            analyze_application(operator, operands),
        _ => Err(EvalError::InvalidSyntax(format!("Unknown: @{:?@}", exp))),
    @}
@}
@end example

@noindent
Here is the simplest syntactic analysis procedure, which handles
self-evaluating expressions.  It returns an execution procedure that 
passes the environment through unchanged:

@example
fn analyze_self_evaluating(n: i64) -> Result<Executor, EvalError> @{
    Ok(Box::new(move |env| Ok((Value::Number(n), env))))
@}
@end example

@noindent
For a quoted expression, we can gain a little efficiency by extracting the 
data once, in the analysis phase:

@example
fn analyze_quoted(quoted: &Expr) -> Result<Executor, EvalError> @{
    let val = expr_to_value(quoted)?;
    Ok(Box::new(move |env| Ok((val.clone(), env))))
@}
@end example

@noindent
Looking up a variable value must still be done in the execution phase, since
this depends upon knowing the environment.@footnote{There is, however, an
important part of the variable search that @emph{can} be done as part of the
syntactic analysis.  As we will show in @ref{5.5.6}, one can determine
the position in the environment structure where the value of the variable will
be found, thus obviating the need to scan the environment for the entry that
matches the variable.}

@example
use std::sync::Arc;

type Executor = Arc<dyn Fn(Environment<Value>) 
    -> Result<(Value, Environment<Value>), EvalError> + Send + Sync>;

fn analyze_variable(name: String) -> Result<Executor, EvalError> @{
    Ok(Arc::new(move |env| @{
        let val = env.lookup(&name)
            .ok_or_else(|| EvalError::UnboundVariable(name.clone()))?
            .clone();
        Ok((val, env))
    @}))
@}

fn analyze_definition(name: String, value: &Expr) -> Result<Executor, EvalError> @{
    let val_proc = analyze(value)?;
    Ok(Arc::new(move |env| @{
        let (val, env) = val_proc(env)?;
        let new_env = env.define(name.clone(), val);
        Ok((Value::Void, new_env))
    @}))
@}

fn analyze_if(
    predicate: &Expr,
    consequent: &Expr,
    alternative: &Expr,
) -> Result<Executor, EvalError> @{
    let pred_proc = analyze(predicate)?;
    let cons_proc = analyze(consequent)?;
    let alt_proc = analyze(alternative)?;
    Ok(Arc::new(move |env| @{
        let (pred_val, env) = pred_proc(env)?;
        if is_true(&pred_val) @{
            cons_proc(env)
        @} else @{
            alt_proc(env)
        @}
    @}))
@}

fn analyze_lambda(
    params: Vec<String>,
    body: &[Expr],
) -> Result<Executor, EvalError> @{
    let body_proc = analyze_sequence(body)?;
    Ok(Arc::new(move |env| @{
        let closure = Value::Closure @{
            params: params.clone(),
            body: vec![], // In analyzed version, we might store body_proc
            env: env.clone(),
            self_name: None,
        @};
        Ok((closure, env))
    @}))
@}
@end example

@noindent
Analysis of a sequence of expressions (as in a @code{begin} or the body of a
@code{lambda} expression) is more involved.@footnote{See @ref{Exercise 4.23}
for some insight into the processing of sequences.} Each expression in the
sequence is analyzed, yielding an execution procedure.  These execution
procedures are combined to produce an execution procedure that takes an
environment as argument and sequentially calls each individual execution
procedure, threading the environment through:

@example
fn analyze_sequence(exps: &[Expr]) -> Result<Executor, EvalError> @{
    if exps.is_empty() @{
        return Err(EvalError::InvalidSyntax("Empty sequence".into()));
    @}

    let procs: Vec<Executor> = exps
        .iter()
        .map(analyze)
        .collect::<Result<_, _>>()?;

    Ok(Arc::new(move |mut env| @{
        let mut last_val = Value::Void;
        for proc in &procs @{
            let (val, next_env) = proc(env)?;
            last_val = val;
            env = next_env;
        @}
        Ok((last_val, env))
    @}))
@}
@end example

@noindent
To analyze an application, we analyze the operator and operands and construct
an execution procedure that calls the operator execution procedure (to obtain
the actual procedure to be applied) and the operand execution procedures (to
obtain the actual arguments).

@example
fn analyze_application(
    operator: &Expr,
    operands: &[Expr],
) -> Result<Executor, EvalError> @{
    let op_proc = analyze(operator)?;
    let arg_procs: Vec<Executor> = operands
        .iter()
        .map(analyze)
        .collect::<Result<_, _>>()?;

    Ok(Arc::new(move |env| @{
        let (proc, env) = op_proc(env)?;
        let mut args = Vec::with_capacity(arg_procs.len());
        let mut current_env = env;
        for arg_proc in &arg_procs @{
            let (val, next_env) = arg_proc(current_env)?;
            args.push(val);
            current_env = next_env;
        @}
        // In analyzed version, apply might need to be different
        let result = apply(proc, args)?;
        Ok((result, current_env))
    @}))
@}
@end example

@noindent
Our new evaluator uses the same data structures, syntax procedures, and
run-time support procedures as in @ref{4.1.2}, @ref{4.1.3}, and
@ref{4.1.4}.

@quotation
@strong{@anchor{Exercise 4.22}Exercise 4.22:} Extend the evaluator in this
section to support the special form @code{let}.  (See @ref{Exercise 4.6}.)
@end quotation

@quotation
@strong{@anchor{Exercise 4.23}Exercise 4.23:} Alyssa P. Hacker doesn't
understand why @code{analyze_sequence} needs to be so complicated.  All the
other analysis procedures are straightforward transformations of the
corresponding evaluation procedures (or @code{eval} clauses) in 
@ref{4.1.1}.  She expected @code{analyze_sequence} to look like this:

@example
// Alyssa's simpler version - loops at execution time
fn analyze_sequence(exps: &[Expr]) -> Result<Executor, EvalError> @{
    fn execute_sequence(
        procs: &[Executor],
        env: &Environment,
    ) -> Result<Value, EvalError> @{
        if procs.len() == 1 @{
            procs[0](env)
        @} else @{
            procs[0](env)?;
            execute_sequence(&procs[1..], env)
        @}
    @}

    let procs: Vec<Executor> = exps
        .iter()
        .map(analyze)
        .collect::<Result<_, _>>()?;

    if procs.is_empty() @{
        return Err(EvalError::EmptySequence);
    @}

    Ok(Box::new(move |env| execute_sequence(&procs, env)))
@}
@end example

Eva Lu Ator explains to Alyssa that the version in the text does more of the
work of evaluating a sequence at analysis time.  Alyssa's sequence-execution
procedure, rather than having the calls to the individual execution procedures
built in, loops through the procedures in order to call them: In effect,
although the individual expressions in the sequence have been analyzed, the
sequence itself has not been.

Compare the two versions of @code{analyze_sequence}.  For example, consider the
common case (typical of procedure bodies) where the sequence has just one
expression.  What work will the execution procedure produced by Alyssa's
program do?  What about the execution procedure produced by the program in the
text above?  How do the two versions compare for a sequence with two
expressions?
@end quotation

@quotation
@strong{@anchor{Exercise 4.24}Exercise 4.24:} Design and carry out some
experiments to compare the speed of the original metacircular evaluator with
the version in this section.  Use your results to estimate the fraction of time
that is spent in analysis versus execution for various procedures.
@end quotation
@node	4.1.8, 4.2, 4.1.7, 4.1
@subsection 선언적 매크로: 코드를 생성하는 코드 (Declarative Macros: Code that Generates Code)

@cindex 선언적 매크로 (declarative macros)
@cindex macro_rules!
@cindex 메타프로그래밍 (metaprogramming)
@cindex 컴파일 타임 코드 생성 (compile-time code generation)

우리의 메타언어적 추상화 탐구에서, 우리는 한 언어를 위한 평가자가 어떻게 다른 언어로 구현될 수 있는지 보았다.
하지만 만약 우리가 구현 언어 자체의 구문을 확장하고 싶다면 어떨까?
Rust는 이를 위한 강력한 메커니즘을 제공한다: @code{macro_rules!} 구조를 사용하여 정의되는 @newterm{선언적 매크로(declarative macros)}이다.

매크로는 함수와 근본적으로 다르다.
함수가 런타임에 @emph{값(values)}에 대해 작동하는 반면, 매크로는 컴파일 타임에 @emph{구문(syntax)}에 대해 작동한다.
매크로는 코드를 입력으로 받아 새로운 코드를 출력으로 생성하며, 이는 마치 직접 작성한 것처럼 컴파일된다.
이것은 매크로를 진정한 형태의 메타언어적 추상화로 만든다 --- 매크로는 언어 자체를 확장할 수 있게 해준다.

@subsubheading 매크로란 무엇인가? (What Are Macros?)

@cindex 위생 (매크로) (hygiene (macro))
@cindex 컴파일 타임 확장 (compile-time expansion)

매크로는 패턴 매칭과 코드 생성 시설이다.
Rust 컴파일러가 매크로 호출(끝에 @code{!}가 붙는 것으로 인식됨)을 만나면, 입력을 매크로의 패턴과 대조하고 해당 템플릿에 따라 새로운 코드를 생성함으로써 매크로를 @newterm{확장(expands)}한다.

내장된 @code{vec!} 매크로를 고려해 보자:

@example
let numbers = vec![1, 2, 3, 4, 5];
@end example

@noindent
이것은 다음과 같이 확장되는 구문적 설탕(syntactic sugar)이다:

@example
let numbers = @{
    let mut temp_vec = Vec::new();
    temp_vec.push(1);
    temp_vec.push(2);
    temp_vec.push(3);
    temp_vec.push(4);
    temp_vec.push(5);
    temp_vec
@};
@end example

@noindent
매크로는 반복적인 코드를 작성하는 수고를 덜어주고 더 깔끔한 구문을 제공했다.
더 중요한 것은, 이 확장이 @emph{컴파일 타임}에 일어나므로 런타임 비용이 없다는 것이다.

@subsubheading 기본 매크로 구문 (Basic Macro Syntax)

@cindex 패턴 매칭 (매크로) (pattern matching (macros))
@cindex 필사 (매크로) (transcription (macros))

선언적 매크로는 @code{macro_rules!} 다음에 이름과 @emph{규칙(rules)} 집합을 사용하여 정의된다.
각 규칙은 @emph{패턴(pattern)}(매처)과 @emph{템플릿(template)}(트랜스크라이버)을 갖는다:

@noindent
@b{Rust:}
@example
macro_rules! say_hello @{
    // 패턴 => 템플릿
    () => @{
        println!("Hello, world!");
    @};
@}

// 사용법:
say_hello!();  // 다음으로 확장됨: println!("Hello, world!");
@end example

@noindent
패턴 @code{()}는 빈 호출과 매칭된다.
템플릿은 어떤 코드를 생성할지 지정한다.
위의 매크로는 단일 규칙을 갖지만, 매크로는 순서대로 시도되는 여러 규칙을 가질 수 있다:

@example
macro_rules! create_function @{
    // 함수 이름과 매칭되는 패턴
    ($func_name:ident) => @{
        fn $func_name() @{
            println!("You called @{:?@}()", stringify!($func_name));
        @}
    @};
@}

// 사용법:
create_function!(foo);
create_function!(bar);

foo();  // 출력: You called "foo"()
bar();  // 출력: You called "bar"()
@end example

@noindent
여기서 @code{$func_name:ident}는 식별자를 캡처하는 @newterm{메타변수(metavariable)}이다.
@code{:ident} 부분은 매크로가 어떤 종류의 구문을 기대해야 하는지 알려주는 @newterm{단편 지정자(fragment specifier)}이다.

@subsubheading 단편 지정자 (Fragment Specifiers)

@cindex 단편 지정자 (fragment specifiers)
@cindex 메타변수 (metavariables)

Rust 매크로는 서로 다른 종류의 구문 요소를 캡처할 수 있다:

@itemize @bullet

@item
@code{ident} --- 식별자 (변수 이름, 함수 이름 등)

@item
@code{expr} --- 표현식 (@code{1 + 2}, @code{foo()} 등)

@item
@code{stmt} --- 문장 (@code{let x = 5;} 등)

@item
@code{ty} --- 타입 (@code{i32}, @code{Vec<String>} 등)

@item
@code{pat} --- 패턴 (match 암 패턴)

@item
@code{path} --- 경로 (@code{std::collections::HashMap})

@item
@code{tt} --- 단일 토큰 트리 (균형 잡힌 단일 토큰)

@item
@code{block} --- 코드 블록 (@code{@{ ... @}})

@item
@code{item} --- 아이템 (함수, 구조체 등)

@item
@code{meta} --- 속성 내용

@item
@code{literal} --- 리터럴 표현식 (@code{42}, @code{"hello"} 등)

@end itemize

@noindent
@b{Rust:}
@example
macro_rules! create_variable @{
    // 변수 이름과 표현식을 캡처
    ($var_name:ident = $value:expr) => @{
        let $var_name = $value;
    @};
@}

// 사용법:
create_variable!(x = 42);
create_variable!(message = "Hello".to_string());
@end example

@subsubheading 반복 패턴 (Repetition Patterns)

@cindex 반복 (매크로) (repetition (macros))
@cindex 가변 인자 매크로 (variadic macros)

선언적 매크로의 가장 강력한 특징 중 하나는 @newterm{반복 패턴(repetition patterns)}을 통해 가변 개수의 인자를 처리할 수 있는 능력이다.
이것들은 @code{$(...)} 다음에 반복 연산자가 오는 형식으로 지정된다:

@itemize @bullet

@item
@code{$(...)*} --- 0회 이상 반복

@item
@code{$(...)+} --- 1회 이상 반복

@item
@code{$(...)@{,@}} --- 특정 토큰(여기서는 쉼표)으로 구분된 0회 이상 반복

@end itemize

@noindent
다음은 우리만의 단순화된 @code{vec!} 매크로를 구현하는 방법이다:

@noindent
@b{Rust:}
@example
macro_rules! my_vec @{
    // 쉼표로 구분된 0개 이상의 표현식과 매칭
    ( $( $element:expr ),* ) => @{
        @{
            let mut temp_vec = Vec::new();
            $(
                temp_vec.push($element);
            )*
            temp_vec
        @}
    @};
@}

// 사용법:
let v = my_vec![1, 2, 3, 4, 5];
let empty: Vec<i32> = my_vec![];
@end example

@noindent
패턴 @code{$( $element:expr ),*}는 쉼표로 구분된 0개 이상의 표현식과 매칭된다.
템플릿 @code{$( temp_vec.push($element); )*}는 캡처된 각 요소에 대해 push 문을 한 번씩 반복한다.

@subsubheading 매크로 위생 (Macro Hygiene)

@cindex 위생 (매크로) (hygiene (macro))
@cindex 이름 충돌 (매크로) (name collision (macros))

Rust 매크로의 중요한 속성은 @newterm{위생(hygiene)}이다.
C 전처리기 매크로와 달리, Rust 매크로는 위생적이어서 매크로가 생성한 코드와 주변 문맥 사이의 의도치 않은 이름 충돌을 피한다.

다음 C 전처리기 매크로(Rust는 사용하지 않음)를 고려해 보자:

@example
// C 전처리기 (Rust 아님!)
#define SWAP(a, b) @{ int temp = a; a = b; b = temp; @}

int temp = 1;
int x = 2;
SWAP(temp, x);  // 버그! 매크로의 temp가 우리 변수를 가림(shadowing)
@end example

@noindent
Rust에서 매크로는 기본적으로 위생적이다:

@noindent
@b{Rust:}
@example
macro_rules! swap @{
    ($a:expr, $b:expr) => @{
        @{
            let temp = $a;  // 이 'temp'는 외부 스코프와 충돌하지 않음
            $a = $b;
            $b = temp;
        @}
    @};
@}
@end example

@noindent
하지만 여기에는 미묘한 점이 있다: 템플릿의 @code{$a}와 @code{$b}는 전달된 @emph{표현식}을 가리키며, 이는 할당 가능(lvalues)해야 한다.
더 나은 구현은 @code{std::mem::swap}을 사용하거나 가변 참조를 요구하는 것이다:

@example
macro_rules! swap @{
    ($a:expr, $b:expr) => @{
        std::mem::swap(&mut $a, &mut $b);
    @};
@}
@end example

@noindent
위생은 매크로 내부에서 도입된 변수가 호출 문맥의 변수를 방해하지 않으며, 그 반대도 마찬가지임을 의미한다.
이는 C 스타일의 텍스트 치환보다 크게 개선된 점이다.

@subsubheading 도메인 특화 언어 구축 (Building a Domain-Specific Language)

@cindex 도메인 특화 언어 (domain-specific language)
@cindex DSL
@cindex 임베디드 DSL (embedded DSL)

매크로는 Rust 내부에 내장된 도메인 특화 언어(@abbr{DSL})를 만드는 데 탁월하다.
깔끔한 구문으로 해시 맵을 정의하기 위한 간단한 @abbr{DSL}을 만들어 보자:

@noindent
@b{Rust:}
@example
use std::collections::HashMap;

macro_rules! hashmap @{
    // 빈 맵
    () => @{
        HashMap::new()
    @};

    // 키-값 쌍이 있는 맵
    ( $( $key:expr => $value:expr ),+ $(,)? ) => @{
        @{
            let mut map = HashMap::new();
            $(
                map.insert($key, $value);
            )+
            map
        @}
    @};
@}

// 사용법:
let capitals = hashmap! @{
    "France" => "Paris",
    "Germany" => "Berlin",
    "Italy" => "Rome",
@};

let empty: HashMap<&str, i32> = hashmap!();
@end example

@noindent
패턴 끝의 @code{$(,)?}를 주목하라 --- 이것은 Rust에서 관용적인 마지막 쉼표(trailing comma) 옵션과 매칭된다.

다음은 단언(assertion) 메시지를 위한 미니 DSL을 만드는 더 정교한 예제이다:

@noindent
@b{Rust:}
@example
macro_rules! assert_bounds @{
    ($value:expr, $min:expr, $max:expr) => @{
        assert!(
            $value >= $min && $value <= $max,
            "@{@} (value: @{@}) must be between @{@} and @{@}",
            stringify!($value),
            $value,
            $min,
            $max
        );
    @};
@}

// 사용법:
let x = 150;
assert_bounds!(x, 0, 100);
// 패닉 메시지: "x (value: 150) must be between 0 and 100"
@end example

@noindent
@code{stringify!} 매크로(Rust 내장)는 구문 트리 단편을 문자열 리터럴로 변환하여 오류 메시지에 변수 이름을 표시할 수 있게 해준다.

@subsubheading 다중 매크로 규칙 (Multiple Macro Rules)

@cindex 패턴 매칭 (매크로) (pattern matching (macros))
@cindex 규칙 우선순위 (매크로) (rule priority (macros))

매크로는 위에서 아래로 순서대로 시도되는 여러 규칙을 가질 수 있다.
첫 번째로 매칭되는 규칙이 사용된다:

@noindent
@b{Rust:}
@example
macro_rules! calculate @{
    // 단일 숫자
    ($value:expr) => @{
        $value
    @};

    // 덧셈
    (add $a:expr, $b:expr) => @{
        $a + $b
    @};

    // 곱셈
    (mul $a:expr, $b:expr) => @{
        $a * $b
    @};

    // 중첩된 표현식
    (eval $($t:tt)*) => @{
        @{
            calculate!($($t)*)
        @}
    @};
@}

// 사용법:
let x = calculate!(5);              // => 5
let y = calculate!(add 3, 4);       // => 7
let z = calculate!(mul 2, 10);      // => 20
@end example

@noindent
@code{tt}(토큰 트리) 지정자는 모든 단일 토큰과 매칭되며, @code{$($t:tt)*}는 모든 토큰을 캡처한다.
이는 재귀적 매크로나 임의의 구문을 통과시키고 싶을 때 유용하다.

@subsubheading 매크로 디버깅 (Debugging Macros)

@cindex cargo expand
@cindex 매크로 디버깅 (macro debugging)
@cindex rustc --pretty=expanded

매크로는 컴파일 타임에 작동하고 코드를 변환하므로, 이를 디버깅하는 것은 어려울 수 있다.
Rust는 도움이 되는 도구들을 제공한다:

@enumerate 1

@item
@b{cargo expand} --- 코드의 확장된 버전을 보여주는 cargo 서브커맨드이다.
@code{cargo install cargo-expand}로 설치한 후 실행하라:

@example
cargo expand
@end example

이것은 모든 매크로가 확장된 소스 코드를 보여주어, 실제로 어떤 코드가 생성되고 있는지 명확하게 해준다.

@item
@b{rustc --pretty=expanded} --- 컴파일러 또한 확장된 코드를 보여줄 수 있다:

@example
rustc src/main.rs -Z unpretty=expanded
@end example

@item
@b{컴파일러 오류 메시지} --- Rust 컴파일러는 매크로 확장이 실패한 지점을 보여주며, 종종 어떤 규칙과 매칭하려고 시도했는지 알려준다.

@end enumerate

@noindent
예를 들어, @code{my_vec!} 매크로를 확장하면 다음과 같다:

@example
// 소스:
let v = my_vec![1, 2, 3];

// 확장됨 (대략적으로):
let v = @{
    let mut temp_vec = Vec::new();
    temp_vec.push(1);
    temp_vec.push(2);
    temp_vec.push(3);
    temp_vec
@};
@end example

@subsubheading 매크로 vs 함수 vs 제네릭 사용 시기 (When to Use Macros vs Functions vs Generics)

@cindex 매크로 사용 시기 (when to use macros)
@cindex 매크로 vs 함수 (macros vs functions)
@cindex 설계 결정 (design decisions)

Rust는 함수, 제네릭, 트레이트 객체, 매크로 등 여러 추상화 메커니즘을 제공한다.
각각을 사용해야 할 때는 다음과 같다:

@b{함수를 사용하는 경우:}

@itemize @bullet

@item
구문이 아니라 @emph{값(values)}에 대해 작동할 때

@item
작업이 잘 정의되어 있고 타입 체크가 가능할 때

@item
상용구(boilerplate) 코드를 생성할 필요가 없을 때

@end itemize

@b{제네릭을 사용하는 경우:}

@itemize @bullet

@item
타입에 대해 컴파일 타임 다형성을 원할 때

@item
트레이트 바운드(trait bounds)로 추상화를 표현할 수 있을 때

@item
타입 추론이 장황함을 줄이는 데 도움이 될 때

@end itemize

@b{매크로를 사용하는 경우:}

@itemize @bullet

@item
반복적인 코드를 생성해야 할 때

@item
사용자 정의 구문이나 @abbr{DSL}을 만들고 싶을 때

@item
제네릭으로 표현할 수 없는 컴파일 타임 계산이 필요할 때

@item
런타임 오버헤드를 완전히 피하고 싶을 때

@item
식별자, 타입, 또는 다른 구문 요소들에 대해 작동해야 할 때

@item
가변 인자(variadic arguments)가 필요할 때 (가변 제네릭이 안정화되기 전까지)

@end itemize

@noindent
@b{예제:} 가변 개수의 인자를 받는 함수를 구현한다고 고려해 보자.
대부분의 언어에서는 가변 인자 함수를 사용한다.
Rust에서(매크로 없이)는 슬라이스를 전달해야 할 것이다:

@example
// 매크로 없이:
fn print_all(items: &[&str]) @{
    for item in items @{
        println!("@{@}", item);
    @}
@}

print_all(&["hello", "world"]);  // 슬라이스를 생성해야 함
@end example

@noindent
매크로를 사용하면 더 인체공학적인 인터페이스를 만들 수 있다:

@example
macro_rules! print_all @{
    ($($item:expr),*) => @{
        $(
            println!("@{@}", $item);
        )*
    @};
@}

print_all!("hello", "world", "!");  // 슬라이스 필요 없음
@end example

@subsubheading 메타언어적 추상화와의 연결 (Connection to Metalinguistic Abstraction)

@cindex 메타언어적 추상화 (metalinguistic abstraction)
@cindex 메타순환 평가자 (meta-circular evaluator)

선언적 매크로는 4장의 핵심인 @newterm{메타언어적 추상화(metalinguistic abstraction)} 원칙을 구체화한다.
우리가 Scheme @emph{내부에서} Scheme을 위한 평가자(메타순환 평가자)를 구축한 것처럼, Rust 매크로는 Rust @emph{내부에서} Rust를 확장할 수 있게 해준다.

그 평행성은 깊다:

@itemize @bullet

@item
@b{패턴 매칭:} 우리 평가자가 표현식(@code{if}, @code{lambda}, @code{define} 등)을 분류하기 위해 패턴 매칭을 사용하는 것처럼, 매크로는 구문 구조를 인식하기 위해 패턴 매칭을 사용한다.

@item
@b{구문 변환:} 우리 평가자가 소스 코드를 평가된 결과로 변환하는 것처럼, 매크로는 소스 코드를 다른 소스 코드로 변환한다.

@item
@b{위생과 스코프:} 우리 평가자가 변수 캡처를 피하기 위해 환경 프레임을 유지하는 것처럼, Rust 매크로는 이름 충돌을 피하기 위해 위생을 유지한다.

@item
@b{컴파일 타임 vs 런타임:} 매크로는 컴파일 타임에 작동하여 나중에 실행될 코드를 생성한다.
이것은 프로그래밍 언어 이론에서의 부분 평가(partial evaluation)나 스테이징(staging)과 유사하다.

@end itemize

@noindent
실제로 매크로는 @emph{구문적 추상화(syntactic abstraction)}의 한 형태이며, 함수는 @emph{절차적 추상화(procedural abstraction)}를 제공한다.
둘 다 대규모 시스템의 복잡성을 관리하는 데 필수적인 도구이다.

@subsubheading 전체 예제: 테스트 DSL (A Complete Example: Testing DSL)

@cindex 테스트 매크로 (test macro)
@cindex DSL 예제 (DSL example)

@code{proptest} 크레이트가 제공하는 것과 유사한, 속성 기반 테스트(property-based testing)를 위한 미니 DSL을 만드는 실용적인 매크로를 만들어 보자:

@noindent
@b{Rust:}
@example
macro_rules! property_test @{
    (
        $test_name:ident:
        forall $var:ident in $range:expr =>
        $property:expr
    ) => @{
        #[test]
        fn $test_name() @{
            for $var in $range @{
                assert!(
                    $property,
                    "Property failed for @{@} = @{@}",
                    stringify!($var),
                    $var
                );
            @}
        @}
    @};
@}

// 사용법:
property_test! @{
    test_square_non_negative:
    forall x in -100..100 =>
    (x * x >= 0)
@}

property_test! @{
    test_double_is_even:
    forall n in 0..1000 =>
    ((n * 2) % 2 == 0)
@}
@end example

@noindent
This macro generates complete test functions with clear failure messages,
demonstrating how macros can reduce boilerplate while maintaining expressiveness.

@subsubheading Limitations and Caveats

@cindex macro limitations
@cindex procedural macros

While powerful, declarative macros have limitations:

@enumerate 1

@item
@b{Complexity:} Large macros can become hard to understand and maintain.

@item
@b{Error messages:} When a macro expansion fails, error messages can be
cryptic.

@item
@b{Debugging:} Stepping through macro-generated code with a debugger is
difficult.

@item
@b{Compile time:} Heavy macro use can slow compilation.

@item
@b{Pattern limitations:} Some syntactic transformations are impossible with
@code{macro_rules!} and require procedural macros (which operate on the
@abbr{AST} directly).

@end enumerate

@noindent
For more complex metaprogramming tasks, Rust offers @newterm{procedural macros},
which are functions that operate on token streams or syntax trees. These include
custom @code{#[derive]} macros, attribute macros, and function-like procedural
macros. Declarative macros are simpler and sufficient for most use cases.

@quotation
@strong{@anchor{Exercise 4.16a}Exercise 4.16a:} Define a macro @code{unless!}
that works like an inverted @code{if} statement---it executes a block of code
only when a condition is @emph{false}:

@example
unless!(x > 10) @{
    println!("x is not greater than 10");
@}
@end example

@noindent
Your macro should support both forms:

@example
// Without else
unless!(condition) @{
    // executed if condition is false
@}

// With else
unless!(condition) @{
    // executed if condition is false
@} else @{
    // executed if condition is true
@}
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 4.17a}Exercise 4.17a:} Write a @code{calc!} macro that
implements a simple calculator @abbr{DSL}. It should support basic arithmetic
with infix notation:

@example
let result = calc!(@{
    2 + 3 * 4
@});  // Should evaluate to 14

let x = 5;
let y = calc!(@{
    x * 2 + 10
@});  // Should evaluate to 20
@end example

@noindent
@emph{Hint:} You may need to use the @code{tt} fragment specifier and recursive
macro rules. Start with a simpler version that only handles two operands:
@code{calc!(2 + 3)}, then extend it.

@noindent
For a greater challenge, implement proper operator precedence (multiplication
before addition).
@end quotation

@quotation
@strong{@anchor{Exercise 4.18a}Exercise 4.18a:} The @code{hashmap!} macro we
defined earlier creates a new @code{HashMap} and inserts elements one by one.
However, if we know the number of elements at compile time, we can pre-allocate
the hash map's capacity for better performance.

@enumerate a

@item
Modify the @code{hashmap!} macro to count the number of key-value pairs and
use @code{HashMap::with_capacity} instead of @code{HashMap::new}.

@item
The standard library's @code{vec!} macro supports both @code{vec![1, 2, 3]}
and @code{vec![0; 100]} (create a vector with 100 zeros). Extend your
@code{hashmap!} macro to support a similar syntax for creating maps with
repeated values:

@example
// Creates a map: @{"a" => 0, "b" => 0, "c" => 0@}
let map = hashmap!("a", "b", "c" => 0);
@end example

@item
Explain why this kind of API design (providing multiple convenient syntaxes)
is particularly well-suited to macros rather than functions.

@end enumerate
@end quotation


@node	4.2, 4.3, 4.1.8, Chapter 4
@section Scheme의 변형 --- 지연 평가 (Variations on a Scheme --- Lazy Evaluation)

Lisp 프로그램으로 표현된 평가자가 있으므로, 우리는 단순히 평가자를 수정함으로써 언어 설계에서의 대안적인 선택들을 실험해 볼 수 있다.
실제로 새로운 언어는 기존의 고수준 언어 내에 새로운 언어를 내장하는 평가자를 먼저 작성함으로써 발명되는 경우가 많다.
예를 들어, 우리가 Lisp 커뮤니티의 다른 멤버와 Lisp에 대한 제안된 수정 사항의 어떤 측면을 논의하고 싶다면, 그 변경 사항을 구체화하는 평가자를 제공할 수 있다.
수신자는 새 평가자로 실험하고 추가 수정 사항으로 의견을 보낼 수 있다.
고수준 구현 기반은 평가자를 테스트하고 디버깅하기 쉽게 만들 뿐만 아니라, 내장(embedding)은 설계자가 가로챌@footnote{가로채다(snarf): ``특히 주인의 허락이 있든 없든 사용하기 위해 큰 문서나 파일을 가져오다.'' 가로채 마시다(snarf down): ``때때로 흡수, 처리 또는 이해의 함축적 의미를 담아 가로채다.'' (이 정의들은 @ref{Steele et al. 1983}에서 가로채왔다. @ref{Raymond 1993}도 보라.)} 수 있게 해준다.
디자이너가 기반 언어의 특징들을 가져올 수 있게 해주는 것이다. 마치 우리의 내장된 Lisp 평가자가 기반 Lisp의 원시 기능과 제어 구조를 사용하는 것과 같다.
나중에(만약 있다면) 설계자는 저수준 언어나 하드웨어로 완전한 구현을 구축하는 수고를 들일 필요가 있다.
이 절과 다음 절에서 우리는 상당한 추가 표현력을 제공하는 Scheme의 몇 가지 변형을 탐구한다.

@menu
* 4.2.1::            정규 순서와 적용 순서 (Normal Order and Applicative Order)
* 4.2.2::            지연 평가가 있는 인터프리터 (An Interpreter with Lazy Evaluation)
* 4.2.3::            지연 리스트로서의 스트림 (Streams as Lazy Lists)
* 4.2.5a::           영속적 데이터 구조 (Persistent Data Structures)
@end menu

@node	4.2.1, 4.2.2, 4.2, 4.2
@subsection 정규 순서와 적용 순서 (Normal Order and Applicative Order)

평가 모델에 대한 논의를 시작한 @ref{1.1}에서, 우리는 Scheme이 @newterm{적용 순서(applicative-order)} 언어임을 주목했다. 즉, Scheme 프로시저의 모든 인자는 프로시저가 적용될 때 평가된다.
대조적으로, @newterm{정규 순서(normal-order)} 언어는 실제 인자 값이 필요할 때까지 프로시저 인자의 평가를 지연시킨다.
프로시저 인자의 평가를 가능한 마지막 순간까지(예: 원시 연산에 필요할 때까지) 지연시키는 것을 @newterm{지연 평가(lazy evaluation)}라고 부른다.@footnote{``지연(lazy)'' 용어와 ``정규 순서(normal-order)'' 용어 사이의 차이는 다소 모호하다. 일반적으로 ``지연''은 특정 평가자의 메커니즘을 가리키고, ``정규 순서''는 특정 평가 전략과 독립적인 언어의 의미론을 가리킨다. 하지만 이것은 딱딱한 구분이 아니며, 두 용어는 종종 서로 바꿔서 사용된다.}
다음 프로시저를 고려해 보자:

@example
fn try_it(a: i64, b: i64) -> i64 @{
    if a == 0 @{ 1 @} else @{ b @}
@}
@end example

@noindent
@code{try_it(0, 1/0)}을 평가하면 Scheme에서는 오류가 발생한다.
지연 평가를 사용하면 오류가 발생하지 않을 것이다.
인자 @code{1/0}이 절대 평가되지 않기 때문에 표현식을 평가하면 1이 반환될 것이다.

지연 평가를 활용하는 예는 @code{unless} 프로시저의 정의이다:

@example
// 지연 평가를 사용하면, 인자들은 필요할 때까지 평가되지 않을 것이다
fn unless<T>(condition: bool, usual_value: T, exceptional_value: T) -> T @{
    if condition @{
        exceptional_value
    @} else @{
        usual_value
    @}
@}
@end example

@noindent
이것은 다음과 같은 표현식에서 사용될 수 있다:

@example
// Rust에서 지연 평가를 위해 클로저를 사용할 것이다
fn unless_lazy<T, F1, F2>(condition: bool, usual: F1, exceptional: F2) -> T
where
    F1: FnOnce() -> T,
    F2: FnOnce() -> T,
@{
    if condition @{
        exceptional()
    @} else @{
        usual()
    @}
@}

unless_lazy(
    b == 0,
    || a / b,
    || @{
        println!("exception: returning 0");
        0
    @}
)
@end example

@noindent
이것은 적용 순서 언어에서는 작동하지 않을 것인데, 왜냐하면 @code{unless}가 호출되기 전에 일반 값(usual value)과 예외적인 값(exceptional value)이 모두 평가될 것이기 때문이다(@ref{Exercise 1.6}과 비교하라).
지연 평가의 장점은 일부 인자의 평가가 오류를 생성하거나 종료되지 않더라도 @code{unless}와 같은 일부 프로시저가 유용한 계산을 수행할 수 있다는 점이다.

인자가 평가되기 전에 프로시저 본문에 진입하면, 그 프로시저는 해당 인자에 대해 @newterm{비엄격(non-strict)}하다고 말한다.
프로시저 본문에 진입하기 전에 인자가 평가되면, 그 프로시저는 해당 인자에 대해 @newterm{엄격(strict)}하다고 말한다.@footnote{``엄격'' 대 ``비엄격'' 용어는 언어 전체가 아니라 개별 프로시저와 인자를 가리킨다는 점을 제외하면 본질적으로 ``적용 순서'' 대 ``정규 순서''와 같은 것을 의미한다. 프로그래밍 언어 컨퍼런스에서 누군가가 ``정규 순서 언어 Hassle은 특정 엄격한 원시 함수들을 갖는다. 다른 프로시저들은 지연 평가를 통해 인자를 취한다.''라고 말하는 것을 들을 수도 있을 것이다.}
순수 적용 순서 언어에서 모든 프로시저는 각 인자가 엄격하다.
순수 정규 순서 언어에서 모든 복합 프로시저는 각 인자가 비엄격하며, 원시 프로시저는 엄격하거나 비엄격할 수 있다.
또한 프로그래머가 자신이 정의하는 프로시저의 엄격성을 상세하게 제어할 수 있게 해주는 언어들도 있다(@ref{Exercise 4.31} 참조).

유용하게 비엄격하게 만들 수 있는 프로시저의 두드러진 예는 @code{cons} (또는 일반적으로 데이터 구조를 위한 거의 모든 생성자)이다.
요소의 값을 알지 못하더라도 요소를 결합하여 데이터 구조를 형성하고 결과 데이터 구조에 대해 작동하는 유용한 계산을 수행할 수 있다.
예를 들어, 리스트에 있는 개별 요소의 값을 알지 못한 채 리스트의 길이를 계산하는 것은 완벽하게 말이 된다.
우리는 @ref{4.2.3}에서 이 아이디어를 활용하여 @ref{Chapter 3}의 스트림을 비엄격한 @code{cons} 쌍으로 형성된 리스트로 구현할 것이다.

@quotation
@strong{@anchor{Exercise 4.25}연습문제 4.25:} (일반적인 적용 순서 Scheme에서) 위에서 보여준 대로 @code{unless}를 정의하고 나서 다음과 같이 @code{unless}의 관점에서 @code{factorial}을 정의한다고 가정해 보자:

@example
fn factorial(n: i64) -> i64 @{
    // 이것은 엄격한 평가에서 무한 재귀를 일으킬 것이다!
    // unless가 호출되기 전에 두 분기가 모두 평가된다
    unless(
        n == 1,
        n * factorial(n - 1),  // 항상 평가됨!
        1,
    )
@}
@end example

@code{factorial(5)}를 평가하려고 시도하면 어떤 일이 발생하는가?
우리의 정의가 정규 순서 언어에서는 작동할까?
@end quotation

@quotation
@strong{@anchor{Exercise 4.26}연습문제 4.26:} Ben Bitdiddle과 Alyssa P. Hacker는 @code{unless}와 같은 것을 구현하기 위한 지연 평가의 중요성에 대해 의견이 엇갈린다.
Ben은 적용 순서에서 @code{unless}를 특수 형식으로 구현하는 것이 가능하다고 지적한다.
Alyssa는 만약 그렇게 한다면 @code{unless}는 단지 구문일 뿐이지 고차 프로시저와 함께 사용될 수 있는 프로시저가 아닐 것이라고 반박한다.
논쟁의 양측에 대한 세부 사항을 채워라.
@code{unless}를 (@code{cond}나 @code{let}과 같은) 파생된 표현식으로 구현하는 방법을 보여주고, @code{unless}를 특수 형식이 아닌 프로시저로 사용하는 것이 유용할 수 있는 상황의 예를 들어라.
@end quotation

@node	4.2.2, 4.2.3, 4.2.1, 4.2
@subsection 지연 평가가 있는 인터프리터 (An Interpreter with Lazy Evaluation)

이 절에서는 복합 프로시저가 각 인자에 대해 비엄격하다는 점을 제외하면 Scheme과 동일한 정규 순서 언어를 구현할 것이다.
원시 프로시저는 여전히 엄격할 것이다.
@ref{4.1.1}의 평가자를 수정하여 해석하는 언어가 이런 방식으로 동작하도록 만드는 것은 어렵지 않다.
필요한 거의 모든 변경 사항은 프로시저 적용을 중심으로 이루어진다.

기본 아이디어는 프로시저를 적용할 때, 인터프리터가 어떤 인자를 평가하고 어떤 인자를 지연시킬지 결정해야 한다는 것이다.
지연된 인자는 평가되지 않는다; 대신 그것들은 @newterm{썽크(thunks)}라고 불리는 객체로 변환된다.@footnote{``썽크(thunk)''라는 단어는 Algol 60에서 이름 호출(call-by-name)의 구현을 논의하던 비공식 작업 그룹에 의해 발명되었다. 그들은 표현식에 대한 대부분의 분석(``생각(thinking)'')이 컴파일 타임에 수행될 수 있음을 관찰했다; 따라서 런타임에 표현식은 이미 ``생각된(thunk)'' 상태일 것이다 (@ref{Ingerman et al. 1960}).}
썽크는 인자 값이 필요할 때, 마치 적용 시점에 평가되었던 것처럼 그 값을 생성하는 데 필요한 정보를 포함해야 한다.
따라서 썽크는 인자 표현식과 프로시저 적용이 평가되고 있는 환경을 포함해야 한다.

썽크 내부의 표현식을 평가하는 프로세스를 @newterm{강제(forcing)}라고 부른다.@footnote{이것은 @ref{Chapter 3}에서 스트림을 표현하기 위해 도입된 지연 객체에 대해 @code{force}를 사용하는 것과 유사하다. 우리가 여기서 하는 일과 @ref{Chapter 3}에서 했던 일 사이의 결정적인 차이는 우리가 평가자 내부에 지연시키기와 강제하기를 구축하고 있으며, 따라서 이것을 언어 전체에서 균일하고 자동적으로 만들고 있다는 점이다.}
일반적으로 썽크는 그 값이 필요할 때만 강제될 것이다: 썽크의 값을 사용할 원시 프로시저에 전달될 때; 조건문의 술어 값일 때; 그리고 프로시저로서 적용되려는 연산자의 값일 때이다.
우리가 선택할 수 있는 한 가지 설계 선택은 @ref{3.5.1}에서 지연 객체로 했던 것처럼 썽크를 @newterm{메모화(memoize)}할지 여부이다.
메모화를 사용하면 썽크가 처음 강제될 때 계산된 값을 저장한다.
이후의 강제는 계산을 반복하지 않고 단순히 저장된 값을 반환한다.
우리는 인터프리터가 메모화하도록 만들 것인데, 왜냐하면 이것이 많은 응용 분야에서 더 효율적이기 때문이다.
하지만 여기에는 까다로운 고려 사항들이 있다.@footnote{메모화와 결합된 지연 평가는 종종 @newterm{이름 호출(call-by-name)} 인자 전달과 대조하여 @newterm{필요 호출(call-by-need)} 인자 전달이라고 불린다. (Algol 60에서 도입된 이름 호출은 메모화되지 않은 지연 평가와 유사하다.) 언어 설계자로서 우리는 평가자가 메모화하도록 구축할 수도 있고, 메모화하지 않도록 구축할 수도 있으며, 이를 프로그래머를 위한 옵션으로 남겨둘 수도 있다 (@ref{Exercise 4.31}). @ref{Chapter 3}에서 예상할 수 있듯이, 이러한 선택들은 대입(assignment)이 있는 상황에서 미묘하고 혼란스러운 문제들을 야기한다. (@ref{Exercise 4.27} 및 @ref{Exercise 4.29}를 보라.) @ref{Clinger (1982)}의 훌륭한 기사는 여기서 발생하는 다차원적인 혼란을 명확히 하려고 시도한다.}

@subsubheading 평가자 수정하기 (Modifying the evaluator)

지연 평가자와 @ref{4.1}의 평가자 사이의 주요 차이점은 @code{eval}과 @code{apply}에서 프로시저 적용을 처리하는 방식에 있다.

@code{eval}의 @code{is_application} 절은 다음과 같이 된다:

@example
// 지연 평가자에서, 적용은 평가되지 않은 피연산자를 전달한다
Expr::Application @{ operator, operands @} => @{
    let proc = actual_value(operator, env)?;
    apply_lazy(proc, operands, env)
@}
@end example

@noindent
이것은 @ref{4.1.1}에 있는 @code{eval}의 @code{is_application} 절과 거의 동일하다.
그러나 지연 평가를 위해, 우리는 피연산자를 평가하여 생성된 인자가 아니라 피연산자 표현식을 사용하여 @code{apply}를 호출한다.
인자를 지연시켜야 할 경우 썽크를 구성하기 위해 환경이 필요하므로, 이것도 함께 전달해야 한다.
우리는 여전히 연산자를 평가하는데, 왜냐하면 @code{apply}는 그것의 유형(원시 대 복합)에 따라 디스패치하고 적용하기 위해 적용될 실제 프로시저가 필요하기 때문이다.

표현식의 실제 값이 필요할 때마다, 우리는 다음을 사용한다:

@example
fn actual_value(exp: &Expr, env: &Environment) -> Result<Value, EvalError> @{
    let result = eval(exp, env)?;
    force_it(result)  // 썽크인 경우, 평가를 강제함
@}
@end example

@noindent
단순히 @code{eval}을 사용하는 대신 이것을 사용함으로써, 표현식의 값이 썽크인 경우 강제되도록 한다.

우리의 새로운 버전의 @code{apply} 또한 @ref{4.1.1}의 버전과 거의 동일하다.
차이점은 @code{eval}이 평가되지 않은 피연산자 표현식을 전달했다는 점이다: (엄격한) 원시 프로시저의 경우, 원시 함수를 적용하기 전에 모든 인자를 평가한다; (비엄격한) 복합 프로시저의 경우, 프로시저를 적용하기 전에 모든 인자를 지연시킨다.

@example
pub fn apply(
    procedure: Value,
    operands: Vec<Expr>,
    env: Environment<Value>,
) -> Result<Value, EvalError> @{
    match procedure @{
        Value::Primitive(prim) => @{
            // 원시 함수는 엄격함: 모든 인자를 강제함
            let args = list_of_arg_values(operands, env)?;
            (prim.func)(&args)
        @}
        Value::Procedure @{ params, body, env: proc_env, .. @} => @{
            // 복합 프로시저는 비엄격함: 인자를 지연시킴
            let delayed_args = list_of_delayed_args(operands, env);
            let extended_env = proc_env.extend(
                params.into_iter().zip(delayed_args)
            );
            let (result, _) = eval(body, extended_env)?;
            Ok(result)
        @}
        _ => Err(EvalError::TypeError("프로시저가 아님".into())),
    @}
@}
@end example

@noindent
인자를 처리하는 프로시저들은 @ref{4.1.1}의 @code{eval_list}와 비슷하지만, @code{list_of_delayed_args}는 인자를 평가하는 대신 지연시키고, @code{list_of_arg_values}는 @code{eval} 대신 @code{actual_value}를 사용한다는 점이 다르다:

@example
fn list_of_arg_values(
    operands: Vec<Expr>,
    env: Environment<Value>,
) -> Result<Vec<Value>, EvalError> @{
    operands.into_iter()
        .map(|expr| actual_value(expr, env.clone()))
        .collect()
@}

fn list_of_delayed_args(
    operands: Vec<Expr>,
    env: Environment<Value>,
) -> Vec<Value> @{
    operands.into_iter()
        .map(|expr| delay_it(expr, env.clone()))
        .collect()
@}
@end example

@noindent
평가자를 변경해야 할 다른 곳은 @code{if}를 처리하는 부분인데, 여기서 우리는 술어가 참인지 거짓인지 테스트하기 전에 술어 표현식의 값을 얻기 위해 @code{eval} 대신 @code{actual_value}를 사용해야 한다:

@example
fn eval_if_lazy(
    test: Expr,
    consequent: Expr,
    alternative: Expr,
    env: Environment<Value>,
) -> Result<(Value, Environment<Value>), EvalError> @{
    let test_val = actual_value(test, env.clone())?;
    if is_true(&test_val) @{
        eval(consequent, env)
    @} else @{
        eval(alternative, env)
    @}
@}
@end example

@noindent
마지막으로, 우리는 @code{driver_loop} 프로시저(@ref{4.1.4})가 @code{eval} 대신 @code{actual_value}를 사용하도록 변경해야 하는데, 그래야 지연된 값이 읽기-평가-출력 루프로 다시 전파될 경우 출력되기 전에 강제되도록 할 수 있다.
또한 우리는 이것이 지연 평가자임을 나타내기 위해 프롬프트를 변경한다:

@example
const INPUT_PROMPT: &str = ";;; L-Eval input:";
const OUTPUT_PROMPT: &str = ";;; L-Eval value:";

fn driver_loop_lazy(mut env: Environment<Value>) @{
    loop @{
        println!("\n@{@}", INPUT_PROMPT);
        let input = read_and_parse();
        // 출력하기 전에 결과를 강제함
        match actual_value(input, env.clone()) @{
            Ok(output) => @{
                println!("@{@}", OUTPUT_PROMPT);
                user_print(&output);
            @}
            Err(e) => eprintln!("Error: @{:?@}", e),
        @}
    @}
@}
@end example

@noindent
이러한 변경을 완료하면 평가자를 시작하고 테스트할 수 있다.
@ref{4.2.1}에서 논의된 @code{try} 표현식의 성공적인 평가는 인터프리터가 지연 평가를 수행하고 있음을 나타낸다:

@example
let mut global_env = setup_environment();

driver_loop_lazy(&mut global_env);

// ;;; L-Eval input:
// fn try_it(a: i64, b: i64) -> i64 @{ if a == 0 @{ 1 @} else @{ b @} @}

// ;;; L-Eval value:
// ok

// ;;; L-Eval input:
// try_it(0, 1/0)  // 지연 인자 덕분에 나눗셈이 평가되지 않음!

// ;;; L-Eval value:
// 1
@end example

@subsubheading 썽크 표현하기 (Representing thunks)

우리의 평가자는 프로시저가 인자에 적용될 때 썽크를 생성하고 나중에 이 썽크들을 강제하도록 정리해야 한다.
썽크는 나중에 인자를 생성할 수 있도록 표현식을 환경과 함께 패키징해야 한다.
썽크를 강제하기 위해, 우리는 단순히 썽크에서 표현식과 환경을 추출하고 그 환경에서 표현식을 평가한다.
우리는 @code{eval} 대신 @code{actual_value}를 사용하는데, 표현식의 값 자체가 썽크인 경우 썽크가 아닌 것에 도달할 때까지 계속 강제하도록 하기 위해서이다:

@example
fn force_it(obj: Value) -> Result<Value, EvalError> @{
    match obj @{
        Value::Thunk @{ expr, env @} => @{
            // 결과가 또한 썽크인 경우를 대비해 재귀적으로 강제함
            actual_value(&expr, &env)
        @}
        other => Ok(other),  // 이미 값임
    @}
@}
@end example

@noindent
표현식을 환경과 함께 패키징하는 한 가지 쉬운 방법은 표현식과 환경을 포함하는 리스트를 만드는 것이다.
따라서 우리는 다음과 같이 썽크를 생성한다:

@example
fn delay_it(expr: Expr, env: Environment) -> Value @{
    Value::Thunk @{ expr, env @}
@}

// Value 열거형에서:
enum Value @{
    // ...다른 변형들...
    Thunk @{ expr: Expr, env: Environment @},
@}
@end example

@noindent
사실 우리 인터프리터에 대해 우리가 원하는 것은 이것이 아니라 메모화된 썽크이다.
썽크가 강제될 때, 우리는 저장된 표현식을 그 값으로 교체하고 @code{thunk} 태그를 변경하여 이미 평가된 것임을 인식할 수 있도록 함으로써 그것을 평가된 썽크로 바꿀 것이다.@footnote{표현식의 값이 계산되고 나면 썽크에서 @code{env}를 지우기도 한다는 점에 주목하라. 이것은 인터프리터가 반환하는 값에는 아무런 차이를 만들지 않는다. 그러나 더 이상 필요하지 않은 @code{env}에 대한 참조를 썽크에서 제거하면 이 구조가 @newterm{가비지 컬렉션(garbage-collected)}되어 그 공간이 재활용될 수 있게 해주므로 공간을 절약하는 데 도움이 된다. 이에 대해서는 @ref{5.3}에서 논의할 것이다.

이와 유사하게, @ref{3.5.1}의 메모화된 지연 객체에서도 불필요한 환경이 가비지 컬렉션되도록 허용할 수 있었을 것인데, @code{memo-proc}이 값을 저장한 후 프로시저 @code{proc} (@code{delay}가 평가된 환경을 포함하는)을 버리기 위해 @code{(set! proc '())}와 같은 작업을 하도록 함으로써 가능했을 것이다.}

@example
use std::cell::OnceCell;

// OnceCell을 사용한 메모화된 썽크
struct MemoizedThunk @{
    expr: Expr,
    env: Environment,
    cached: OnceCell<Value>,
@}

impl MemoizedThunk @{
    fn new(expr: Expr, env: Environment) -> Self @{
        Self @{ expr, env, cached: OnceCell::new() @}
    @}

    fn force(&self) -> Result<Value, EvalError> @{
        // OnceCell은 우리가 단 한 번만 평가하도록 보장함
        self.cached
            .get_or_try_init(|| actual_value(&self.expr, &self.env))
            .cloned()
    @}
@}

fn force_it_memoized(obj: &Value) -> Result<Value, EvalError> @{
    match obj @{
        Value::MemoThunk(thunk) => thunk.force(),
        Value::EvaluatedThunk(val) => Ok(val.clone()),
        other => Ok(other.clone()),
    @}
@}
@end example

@noindent
메모화를 사용하든 사용하지 않든 동일한 @code{delay_it} 프로시저가 작동한다는 점에 주목하라.

@quotation
@strong{@anchor{Exercise 4.27}연습문제 4.27:} 지연 평가자에 다음과 같은 정의를 입력한다고 가정해 보자:

@example
use std::cell::Cell;

let count = Cell::new(0);
fn id(x: i64, count: &Cell<i64>) -> i64 @{
    count.set(count.get() + 1);
    x
@}
@end example

다음 일련의 상호 작용에서 빠진 값들을 채우고, 당신의 답을 설명하라.@footnote{이 연습문제는 지연 평가와 부수 효과 사이의 상호 작용이 매우 혼란스러울 수 있음을 보여준다. 이것은 바로 @ref{Chapter 3}의 논의에서 기대할 수 있는 바이다.}

@example
let w = id(id(10, &count), &count);  // 지연: 아직 어떤 id도 호출되지 않음

// ;;; L-Eval input:
count.get()
// ;;; L-Eval value:
// @var{response}  (정의 도중 외부 id가 호출됨)

// ;;; L-Eval input:
w  // w를 강제함
// ;;; L-Eval value:
// @var{response}

// ;;; L-Eval input:
count.get()
// ;;; L-Eval value:
// @var{response}  (이제 두 id가 모두 호출됨)
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 4.28}연습문제 4.28:} @code{eval}은 연산자의 값을 강제하기 위해 @code{apply}에 전달하기 전에 @code{eval} 대신 @code{actual_value}를 사용하여 연산자를 평가한다. 이러한 강제의 필요성을 보여주는 예를 제시하라.

@noindent
@strong{@anchor{Exercise 4.29}연습문제 4.29:} 메모화가 없을 때보다 있을 때 훨씬 더 느리게 실행될 것으로 기대되는 프로그램을 보여라.
또한, @code{id} 프로시저가 @ref{Exercise 4.27}에서와 같이 정의되고 @code{count}가 0에서 시작하는 다음 상호 작용을 고려해 보자:

@example
fn square(x: i64) -> i64 @{ x * x @}

// ;;; L-Eval input:
square(id(10, &count))

// ;;; L-Eval value:
// @var{response}

// ;;; L-Eval input:
count.get()

// ;;; L-Eval value:
// @var{response}
@end example

평가자가 메모화할 때와 하지 않을 때 각각의 응답을 제시하라.
@end quotation

@quotation
@strong{@anchor{Exercise 4.30}연습문제 4.30:} 개과천선한 C 프로그래머인 Cy D. Fect는 지연 평가자가 시퀀스에 있는 표현식들을 강제하지 않기 때문에 일부 부수 효과가 절대 일어나지 않을 수도 있다는 점을 걱정하고 있다.
시퀀스의 마지막 표현식이 아닌 표현식의 값은 사용되지 않기 때문에(그 표현식은 변수에 대입하거나 출력하는 것과 같은 그 효과를 위해서만 존재함), 나중에 이 값이 사용되어 강제되게 할 일이 없을 것이다 (예: 원시 프로시저의 인자로서).
Cy는 따라서 시퀀스를 평가할 때 마지막 표현식을 제외한 시퀀스의 모든 표현식을 강제해야 한다고 생각한다.
그는 @ref{4.1.1}의 @code{eval_sequence}를 @code{eval} 대신 @code{actual_value}를 사용하도록 수정할 것을 제안한다:

@example
fn eval_sequence_cy(exps: &[Expr], env: &Environment) -> Result<Value, EvalError> @{
    if exps.len() == 1 @{
        eval(&exps[0], env)
    @} else @{
        // Cy의 버전: 마지막이 아닌 표현식들을 강제함
        actual_value(&exps[0], env)?;
        eval_sequence_cy(&exps[1..], env)
    @}
@}
@end example

@enumerate a

@item
Ben Bitdiddle은 Cy가 틀렸다고 생각한다. 그는 Cy에게 부수 효과가 있는 시퀀스의 중요한 예를 제공하는 @ref{Exercise 2.23}에서 설명된 @code{for-each} 프로시저를 보여준다:

@example
fn for_each<T, F>(proc: F, items: &[T])
where
    F: Fn(&T),
@{
    for item in items @{
        proc(item);
    @}
@}
@end example

그는 텍스트에 있는 평가자(원래의 @code{eval_sequence}를 사용한)가 이것을 올바르게 처리한다고 주장한다:

@example
// ;;; L-Eval input:
for_each(
    |x| println!("@{@}", x),
    &[57, 321, 88],
);
// 57
// 321
// 88

// ;;; L-Eval value:
// (단위 - for_each는 아무것도 반환하지 않음)
@end example

@code{for-each}의 동작에 대해 Ben이 왜 옳은지 설명하라.

@item
Cy는 @code{for-each} 예제에 대해 Ben이 옳다는 데 동의하지만, 그것이 그가 @code{eval_sequence}를 변경하겠다고 제안했을 때 생각했던 종류의 프로그램은 아니라고 말한다. 그는 지연 평가자에서 다음 두 프로시저를 정의한다:

@example
fn p1(mut x: Vec<i64>) -> Vec<i64> @{
    x.push(2);  // x를 변이시킴
    x           // 수정된 x를 반환함
@}

fn p2(mut x: Vec<i64>) -> Vec<i64> @{
    fn p<T>(_e: T, x: Vec<i64>) -> Vec<i64> @{ x @}
    // set! 표현식은 전달되지만 p의 본문에서 무시됨
    x.push(2);
    p((), x)
@}
@end example

원래의 @code{eval_sequence}를 사용했을 때 @code{(p1 1)}과 @code{(p2 1)}의 값은 무엇인가? Cy가 제안한 @code{eval_sequence} 변경 사항을 사용하면 그 값들은 무엇이 될 것인가?

@item
Cy는 또한 그가 제안한 대로 @code{eval_sequence}를 변경하는 것이 a 부분의 예제 동작에 영향을 주지 않는다는 점을 지적한다. 이것이 왜 사실인지 설명하라.

@item
지연 평가자에서 시퀀스가 어떻게 처리되어야 한다고 생각하는가? 당신은 Cy의 접근 방식, 텍스트의 접근 방식, 아니면 또 다른 접근 방식 중 무엇을 선호하는가?

@end enumerate
@end quotation

@quotation
@strong{@anchor{Exercise 4.31}연습문제 4.31:} 이 절에서 취한 접근 방식은 Scheme에 호환되지 않는 변경을 가하기 때문에 다소 불쾌하다.
지연 평가를 @newterm{상향 호환성 확장(upward-compatible extension)}으로 구현하는 것이 더 좋을 수 있는데, 즉 일반적인 Scheme 프로그램이 이전처럼 작동하도록 하는 것이다.
우리는 사용자가 인자를 지연시킬지 여부를 제어할 수 있도록 프로시저 선언의 구문을 확장함으로써 이를 수행할 수 있다.
이왕 하는 김에, 우리는 또한 사용자에게 메모화를 사용할지 말지 선택권을 줄 수도 있다. 예를 들어, 다음 정의는

@example
// Rust 접근 방식: 클로저나 OnceCell을 통한 명시적 지연성
fn f<B, D>(
    a: i64,                      // 엄격함 (즉시 평가됨)
    b: impl FnOnce() -> B,       // 지연됨 (클로저, 메모화되지 않음)
    c: i64,                      // 엄격함
    d: Lazy<D>,                  // 지연되고 메모화됨
) @{
    // ...
@}
@end example

@noindent
네 개의 인자를 받는 프로시저 @code{f}를 정의하는데, 첫 번째와 세 번째 인자는 프로시저가 호출될 때 평가되고, 두 번째 인자는 지연되고, 네 번째 인자는 지연되면서 동시에 메모화된다.
따라서 일반적인 프로시저 정의는 일반 Scheme과 동일한 동작을 생성할 것이며, 반면에 모든 복합 프로시저의 각 매개변수에 @code{lazy-memo} 선언을 추가하면 이 절에서 정의된 지연 평가자의 동작을 생성할 것이다.
Scheme에 이러한 확장을 생성하기 위해 필요한 변경 사항을 설계하고 구현하라.
새로운 정의 구문을 처리하기 위해 새로운 구문 프로시저를 구현해야 할 것이다.
또한 @code{eval}이나 @code{apply}가 언제 인자를 지연시켜야 할지 결정하고 그에 따라 인자를 강제하거나 지연시키도록 정리해야 하며, 강제할 때 적절하게 메모화할지 여부도 정리해야 한다.
@end quotation

@node	4.2.3, 4.2.5a, 4.2.2, 4.2
@subsection 지연 리스트로서의 스트림 (Streams as Lazy Lists)

@ref{3.5.1}에서 우리는 스트림을 지연된 리스트로 구현하는 방법을 보여주었다.
우리는 @code{delay}와 @code{cons-stream}이라는 특수 형식을 도입하여, 나중에까지 그 약속을 실제로 이행하지 않고도 스트림의 @code{cdr}을 계산하겠다는 ``약속(promise)''을 구성할 수 있게 했다.
우리는 평가 과정에 대해 더 많은 제어가 필요할 때마다 특수 형식을 도입하는 이 일반적인 기술을 사용할 수 있었지만, 이것은 번거롭다.
우선, 특수 형식은 프로시저와 같은 일급 객체(first-class object)가 아니므로 고차 프로시저와 함께 사용할 수 없다.@footnote{이것이 바로 @ref{Exercise 4.26}에서 다룬 @code{unless} 프로시저의 문제이기도 하다.}
또한, 우리는 스트림을 리스트와 유사하지만 동일하지는 않은 새로운 종류의 데이터 객체로 만들어야 했고, 이로 인해 스트림과 함께 사용하기 위해 많은 일반 리스트 연산(@code{map}, @code{append} 등)을 다시 구현해야 했다.

지연 평가를 사용하면 스트림과 리스트가 동일해질 수 있으므로, 특수 형식이나 별도의 리스트 및 스트림 연산이 필요하지 않다.
우리가 해야 할 일은 @code{cons}가 비엄격(non-strict)하도록 정리하는 것뿐이다.
이를 달성하는 한 가지 방법은 지연 평가자를 확장하여 비엄격한 원시 함수를 허용하고 @code{cons}를 그 중 하나로 구현하는 것이다.
더 쉬운 방법은 @code{cons}를 원시 함수로 구현할 근본적인 필요가 전혀 없음을 상기하는 것이다(@ref{2.1.3}).
대신, 우리는 쌍을 프로시저로 표현할 수 있다:@footnote{이것은 @ref{Exercise 2.4}에서 설명된 프로시저적 표현이다. 본질적으로 어떤 프로시저적 표현(예: 메시지 전달 구현)도 마찬가지로 작동할 것이다. 지연 평가자의 드라이버 루프에서 이 정의들을 입력하기만 하면 이 정의들을 설치할 수 있음에 주목하라. 만약 우리가 원래 전역 환경에 @code{cons}, @code{car}, @code{cdr}을 원시 함수로 포함시켰다면, 그것들은 재정의될 것이다. (또한 @ref{Exercise 4.33} 및 @ref{Exercise 4.34}를 보라.)}

@example
// 쌍의 프로시저적 표현 (Procedural representation of pairs)
fn cons<T, U>(x: T, y: U) -> impl Fn(fn(T, U) -> R) -> R
where
    T: Clone,
    U: Clone,
@{
    move |m| m(x.clone(), y.clone())
@}

fn car<T: Clone, U>(z: impl Fn(fn(T, U) -> T) -> T) -> T @{
    z(|p, _q| p)
@}

fn cdr<T, U: Clone>(z: impl Fn(fn(T, U) -> U) -> U) -> U @{
    z(|_p, q| q)
@}
@end example

@noindent
이러한 기본 연산들의 관점에서, 리스트 연산의 표준 정의는 유한한 리스트뿐만 아니라 무한한 리스트(스트림)에서도 작동할 것이며, 스트림 연산은 리스트 연산으로 구현될 수 있다. 다음은 몇 가지 예이다:

@example
// Rust 반복자를 사용하면 이것들은 자연스러운 연산이 된다
fn list_ref<T: Clone>(items: impl Iterator<Item = T>, n: usize) -> Option<T> @{
    items.skip(n).next()
@}

// map은 Iterator::map에 내장되어 있다
// scale은 단지 .map(|x| x * factor) 이다

fn add_lists(
    list1: impl Iterator<Item = i64>,
    list2: impl Iterator<Item = i64>,
) -> impl Iterator<Item = i64> @{
    list1.zip(list2).map(|(a, b)| a + b)
@}

// std::iter를 사용한 무한 스트림
let ones = std::iter::repeat(1);

let integers = std::iter::successors(Some(1), |n| Some(n + 1));

// ;;; L-Eval input:
integers.clone().nth(17)
// ;;; L-Eval value:
// Some(18)
@end example

@noindent
이 지연 리스트들은 @ref{Chapter 3}의 스트림보다 훨씬 더 지연된다는 점에 주목하라: 리스트의 @code{cdr}뿐만 아니라 @code{car}도 지연된다.@footnote{이것은 우리가 시퀀스뿐만 아니라 더 일반적인 종류의 리스트 구조의 지연 버전을 생성할 수 있게 해준다. @ref{Hughes 1990}은 ``지연 트리(lazy trees)''의 몇 가지 응용 분야를 논의한다.}
사실, 지연된 쌍의 @code{car}나 @code{cdr}에 접근하는 것조차 리스트 요소의 값을 강제할 필요가 없다.
그 값은 정말로 필요할 때만 --- 예를 들어 원시 함수의 인자로 사용되거나 답으로 출력될 때만 --- 강제될 것이다.

지연된 쌍은 또한 @ref{3.5.4}에서 스트림과 관련하여 발생했던 문제를 해결하는 데 도움이 된다. 거기서 우리는 루프가 있는 시스템의 스트림 모델을 구성할 때 프로그램에 @code{cons-stream}이 제공하는 것 이상의 명시적인 @code{delay} 연산을 흩뿌려야 할 수도 있음을 발견했다.
지연 평가를 사용하면 프로시저에 대한 모든 인자가 균일하게 지연된다.
예를 들어, 우리는 @ref{3.5.4}에서 원래 의도했던 대로 리스트를 적분하고 미분 방정식을 푸는 프로시저를 구현할 수 있다:

@example
// 지연 평가를 사용하면 순환 종속성이 자연스럽게 해결됨
fn solve<F>(f: F, y0: f64, dt: f64) -> impl Iterator<Item = f64>
where
    F: Fn(f64) -> f64,
@{
    // 자기 참조 스트림을 위해 successors 사용
    std::iter::successors(Some(y0), move |&y| @{
        let dy = f(y);
        Some(y + dy * dt)
    @})
@}

// ;;; L-Eval input:
solve(|x| x, 1.0, 0.001).nth(1000)

// ;;; L-Eval value:
// Some(2.716924...)  // e에 근사함
@end example

@quotation
@strong{@anchor{Exercise 4.32}연습문제 4.32:} @ref{Chapter 3}의 스트림과 이 절에서 설명된 ``더 지연된'' 지연 리스트 사이의 차이점을 보여주는 몇 가지 예를 제시하라.
이러한 추가적인 지연성을 어떻게 활용할 수 있는가?
@end quotation

@quotation
@strong{@anchor{Exercise 4.33}연습문제 4.33:} Ben Bitdiddle은 다음 표현식을 평가함으로써 위에 제시된 지연 리스트 구현을 테스트한다:

@example
// 인용된 리스트에 대해 프로시저적 car를 사용하려고 시도
car(quote!(a b c))  // 오류: 인용된 리스트는 클로저가 아님!
@end example

놀랍게도 이것은 오류를 생성한다.
잠시 생각한 후, 그는 인용된 표현식을 읽어 들여서 얻은 ``리스트''가 @code{cons}, @code{car}, @code{cdr}의 새로운 정의에 의해 조작되는 리스트와 다르다는 것을 깨닫는다.
드라이버 루프에서 입력된 인용된 리스트가 진정한 지연 리스트를 생성하도록 인용된 표현식에 대한 평가자의 처리를 수정하라.
@end quotation

@quotation
@strong{@anchor{Exercise 4.34}연습문제 4.34:} 지연된 쌍과 리스트가 합리적인 방식으로 출력되도록 평가자의 드라이버 루프를 수정하라. (무한 리스트에 대해 어떻게 할 것인가?)
또한 평가자가 지연된 쌍을 출력하기 위해 식별할 수 있도록 그것들의 표현을 수정해야 할 수도 있다.
@end quotation
@node	4.2.5a, 4.3, 4.2.3, 4.2
@subsection 영속적 데이터 구조와 구조적 공유 (Persistent Data Structures and Structural Sharing)

@cindex 영속적 데이터 구조 (persistent data structures)
@cindex 구조적 공유 (structural sharing)
@cindex 불변성 (immutability)
@cindex 함수형 프로그래밍 (functional programming)

이 장 전체에서 우리는 함수형 프로그래밍과 불변성의 힘을 강조해 왔다.
우리의 지연 리스트(스트림)는 기존 데이터를 절대 수정하지 않으며, 오래된 구조의 일부를 공유하는 새로운 구조를 만든다.
하지만 해시 맵, 세트, 벡터와 같은 더 복잡한 데이터 구조는 어떨까?
업데이트할 때마다 완전한 복사본을 만드는 것은 엄청나게 비용이 많이 들 것이다.

해결책은 @newterm{영속적 데이터 구조(persistent data structures)}이다: 수정될 때 이전 버전을 보존하면서, 불필요한 복사를 피하기 위해 버전 간에 구조를 공유하는 컬렉션이다.
이것은 불변성의 이점(@emph{모든} 과거 버전에 계속 접근 가능함)을 제공하면서도 가변 구조에 근접하는 성능을 제공한다.

@subsubheading ``영속적''이라는 말은 무엇을 의미하는가? (What Does ``Persistent'' Mean?)

@cindex 영속성 (데이터 구조) (persistence (data structures))
@cindex 덧없는 구조 (ephemeral structures)
@cindex 버전 기록 (version history)

데이터 구조의 문맥에서 @newterm{영속성(persistence)}은 데이터를 디스크에 저장하는 것과는 아무런 상관이 없다.
대신, 데이터 구조의 모든 버전이 수정 후에도 사용 가능한 상태로 유지됨을 의미한다.
영속적 구조를 ``업데이트''하면 @emph{새로운} 버전을 얻게 되지만, 이전 버전은 여전히 온전하고 사용 가능하다.

다음 두 가지 접근 방식을 비교해 보자:

@noindent
@b{덧없는(가변) 구조 (Ephemeral (mutable) structure):}
@example
let mut map = HashMap::new();
map.insert("a", 1);
map.insert("b", 2);
// 원래의 빈 맵은 사라짐 --- 접근할 수 없음
map.insert("c", 3);
// 요소가 두 개인 맵도 사라짐
@end example

@noindent
@b{영속적(불변) 구조 (Persistent (immutable) structure):}
@example
use im::HashMap;

let map0 = HashMap::new();
let map1 = map0.update("a", 1);
let map2 = map1.update("b", 2);
// map0, map1, and map2 are all still accessible!
let map3 = map2.update("c", 3);

assert_eq!(map0.len(), 0);  // Original is unchanged
assert_eq!(map1.len(), 1);  // First version is preserved
assert_eq!(map2.len(), 2);  // Second version is preserved
assert_eq!(map3.len(), 3);  // New version exists
@end example

@noindent
핵심 통찰은 @code{map1}, @code{map2}, @code{map3}가 내부 구조의 대부분을 @emph{공유(share)}한다는 것이다.
@code{map1}으로부터 @code{map2}를 생성할 때 전체 맵을 복사하지 않는다 --- 단지 변경 사항을 표현하는 데 필요한 아주 적은 양의 새로운 구조만 생성하고, @code{map1}의 데이터 대부분을 재사용한다.

@subsubheading Structural Sharing

@cindex structural sharing
@cindex memory efficiency
@cindex reference counting

@newterm{Structural sharing} is the technique that makes persistent data
structures efficient. Instead of copying entire structures, we share the
unchanged parts between versions.

Consider a simple example with a binary tree. When we insert a new element,
we create new nodes along the path from the root to the insertion point, but
we reuse all other nodes:

@example
     [Original tree]              [After inserting 6]
         5                              5
        / \                            / \
       3   8              =>          3   8
      / \                            / \   \
     1   4                          1   4   6
                                    ^   ^   ^
                                    |   |   |
                                 (shared nodes)
@end example

@noindent
In the new tree, nodes 1, 3, and 4 are @emph{the same nodes} as in the original
tree (not copies). Only the nodes along the path from root to the new element
(5 and 8) need to be copied, plus the new node (6). This is O(log n) new
structure for a tree with n elements.

In Rust, structural sharing is typically implemented using @code{Arc<T>}
(atomic reference counting), which allows multiple owners to share read-only
access to data:

@noindent
@b{Rust:}
@example
use std::sync::Arc;

#[derive(Clone)]
struct TreeNode<T> @{
    value: T,
    left: Option<Arc<TreeNode<T>>>,
    right: Option<Arc<TreeNode<T>>>,
@}

impl<T: Ord + Clone> TreeNode<T> @{
    fn insert(&self, new_value: T) -> Arc<Self> @{
        if new_value < self.value @{
            // 왼쪽 자식이 업데이트된 새로운 노드 생성
            Arc::new(TreeNode @{
                value: self.value.clone(),
                left: Some(match &self.left @{
                    Some(left) => left.insert(new_value),
                    None => Arc::new(TreeNode @{
                        value: new_value,
                        left: None,
                        right: None,
                    @}),
                @}),
                right: self.right.clone(),  // 오른쪽 서브트리는 공유됨
            @})
        @} else @{
            // 오른쪽 자식에 대해서도 유사함
            Arc::new(TreeNode @{
                value: self.value.clone(),
                left: self.left.clone(),  // 왼쪽 서브트리는 공유됨
                right: Some(match &self.right @{
                    Some(right) => right.insert(new_value),
                    None => Arc::new(TreeNode @{
                        value: new_value,
                        left: None,
                        right: None,
                    @}),
                @}),
            @})
        @}
    @}
@}
@end example

@noindent
@code{Arc<T>}를 복제(clone)하는 것은 저렴하며(단순히 참조 카운트를 증가시킴), 따라서 @code{self.left.clone()}과 @code{self.right.clone()}은 기존 서브트리를 공유하는 O(1) 연산이다.

@subsubheading @code{im} 크레이트 (The @code{im} Crate)

@cindex im 크레이트 (im crate)
@cindex 영속적 컬렉션 (persistent collections)
@cindex 불변 데이터 구조 (immutable data structures)

효율적인 영속적 데이터 구조를 처음부터 구현하는 것은 복잡하다.
@code{im} 크레이트(@url{https://docs.rs/im/})는 일반적인 영속적 컬렉션의 제품 수준 구현을 제공한다:

@itemize @bullet

@item
@code{im::Vector<T>} --- 영속적 벡터 (@code{Vec<T>}와 유사함)

@item
@code{im::HashMap<K, V>} --- 영속적 해시 맵

@item
@code{im::HashSet<T>} --- 영속적 해시 세트

@item
@code{im::OrdMap<K, V>} --- 영속적 정렬된 맵 (@code{BTreeMap}과 유사함)

@item
@code{im::OrdSet<T>} --- 영속적 정렬된 세트

@end itemize

@noindent
이것들을 예제로 살펴보자:

@noindent
@b{Rust:}
@example
use im::@{HashMap, Vector@};

// 영속적 벡터
let v0 = Vector::new();
let v1 = v0.push_back(1);
let v2 = v1.push_back(2);
let v3 = v2.push_back(3);

// 모든 버전이 공존함
assert_eq!(v0.len(), 0);
assert_eq!(v1.len(), 1);
assert_eq!(v2.len(), 2);
assert_eq!(v3.len(), 3);

// 구조적 공유를 통한 효율적인 복제
let v4 = v3.clone();
let v5 = v4.push_back(4);

// 영속적 해시 맵
let m0 = HashMap::new();
let m1 = m0.update("name", "Alice");
let m2 = m1.update("age", 30);
let m3 = m1.update("name", "Bob");  // m1에서 분기됨

assert_eq!(m2.get("name"), Some(&"Alice"));
assert_eq!(m3.get("name"), Some(&"Bob"));
assert_eq!(m2.get("age"), Some(&30));
assert_eq!(m3.get("age"), None);  // age가 추가되기 전에 분기됨
@end example

@noindent
@code{m2}와 @code{m3}가 @code{m1}으로부터 어떻게 분기되는지 주목하라 --- 그것들은 @code{m0}와 @code{m1}의 구조를 공유하지만, 그 이후에는 서로 다른 길을 간다. 이것이 영속성의 본질이다.

@subsubheading 쓰기 시 복사 의미론 (Copy-on-Write Semantics)

@cindex 쓰기 시 복사 (copy-on-write)
@cindex COW
@cindex 최적화 (optimization)

영속적 데이터 구조는 @newterm{쓰기 시 복사(copy-on-write, COW)} 의미론을 구현한다.
구조를 수정할 때 실제로 변경되는 부분만 복사되고, 나머지는 참조를 통해 공유된다.

이것은 Rust의 소유권 시스템과 결합될 때 특히 강력하다. 다음 패턴을 고려해 보자:

@noindent
@b{Rust:}
@example
use im::Vector;

fn process(v: Vector<i32>) -> Vector<i32> @{
    // v가 유일한 소유자라면, 변이는 제자리(in-place)에서 일어남
    // v가 공유되고 있다면, 먼저 복사본이 만들어짐
    v.push_back(42)
@}

let v1 = Vector::from(vec![1, 2, 3]);
let v2 = process(v1);  // v1이 이동(move)되었으므로 업데이트는 제자리에서 일어남

let v3 = Vector::from(vec![4, 5, 6]);
let v4 = v3.clone();
let v5 = process(v3);  // v3가 이동되었지만 v4가 여전히 공유하고 있으므로 복사가 발생함
@end example

@noindent
@code{im} 크레이트는 구조가 유일하게 소유되고 있는지 감지하기 위해 참조 카운팅을 사용한다.
만약 당신이 유일한 소유자라면 안전하게 제자리에서 변이할 수 있다 (많은 연산에 대해 O(1)).
구조가 공유되고 있다면 필요한 부분만 복사한다.

@subsubheading 성능 특성 (Performance Characteristics)

@cindex 성능 (영속적 구조) (performance (persistent structures))
@cindex 시간 복잡도 (time complexity)
@cindex 공간 복잡도 (space complexity)

영속적 데이터 구조는 가변 데이터 구조와 비교했을 때 다른 성능 특성을 갖는다:

@multitable @columnfractions .30 .35 .35
@headitem 연산 @tab 가변 (std) @tab 영속적 (im)
@item 벡터 푸시 (push) @tab O(1) 분할 상환 @tab O(log n) 최악의 경우
@item 벡터 임의 접근 @tab O(1) @tab O(log n) 최악의 경우
@item 해시맵 삽입 @tab O(1) 평균 @tab O(log n) 최악의 경우
@item 해시맵 조회 @tab O(1) 평균 @tab O(log n) 최악의 경우
@item 전체 구조 복제 (clone) @tab O(n) @tab O(1)
@end multitable

@noindent
주요 트레이드오프는 다음과 같다:

@itemize @bullet

@item
@b{가변 구조:} 빠른 업데이트(O(1))가 가능하지만 복제 비용이 비싸고(O(n)) 모든 버전이 공존할 수 없다.

@item
@b{영속적 구조:} 업데이트가 더 느리지만(O(log n)) 복제 비용이 저렴하고(O(1)) 모든 버전을 계속 사용할 수 있다.

@end itemize

@noindent
@code{im::Vector}의 경우, O(log n)은 매우 작은 상수 인자를 갖는다.
이 벡터는 32의 분기 계수를 가진 @newterm{RRB-트리(RRB-trees, Relaxed Radix Balanced trees)}라는 기술을 사용하므로, 백만 개의 요소에 대해서도 log@math{_{32}}(1,000,000) @math{\approx} 4회의 연산만 필요하다.

@noindent
@code{im::HashMap}의 경우, 구현에 @newterm{HAMT(Hash Array Mapped Trie)}를 사용하는데, 이는 뛰어난 캐시 지역성과 낮은 상수 인자를 가진 O(log n) 연산을 제공한다.

@subsubheading 영속적 구조 대 가변 구조 사용 시기 (When to Use Persistent vs Mutable Structures)

@cindex 설계 결정 (design decisions)
@cindex 트레이드오프 (trade-offs)

다음과 같은 경우 영속적 구조를 선택하라:

@itemize @bullet

@item
@emph{버전 기록}을 유지해야 할 때 (실행 취소/다시 실행, 타임 트래블 디버깅)

@item
You're implementing @emph{functional algorithms} (recursive tree traversal,
backtracking)

@item
You need @emph{cheap snapshots} (checkpointing, forking state)

@item
You're building an @emph{evaluator} or @emph{interpreter} (environment frames
that need to be extended without mutation)

@item
You're working with @emph{concurrent} or @emph{parallel} code where sharing
immutable data is easier than locking mutable data

@item
The structure is @emph{small to medium} sized (< 10,000 elements) where
O(log n) vs O(1) doesn't dominate

@end itemize

@noindent
Choose mutable structures when:

@itemize @bullet

@item
You're doing @emph{hot-path} operations where O(1) vs O(log n) matters

@item
You're working with @emph{large structures} (millions of elements)

@item
You only need the @emph{current version} (no history needed)

@item
You're doing many @emph{sequential updates} to the same structure

@item
@emph{Memory} is constrained (mutable structures have lower overhead)

@end itemize

@subsubheading Connection to the Metacircular Evaluator

@cindex metacircular evaluator
@cindex environment frames
@cindex functional state

In @ref{4.1, , The Metacircular Evaluator}, we implemented environments as
lists of frames. Each frame is a mapping from variables to values. When we
evaluate a @code{lambda}, we extend the environment with a new frame:

@noindent
@b{Rust (using standard library):}
@example
use std::collections::HashMap;

#[derive(Clone)]
struct Environment @{
    frames: Vec<HashMap<String, Value>>,
@}

impl Environment @{
    fn extend(&self, bindings: Vec<(String, Value)>) -> Self @{
        let mut new_frames = self.frames.clone();  // O(n) copy!
        let frame: HashMap<String, Value> = bindings.into_iter().collect();
        new_frames.push(frame);
        Environment @{ frames: new_frames @}
    @}
@}
@end example

@noindent
This works, but @code{self.frames.clone()} copies the @emph{entire} environment
chain on every function call. For deeply nested calls, this becomes expensive.

@noindent
@b{Rust (using persistent structures):}
@example
use im::@{HashMap, Vector@};

#[derive(Clone)]
struct Environment @{
    frames: Vector<HashMap<String, Value>>,
@}

impl Environment @{
    fn extend(&self, bindings: Vec<(String, Value)>) -> Self @{
        let frame: HashMap<String, Value> = bindings.into_iter().collect();
        Environment @{
            frames: self.frames.push_back(frame),  // O(log n), shares structure!
        @}
    @}

    fn lookup(&self, name: &str) -> Option<&Value> @{
        // Search frames from most recent to oldest
        self.frames.iter().rev()
            .find_map(|frame| frame.get(name))
    @}
@}
@end example

@noindent
Now extending the environment is much cheaper. The new @code{frames} vector
shares all the old frames with the parent environment. This is exactly the
kind of structural sharing we want for functional programming.

@subsubheading 불변성과 동시성 (Immutability and Concurrency)

@cindex 동시성 (concurrency)
@cindex 스레드 안전 (thread safety)
@cindex 병렬성 (parallelism)

영속적 데이터 구조는 동시성 문맥에서 빛을 발한다. 불변이기 때문에 락(lock) 없이 스레드 간에 안전하게 공유될 수 있다:

@noindent
@b{Rust:}
@example
use im::HashMap;
use std::sync::Arc;
use std::thread;

let shared_map = Arc::new(HashMap::from([
    ("a", 1),
    ("b", 2),
    ("c", 3),
]));

let handles: Vec<_> = (0..4).map(|i| @{
    let map = Arc::clone(&shared_map);
    thread::spawn(move || @{
        // 각 스레드는 락 없이 읽을 수 있음
        let value = map.get("a").copied().unwrap_or(0);
        let new_map = map.update("d", value + i);
        // 각 스레드는 "d"가 삽입된 자신만의 버전을 얻음
        new_map
    @})
@}).collect();

for handle in handles @{
    let result = handle.join().unwrap();
    println!("스레드가 @{@}개의 엔트리를 가진 맵을 생성함", result.len());
@}
@end example

@noindent
각 스레드는 동기화 없이 @code{shared_map}으로부터 읽을 수 있고, 다른 스레드에 영향을 주지 않고 자신만의 수정된 버전을 만들 수 있다. 락도, 데이터 경합도, 조정도 필요하지 않다.

@subsubheading 고급: 간단한 영속적 리스트 구현하기 (Advanced: Implementing a Simple Persistent List)

@cindex 영속적 리스트 (persistent list)
@cindex 구조적 공유 (예제) (structural sharing (example))

영속성이 내부적으로 어떻게 작동하는지 이해하기 위해, @code{Arc}를 사용하여 간단한 영속적 단일 연결 리스트를 구현해 보자:

@noindent
@b{Rust:}
@example
use std::sync::Arc;

#[derive(Clone)]
pub struct List<T> @{
    head: Option<Arc<Node<T>>>,
@}

struct Node<T> @{
    value: T,
    next: Option<Arc<Node<T>>>,
@}

impl<T: Clone> List<T> @{
    pub fn new() -> Self @{
        List @{ head: None @}
    @}

    pub fn push_front(&self, value: T) -> Self @{
        List @{
            head: Some(Arc::new(Node @{
                value,
                next: self.head.clone(),  // 꼬리를 공유함!
            @})),
        @}
    @}

    pub fn head(&self) -> Option<&T> @{
        self.head.as_ref().map(|node| &node.value)
    @}

    pub fn tail(&self) -> List<T> @{
        List @{
            head: self.head.as_ref().and_then(|node| node.next.clone()),
        @}
    @}
@}

// 사용법:
let list1 = List::new();
let list2 = list1.push_front(1);
let list3 = list2.push_front(2);
let list4 = list2.push_front(3);  // list2에서 분기됨

assert_eq!(list3.head(), Some(&2));
assert_eq!(list4.head(), Some(&3));
assert_eq!(list3.tail().head(), Some(&1));
assert_eq!(list4.tail().head(), Some(&1));  // 공유된 꼬리
@end example

@noindent
@code{list3}와 @code{list4}는 1을 포함하는 노드(그리고 그 뒤의 모든 것)를 공유한다. 첫 번째 노드만 다르다. 이것이 바로 구조적 공유가 실제로 작동하는 방식이다.

@subsubheading 영속적 벡터: 더 깊이 들여다보기 (Persistent Vectors: A Deeper Look)

@cindex RRB-트리 (RRB-trees)
@cindex 영속적 벡터 (persistent vectors)
@cindex 트라이 (trie)

@code{im::Vector}는 연결 리스트보다 더 정교하다. 이것은 @newterm{RRB-트리(RRB-tree)}를 사용하는데, 이는 다음을 제공한다:

@itemize @bullet

@item
O(log n) 인덱스 접근 (O(n)인 연결 리스트와 다름)

@item
O(log n) 업데이트

@item
O(1) 복제 (cloning)

@item
효율적인 이어붙이기 (O(n) 대신 O(log n))

@end itemize

@noindent
핵심 아이디어는 각 노드가 최대 32개의 자식을 갖는 트리에 요소들을 저장하는 것이다. 100번째 요소에 접근하려면:

@enumerate 1
@item 100 / 32 = 3을 계산 (최상위 레벨에서 3번째 자식으로 이동)
@item (100 % 32) / 32 = 0을 계산 (다음 레벨에서 0번째 자식으로 이동)
@item 리프 노드에서 100 % 32 = 4번째 요소에 접근
@end enumerate

@noindent
요소를 업데이트할 때, 루트에서 해당 요소까지의 경로에 있는 노드들만 복사되고 다른 모든 노드들은 공유된다. 백만 개의 요소가 있는 벡터의 경우, 업데이트당 약 4개의 노드(레벨당 하나씩)만 복사된다.

@subsubheading 표준 라이브러리와의 비교 (Comparison with Standard Library)

@cindex std::collections
@cindex 성능 비교 (performance comparison)

다음은 @code{Vec}과 @code{im::Vector}의 실질적인 비교이다:

@noindent
@b{Rust:}
@example
use im::Vector as PersistentVec;

// 표준 라이브러리 Vec
let mut std_vec = Vec::new();
std_vec.push(1);
std_vec.push(2);
let std_vec_copy = std_vec.clone();  // O(n) 전체 복사
std_vec.push(3);
// std_vec와 std_vec_copy는 이제 독립적임

// 영속적 벡터
let persistent_vec = PersistentVec::new();
let persistent_vec = persistent_vec.push_back(1);
let persistent_vec = persistent_vec.push_back(2);
let vec_copy = persistent_vec.clone();  // O(1) 공유
let persistent_vec = persistent_vec.push_back(3);
// 두 버전이 구조를 공유하며 공존함
@end example

@noindent
벤치마크 결과 (대략적이며 사용 사례에 따라 다름):

@itemize @bullet

@item
@b{복제 (Clone):} 큰 벡터의 경우 @code{Vec::clone()}이 1000배 더 느림

@item
@b{푸시 (Push):} @code{Vec::push()}가 @code{Vector::push_back()}보다 2-5배 더 빠름

@item
@b{접근 (Access):} @code{Vec[i]}가 @code{Vector::get(i)}보다 2-3배 더 빠름

@item
@b{메모리:} @code{Vector}가 트리 구조 때문에 약 1.5-2배 더 많은 메모리를 사용함

@end itemize

@quotation
@strong{@anchor{Exercise 4.28a}연습문제 4.28a:} 구조적 공유를 사용하여 영속적 이진 탐색 트리를 구현하라. 당신의 트리는 다음을 지원해야 한다:

@example
pub struct PersistentBST<T> @{
    root: Option<Arc<Node<T>>>,
@}

impl<T: Ord + Clone> PersistentBST<T> @{
    pub fn new() -> Self;
    pub fn insert(&self, value: T) -> Self;
    pub fn contains(&self, value: &T) -> bool;
    pub fn remove(&self, value: &T) -> Self;
@}
@end example

@enumerate a

@item
원본 트리와 가능한 한 많은 구조를 공유하면서 하나의 요소가 추가된 새로운 트리를 생성하도록 @code{insert}를 구현하라.

@item
하나의 요소가 제거된 새로운 트리를 생성하도록 @code{remove}를 구현하라. 자식이 두 개인 노드를 제거하려면 구조 재편이 필요하다는 점이 도전 과제이다. 어떻게 하면 새로 생성되는 구조의 양을 최소화할 수 있겠는가?

@item
요소의 개수를 반환하는 @code{size(&self) -> usize} 메서드를 추가하라. 이것은 O(1) 시간에 실행되어야 하며, 이는 각 노드에 크기를 저장해야 함을 의미한다. 이것이 왜 구조적 공유를 위반하지 않는지 설명하라.

@end enumerate
@end quotation

@quotation
@strong{@anchor{Exercise 4.29a}연습문제 4.29a:} 메타순환 평가자의 환경을 구현하기 위해 영속적 구조와 가변 구조를 비교하라.

@enumerate a

@item
환경의 두 가지 버전을 구현하라: 하나는 @code{Vec<HashMap>} (가변)을 사용하고, 다른 하나는 @code{im::Vector<im::HashMap>} (영속적)을 사용한다.

@item
깊게 재귀적인 함수(예: 순진한 재귀 알고리즘을 사용하여 20번째 피보나치 수 계산)를 평가하는 벤치마크를 작성하라. 두 구현 모두에 대해 총 시간과 메모리 사용량을 측정하라.

@item
결과를 설명하라. 어떤 시나리오에서 영속적 버전이 더 빠르겠는가? 어떤 시나리오에서 가변 버전이 더 빠르겠는가?

@item
평가자가 ``타임 트래블'' --- 환경을 임의의 이전 상태로 되돌리는 능력 --- 을 지원하도록 수정하라. 이것은 영속적 구조에서는 사소하지만 가변 구조에서는 상당한 작업이 필요하다. 둘 다 구현해 보고 복잡성을 비교하라.

@end enumerate
@end quotation


@node	4.3, 4.4, 4.2.5a, Chapter 4
@section Scheme의 변형 --- 비결정적 컴퓨팅 (Variations on a Scheme --- Nondeterministic Computing)

이 절에서 우리는 자동 검색을 지원하는 기능을 평가자에 구축함으로써, @newterm{비결정적 컴퓨팅(nondeterministic computing)}이라고 불리는 프로그래밍 패러다임을 지원하도록 Scheme 평가자를 확장한다.
이것은 @ref{4.2}에서 지연 평가를 도입한 것보다 훨씬 더 근본적인 언어의 변화이다.

비결정적 컴퓨팅은 스트림 처리와 마찬가지로 ``생성 및 테스트(generate and test)'' 응용 프로그램에 유용하다.
두 개의 양의 정수 리스트에서 시작하여, 첫 번째 리스트에서 하나, 두 번째 리스트에서 하나를 골라 그 합이 소수인 정수 쌍을 찾는 작업을 고려해 보자.
우리는 @ref{2.2.3}에서 유한 시퀀스 연산으로, @ref{3.5.3}에서 무한 스트림으로 이를 처리하는 방법을 보았다.
우리의 접근 방식은 가능한 모든 쌍의 시퀀스를 생성하고 합이 소수인 쌍을 선택하기 위해 필터링하는 것이었다.
우리가 실제로 @ref{Chapter 2}에서처럼 쌍의 전체 시퀀스를 먼저 생성하든, 아니면 @ref{Chapter 3}에서처럼 생성과 필터링을 엇갈리게 수행하든, 계산이 어떻게 구성되는지에 대한 본질적인 이미지에는 중요하지 않다.

비결정적 접근 방식은 다른 이미지를 불러일으킨다.
단순히 첫 번째 리스트에서 숫자 하나를 선택하고(어떤 방식으로든), 두 번째 리스트에서 숫자 하나를 선택한 후, (어떤 메커니즘을 사용하여) 그 합이 소수일 것을 요구한다고 상상해 보라.
이것은 다음 프로시저로 표현된다:

@example
// 비결정적 선택 - Rust에서는 백트래킹이 있는 반복자를 사용할 것이다
fn prime_sum_pair(list1: &[i64], list2: &[i64]) -> Option<(i64, i64)> @{
    for &a in list1 @{
        for &b in list2 @{
            if is_prime(a + b) @{
                return Some((a, b));
            @}
        @}
    @}
    None
@}
@end example

@noindent
이 프로시저는 문제를 해결하는 방법을 명시하기보다는 단순히 문제를 다시 기술하는 것처럼 보일 수 있다.
그럼에도 불구하고, 이것은 정당한 비결정적 프로그램이다.@footnote{우리는 숫자가 소수인지 테스트하는 @code{is_prime} 프로시저를 이전에 정의했다고 가정한다. @code{is_prime}이 정의되어 있더라도, @code{prime_sum_pair} 프로시저는 @ref{1.1.7}의 시작 부분에서 설명한 제곱근 함수를 정의하려는 도움이 되지 않는 ``의사-Lisp(pseudo-Lisp)'' 시도와 비슷해 보일 수 있다. 사실, 그러한 라인의 제곱근 프로시저는 실제로 비결정적 프로그램으로 공식화될 수 있다. 평가자에 검색 메커니즘을 통합함으로써, 우리는 순수하게 선언적인 설명과 답을 계산하는 방법에 대한 명령적인 명세 사이의 구분을 허물고 있다. 우리는 @ref{4.4}에서 이 방향으로 더 나아갈 것이다.}

여기서 핵심 아이디어는 비결정적 언어의 표현식이 하나 이상의 가능한 값을 가질 수 있다는 것이다.
예를 들어, @code{an_element_of}는 주어진 리스트의 임의의 요소를 반환할 수 있다.
우리의 비결정적 프로그램 평가자는 자동으로 가능한 값을 선택하고 그 선택을 추적함으로써 작동할 것이다.
만약 후속 요구 사항이 충족되지 않으면, 평가자는 다른 선택을 시도할 것이며, 평가가 성공하거나 선택지가 바닥날 때까지 계속 새로운 선택을 시도할 것이다.
지연 평가자가 프로그래머를 값이 어떻게 지연되고 강제되는지에 대한 세부 사항으로부터 해방시켰듯이, 비결정적 프로그램 평가자는 프로그래머를 선택이 어떻게 이루어지는지에 대한 세부 사항으로부터 해방시킬 것이다.

비결정적 평가와 스트림 처리가 불러일으키는 시간의 서로 다른 이미지를 대조해 보는 것은 유익하다.
스트림 처리는 가능한 답의 스트림이 조립되는 시점과 실제 스트림 요소가 생성되는 시점을 분리하기 위해 지연 평가를 사용한다.
평가자는 가능한 모든 답이 시대를 초월한 시퀀스로 우리 앞에 펼쳐져 있다는 환상을 지원한다.
비결정적 평가에서 표현식은 일련의 선택에 의해 결정되는 가능한 세계들의 집합에 대한 탐색을 나타낸다.
가능한 세계들 중 일부는 막다른 골목으로 이어지지만, 다른 세계들은 유용한 값을 갖는다.
비결정적 프로그램 평가자는 시간이 갈라지고, 우리의 프로그램이 서로 다른 가능한 실행 이력을 갖는다는 환상을 지원한다.
우리가 막다른 골목에 도달하면, 이전 선택 지점을 다시 방문하여 다른 분기를 따라 진행할 수 있다.

아래에서 구현된 비결정적 프로그램 평가자는 @code{amb}라고 불리는 새로운 특수 형식에 기초하기 때문에 @code{amb} 평가자라고 불린다.
우리는 위에서 정의한 @code{prime_sum_pair}를 @code{amb} 평가자 드라이버 루프에서 입력하고(@code{is_prime}, @code{an_element_of}, @code{require}의 정의와 함께) 다음과 같이 프로시저를 실행할 수 있다:

@example
// ;;; Amb-Eval input:
prime_sum_pair(&[1, 3, 5, 8], &[20, 35, 110])

// ;;; Starting a new problem
// ;;; Amb-Eval value:
// Some((3, 20))  // 3 + 20 = 23이며, 이는 소수임
@end example

@noindent
반환된 값은 평가자가 성공적인 선택이 이루어질 때까지 각 리스트에서 요소를 반복적으로 선택한 후에 얻은 것이다.

@ref{4.3.1}에서는 @code{amb}를 소개하고 그것이 평가자의 자동 검색 메커니즘을 통해 비결정성을 어떻게 지원하는지 설명한다.
@ref{4.3.2}에서는 비결정적 프로그램의 예들을 제시하며, @ref{4.3.3}에서는 일반적인 Scheme 평가자를 수정하여 @code{amb} 평가자를 구현하는 방법의 세부 사항을 다룬다.

@menu
* 4.3.1::            Amb와 검색 (Amb and Search)
* 4.3.2::            비결정적 프로그램의 예 (Examples of Nondeterministic Programs)
* 4.3.3::            @code{Amb} 평가자 구현하기 (Implementing the @code{Amb} Evaluator)
@end menu

@node	4.3.1, 4.3.2, 4.3, 4.3
@subsection Amb와 검색 (Amb and Search)

비결정성을 지원하도록 Scheme을 확장하기 위해, 우리는 @code{amb}라고 불리는 새로운 특수 형식을 도입한다.@footnote{비결정적 프로그래밍을 위한 @code{amb}의 아이디어는 1961년 John McCarthy에 의해 처음 기술되었다 (@ref{McCarthy 1963} 참조).}
표현식

@example
amb![@var{e_1}, @var{e_2}, @dots{}, @var{e_n}]
@end example

@noindent
은 @math{n}개의 표현식 @math{{⟨\kern0.03em e_i⟩}} 중 하나의 값을 ``모호하게'' 반환한다.
예를 들어, 표현식

@example
// 반복자를 통한 모든 가능한 조합
[1, 2, 3].iter()
    .flat_map(|&n| ["a", "b"].iter().map(move |&c| (n, c)))
    .collect::<Vec<_>>()
@end example

@noindent
은 여섯 개의 가능한 값을 가질 수 있다:

@example
@code{(1 a)} @code{(1 b)} @code{(2 a)} @code{(2 b)} @code{(3 a)} @code{(3 b)}
@end example

@noindent
단일 선택지가 있는 @code{amb}는 일반적인(단일) 값을 생성한다.

선택지가 없는 @code{amb} --- 표현식 @code{(amb)} --- 는 받아들일 수 있는 값이 없는 표현식이다.
조작적으로 우리는 @code{(amb)}를 평가될 때 계산을 ``실패''하게 만드는 표현식으로 생각할 수 있다: 계산이 중단되고 아무런 값도 생성되지 않는다.
이 아이디어를 사용하여, 특정 술어 표현식 @code{p}가 참이어야 한다는 요구 사항을 다음과 같이 표현할 수 있다:

@example
// 필터로서의 require - 술어가 거짓이면 실패함
fn require(p: bool) -> Result<(), Backtrack> @{
    if p @{ Ok(()) @} else @{ Err(Backtrack) @}
@}
@end example

@noindent
@code{amb}와 @code{require}를 사용하여, 위에서 사용된 @code{an_element_of} 프로시저를 구현할 수 있다:

@example
// 반복자를 통한 an_element_of - 백트래킹을 위해 각 요소를 산출함
fn an_element_of<T: Clone>(items: &[T]) -> impl Iterator<Item = T> + '_ @{
    items.iter().cloned()
@}
@end example

@noindent
@code{an_element_of}는 리스트가 비어 있으면 실패한다.
그렇지 않으면 리스트의 첫 번째 요소를 반환하거나 리스트의 나머지에서 선택된 요소를 모호하게 반환한다.

우리는 또한 무한한 범위의 선택지를 표현할 수 있다.
다음 프로시저는 주어진 @math{n}보다 크거나 같은 임의의 정수를 잠재적으로 반환한다:

@example
// n에서 시작하는 무한 정수 스트림
fn an_integer_starting_from(n: i64) -> impl Iterator<Item = i64> @{
    std::iter::successors(Some(n), |&x| Some(x + 1))
@}
@end example

@noindent
이것은 @ref{3.5.2}에서 설명된 스트림 프로시저 @code{integers-starting-from}과 비슷하지만, 중요한 차이점이 있다: 스트림 프로시저는 @math{n}으로 시작하는 모든 정수의 시퀀스를 나타내는 객체를 반환하는 반면, @code{amb} 프로시저는 단일 정수를 반환한다.@footnote{사실상, 단일 선택지를 비결정적으로 반환하는 것과 모든 선택지를 반환하는 것 사이의 구분은 다소 우리의 관점에 달려 있다. 값을 사용하는 코드의 관점에서, 비결정적 선택은 단일 값을 반환한다. 코드를 설계하는 프로그래머의 관점에서, 비결정적 선택은 잠재적으로 가능한 모든 값을 반환하며, 계산이 분기되어 각 값이 개별적으로 조사된다.}

추상적으로, 우리는 @code{amb} 표현식을 평가하는 것이 시간이 여러 분기로 나뉘게 하여, 계산이 표현식의 가능한 값들 중 하나를 가지고 각 분기에서 계속되게 한다고 상상할 수 있다.
우리는 @code{amb}가 @newterm{비결정적 선택 지점(nondeterministic choice point)}을 나타낸다고 말한다.
만약 우리가 동적으로 할당될 수 있는 충분한 수의 프로세서를 가진 기계를 가지고 있다면, 우리는 검색을 간단한 방식으로 구현할 수 있을 것이다.
실행은 @code{amb} 표현식을 만날 때까지 순차적 기계에서와 같이 진행될 것이다.
이 지점에서 더 많은 프로세서가 할당되고 초기화되어 선택에 의해 암시된 모든 병렬 실행을 계속할 것이다.
각 프로세서는 그것이 유일한 선택인 것처럼 순차적으로 진행될 것이며, 실패를 만나서 종료되거나, 더 세분화되거나, 또는 끝날 때까지 계속될 것이다.@footnote{이것이 가망 없을 정도로 비효율적인 메커니즘이라고 반대할 수도 있다. 쉽게 기술된 어떤 문제를 이런 방식으로 풀기 위해 수백만 개의 프로세서가 필요할 수도 있고, 대부분의 시간 동안 그 프로세서들 중 대부분은 유휴 상태일 것이다. 이 반대는 역사의 맥락에서 받아들여져야 한다. 메모리 또한 예전에는 그와 같이 비싼 상품으로 여겨졌다. 1964년에 1MB의 RAM 비용은 약 $400,000였다. 이제 모든 개인용 컴퓨터는 수많은 MB의 RAM을 가지고 있으며, 대부분의 시간 동안 그 RAM의 대부분은 사용되지 않는다. 대량 생산된 전자 제품의 비용을 과소평가하기는 어렵다.}

반면에, 우리가 하나의 프로세스(또는 몇 개의 동시 프로세스)만 실행할 수 있는 기계를 가지고 있다면, 우리는 대안들을 순차적으로 고려해야 한다.
선택 지점을 만날 때마다 따라갈 분기를 무작위로 고르도록 평가자를 수정하는 것을 상상할 수 있다.
그러나 무작위 선택은 쉽게 실패하는 값으로 이어질 수 있다.
우리는 무작위 선택을 하며 평가자를 계속해서 실행하여 실패하지 않는 값을 찾기를 희망할 수도 있지만, 모든 가능한 실행 경로를 @newterm{체계적으로 검색(systematically search)}하는 것이 더 낫다.
우리가 이 절에서 개발하고 작업할 @code{amb} 평가자는 다음과 같이 체계적인 검색을 구현한다: 평가자가 @code{amb}의 적용을 만나면, 처음에는 첫 번째 대안을 선택한다.
이 선택 자체가 추가적인 선택으로 이어질 수 있다.
평가자는 항상 각 선택 지점에서 처음에는 첫 번째 대안을 선택할 것이다.
만약 어떤 선택이 실패로 끝나면, 평가자는 자동으로@footnote{@anchor{Footnote 250}자동적으로(Automagically): ``자동으로, 하지만 어떤 이유에서인지(보통 너무 복잡하거나, 너무 추하거나, 아니면 심지어 너무 사소해서) 화자가 설명하고 싶지 않은 방식으로.'' (@ref{Steele et al. 1983}, @ref{Raymond 1993})} 가장 최근의 선택 지점으로 @newterm{백트래킹(backtracks)}하여 다음 대안을 시도한다.
만약 어떤 선택 지점에서 대안이 바닥나면, 평가자는 이전 선택 지점으로 물러나 그곳에서부터 다시 시작한다.
이 프로세스는 @newterm{깊이 우선 검색(depth-first search)} 또는 @newterm{연대순 백트래킹(chronological backtracking)}으로 알려진 검색 전략으로 이어진다.@footnote{자동 검색 전략을 프로그래밍 언어에 통합하는 것은 길고 파란만장한 역사를 가지고 있다. 비결정적 알고리즘이 검색과 자동 백트래킹이 있는 프로그래밍 언어에서 우아하게 인코딩될 수 있다는 첫 번째 제안은 Robert @ref{Floyd (1967)}로부터 나왔다. Carl @ref{Hewitt (1969)}는 자동 연대순 백트래킹을 명시적으로 지원하는 Planner라는 프로그래밍 언어를 발명하여 내장된 깊이 우선 검색 전략을 제공했다. @ref{Sussman et al. (1971)}은 문제 해결과 로봇 계획 작업을 지원하기 위해 사용된 MicroPlanner라고 불리는 이 언어의 부분 집합을 구현했다. 논리와 정리 증명에서 유래한 비슷한 아이디어들은 에든버러와 마르세유에서 우아한 언어인 Prolog의 탄생으로 이어졌다(@ref{4.4}에서 논의할 것이다). 자동 검색에 대한 충분한 좌절 후에, @ref{McDermott and Sussman (1972)}은 검색 전략을 프로그래머의 제어 하에 두기 위한 메커니즘을 포함하는 Conniver라고 불리는 언어를 개발했다. 그러나 이것은 다루기 힘들다는 것이 입증되었고, @ref{Sussman and Stallman 1975}는 전기 회로를 위한 기호 분석 방법을 조사하던 중 더 다루기 쉬운 접근 방식을 발견했다. 그들은 사실들을 연결하는 논리적 의존성을 추적하는 것에 기반한 비연대순 백트래킹 체계를 개발했는데, 이 기술은 @newterm{의존성 주도 백트래킹(dependency-directed backtracking)}으로 알려지게 되었다. 그들의 방법은 복잡했지만, 중복된 검색을 거의 하지 않았기 때문에 상당히 효율적인 프로그램을 생성했다. @ref{Doyle (1979)}과 @ref{McAllester (1978; 1980)}는 Stallman과 Sussman의 방법들을 일반화하고 명확히 하여, 현재 @newterm{진실 유지(truth maintenance)}라고 불리는 검색을 공식화하는 새로운 패러다임을 개발했다. 현대의 문제 해결 시스템들은 모두 어떤 형태의 진실 유지 시스템을 토대로 사용한다. 진실 유지 시스템을 구축하는 우아한 방법들과 진실 유지를 사용한 응용 프로그램들에 대한 논의는 @ref{Forbus and deKleer 1993}을 보라. @ref{Zabih et al. 1987}은 @code{amb}에 기초한 Scheme의 비결정적 확장을 설명한다; 이것은 이 절에서 설명된 인터프리터와 비슷하지만, 연대순 백트래킹 대신 의존성 주도 백트래킹을 사용하기 때문에 더 정교하다. @ref{Winston 1992}는 두 종류의 백트래킹에 대한 입문을 제공한다.}

@subsubheading 드라이버 루프 (Driver loop)

@code{amb} 평가자를 위한 드라이버 루프는 몇 가지 특이한 속성을 갖는다.
그것은 표현식을 읽고 위에서 보여준 @code{prime_sum_pair} 예제에서처럼 첫 번째 실패하지 않은 실행의 값을 출력한다.
만약 우리가 다음 성공적인 실행의 값을 보고 싶다면, 우리는 인터프리터에게 백트래킹하여 두 번째 실패하지 않은 실행을 생성하도록 시도할 것을 요청할 수 있다.

Rust에서 이러한 종류의 비결정적 검색은 자연스럽게 @code{Iterator}를 사용하여 모델링된다.
성공은 @code{Some} 값(또는 반복의 요소)에 해당하고, 실패는 @code{None}(또는 빈 반복자)에 해당한다.
백트래킹은 단순히 반복자에 대해 @code{next()}를 호출함으로써 달성된다.

@example
// Rust에서 우리는 모든 해를 생성하기 위해 반복자를 사용한다
let mut solutions = find_prime_sum_pairs(&[1, 3, 5, 8], &[20, 35, 110]);

solutions.next()  // => Some((3, 20))
solutions.next()  // => Some((3, 110))  // 3 + 110 = 113 (소수)
solutions.next()  // => Some((8, 35))   // 8 + 35 = 43 (소수)
solutions.next()  // => None (더 이상의 해가 없음)
@end example

@quotation
@strong{@anchor{Exercise 4.35}연습문제 4.35:} 두 개의 주어진 범위 사이의 정수들에 대한 반복자를 반환하는 프로시저 @code{an_integer_between}을 작성하라.
이것은 다음과 같이 주어진 범위 내에서 @math{{i \le j}}이고 @math{{i^2 + j^2 = k^2}}인 정수 세 쌍 @math{{(i, j, k)}}, 즉 피타고라스 세 쌍(Pythagorean triples)을 찾는 프로시저를 구현하는 데 사용될 수 있다:

@example
fn pythagorean_triples_between(low: i32, high: i32) -> impl Iterator<Item = (i32, i32, i32)> @{
    (low..=high).flat_map(move |i| @{
        (i..=high).flat_map(move |j| @{
            (j..=high).filter_map(move |k| @{
                if i * i + j * j == k * k @{
                    Some((i, j, k))
                @} else @{
                    None
                @}
            @})
        @})
    @})
@}

// 사용법: pythagorean_triples_between(3, 50).next()
// => Some((3, 4, 5))
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 4.36}연습문제 4.36:} @ref{Exercise 3.69}에서는 검색할 정수의 크기에 상한이 없는, @emph{모든} 피타고라스 세 쌍의 스트림을 생성하는 방법을 논의했다.
@ref{Exercise 4.35}의 프로시저에서 @code{an_integer_between}을 @code{an_integer_starting_from}으로 단순히 바꾸는 것이 임의의 피타고라스 세 쌍을 생성하기 위한 적절한 방법이 아닌 이유를 설명하라.
이것을 실제로 달성할 프로시저를 작성하라. (즉, @code{try-again}을 반복적으로 입력하면 원칙적으로 결국 모든 피타고라스 세 쌍을 생성할 프로시저를 작성하라.)
@end quotation

@quotation
@strong{@anchor{Exercise 4.37}연습문제 4.37:} Ben Bitdiddle은 피타고라스 세 쌍을 생성하는 다음 방법이 @ref{Exercise 4.35}의 방법보다 더 효율적이라고 주장한다.
그가 옳은가? (힌트: 조사해야 하는 가능성의 수를 고려하라.)

@example
fn pythagorean_triples_optimized(low: i64, high: i64) -> impl Iterator<Item = (i64, i64, i64)> @{
    let hsq = high * high;
    (low..=high).flat_map(move |i| @{
        (i..=high).filter_map(move |j| @{
            let ksq = i * i + j * j;
            if ksq <= hsq @{
                let k = (ksq as f64).sqrt();
                if k.fract() == 0.0 @{
                    Some((i, j, k as i64))
                @} else @{
                    None
                @}
            @} else @{
                None
            @}
        @})
    @})
@}

// 더 효율적임: i, j만 반복하고, k를 직접 계산함
@end example
@end quotation

@subsubheading 드라이버 루프 (Driver loop)

@code{amb} 평가자를 위한 드라이버 루프는 몇 가지 특이한 속성을 갖는다.
그것은 표현식을 읽고 위에서 보여준 @code{prime_sum_pair} 예제에서처럼 첫 번째 실패하지 않은 실행의 값을 출력한다.
만약 우리가 다음 성공적인 실행의 값을 보고 싶다면, 우리는 인터프리터에게 백트래킹하여 두 번째 실패하지 않은 실행을 생성하도록 시도할 것을 요청할 수 있다.

Rust에서 이러한 종류의 비결정적 검색은 자연스럽게 @code{Iterator}를 사용하여 모델링된다.
성공은 @code{Some} 값(또는 반복의 요소)에 해당하고, 실패는 @code{None}(또는 빈 반복자)에 해당한다.
백트래킹은 단순히 반복자에 대해 @code{next()}를 호출함으로써 달성된다.

@example
// Rust에서 우리는 모든 해를 생성하기 위해 반복자를 사용한다
let mut solutions = find_prime_sum_pairs(&[1, 3, 5, 8], &[20, 35, 110]);

solutions.next()  // => Some((3, 20))
solutions.next()  // => Some((3, 110))  // 3 + 110 = 113 (소수)
solutions.next()  // => Some((8, 35))   // 8 + 35 = 43 (소수)
solutions.next()  // => None (더 이상의 해가 없음)
@end example

@quotation
@strong{@anchor{Exercise 4.35}연습문제 4.35:} 두 개의 주어진 범위 사이의 정수들에 대한 반복자를 반환하는 프로시저 @code{an_integer_between}을 작성하라.
이것은 다음과 같이 주어진 범위 내에서 @math{{i \le j}}이고 @math{{i^2 + j^2 = k^2}}인 정수 세 쌍 @math{{(i, j, k)}}, 즉 피타고라스 세 쌍(Pythagorean triples)을 찾는 프로시저를 구현하는 데 사용될 수 있다:

@example
fn pythagorean_triples_between(low: i32, high: i32) -> impl Iterator<Item = (i32, i32, i32)> @{
    (low..=high).flat_map(move |i| @{
        (i..=high).flat_map(move |j| @{
            (j..=high).filter_map(move |k| @{
                if i * i + j * j == k * k @{
                    Some((i, j, k))
                @} else @{
                    None
                @}
            @})
        @})
    @})
@}

// 사용법: pythagorean_triples_between(3, 50).next()
// => Some((3, 4, 5))
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 4.36}연습문제 4.36:} @ref{Exercise 3.69}에서는 검색할 정수의 크기에 상한이 없는, @emph{모든} 피타고라스 세 쌍의 스트림을 생성하는 방법을 논의했다.
@ref{Exercise 4.35}의 프로시저에서 @code{an_integer_between}을 @code{an_integer_starting_from}으로 단순히 바꾸는 것이 임의의 피타고라스 세 쌍을 생성하기 위한 적절한 방법이 아닌 이유를 설명하라.
이것을 실제로 달성할 프로시저를 작성하라. (즉, @code{try-again}을 반복적으로 입력하면 원칙적으로 결국 모든 피타고라스 세 쌍을 생성할 프로시저를 작성하라.)
@end quotation

@quotation
@strong{@anchor{Exercise 4.37}연습문제 4.37:} Ben Bitdiddle은 피타고라스 세 쌍을 생성하는 다음 방법이 @ref{Exercise 4.35}의 방법보다 더 효율적이라고 주장한다.
그가 옳은가? (힌트: 조사해야 하는 가능성의 수를 고려하라.)

@example
fn pythagorean_triples_optimized(low: i64, high: i64) -> impl Iterator<Item = (i64, i64, i64)> @{
    let hsq = high * high;
    (low..=high).flat_map(move |i| @{
        (i..=high).filter_map(move |j| @{
            let ksq = i * i + j * j;
            if ksq <= hsq @{
                let k = (ksq as f64).sqrt();
                if k.fract() == 0.0 @{
                    Some((i, j, k as i64))
                @} else @{
                    None
                @}
            @} else @{
                None
            @}
        @})
    @})
@}

// 더 효율적임: i, j만 반복하고, k를 직접 계산함
@end example
@end quotation

@node	4.3.2, 4.3.3, 4.3.1, 4.3
@subsection 비결정적 프로그램의 예 (Examples of Nondeterministic Programs)

@ref{4.3.3}에서는 @code{amb} 평가자의 구현을 설명한다.
하지만 먼저, 그것이 어떻게 사용될 수 있는지에 대한 몇 가지 예를 들어보자.
비결정적 프로그래밍의 장점은 검색이 수행되는 방식의 세부 사항을 억제할 수 있으므로, 프로그램을 더 높은 수준의 추상화에서 표현할 수 있다는 것이다.

@subsubheading 논리 퍼즐 (Logic Puzzles)

다음 퍼즐(@ref{Dinesman 1968}에서 발췌)은 단순한 논리 퍼즐의 전형적인 예이다:

@quotation
Baker, Cooper, Fletcher, Miller, 그리고 Smith는 5층짜리 아파트의 서로 다른 층에 살고 있다.
Baker는 꼭대기 층에 살지 않는다.
Cooper는 1층에 살지 않는다.
Fletcher는 꼭대기 층이나 1층에 살지 않는다.
Miller는 Cooper보다 높은 층에 산다.
Smith는 Fletcher와 인접한 층에 살지 않는다.
Fletcher는 Cooper와 인접한 층에 살지 않는다.
각자 어느 층에 살고 있는가?
@end quotation

@noindent
우리는 모든 가능성을 열거하고 주어진 제한 사항을 부과함으로써 각자가 어느 층에 살고 있는지 간단한 방식으로 결정할 수 있다:@footnote{우리 프로그램은 리스트의 요소들이 서로 다른지 결정하기 위해 다음 프로시저를 사용한다:

@example
fn distinct<T: Eq>(items: &[T]) -> bool @{
    for (i, item) in items.iter().enumerate() @{
        if items[i + 1..].contains(item) @{
            return false;
        @}
    @}
    true
@}

// 또는 O(n) 복잡도를 위해 HashSet을 사용함:
// use std::collections::HashSet;
// items.iter().collect::<HashSet<_>>().len() == items.len()
@end example

@code{Member}는 동등성 테스트를 위해 @code{eq?} 대신 @code{equal?}을 사용한다는 점을 제외하면 @code{memq}와 같다.}

@example
fn multiple_dwelling() -> Option<[(&'static str, i32); 5]> @{
    let floors = 1..=5;
    for baker in floors.clone() @{
        if baker == 5 @{ continue; @}  // Baker는 꼭대기 아님
        for cooper in floors.clone() @{
            if cooper == 1 @{ continue; @}  // Cooper는 1층 아님
            if cooper == baker @{ continue; @}
            for fletcher in floors.clone() @{
                if fletcher == 5 || fletcher == 1 @{ continue; @}
                if fletcher == baker || fletcher == cooper @{ continue; @}
                if (fletcher - cooper).abs() == 1 @{ continue; @}
                for miller in floors.clone() @{
                    if miller <= cooper @{ continue; @}  // Miller는 Cooper보다 위
                    if miller == baker || miller == cooper || miller == fletcher @{
                        continue;
                    @}
                    for smith in floors.clone() @{
                        if smith == baker || smith == cooper
                            || smith == fletcher || smith == miller @{
                            continue;
                        @}
                        if (smith - fletcher).abs() == 1 @{ continue; @}
                        return Some([
                            ("baker", baker), ("cooper", cooper),
                            ("fletcher", fletcher), ("miller", miller),
                            ("smith", smith),
                        ]);
                    @}
                @}
            @}
        @}
    @}
    None
@}
@end example

@noindent
표현식 @code{(multiple_dwelling)}을 평가하면 다음 결과가 생성된다:

@example
Some([("baker", 3), ("cooper", 2), ("fletcher", 4),
      ("miller", 5), ("smith", 1)])
@end example

@noindent
이 간단한 프로시저가 작동하긴 하지만, 매우 느리다.
@ref{Exercise 4.39}와 @ref{Exercise 4.40}에서 몇 가지 가능한 개선 사항을 논의한다.

@quotation
@strong{@anchor{Exercise 4.38}연습문제 4.38:} Smith와 Fletcher가 인접한 층에 살지 않아야 한다는 요구 사항을 생략하도록 @code{multiple_dwelling} 프로시저를 수정하라.
이 수정된 퍼즐에는 얼마나 많은 해가 있는가?
@end quotation

@quotation
@strong{@anchor{Exercise 4.39}연습문제 4.39:} @code{multiple_dwelling} 프로시저에서 제한 사항의 순서가 답에 영향을 미치는가?
답을 찾는 시간에 영향을 미치는가?
만약 그것이 중요하다고 생각한다면, 제한 사항의 순서를 바꾸어 얻은 더 빠른 프로그램을 제시하라.
만약 중요하지 않다고 생각한다면, 당신의 논거를 제시하라.
@end quotation

@quotation
@strong{@anchor{Exercise 4.40}연습문제 4.40:} 거주지 문제에서, 층 배정이 서로 달라야 한다는 요구 사항 전후에 사람들을 층에 배정하는 방법은 각각 몇 가지인가?
사람들을 층에 배정하는 가능한 모든 경우를 생성한 다음 백트래킹이 그것들을 제거하도록 내버려 두는 것은 매우 비효율적이다.
예를 들어, 대부분의 제한 사항은 한두 명의 사람-층 변수에만 의존하므로, 모든 사람에 대해 층이 선택되기 전에 부과될 수 있다.
이전 제한 사항에 의해 아직 배제되지 않은 가능성들만을 생성하는 것에 기반하여 이 문제를 해결하는 훨씬 더 효율적인 비결정적 프로시저를 작성하고 시연하라. (힌트: 이것은 @code{let} 표현식들의 중첩을 요구할 것이다.)
@end quotation

@quotation
@strong{@anchor{Exercise 4.41}연습문제 4.41:} 거주지 퍼즐을 풀기 위한 일반적인 Scheme 프로그램을 작성하라.
@end quotation

@quotation
@strong{@anchor{Exercise 4.42}연습문제 4.42:} 다음 ``거짓말쟁이(Liars)'' 퍼즐(@ref{Phillips 1934}에서 발췌)을 풀어라:

다섯 명의 여학생이 시험을 보았다. 그들의 부모들은 --- 여학생들이 생각하기에 --- 결과에 대해 지나친 관심을 보였다.
그래서 그들은 집에 시험에 대해 편지를 쓸 때, 각자 한 가지는 참인 말을 하고 한 가지는 거짓인 말을 하기로 합의했다.
다음은 그들의 편지에서 발췌한 관련 구절들이다:

@itemize @bullet

@item
Betty: ``Kitty는 시험에서 2등을 했어. 나는 3등밖에 못 했어.''

@item
Ethel: ``내가 1등을 했다는 소식을 들으면 기뻐하실 거예요. Joan은 2등을 했어요.''

@item
Joan: ``나는 3등이었고, 불쌍한 Ethel은 꼴찌였어.''

@item
Kitty: ``나는 2등이 되었어. Mary는 4등밖에 못 했어.''

@item
Mary: ``나는 4등이었어. 1등은 Betty가 차지했어.''

@end itemize

실제로 다섯 소녀의 등수 순서는 어떠했는가?
@end quotation

@quotation
@strong{@anchor{Exercise 4.43}연습문제 4.43:} 다음 퍼즐을 풀기 위해 @code{amb} 평가자를 사용하라:@footnote{이것은 1960년대 Litton Industries에서 발행된 ``Problematical Recreations''라는 소책자에서 가져온 것으로, @cite{Kansas State Engineer}의 공으로 돌려졌다.}

@quotation
Mary Ann Moore의 아버지는 요트를 가지고 있고, 그의 네 명의 친구인 Colonel Downing, Mr. Hall, Sir Barnacle Hood, 그리고 Dr. Parker도 각자 요트를 가지고 있다.
다섯 명 모두 한 명의 딸을 가지고 있으며, 각자 다른 사람 중 한 명의 딸의 이름을 따서 자신의 요트 이름을 지었다.
Sir Barnacle의 요트 이름은 Gabrielle이고, Mr. Moore는 Lorna를 소유하고 있으며, Mr. Hall은 Rosalind를 소유하고 있다.
Colonel Downing이 소유한 Melissa는 Sir Barnacle의 딸의 이름을 따서 지어졌다.
Gabrielle의 아버지는 Dr. Parker의 딸의 이름을 딴 요트를 소유하고 있다.
Lorna의 아버지는 누구인가?
@end quotation

프로그램이 효율적으로 실행되도록 작성하라 (@ref{Exercise 4.40} 참조).
또한 Mary Ann의 성이 Moore라는 사실을 듣지 못했을 때 얼마나 많은 해가 있는지 결정하라.
@end quotation

@quotation
@strong{@anchor{Exercise 4.44}연습문제 4.44:} @ref{Exercise 2.42}는 체스판에 어떤 두 퀸도 서로 공격하지 않도록 퀸들을 배치하는 ``8-퀸 퍼즐''을 설명했다.
이 퍼즐을 풀기 위한 비결정적 프로그램을 작성하라.
@end quotation

@subsubheading 자연어 분석 (Parsing natural language)

자연어를 입력으로 받도록 설계된 프로그램은 대개 입력을 @newterm{구문 분석(parse)}하려는 시도에서 시작한다. 즉, 입력을 어떤 문법적 구조와 대조하는 것이다.
예를 들어, 우리는 ``The cat eats''와 같이 관사, 명사, 동사로 구성된 단순한 문장을 인식하려고 시도할 수 있다.
그러한 분석을 수행하려면, 우리는 개별 단어의 품사를 식별할 수 있어야 한다.
우리는 다양한 단어들을 분류하는 몇 가지 리스트에서 시작할 수 있다:@footnote{여기서 우리는 각 리스트의 첫 번째 요소가 리스트의 나머지 단어들에 대한 품사를 지정한다는 관례를 사용한다.}

@example
const NOUNS: &[&str] = &["student", "professor", "cat", "class"];

const VERBS: &[&str] = &["studies", "lectures", "eats", "sleeps"];

const ARTICLES: &[&str] = &["the", "a"];
@end example

@noindent
우리는 또한 문법 요소들이 어떻게 더 단순한 요소들로부터 구성되는지 설명하는 규칙들의 집합인 @newterm{문법(grammar)}이 필요하다.
매우 단순한 문법은 문장이 항상 명사구 다음에 동사가 오는 두 조각으로 구성되며, 명사구는 관사 다음에 명사가 오는 것으로 구성된다고 규정할 수 있다.
이 문법을 사용하면, ``The cat eats'' 문장은 다음과 같이 분석된다:

@example
Sentence @{
    noun_phrase: NounPhrase @{
        article: "the",
        noun: "cat",
    @},
    verb: "eats",
@}
@end example

@noindent
우리는 각 문법 규칙에 대해 별도의 프로시저를 갖는 단순한 프로그램으로 그러한 분석을 생성할 수 있다.
문장을 분석하기 위해, 우리는 그것의 두 구성 조각을 식별하고 @code{sentence} 기호로 태그가 지정된 이 두 요소의 리스트를 반환한다:

@example
fn parse_sentence(input: &mut &[&str]) -> Option<Sentence> @{
    let noun_phrase = parse_noun_phrase(input)?;
    let verb = parse_word(input, VERBS)?;
    Some(Sentence @{ noun_phrase, verb @})
@}
@end example

@noindent
명사구 또한 비슷하게 관사 다음에 명사가 오는 것을 찾음으로써 분석된다:

@example
fn parse_noun_phrase(input: &mut &[&str]) -> Option<NounPhrase> @{
    let article = parse_word(input, ARTICLES)?;
    let noun = parse_word(input, NOUNS)?;
    Some(NounPhrase @{ article, noun @})
@}
@end example

@noindent
가장 낮은 수준에서, 분석은 다음 분석되지 않은 단어가 요구되는 품사의 단어 리스트의 멤버인지 반복적으로 확인하는 것으로 귀결된다.
이를 구현하기 위해, 우리는 아직 분석되지 않은 입력인 전역 변수 @code{*unparsed*}를 유지한다.
단어를 확인할 때마다, 우리는 @code{*unparsed*}가 비어 있지 않아야 하며 지정된 리스트의 단어로 시작해야 함을 요구한다.
만약 그렇다면, 우리는 @code{*unparsed*}에서 그 단어를 제거하고 단어와 그것의 품사(리스트의 머리에서 발견됨)를 함께 반환한다:@footnote{@code{parse_word}가 분석되지 않은 입력 리스트를 수정하기 위해 @code{set!}을 사용함에 주목하라. 이것이 작동하려면, 우리 @code{amb} 평가자는 백트래킹할 때 @code{set!} 연산의 효과를 취소해야 한다.}

@example
fn parse_word<'a>(
    input: &mut &'a [&'a str],
    word_list: &[&str],
) -> Option<&'a str> @{
    let (&first, rest) = input.split_first()?;
    if word_list.contains(&first) @{
        *input = rest;  // 입력을 전진시킴
        Some(first)
    @} else @{
        None
    @}
@}
@end example

@noindent
분석을 시작하기 위해, 우리가 해야 할 일은 @code{*unparsed*}를 전체 입력으로 설정하고, 문장을 분석하려고 시도하며, 남은 것이 없는지 확인하는 것뿐이다:

@example
fn parse(input: &[&str]) -> Option<Sentence> @{
    let mut remaining = input;
    let sentence = parse_sentence(&mut remaining)?;
    if remaining.is_empty() @{
        Some(sentence)
    @} else @{
        None  // 분석되지 않은 입력이 남음
    @}
@}
@end example

@noindent
우리는 이제 파서를 시도해 보고 우리의 단순한 테스트 문장에 대해 그것이 작동하는지 확인할 수 있다:

@example
parse(&["the", "cat", "eats"])
// => Some(Sentence @{
//        noun_phrase: NounPhrase @{
//            article: "the",
//            noun: "cat",
//        @},
//        verb: "eats",
//    @})
@end example

@noindent
@code{amb} 평가자는 여기서 유용한데, @code{require}의 도움으로 분석 제약 조건을 표현하는 것이 편리하기 때문이다.
자동 검색과 백트래킹은 단위들이 어떻게 분해될 수 있는지에 대한 선택지가 있는 더 복잡한 문법을 고려할 때 정말로 진가를 발휘한다.

우리 문법에 전치사 리스트를 추가해 보자:

@example
const PREPOSITIONS: &[&str] = &["for", "to", "in", "by", "with"];
@end example

@noindent
그리고 전치사구(예: ``for the cat'')를 전치사 다음에 명사구가 오는 것으로 정의하자:

@example
fn parse_prepositional_phrase(input: &mut &[&str]) -> Option<PrepPhrase> @{
    let prep = parse_word(input, PREPOSITIONS)?;
    let noun_phrase = parse_noun_phrase(input)?;
    Some(PrepPhrase @{ prep, noun_phrase @})
@}
@end example

@noindent
이제 우리는 문장을 명사구 다음에 동사구가 오는 것으로 정의할 수 있다. 여기서 동사구는 동사이거나 전치사구에 의해 확장된 동사구일 수 있다:@footnote{이 정의가 재귀적임에 주목하라 --- 동사 뒤에는 임의의 수의 전치사구가 올 수 있다.}

@example
fn parse_sentence_ext(input: &mut &[&str]) -> Option<SentenceExt> @{
    let noun_phrase = parse_noun_phrase_ext(input)?;
    let verb_phrase = parse_verb_phrase(input)?;
    Some(SentenceExt @{ noun_phrase, verb_phrase @})
@}

// 모든 유효한 동사구 분석의 반복자를 반환함
fn parse_verb_phrase(input: &mut &[&str]) -> Option<VerbPhrase> @{
    let verb = parse_word(input, VERBS)?;
    // 전치사구로 확장을 시도함
    let mut vp = VerbPhrase::Verb(verb);
    while let Some(prep) = parse_prepositional_phrase(input) @{
        vp = VerbPhrase::Extended(Box::new(vp), prep);
    @}
    Some(vp)
@}
@end example

@noindent
이왕 하는 김에, 우리는 또한 ``a cat in the class''와 같은 것을 허용하도록 명사구의 정의를 정교화할 수 있다.
우리가 명사구라고 부르던 것을 이제는 단순 명사구라고 부를 것이고, 명사구는 이제 단순 명사구이거나 전치사구에 의해 확장된 명사구일 것이다:

@example
fn parse_simple_noun_phrase(input: &mut &[&str]) -> Option<SimpleNounPhrase> @{
    let article = parse_word(input, ARTICLES)?;
    let noun = parse_word(input, NOUNS)?;
    Some(SimpleNounPhrase @{ article, noun @})
@}

fn parse_noun_phrase_ext(input: &mut &[&str]) -> Option<NounPhraseExt> @{
    let simple = parse_simple_noun_phrase(input)?;
    let mut np = NounPhraseExt::Simple(simple);
    // 전치사구로 확장함
    while let Some(prep) = parse_prepositional_phrase(input) @{
        np = NounPhraseExt::Extended(Box::new(np), prep);
    @}
    Some(np)
@}
@end example

@noindent
우리의 새로운 문법은 더 복잡한 문장을 분석할 수 있게 해준다. 예를 들어

@example
parse(&["the", "student", "with", "the", "cat",
        "sleeps", "in", "the", "class"])
@end example

@noindent
은 다음을 생성한다

@example
SentenceExt @{
    noun_phrase: NounPhraseExt::Extended(
        Box::new(NounPhraseExt::Simple(
            SimpleNounPhrase @{ article: "the", noun: "student" @}
        )),
        PrepPhrase @{
            prep: "with",
            noun_phrase: SimpleNounPhrase @{ article: "the", noun: "cat" @},
        @}
    ),
    verb_phrase: VerbPhrase::Extended(
        Box::new(VerbPhrase::Verb("sleeps")),
        PrepPhrase @{
            prep: "in",
            noun_phrase: SimpleNounPhrase @{ article: "the", noun: "class" @},
        @}
    ),
@}
@end example

@noindent
주어진 입력이 하나 이상의 적법한 분석을 가질 수 있음에 주목하라.
``The professor lectures to the student with the cat'' 문장에서, 교수가 고양이와 함께 강의하고 있는 것일 수도 있고, 학생이 고양이를 가지고 있는 것일 수도 있다.
우리 비결정적 프로그램은 두 가지 가능성을 모두 찾는다:

@example
parse(&["the", "professor", "lectures", "to",
        "the", "student", "with", "the", "cat"])
@end example

@noindent
은 다음을 생성한다

@example
// 해석 1: 교수가 강의한다 (고양이와 함께)
SentenceExt @{
    noun_phrase: NounPhraseExt::Simple(
        SimpleNounPhrase @{ article: "the", noun: "professor" @}
    ),
    verb_phrase: VerbPhrase::Extended(
        Box::new(VerbPhrase::Extended(
            Box::new(VerbPhrase::Verb("lectures")),
            PrepPhrase @{ prep: "to", /* ... student ... */ @}
        )),
        PrepPhrase @{ prep: "with", /* ... cat ... */ @}
    ),
@}
@end example

@noindent
평가자에게 다시 시도할 것을 요청하면 다음을 산출한다

@example
// 해석 2: 학생이 고양이를 가지고 있다
SentenceExt @{
    noun_phrase: NounPhraseExt::Simple(
        SimpleNounPhrase @{ article: "the", noun: "professor" @}
    ),
    verb_phrase: VerbPhrase::Extended(
        Box::new(VerbPhrase::Verb("lectures")),
        PrepPhrase @{
            prep: "to",
            noun_phrase: NounPhraseExt::Extended(
                Box::new(NounPhraseExt::Simple(/* student */)),
                PrepPhrase @{ prep: "with", /* cat */ @}
            ),
        @}
    ),
@}
@end example

@quotation
@strong{@anchor{Exercise 4.45}연습문제 4.45:} 위에 주어진 문법으로, 다음 문장은 다섯 가지 서로 다른 방식으로 분석될 수 있다: ``The professor lectures to the student in the class with the cat.''
다섯 가지 분석을 제시하고 그들 사이의 의미 차이를 설명하라.
@end quotation

@quotation
@strong{@anchor{Exercise 4.46}연습문제 4.46:} @ref{4.1}과 @ref{4.2}의 평가자들은 피연산자가 어떤 순서로 평가되는지 결정하지 않는다.
우리는 @code{amb} 평가자가 그것들을 왼쪽에서 오른쪽으로 평가한다는 것을 보게 될 것이다.
만약 피연산자들이 다른 순서로 평가된다면 왜 우리 분석 프로그램이 작동하지 않을지 설명하라.
@end quotation

@quotation
@strong{@anchor{Exercise 4.47}연습문제 4.47:} Louis Reasoner는 동사구가 동사이거나 동사구 다음에 전치사구가 오는 것이므로, @code{parse_verb_phrase} 프로시저를 다음과 같이 정의하는 것이 훨씬 더 간단할 것이라고 제안한다(명사구에 대해서도 마찬가지이다):

@example
// Louis의 버전 - 좌측 재귀적이며, 무한 루프를 일으킴!
fn parse_verb_phrase_louis(input: &mut &[&str]) -> Option<VerbPhrase> @{
    // 단순 동사이거나...
    parse_word(input, VERBS).map(VerbPhrase::Verb)
    // ...또는 동사구 다음에 전치사구가 오는 것
    // 이것은 좌측 재귀적(left-recursive)이며 무한히 루프를 돌 것이다
    .or_else(|| @{
        let vp = parse_verb_phrase_louis(input)?;  // 무한 재귀!
        let prep = parse_prepositional_phrase(input)?;
        Some(VerbPhrase::Extended(Box::new(vp), prep))
    @})
@}
@end example

이것이 작동하는가? @code{amb}에서 표현식의 순서를 바꾸면 프로그램의 동작이 변하는가?
@end quotation

@quotation
@strong{@anchor{Exercise 4.48}연습문제 4.48:} 더 복잡한 문장을 처리하도록 위에 주어진 문법을 확장하라.
예를 들어, 형용사와 부사를 포함하도록 명사구와 동사구를 확장하거나, 복합 문장을 처리할 수 있다.@footnote{이러한 종류의 문법은 임의로 복잡해질 수 있지만, 실제 언어 이해에 관한 한 장난감에 불과하다. 컴퓨터에 의한 진정한 자연어 이해는 정교한 구문 분석과 의미 해석의 혼합을 요구한다. 반면에, 장난감 파서조차 정보 검색 시스템과 같은 프로그램을 위한 유연한 명령 언어를 지원하는 데 유용할 수 있다. @ref{Winston 1992}는 실제 언어 이해에 대한 계산적 접근 방식과 단순한 문법의 명령 언어 응용에 대해 논의한다.}
@end quotation

@quotation
@strong{@anchor{Exercise 4.49}연습문제 4.49:} Alyssa P. Hacker는 문장을 분석하는 것보다 흥미로운 문장을 생성하는 것에 더 관심이 있다.
그녀는 @code{parse_word} 프로시저를 단순히 수정하여 ``입력 문장''을 무시하고 대신 항상 성공하여 적절한 단어를 생성하게 함으로써, 우리가 분석을 위해 구축했던 프로그램들을 생성에 대신 사용할 수 있다고 추론한다.
Alyssa의 아이디어를 구현하고, 처음 반 다스 정도 생성된 문장들을 보여라.@footnote{Alyssa의 아이디어는 잘 작동하긴 하지만(그리고 놀라울 정도로 단순하지만), 그것이 생성하는 문장들은 약간 지루하다 --- 그것들은 이 언어의 가능한 문장들을 매우 흥미로운 방식으로 샘플링하지 않는다. 사실, 문법은 많은 곳에서 고도로 재귀적이며, Alyssa의 기술은 이러한 재귀들 중 하나에 ``빠져서'' 갇히게 된다. 이를 처리하는 방법은 @ref{Exercise 4.50}을 보라.}
@end quotation

@node	4.3.3, 4.4, 4.2, 4.3
@subsection @code{Amb} 평가자 구현하기 (Implementing the @code{Amb} Evaluator)

일반적인 Scheme 표현식의 평가는 값을 반환하거나, 영원히 종료되지 않거나, 또는 오류를 발생시킬 수 있다.
비결정적 Scheme에서 표현식의 평가는 추가적으로 막다른 골목(dead end)의 발견으로 이어질 수 있으며, 이 경우 평가는 이전 선택 지점으로 백트래킹해야 한다.
비결정적 Scheme의 해석은 이 추가적인 케이스 때문에 복잡해진다.

우리는 @ref{4.1.7}의 분석적 평가자를 수정하여 비결정적 Scheme을 위한 @code{amb} 평가자를 구축할 것이다.@footnote{우리는 @ref{4.2}의 지연 평가자를 @ref{4.1.1}의 일반적인 메타순환 평가자의 수정본으로 구현하기로 선택했다. 대조적으로, 우리는 @code{amb} 평가자를 @ref{4.1.7}의 분석적 평가자에 기초할 것인데, 그 평가자의 실행 프로시저가 백트래킹을 구현하기 위한 편리한 프레임워크를 제공하기 때문이다.}
분석적 평가자에서와 마찬가지로, 표현식의 평가는 해당 표현식의 분석에 의해 생성된 실행 프로시저를 호출함으로써 달성된다.
일반적인 Scheme의 해석과 비결정적 Scheme의 해석 사이의 차이는 전적으로 실행 프로시저에 있을 것이다.

@subsubheading 실행 프로시저와 계속 (Execution procedures and continuations)

일반 평가자를 위한 실행 프로시저는 하나의 인자, 즉 실행 환경을 받는다는 것을 상기하라.
대조적으로, @code{amb} 평가자의 실행 프로시저는 세 개의 인자를 받는다: 환경, 그리고 @newterm{계속 프로시저(continuation procedures)}라고 불리는 두 개의 프로시저이다.
표현식의 평가는 이 두 계속 중 하나를 호출함으로써 끝날 것이다: 만약 평가가 값으로 결과가 나오면, @newterm{성공 계속(success continuation)}이 그 값과 함께 호출된다; 만약 평가가 막다른 골목의 발견으로 결과가 나오면, @newterm{실패 계속(failure continuation)}이 호출된다.
적용 가능한 계속을 구성하고 호출하는 것이 비결정적 평가자가 백트래킹을 구현하는 메커니즘이다.

성공 계속의 역할은 값을 받아 계산을 진행하는 것이다.
그 값과 함께, 성공 계속은 나중에 그 값의 사용이 막다른 골목으로 이어질 경우 호출될 또 다른 실패 계속을 전달받는다.

실패 계속의 역할은 비결정적 프로세스의 다른 분기를 시도하는 것이다.
비결정적 언어의 본질은 표현식이 대안들 사이의 선택을 나타낼 수 있다는 사실에 있다.
그러한 표현식의 평가는 어떤 선택이 받아들일 수 있는 결과로 이어질지 미리 알지 못하더라도, 표시된 대안 선택지들 중 하나를 가지고 진행되어야 한다.
이를 처리하기 위해, 평가자는 대안들 중 하나를 고르고 이 값을 성공 계속에 전달한다.
이 값과 함께, 평가자는 나중에 다른 대안을 선택하기 위해 호출될 수 있는 실패 계속을 구성하여 전달한다.

평가 도중 실패는 사용자 프로그램이 현재의 공격 라인을 명시적으로 거부할 때(예를 들어, @code{require}에 대한 호출이 항상 실패하는 표현식인 @code{(amb)}의 실행으로 이어질 때 --- @ref{4.3.1} 참조) 트리거된다(즉, 실패 계속이 호출된다).
그 시점에 손에 쥐고 있는 실패 계속은 가장 최근의 선택 지점이 다른 대안을 선택하도록 만들 것이다.
만약 그 선택 지점에서 더 이상 고려할 대안이 없으면, 이전 선택 지점에서의 실패가 트리거되는 식이다.
실패 계속은 또한 표현식의 다른 값을 찾기 위한 @code{try-again} 요청에 응답하여 드라이버 루프에 의해 호출된다.

또한, 선택에서 비롯된 프로세스의 분기에서 부수 효과 연산(예: 변수에 대입)이 발생하는 경우, 프로세스가 막다른 골목을 찾았을 때 새로운 선택을 하기 전에 부수 효과를 취소해야 할 수도 있다.
이것은 부수 효과 연산이 부수 효과를 취소하고 실패를 전파하는 실패 계속을 생성하도록 함으로써 달성된다.

요약하자면, 실패 계속은 다음에 의해 구성된다:

@itemize @bullet

@item
@code{amb} 표현식 --- @code{amb} 표현식에 의해 이루어진 현재 선택이 막다른 골목으로 이어질 경우 대안적인 선택을 할 수 있는 메커니즘을 제공하기 위해;

@item
최상위 드라이버 --- 선택지가 고갈되었을 때 실패를 보고하는 메커니즘을 제공하기 위해;

@item
대입 --- 백트래킹 중에 실패를 가로채고 대입을 취소하기 위해.

@end itemize

@noindent
실패는 막다른 골목을 만났을 때만 시작된다. 이것은 다음과 같은 경우에 발생한다:

@itemize @bullet

@item
사용자 프로그램이 @code{(amb)}를 실행할 때;

@item
사용자가 최상위 드라이버에서 @code{try-again}을 입력할 때.

@end itemize

@noindent
실패 계속은 실패 처리 도중에도 호출된다:

@itemize @bullet

@item
성공 계속이 부수 효과의 취소를 마치면, 실패를 이 대입으로 이끌었던 선택 지점이나 최상위 레벨로 다시 전파하기 위해 가로챘던 실패 계속을 호출한다.

@item
@code{amb}를 위한 실패 계속이 선택지를 다 써버리면, 실패를 이전 선택 지점이나 최상위 레벨로 다시 전파하기 위해 원래 @code{amb}에게 주어졌던 실패 계속을 호출한다.

@end itemize

@subsubheading Structure of the evaluator

The syntax- and data-representation procedures for the @code{amb} evaluator,
and also the basic @code{analyze} procedure, are identical to those in the
evaluator of @ref{4.1.7}, except for the fact that we need additional
syntax procedures to recognize the @code{amb} special form:@footnote{We assume
that the evaluator supports @code{let} (see @ref{Exercise 4.22}), which we have
used in our nondeterministic programs.}

@example
// In Rust, amb is represented as an enum variant
enum Expr @{
    // ... other variants ...
    Amb(Vec<Expr>),  // Nondeterministic choice
@}

fn is_amb(exp: &Expr) -> bool @{
    matches!(exp, Expr::Amb(_))
@}

fn amb_choices(exp: &Expr) -> &[Expr] @{
    match exp @{
        Expr::Amb(choices) => choices,
        _ => panic!("Not an amb expression"),
    @}
@}
@end example

@noindent
We must also add to the dispatch in @code{analyze} a clause that will recognize
this special form and generate an appropriate execution procedure:

@example
Expr::Amb(choices) => analyze_amb(choices),
@end example

@noindent
The top-level procedure @code{ambeval} (similar to the version of @code{eval}
given in @ref{4.1.7}) analyzes the given expression and applies the
resulting execution procedure to the given environment, together with two given
continuations:

@example
fn ambeval<S, F>(exp: &Expr, env: &Environment, succeed: S, fail: F)
where
    S: FnOnce(Value, Box<dyn FnOnce()>),
    F: FnOnce(),
@{
    let executor = analyze(exp);
    executor(env, succeed, fail)
@}
@end example

@noindent
A success continuation is a procedure of two arguments: the value just obtained
and another failure continuation to be used if that value leads to a subsequent
failure. A failure continuation is a procedure of no arguments.  So the general
form of an execution procedure is

@example
// Execution procedure signature:
type Executor = Box<dyn Fn(
    &Environment,
    Box<dyn FnOnce(Value, Box<dyn FnOnce()>)>,  // succeed
    Box<dyn FnOnce()>,                           // fail
)>;

// succeed: (value, fail_continuation) -> ()
// fail: () -> ()
@end example

@noindent
For example, executing

@example
ambeval(
    &exp,
    &global_env,
    Box::new(|value, _fail| value),      // On success, return value
    Box::new(|| Value::Symbol("failed")) // On failure, return 'failed
)
@end example

@noindent
will attempt to evaluate the given expression and will return either the
expression's value (if the evaluation succeeds) or the symbol @code{failed} (if
the evaluation fails).  The call to @code{ambeval} in the driver loop shown
below uses much more complicated continuation procedures, which continue the
loop and support the @code{try-again} request.

Most of the complexity of the @code{amb} evaluator results from the mechanics
of passing the continuations around as the execution procedures call each
other.  In going through the following code, you should compare each of the
execution procedures with the corresponding procedure for the ordinary
evaluator given in @ref{4.1.7}.

@subsubheading Simple expressions

The execution procedures for the simplest kinds of expressions are essentially
the same as those for the ordinary evaluator, except for the need to manage the
continuations.  The execution procedures simply succeed with the value of the
expression, passing along the failure continuation that was passed to them.

@example
fn analyze_self_evaluating(n: i64) -> Executor @{
    Box::new(move |_env, succeed, fail| @{
        succeed(Value::Number(n), fail);
    @})
@}

fn analyze_quoted(val: Value) -> Executor @{
    Box::new(move |_env, succeed, fail| @{
        succeed(val.clone(), fail);
    @})
@}

fn analyze_variable(name: String) -> Executor @{
    Box::new(move |env, succeed, fail| @{
        let value = env.lookup(&name).expect("Unbound variable");
        succeed(value.clone(), fail);
    @})
@}

fn analyze_lambda(params: Vec<String>, body: Vec<Expr>) -> Executor @{
    let bproc = analyze_sequence(&body);
    Box::new(move |env, succeed, fail| @{
        succeed(
            Value::Closure @{
                params: params.clone(),
                body: bproc.clone(),
                env: env.clone(),
            @},
            fail,
        );
    @})
@}
@end example

@noindent
Notice that looking up a variable always `succeeds.'  If
@code{lookup_variable_value} fails to find the variable, it signals an error,
as usual.  Such a ``failure'' indicates a program bug---a reference to an
unbound variable; it is not an indication that we should try another
nondeterministic choice instead of the one that is currently being tried.

@subsubheading Conditionals and sequences

Conditionals are also handled in a similar way as in the ordinary evaluator.
The execution procedure generated by @code{analyze_if} invokes the predicate
execution procedure @code{pproc} with a success continuation that checks
whether the predicate value is true and goes on to execute either the
consequent or the alternative.  If the execution of @code{pproc} fails, the
original failure continuation for the @code{if} expression is called.

@example
fn analyze_if(predicate: &Expr, consequent: &Expr, alternative: &Expr) -> Executor @{
    let pproc = analyze(predicate);
    let cproc = analyze(consequent);
    let aproc = analyze(alternative);
    Box::new(move |env, succeed, fail| @{
        pproc(
            env,
            // Success continuation for predicate
            Box::new(|pred_value, fail2| @{
                if is_truthy(&pred_value) @{
                    cproc(env, succeed, fail2)
                @} else @{
                    aproc(env, succeed, fail2)
                @}
            @}),
            // Failure continuation for predicate
            fail,
        )
    @})
@}
@end example

@noindent
Sequences are also handled in the same way as in the previous evaluator, except
for the machinations in the subprocedure @code{sequentially} that are required
for passing the continuations.  Namely, to sequentially execute @code{a} and
then @code{b}, we call @code{a} with a success continuation that calls
@code{b}.

@example
fn analyze_sequence(exps: &[Expr]) -> Executor @{
    fn sequentially(a: Executor, b: Executor) -> Executor @{
        Box::new(move |env, succeed, fail| @{
            a(
                env,
                // Success continuation: run b after a succeeds
                Box::new(|_a_value, fail2| @{
                    b(env, succeed, fail2)
                @}),
                // Failure continuation: propagate
                fail,
            )
        @})
    @}

    let procs: Vec<Executor> = exps.iter().map(analyze).collect();
    if procs.is_empty() @{
        panic!("Empty sequence");
    @}

    procs.into_iter().reduce(sequentially).unwrap()
@}
@end example

@subsubheading Definitions and assignments

Definitions are another case where we must go to some trouble to manage the
continuations, because it is necessary to evaluate the definition_value
expression before actually defining the new variable.  To accomplish this, the
definition_value execution procedure @code{vproc} is called with the
environment, a success continuation, and the failure continuation.  If the
execution of @code{vproc} succeeds, obtaining a value @code{val} for the
defined variable, the variable is defined and the success is propagated:

@example
fn analyze_definition(var: String, value_expr: &Expr) -> Executor @{
    let vproc = analyze(value_expr);
    Box::new(move |env, succeed, fail| @{
        vproc(
            env,
            Box::new(|val, fail2| @{
                // Note: In Rust, we'd return a new environment
                let new_env = env.define(var.clone(), val);
                succeed(Value::Symbol("ok"), fail2)
            @}),
            fail,
        )
    @})
@}
@end example

@noindent
Assignments are more interesting.  This is the first place where we really use
the continuations, rather than just passing them around.  The execution
procedure for assignments starts out like the one for definitions.  It first
attempts to obtain the new value to be assigned to the variable. If this
evaluation of @code{vproc} fails, the assignment fails.

If @code{vproc} succeeds, however, and we go on to make the assignment, we must
consider the possibility that this branch of the computation might later fail,
which will require us to backtrack out of the assignment.  Thus, we must
arrange to undo the assignment as part of the backtracking process.@footnote{We
didn't worry about undoing definitions, since we can assume that internal
definitions are scanned out (@ref{4.1.6}).}

This is accomplished by giving @code{vproc} a success continuation (marked with
the comment ``*1*'' below) that saves the old value of the variable before
assigning the new value to the variable and proceeding from the assignment.
The failure continuation that is passed along with the value of the assignment
(marked with the comment ``*2*'' below) restores the old value of the variable
before continuing the failure.  That is, a successful assignment provides a
failure continuation that will intercept a subsequent failure; whatever failure
would otherwise have called @code{fail2} calls this procedure instead, to undo
the assignment before actually calling @code{fail2}.

@example
fn analyze_assignment(var: String, value_expr: &Expr) -> Executor @{
    let vproc = analyze(value_expr);
    Box::new(move |env, succeed, fail| @{
        vproc(
            env,
            Box::new(|val, fail2| @{  // *1* Success continuation
                let old_value = env.lookup(&var).unwrap().clone();
                // Note: In functional Rust, we'd return new env
                // But for backtracking we need undo capability
                env.set(&var, val);
                succeed(
                    Value::Symbol("ok"),
                    Box::new(|| @{  // *2* Undo on backtrack
                        env.set(&var, old_value);
                        fail2()
                    @}),
                );
            @}),
            fail,
        )
    @})
@}
@end example

@subsubheading Procedure applications

The execution procedure for applications contains no new ideas except for the
technical complexity of managing the continuations.  This complexity arises in
@code{analyze_application}, due to the need to keep track of the success and
failure continuations as we evaluate the operands.  We use a procedure
@code{get_args} to evaluate the list of operands, rather than a simple
@code{map} as in the ordinary evaluator.

@example
fn analyze_application(operator: &Expr, operands: &[Expr]) -> Executor @{
    let fproc = analyze(operator);
    let aprocs: Vec<Executor> = operands.iter().map(analyze).collect();
    Box::new(move |env, succeed, fail| @{
        fproc(
            env,
            Box::new(|proc, fail2| @{
                get_args(
                    &aprocs,
                    env,
                    Box::new(|args, fail3| @{
                        execute_application(proc, args, succeed, fail3)
                    @}),
                    fail2,
                )
            @}),
            fail,
        )
    @})
@}
@end example

@noindent
In @code{get_args}, notice how @code{cdr}-ing down the list of @code{aproc}
execution procedures and @code{cons}ing up the resulting list of @code{args} is
accomplished by calling each @code{aproc} in the list with a success
continuation that recursively calls @code{get_args}.  Each of these recursive
calls to @code{get_args} has a success continuation whose value is the
@code{cons} of the newly obtained argument onto the list of accumulated
arguments:

@example
fn get_args(
    aprocs: &[Executor],
    env: &Environment,
    succeed: Box<dyn FnOnce(Vec<Value>, Box<dyn FnOnce()>)>,
    fail: Box<dyn FnOnce()>,
) @{
    if aprocs.is_empty() @{
        succeed(vec![], fail);
    @} else @{
        aprocs[0](
            env,
            // Success continuation for this aproc
            Box::new(|arg, fail2| @{
                get_args(
                    &aprocs[1..],
                    env,
                    // Success continuation for recursive call
                    Box::new(|mut args, fail3| @{
                        args.insert(0, arg);  // cons arg to front
                        succeed(args, fail3)
                    @}),
                    fail2,
                )
            @}),
            fail,
        );
    @}
@}
@end example

@noindent
The actual procedure application, which is performed by
@code{execute_application}, is accomplished in the same way as for the ordinary
evaluator, except for the need to manage the continuations.

@example
fn execute_application(
    proc: Value,
    args: Vec<Value>,
    succeed: Box<dyn FnOnce(Value, Box<dyn FnOnce()>)>,
    fail: Box<dyn FnOnce()>,
) @{
    match proc @{
        Value::Primitive(f) => @{
            succeed(f(&args), fail);
        @}
        Value::Closure @{ params, body, env @} => @{
            let extended = env.extend(
                params.into_iter().zip(args)
            );
            body(&extended, succeed, fail);
        @}
        _ => panic!("Unknown procedure type"),
    @}
@}
@end example

@subsubheading Evaluating @code{amb} expressions

The @code{amb} special form is the key element in the nondeterministic
language.  Here we see the essence of the interpretation process and the reason
for keeping track of the continuations.  The execution procedure for @code{amb}
defines a loop @code{try_next} that cycles through the execution procedures for
all the possible values of the @code{amb} expression.  Each execution procedure
is called with a failure continuation that will try the next one.  When there
are no more alternatives to try, the entire @code{amb} expression fails.

@example
fn analyze_amb(choices: &[Expr]) -> Executor @{
    let cprocs: Vec<Executor> = choices.iter().map(analyze).collect();
    Box::new(move |env, succeed, fail| @{
        fn try_next(
            choices: &[Executor],
            env: &Environment,
            succeed: &dyn Fn(Value, Box<dyn FnOnce()>),
            fail: Box<dyn FnOnce()>,
        ) @{
            if choices.is_empty() @{
                fail();
            @} else @{
                choices[0](
                    env,
                    succeed,
                    Box::new(|| try_next(&choices[1..], env, succeed, fail)),
                );
            @}
        @}
        try_next(&cprocs, env, &*succeed, fail)
    @})
@}
@end example

@subsubheading Driver loop

The driver loop for the @code{amb} evaluator is complex, due to the mechanism
that permits the user to try again in evaluating an expression.  The driver
uses a procedure called @code{internal_loop}, which takes as argument a
procedure @code{try-again}.  The intent is that calling @code{try-again} should
go on to the next untried alternative in the nondeterministic evaluation.
@code{Internal-loop} either calls @code{try-again} in response to the user
typing @code{try-again} at the driver loop, or else starts a new evaluation by
calling @code{ambeval}.

The failure continuation for this call to @code{ambeval} informs the user that
there are no more values and re-invokes the driver loop.

The success continuation for the call to @code{ambeval} is more subtle.  We
print the obtained value and then invoke the internal loop again with a
@code{try-again} procedure that will be able to try the next alternative.  This
@code{next-alternative} procedure is the second argument that was passed to the
success continuation.  Ordinarily, we think of this second argument as a
failure continuation to be used if the current evaluation branch later fails.
In this case, however, we have completed a successful evaluation, so we can
invoke the ``failure'' alternative branch in order to search for additional
successful evaluations.

@example
const INPUT_PROMPT: &str = ";;; Amb-Eval input:";
const OUTPUT_PROMPT: &str = ";;; Amb-Eval value:";

fn driver_loop(global_env: Environment) @{
    // Store the "try again" continuation
    let mut try_again: Option<Box<dyn FnOnce()>> = None;

    loop @{
        println!("@{@}", INPUT_PROMPT);
        let input = read_input();

        if input == "try-again" @{
            if let Some(cont) = try_again.take() @{
                cont();
            @} else @{
                println!("No current problem");
            @}
        @} else @{
            println!(";;; Starting a new problem");
            let expr = parse(&input);
            ambeval(
                &expr,
                &global_env,
                // Success continuation
                Box::new(|val, next_alternative| @{
                    println!("@{@} @{:?@}", OUTPUT_PROMPT, val);
                    try_again = Some(next_alternative);
                @}),
                // Failure continuation
                Box::new(|| @{
                    println!(";;; No more values of @{:?@}", input);
                @}),
            );
        @}
    @}
@}

// Note: In Rust, this would use an iterator-based approach
// rather than continuation-passing style for simplicity
@end example

@noindent
The initial call to @code{internal_loop} uses a @code{try-again} procedure that
complains that there is no current problem and restarts the driver loop.  This
is the behavior that will happen if the user types @code{try-again} when there
is no evaluation in progress.

@quotation
@strong{@anchor{Exercise 4.50}Exercise 4.50:} Implement a new special form
@code{ramb} that is like @code{amb} except that it searches alternatives in a
random order, rather than from left to right.  Show how this can help with
Alyssa's problem in @ref{Exercise 4.49}.
@end quotation

@quotation
@strong{@anchor{Exercise 4.51}Exercise 4.51:} Implement a new kind of
assignment called @code{permanent-set!} that is not undone upon failure.  For
example, we can choose two distinct elements from a list and count the number
of trials required to make a successful choice as follows:

@example
// Using a Cell to simulate permanent-set! (not rolled back)
use std::cell::Cell;
let count = Cell::new(0);
let elements = ["a", "b", "c"];

for x in &elements @{
    for y in &elements @{
        count.set(count.get() + 1);  // permanent-set!
        if x != y @{
            println!("(@{@}, @{@}, @{@})", x, y, count.get());
            // => ("a", "b", 2)
            // try-again => ("a", "c", 3)
        @}
    @}
@}
@end example

What values would have been displayed if we had used @code{set!} here
rather than @code{permanent-set!}?
@end quotation

@quotation
@strong{@anchor{Exercise 4.52}Exercise 4.52:} Implement a new construct called
@code{if-fail} that permits the user to catch the failure of an expression.
@code{If-fail} takes two expressions.  It evaluates the first expression as
usual and returns as usual if the evaluation succeeds.  If the evaluation
fails, however, the value of the second expression is returned, as in the
following example:

@example
// if_fail: try primary, return fallback on failure
fn find_even(list: &[i64]) -> Result<i64, &'static str> @{
    list.iter()
        .copied()
        .find(|x| x % 2 == 0)
        .ok_or("all-odd")
@}

find_even(&[1, 3, 5])
// => Err("all-odd")

find_even(&[1, 3, 5, 8])
// => Ok(8)
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 4.53}Exercise 4.53:} With @code{permanent-set!} as
described in @ref{Exercise 4.51} and @code{if-fail} as in @ref{Exercise 4.52},
what will be the result of evaluating

@example
// Collect all prime-sum pairs
let list1 = [1, 3, 5, 8];
let list2 = [20, 35, 110];

let pairs: Vec<_> = list1.iter()
    .flat_map(|&a| list2.iter().map(move |&b| (a, b)))
    .filter(|&(a, b)| is_prime(a + b))
    .collect();

// => [(3, 20), (3, 110), (8, 35)]
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 4.54}Exercise 4.54:} If we had not realized that
@code{require} could be implemented as an ordinary procedure that uses
@code{amb}, to be defined by the user as part of a nondeterministic program, we
would have had to implement it as a special form.  This would require syntax
procedures

@example
fn is_require(exp: &Expr) -> bool @{
    matches!(exp, Expr::Require(_))
@}

fn require_predicate(exp: &Expr) -> &Expr @{
    match exp @{
        Expr::Require(pred) => pred,
        _ => panic!("Not a require expression"),
    @}
@}
@end example

@noindent
and a new clause in the dispatch in @code{analyze}

@example
Expr::Require(pred) => analyze_require(pred),
@end example

@noindent
as well the procedure @code{analyze-require} that handles @code{require}
expressions.  Complete the following definition of @code{analyze-require}.

@example
fn analyze_require(predicate: &Expr) -> Executor @{
    let pproc = analyze(predicate);
    Box::new(move |env, succeed, fail| @{
        pproc(
            env,
            Box::new(|pred_value, fail2| @{
                if !is_truthy(&pred_value) @{
                    // Requirement not met - fail!
                    fail2()
                @} else @{
                    succeed(Value::Symbol("ok"), fail2)
                @}
            @}),
            fail,
        )
    @})
@}
@end example
@end quotation

@node	4.4, Chapter 5, 4.3, Chapter 4
@section 논리 프로그래밍 (Logic Programming)

@ref{Chapter 1}에서 우리는 컴퓨터 과학이 명령적(어떻게 할 것인가) 지식을 다루는 반면, 수학은 선언적(무엇인가) 지식을 다룬다고 강조했다.
실제로 프로그래밍 언어는 프로그래머가 특정 문제를 해결하기 위한 단계별 방법을 나타내는 형태로 지식을 표현할 것을 요구한다.
반면에 고수준 언어는 언어 구현의 일부로서 상당한 양의 방법론적 지식을 제공하여 사용자가 지정된 계산이 어떻게 진행될지에 대한 수많은 세부 사항에 신경 쓰지 않도록 해준다.

Lisp를 포함한 대부분의 프로그래밍 언어는 수학 함수의 값을 계산하는 것을 중심으로 구성된다.
표현식 지향 언어(Lisp, Fortran, Algol 등)는 함수의 값을 설명하는 표현식이 그 값을 계산하는 수단으로도 해석될 수 있다는 ``말장난(pun)''을 활용한다.
이 때문에 대부분의 프로그래밍 언어는 단방향 계산(입력과 출력이 잘 정의된 계산)에 강하게 편향되어 있다.
그러나 이러한 편향을 완화하는 근본적으로 다른 프로그래밍 언어들도 있다.
우리는 @ref{3.3.5}에서 그러한 예를 보았는데, 거기서 계산의 대상은 산술 제약 조건이었다.
제약 조건 시스템에서는 계산의 방향과 순서가 그렇게 잘 지정되지 않는다; 따라서 시스템은 계산을 수행할 때 일반적인 산술 계산의 경우보다 더 상세한 ``어떻게 할 것인가''에 대한 지식을 제공해야 한다.
그러나 이것이 사용자가 명령적 지식을 제공해야 할 책임에서 완전히 해방된다는 것을 의미하지는 않는다.
동일한 제약 조건 집합을 구현하는 많은 제약 조건 네트워크가 있으며, 사용자는 수학적으로 동등한 네트워크 집합 중에서 특정 계산을 지정하기에 적합한 네트워크를 선택해야 한다.

@ref{4.3}의 비결정적 프로그램 평가자 또한 프로그래밍이 단방향 함수를 계산하기 위한 알고리즘을 구성하는 것이라는 관점에서 벗어난다.
비결정적 언어에서 표현식은 하나 이상의 값을 가질 수 있으며, 결과적으로 계산은 단일 값 함수보다는 관계를 다룬다.
논리 프로그래밍은 프로그래밍의 관계적 비전을 @newterm{단일화(unification)}라고 불리는 강력한 종류의 기호 패턴 매칭과 결합함으로써 이 아이디어를 확장한다.@footnote{논리 프로그래밍은 자동 정리 증명에 대한 긴 연구 역사에서 성장했다. 초기 정리 증명 프로그램들은 가능한 증명의 공간을 철저하게 검색했기 때문에 거의 성과를 거두지 못했다. 그러한 검색을 그럴듯하게 만든 주요 돌파구는 1960년대 초반 @newterm{단일화 알고리즘(unification algorithm)}과 @newterm{해상 원리(resolution principle)}의 발견이었다 (@ref{Robinson 1965}). 해상은 예를 들어 @ref{Green and Raphael (1968)} (또한 @ref{Green 1969} 참조)에 의해 연역적 질의응답 시스템의 기초로 사용되었다. 이 기간의 대부분 동안 연구자들은 증명이 존재한다면 반드시 찾아내는 알고리즘에 집중했다. 그러한 알고리즘들은 제어하기 어렵고 증명 쪽으로 유도하기 어려웠다. @ref{Hewitt (1969)}는 프로그래밍 언어의 제어 구조와 논리 조작 시스템의 연산을 통합할 가능성을 인식했고, 이는 @ref{4.3.1}(@ref{Footnote 250})에서 언급된 자동 검색 작업으로 이어졌다. 이 작업이 수행되는 동시에 마르세유의 Colmerauer는 자연어를 조작하기 위한 규칙 기반 시스템을 개발하고 있었다 (@ref{Colmerauer et al. 1973} 참조). 그는 그러한 규칙들을 표현하기 위해 Prolog라는 프로그래밍 언어를 발명했다. 에든버러의 @ref{Kowalski (1973; 1979)}는 Prolog 프로그램의 실행이 정리 증명(선형 혼절 해상(linear Horn-clause resolution)이라는 증명 기술을 사용)으로 해석될 수 있음을 인식했다. 마지막 두 흐름의 통합은 논리 프로그래밍 운동으로 이어졌다. 따라서 논리 프로그래밍의 발전에 대한 공로를 인정할 때, 프랑스인들은 마르세유 대학에서의 Prolog의 탄생을 지적할 수 있고, 영국인들은 에든버러 대학에서의 작업을 강조할 수 있다. @abbr{MIT} 사람들에 따르면, 논리 프로그래밍은 Hewitt가 그의 훌륭하지만 이해하기 힘든 박사 학위 논문에서 무슨 말을 하고 있는지 알아내려는 시도에서 이 그룹들에 의해 개발되었다. 논리 프로그래밍의 역사에 대해서는 @ref{Robinson 1983}을 보라.}

이 접근 방식은, 작동할 때는, 프로그램을 작성하는 매우 강력한 방법이 될 수 있다.
그 힘의 일부는 단일한 ``무엇인가''라는 사실이 서로 다른 ``어떻게 할 것인가'' 구성 요소를 갖는 여러 다른 문제를 해결하는 데 사용될 수 있다는 사실에서 나온다.
예를 들어, 두 개의 리스트를 인자로 받아 그 요소들을 결합하여 단일 리스트를 형성하는 @code{append} 연산을 고려해 보자.
Lisp와 같은 절차적 언어에서, 우리는 @ref{2.2.1}에서 했던 것처럼 기본 리스트 생성자 @code{cons}의 관점에서 @code{append}를 정의할 수 있다:

@example
fn append<T: Clone>(x: &[T], y: &[T]) -> Vec<T> @{
    if x.is_empty() @{
        y.to_vec()
    @} else @{
        let mut result = vec![x[0].clone()];
        result.extend(append(&x[1..], y));
        result
    @}
@}

// 또는 관용적으로: x.iter().chain(y).cloned().collect()
@end example

@noindent
이 프로시저는 다음 두 규칙의 Lisp 번역으로 간주될 수 있는데, 첫 번째는 첫 번째 리스트가 비어 있는 경우를 다루고 두 번째는 비어 있지 않은 리스트(두 부분의 @code{cons})인 경우를 다룬다:

@itemize @bullet

@item
임의의 리스트 @code{y}에 대해, 빈 리스트와 @code{y}는 @code{append}하여 @code{y}를 형성한다.

@item
임의의 @code{u}, @code{v}, @code{y}, @code{z}에 대해, 만약 @code{v}와 @code{y}가 @code{append}하여 @code{z}를 형성한다면, @code{(cons u v)}와 @code{y}는 @code{append}하여 @code{(cons u z)}를 형성한다.@footnote{규칙과 프로시저 사이의 대응 관계를 보려면, 프로시저의 @code{x}(여기서 @code{x}는 비어 있지 않음)가 규칙의 @code{(cons u v)}에 해당하게 하라. 그러면 규칙의 @code{z}는 @code{(cdr x)}와 @code{y}의 @code{append}에 해당한다.}

@end itemize

@noindent
@code{append} 프로시저를 사용하여 다음과 같은 질문에 답할 수 있다.

@quotation
@code{(a b)}와 @code{(c d)}의 @code{append}를 찾아라.
@end quotation

@noindent
그러나 동일한 두 규칙은 프로시저가 답할 수 없는 다음과 같은 종류의 질문에 답하기에도 충분하다.

@quotation
@code{(a b)}와 @code{append}하여 @code{(a b c d)}를 생성하는 리스트 @code{y}를 찾아라.

@code{append}하여 @code{(a b c d)}를 형성하는 모든 @code{x}와 @code{y}를 찾아라.
@end quotation

@noindent
논리 프로그래밍 언어에서, 프로그래머는 위에 주어진 @code{append}에 대한 두 규칙을 기술함으로써 @code{append} ``프로시저''를 작성한다.
``어떻게 할 것인가''에 대한 지식은 인터프리터에 의해 자동으로 제공되어, 이 단일한 규칙 쌍이 @code{append}에 대한 세 가지 유형의 질문 모두에 답하는 데 사용될 수 있게 해준다.@footnote{이것이 물론 답을 계산하는 방법이라는 전체 문제로부터 사용자를 해방시키는 것은 아니다. @code{append} 관계를 공식화하기 위한 수학적으로 동등한 많은 다른 규칙 집합이 있으며, 그 중 일부만이 임의의 방향으로 계산하기 위한 효과적인 장치로 전환될 수 있다. 또한 때로는 ``무엇인가'' 정보가 답을 계산하는 ``어떻게 할 것인가''에 대한 단서를 전혀 주지 않기도 한다. 예를 들어, @math{{y^2 = x}}인 @math{y}를 계산하는 문제를 고려해 보라.}

현대의 논리 프로그래밍 언어(여기서 우리가 구현하는 언어를 포함하여)는 일반적인 ``어떻게 할 것인가'' 방법이 가짜 무한 루프나 다른 바람직하지 않은 동작으로 이어질 수 있다는 점에서 실질적인 결함을 가지고 있다.
논리 프로그래밍은 컴퓨터 과학에서 활발한 연구 분야이다.@footnote{논리 프로그래밍에 대한 관심은 일본 정부가 논리 프로그래밍 언어를 실행하도록 최적화된 초고속 컴퓨터를 구축하는 것을 목표로 야심 찬 프로젝트를 시작했던 80년대 초반에 정점에 달했다. 그러한 컴퓨터의 속도는 일반적인 FLOPS(초당 부동 소수점 연산)가 아니라 LIPS(초당 논리적 추론)로 측정될 것이었다. 비록 프로젝트가 원래 계획대로 하드웨어와 소프트웨어를 개발하는 데 성공했지만, 국제 컴퓨터 산업은 다른 방향으로 움직였다. 일본 프로젝트에 대한 개괄적인 평가는 @ref{Feigenbaum and Shrobe 1993}을 보라. 논리 프로그래밍 커뮤니티 또한 단순한 패턴 매칭 이외의 기술, 예를 들어 @ref{3.3.5}의 제약 조건 전파 시스템에서 예시된 수치적 제약 조건을 다루는 능력과 같은 기술에 기초한 관계형 프로그래밍을 고려하는 것으로 나아갔다.}

이 장의 앞부분에서 우리는 인터프리터를 구현하는 기술을 탐구했고 Lisp와 같은 언어(실제로는 모든 기존 언어)를 위한 인터프리터에 필수적인 요소들을 설명했다.
이제 우리는 이 아이디어들을 적용하여 논리 프로그래밍 언어를 위한 인터프리터를 논의할 것이다.
우리는 이 언어를 @newterm{질의 언어(query language)}라고 부르는데, 왜냐하면 그것이 언어로 표현된 @newterm{질의(queries)}, 즉 질문을 공식화하여 데이터베이스에서 정보를 검색하는 데 매우 유용하기 때문이다.
질의 언어가 Lisp와 매우 다르지만, 우리는 우리가 줄곧 사용해 온 것과 같은 일반적인 프레임워크의 관점에서 언어를 설명하는 것이 편리하다는 것을 알게 될 것이다: 원시 요소들의 모음, 단순한 요소들을 결합하여 더 복잡한 요소를 만들 수 있게 해주는 결합 수단, 그리고 복잡한 요소들을 단일 개념 단위로 간주할 수 있게 해주는 추상화 수단이다.
논리 프로그래밍 언어를 위한 인터프리터는 Lisp와 같은 언어를 위한 인터프리터보다 훨씬 더 복잡하다.
그럼에도 불구하고, 우리는 우리의 질의 언어 인터프리터가 @ref{4.1}의 인터프리터에서 발견된 것과 같은 많은 요소들을 포함하고 있음을 보게 될 것이다.
특히, 유형에 따라 표현식을 분류하는 ``eval'' 부분과 언어의 추상화 메커니즘(Lisp의 경우 프로시저, 논리 프로그래밍의 경우 @newterm{규칙(rules)})을 구현하는 ``apply'' 부분이 있을 것이다.
또한, 기호와 연관된 값 사이의 대응 관계를 결정하는 프레임 데이터 구조가 구현에서 중심적인 역할을 한다.
우리 질의 언어 구현의 또 다른 흥미로운 측면은 @ref{Chapter 3}에서 소개된 스트림을 상당히 많이 사용한다는 점이다.

@menu
* 4.4.1::            연역적 정보 검색 (Deductive Information Retrieval)
* 4.4.2::            질의 시스템의 작동 방식 (How the Query System Works)
* 4.4.3::            논리 프로그래밍은 수학적 논리인가? (Is Logic Programming Mathematical Logic?)
* 4.4.4::            질의 시스템 구현하기 (Implementing the Query System)
@end menu

@node	4.4.1, 4.4.2, 4.4, 4.4
@subsection Deductive Information Retrieval

Logic programming excels in providing interfaces to data bases for information
retrieval.  The query language we shall implement in this chapter is designed
to be used in this way.

In order to illustrate what the query system does, we will show how it can be
used to manage the data base of personnel records for Microshaft, a thriving
high-technology company in the Boston area.  The language provides
pattern-directed access to personnel information and can also take advantage of
general rules in order to make logical deductions.

@subsubheading A sample data base

The personnel data base for Microshaft contains @newterm{assertions} about
company personnel.  Here is the information about Ben Bitdiddle, the resident
computer wizard:

@example
// Database assertions are Terms
Term::List(vec![
    Term::Atom("address".to_string()),
    Term::List(vec![
        Term::Atom("Bitdiddle".to_string()),
        Term::Atom("Ben".to_string())
    ]),
    Term::List(vec![
        Term::Atom("Slumerville".to_string()),
        Term::Atom("Ridge Road".to_string()),
        Term::Atom("10".to_string())
    ])
])

Term::List(vec![
    Term::Atom("job".to_string()),
    Term::List(vec![
        Term::Atom("Bitdiddle".to_string()),
        Term::Atom("Ben".to_string())
    ]),
    Term::List(vec![
        Term::Atom("computer".to_string()),
        Term::Atom("wizard".to_string())
    ])
])

Term::List(vec![
    Term::Atom("salary".to_string()),
    Term::List(vec![
        Term::Atom("Bitdiddle".to_string()),
        Term::Atom("Ben".to_string())
    ]),
    Term::Atom("60000".to_string())
])
@end example

@noindent
Each assertion is a list (in this case a triple) whose elements can themselves
be lists.

As resident wizard, Ben is in charge of the company's computer division, and he
supervises two programmers and one technician.  Here is the information about
them:

@example
Term::List(vec![
    Term::Atom("address".to_string()),
    Term::List(vec![
        Term::Atom("Hacker".to_string()),
        Term::Atom("Alyssa P".to_string())
    ]),
    Term::List(vec![
        Term::Atom("Cambridge".to_string()),
        Term::Atom("Mass Ave".to_string()),
        Term::Atom("78".to_string())
    ])
])

Term::List(vec![
    Term::Atom("job".to_string()),
    Term::List(vec![
        Term::Atom("Hacker".to_string()),
        Term::Atom("Alyssa P".to_string())
    ]),
    Term::List(vec![
        Term::Atom("computer".to_string()),
        Term::Atom("programmer".to_string())
    ])
])

Term::List(vec![
    Term::Atom("salary".to_string()),
    Term::List(vec![
        Term::Atom("Hacker".to_string()),
        Term::Atom("Alyssa P".to_string())
    ]),
    Term::Atom("40000".to_string())
])

Term::List(vec![
    Term::Atom("supervisor".to_string()),
    Term::List(vec![
        Term::Atom("Hacker".to_string()),
        Term::Atom("Alyssa P".to_string())
    ]),
    Term::List(vec![
        Term::Atom("Bitdiddle".to_string()),
        Term::Atom("Ben".to_string())
    ])
])
@end example

@noindent
There is also a programmer trainee, who is supervised by Alyssa:

@example
Term::List(vec![
    Term::Atom("address".to_string()),
    Term::List(vec![
        Term::Atom("Reasoner".to_string()),
        Term::Atom("Louis".to_string())
    ]),
    Term::List(vec![
        Term::Atom("Slumerville".to_string()),
        Term::Atom("Pine Tree Road".to_string()),
        Term::Atom("80".to_string())
    ])
])

Term::List(vec![
    Term::Atom("job".to_string()),
    Term::List(vec![
        Term::Atom("Reasoner".to_string()),
        Term::Atom("Louis".to_string())
    ]),
    Term::List(vec![
        Term::Atom("computer".to_string()),
        Term::Atom("programmer".to_string()),
        Term::Atom("trainee".to_string())
    ])
])

Term::List(vec![
    Term::Atom("salary".to_string()),
    Term::List(vec![
        Term::Atom("Reasoner".to_string()),
        Term::Atom("Louis".to_string())
    ]),
    Term::Atom("30000".to_string())
])

Term::List(vec![
    Term::Atom("supervisor".to_string()),
    Term::List(vec![
        Term::Atom("Reasoner".to_string()),
        Term::Atom("Louis".to_string())
    ]),
    Term::List(vec![
        Term::Atom("Hacker".to_string()),
        Term::Atom("Alyssa P".to_string())
    ])
])
@end example

@noindent
All of these people are in the computer division, as indicated by the word
@code{computer} as the first item in their job descriptions.

Ben is a high-level employee.  His supervisor is the company's big wheel
himself:

@example
Term::List(vec![
    Term::Atom("supervisor".to_string()),
    Term::List(vec![
        Term::Atom("Bitdiddle".to_string()),
        Term::Atom("Ben".to_string())
    ]),
    Term::List(vec![
        Term::Atom("Warbucks".to_string()),
        Term::Atom("Oliver".to_string())
    ])
])

Term::List(vec![
    Term::Atom("address".to_string()),
    Term::List(vec![
        Term::Atom("Warbucks".to_string()),
        Term::Atom("Oliver".to_string())
    ]),
    Term::List(vec![
        Term::Atom("Swellesley".to_string()),
        Term::Atom("Top Heap Road".to_string())
    ])
])

Term::List(vec![
    Term::Atom("job".to_string()),
    Term::List(vec![
        Term::Atom("Warbucks".to_string()),
        Term::Atom("Oliver".to_string())
    ]),
    Term::List(vec![
        Term::Atom("administration".to_string()),
        Term::Atom("big".to_string()),
        Term::Atom("wheel".to_string())
    ])
])

Term::List(vec![
    Term::Atom("salary".to_string()),
    Term::List(vec![
        Term::Atom("Warbucks".to_string()),
        Term::Atom("Oliver".to_string())
    ]),
    Term::Atom("150000".to_string())
])
@end example

@noindent
Besides the computer division supervised by Ben, the company has an accounting
division, consisting of a chief accountant and his assistant:

@example
Term::List(vec![
    Term::Atom("address".to_string()),
    Term::List(vec![
        Term::Atom("Scrooge".to_string()),
        Term::Atom("Eben".to_string())
    ]),
    Term::List(vec![
        Term::Atom("Weston".to_string()),
        Term::Atom("Shady Lane".to_string()),
        Term::Atom("10".to_string())
    ])
])

Term::List(vec![
    Term::Atom("job".to_string()),
    Term::List(vec![
        Term::Atom("Scrooge".to_string()),
        Term::Atom("Eben".to_string())
    ]),
    Term::List(vec![
        Term::Atom("accounting".to_string()),
        Term::Atom("chief".to_string()),
        Term::Atom("accountant".to_string())
    ])
])

Term::List(vec![
    Term::Atom("salary".to_string()),
    Term::List(vec![
        Term::Atom("Scrooge".to_string()),
        Term::Atom("Eben".to_string())
    ]),
    Term::Atom("75000".to_string())
])

Term::List(vec![
    Term::Atom("supervisor".to_string()),
    Term::List(vec![
        Term::Atom("Scrooge".to_string()),
        Term::Atom("Eben".to_string())
    ]),
    Term::List(vec![
        Term::Atom("Warbucks".to_string()),
        Term::Atom("Oliver".to_string())
    ])
])

Term::List(vec![
    Term::Atom("address".to_string()),
    Term::List(vec![
        Term::Atom("Cratchet".to_string()),
        Term::Atom("Robert".to_string())
    ]),
    Term::List(vec![
        Term::Atom("Allston".to_string()),
        Term::Atom("N Harvard Street".to_string()),
        Term::Atom("16".to_string())
    ])
])

Term::List(vec![
    Term::Atom("job".to_string()),
    Term::List(vec![
        Term::Atom("Cratchet".to_string()),
        Term::Atom("Robert".to_string())
    ]),
    Term::List(vec![
        Term::Atom("accounting".to_string()),
        Term::Atom("scrivener".to_string())
    ])
])

Term::List(vec![
    Term::Atom("salary".to_string()),
    Term::List(vec![
        Term::Atom("Cratchet".to_string()),
        Term::Atom("Robert".to_string())
    ]),
    Term::Atom("18000".to_string())
])

Term::List(vec![
    Term::Atom("supervisor".to_string()),
    Term::List(vec![
        Term::Atom("Cratchet".to_string()),
        Term::Atom("Robert".to_string())
    ]),
    Term::List(vec![
        Term::Atom("Scrooge".to_string()),
        Term::Atom("Eben".to_string())
    ])
])
@end example

@noindent
There is also a secretary for the big wheel:

@example
Term::List(vec![
    Term::Atom("address".to_string()),
    Term::List(vec![
        Term::Atom("Aull".to_string()),
        Term::Atom("DeWitt".to_string())
    ]),
    Term::List(vec![
        Term::Atom("Slumerville".to_string()),
        Term::Atom("Onion Square".to_string()),
        Term::Atom("5".to_string())
    ])
])

Term::List(vec![
    Term::Atom("job".to_string()),
    Term::List(vec![
        Term::Atom("Aull".to_string()),
        Term::Atom("DeWitt".to_string())
    ]),
    Term::List(vec![
        Term::Atom("administration".to_string()),
        Term::Atom("secretary".to_string())
    ])
])

Term::List(vec![
    Term::Atom("salary".to_string()),
    Term::List(vec![
        Term::Atom("Aull".to_string()),
        Term::Atom("DeWitt".to_string())
    ]),
    Term::Atom("25000".to_string())
])

Term::List(vec![
    Term::Atom("supervisor".to_string()),
    Term::List(vec![
        Term::Atom("Aull".to_string()),
        Term::Atom("DeWitt".to_string())
    ]),
    Term::List(vec![
        Term::Atom("Warbucks".to_string()),
        Term::Atom("Oliver".to_string())
    ])
])
@end example

@noindent
The data base also contains assertions about which kinds of jobs can be done by
people holding other kinds of jobs.  For instance, a computer wizard can do the
jobs of both a computer programmer and a computer technician:

@example
Term::List(vec![
    Term::Atom("can-do-job".to_string()),
    Term::List(vec![
        Term::Atom("computer".to_string()),
        Term::Atom("wizard".to_string())
    ]),
    Term::List(vec![
        Term::Atom("computer".to_string()),
        Term::Atom("programmer".to_string())
    ])
])

Term::List(vec![
    Term::Atom("can-do-job".to_string()),
    Term::List(vec![
        Term::Atom("computer".to_string()),
        Term::Atom("wizard".to_string())
    ]),
    Term::List(vec![
        Term::Atom("computer".to_string()),
        Term::Atom("technician".to_string())
    ])
])
@end example

@noindent
A computer programmer could fill in for a trainee:

@example
Term::List(vec![
    Term::Atom("can-do-job".to_string()),
    Term::List(vec![
        Term::Atom("computer".to_string()),
        Term::Atom("programmer".to_string())
    ]),
    Term::List(vec![
        Term::Atom("computer".to_string()),
        Term::Atom("programmer".to_string()),
        Term::Atom("trainee".to_string())
    ])
])
@end example

@noindent
Also, as is well known,

@example
Term::List(vec![
    Term::Atom("can-do-job".to_string()),
    Term::List(vec![
        Term::Atom("administration".to_string()),
        Term::Atom("secretary".to_string())
    ]),
    Term::List(vec![
        Term::Atom("administration".to_string()),
        Term::Atom("big".to_string()),
        Term::Atom("wheel".to_string())
    ])
])
@end example

@subsubheading Simple queries

The query language allows users to retrieve information from the data base by
posing queries in response to the system's prompt.  For example, to find all
computer programmers one can say

@example
// Query: find all computer programmers
db.employees.iter()
    .filter(|e| e.job == ["computer", "programmer"])
    .collect::<Vec<_>>()
@end example

@noindent
The system will respond with the following items:

@example
// Query results:
// [("Hacker", "Alyssa P"), ("Fect", "Cy D")]
@end example

@noindent
The input query specifies that we are looking for entries in the data base that
match a certain @newterm{pattern}.  In this example, the pattern specifies
entries consisting of three items, of which the first is the literal symbol
@code{job}, the second can be anything, and the third is the literal list
@code{(computer programmer)}.  The ``anything'' that can be the second item in
the matching list is specified by a @newterm{pattern variable}, @code{?x}.  The
general form of a pattern variable is a symbol, taken to be the name of the
variable, preceded by a question mark.  We will see below why it is useful to
specify names for pattern variables rather than just putting @code{?} into
patterns to represent ``anything.''  The system responds to a simple query by
showing all entries in the data base that match the specified pattern.

A pattern can have more than one variable.  For example, the query

@example
// Query: all employee addresses (pattern: any x, any y)
db.employees.iter()
    .map(|e| (&e.name, &e.address))
    .collect::<Vec<_>>()
@end example

@noindent
will list all the employees' addresses.

A pattern can have no variables, in which case the query simply determines
whether that pattern is an entry in the data base.  If so, there will be one
match; if not, there will be no matches.

The same pattern variable can appear more than once in a query, specifying that
the same ``anything'' must appear in each position.  This is why variables have
names.  For example,

@example
// Query: people who supervise themselves (same variable = same value)
db.employees.iter()
    .filter(|e| e.supervisor == Some(e.name.clone()))
    .collect::<Vec<_>>()  // Empty in this database
@end example

@noindent
finds all people who supervise themselves (though there are no such assertions
in our sample data base).

The query

@example
// Query: jobs starting with "computer" and exactly one more element
db.employees.iter()
    .filter(|e| e.job.len() == 2 && e.job[0] == "computer")
    .collect::<Vec<_>>()
@end example

@noindent
matches all job entries whose third item is a two-element list whose first item
is @code{computer}:

@example
// Results (each has exactly 2-element job starting with "computer"):
// ("Bitdiddle", "Ben") => ["computer", "wizard"]
// ("Hacker", "Alyssa P") => ["computer", "programmer"]
// ("Fect", "Cy D") => ["computer", "programmer"]
// ("Tweakit", "Lem E") => ["computer", "technician"]
@end example

@noindent
This same pattern does @emph{not} match

@example
// This does NOT match (3 elements, not 2):
// ("Reasoner", "Louis") => ["computer", "programmer", "trainee"]
@end example

@noindent
because the third item in the entry is a list of three elements, and the
pattern's third item specifies that there should be two elements.  If we wanted
to change the pattern so that the third item could be any list beginning with
@code{computer}, we could specify@footnote{This uses the dotted-tail notation
introduced in @ref{Exercise 2.20}.}

@example
// Query: jobs starting with "computer" (any length)
db.employees.iter()
    .filter(|e| e.job.first() == Some(&"computer"))
    .collect::<Vec<_>>()
@end example

@noindent
For example,

@example
// Pattern: "computer" followed by anything (dot notation = rest)
["computer", rest @ ..]  // Rust slice pattern
@end example

@noindent
matches the data

@example
// Matches: ["computer", "programmer", "trainee"]
// ?type binds to ["programmer", "trainee"]
@end example

@noindent
with @code{?type} as the list @code{(programmer trainee)}.  It also
matches the data

@example
// Also matches: ["computer", "programmer"]
// ?type binds to ["programmer"]
@end example

@noindent
with @code{?type} as the list @code{(programmer)}, and matches the data

@example
// Also matches: ["computer"]
// ?type binds to [] (empty)
@end example

@noindent
with @code{?type} as the empty list @code{()}.

We can describe the query language's processing of simple queries as follows:

@itemize @bullet

@item
The system finds all assignments to variables in the query pattern that
@newterm{satisfy} the pattern---that is, all sets of values for the variables
such that if the pattern variables are @newterm{instantiated with} (replaced
by) the values, the result is in the data base.

@item
The system responds to the query by listing all instantiations of the query
pattern with the variable assignments that satisfy it.

@end itemize

@noindent
Note that if the pattern has no variables, the query reduces to a determination
of whether that pattern is in the data base.  If so, the empty assignment,
which assigns no values to variables, satisfies that pattern for that data
base.

@quotation
@strong{@anchor{Exercise 4.55}Exercise 4.55:} Give simple queries that retrieve
the following information from the data base:

@enumerate

@item
all people supervised by Ben Bitdiddle;

@item
the names and jobs of all people in the accounting division;

@item
the names and addresses of all people who live in Slumerville.

@end enumerate
@end quotation

@subsubheading Compound queries

Simple queries form the primitive operations of the query language.  In order
to form compound operations, the query language provides means of combination.
One thing that makes the query language a logic programming language is that
the means of combination mirror the means of combination used in forming
logical expressions: @code{and}, @code{or}, and @code{not}.  (Here @code{and},
@code{or}, and @code{not} are not the Lisp primitives, but rather operations
built into the query language.)

We can use @code{and} as follows to find the addresses of all the computer
programmers:

@example
// Query: find programmers AND their addresses
db.employees.iter()
    .filter(|e| e.job == ["computer", "programmer"])
    .map(|e| (&e.name, &e.address))
    .collect::<Vec<_>>()
@end example

@noindent
The resulting output is

@example
// Results:
// (("Hacker", "Alyssa P"), ("Cambridge", "Mass Ave", 78))
// (("Fect", "Cy D"), ("Cambridge", "Ames Street", 3))
@end example

@noindent
In general,

@example
// Conjunction: all conditions must be satisfied
.filter(|x| condition1(x) && condition2(x) && /* ... */)
@end example

@noindent
is satisfied by all sets of values for the pattern variables that
simultaneously satisfy @math{{⟨\kern0.1em query_1⟩}} @r{…} @math{{⟨\kern0.1em query_n⟩}}.

As for simple queries, the system processes a compound query by finding all
assignments to the pattern variables that satisfy the query, then displaying
instantiations of the query with those values.

Another means of constructing compound queries is through @code{or}.  For
example,

@example
// Query: employees supervised by Ben OR Alyssa
db.employees.iter()
    .filter(|e| @{
        e.supervisor == Some(("Bitdiddle", "Ben"))
            || e.supervisor == Some(("Hacker", "Alyssa P"))
    @})
@end example

@noindent
will find all employees supervised by Ben Bitdiddle or Alyssa P.  Hacker:

@example
// Results: all employees supervised by Ben or Alyssa
// - ("Hacker", "Alyssa P") - supervised by Ben
// - ("Fect", "Cy D") - supervised by Ben
// - ("Tweakit", "Lem E") - supervised by Ben
// - ("Reasoner", "Louis") - supervised by Alyssa
@end example

@noindent
In general,

@example
// Disjunction: at least one condition must be satisfied
.filter(|x| condition1(x) || condition2(x) || /* ... */)
@end example

@noindent
is satisfied by all sets of values for the pattern variables that satisfy at
least one of @math{{⟨\kern0.1em query_1⟩}} @r{…} @math{{⟨\kern0.1em query_n⟩}}.

Compound queries can also be formed with @code{not}. For example,

@example
// Query: Ben's supervisees who are NOT programmers
db.employees.iter()
    .filter(|e| e.supervisor == Some(("Bitdiddle", "Ben")))
    .filter(|e| e.job != ["computer", "programmer"])
@end example

@noindent
finds all people supervised by Ben Bitdiddle who are not computer programmers.
In general,

@example
// Negation: condition must NOT be satisfied
.filter(|x| !condition(x))
@end example

@noindent
is satisfied by all assignments to the pattern variables that do not satisfy
@math{{⟨\kern0.1em query_1⟩}}.@footnote{Actually, this description of @code{not} is valid
only for simple cases.  The real behavior of @code{not} is more complex.  We
will examine @code{not}'s peculiarities in @ref{4.4.2} and
@ref{4.4.3}.}

The final combining form is called @code{lisp-value}.  When @code{lisp-value}
is the first element of a pattern, it specifies that the next element is a Lisp
predicate to be applied to the rest of the (instantiated) elements as
arguments.  In general,

@example
// Apply a predicate function to matched values
.filter(|x| predicate(x.arg1, x.arg2, /* ... */))
@end example

@noindent
will be satisfied by assignments to the pattern variables for which the
@code{⟨}@var{predicate}@code{⟩} applied to the instantiated @math{{⟨\kern0.1em arg_1⟩}} @r{…}
@math{{⟨\kern0.1em arg_n⟩}} is true.  For example, to find all people whose salary is
greater than $30,000 we could write@footnote{@code{Lisp-value} should be used
only to perform an operation not provided in the query language.  In
particular, it should not be used to test equality (since that is what the
matching in the query language is designed to do) or inequality (since that can
be done with the @code{same} rule shown below).}

@example
// Query: all people earning > $30,000
db.employees.iter()
    .filter(|e| e.salary > 30000)
    .map(|e| (&e.name, e.salary))
@end example

@quotation
@strong{@anchor{Exercise 4.56}Exercise 4.56:} Formulate compound queries that
retrieve the following information:

@enumerate a

@item
the names of all people who are supervised by Ben Bitdiddle, together with
their addresses;

@item
all people whose salary is less than Ben Bitdiddle's, together with their
salary and Ben Bitdiddle's salary;

@item
all people who are supervised by someone who is not in the computer division,
together with the supervisor's name and job.

@end enumerate
@end quotation

@subsubheading Rules

In addition to primitive queries and compound queries, the query language
provides means for abstracting queries.  These are given by @newterm{rules}.
The rule

@example
// Rule: lives_near matches two people in the same town
(rule (lives-near ?person-1 ?person-2)
      (and (address ?person-1
                    (?town . ?rest-1))
           (address ?person-2
                    (?town . ?rest-2))
           (not (same ?person-1 ?person-2))))
@end example

@noindent
specifies that two people live near each other if they live in the same town.
The final @code{not} clause prevents the rule from saying that all people live
near themselves.  The @code{same} relation is defined by a very simple
rule:@footnote{Notice that we do not need @code{same} in order to make two
things be the same: We just use the same pattern variable for each---in effect,
we have one thing instead of two things in the first place.  For example, see
@code{?town} in the @code{lives_near} rule and @code{?middle-manager} in the
@code{wheel} rule below.  @code{Same} is useful when we want to force two
things to be different, such as @code{?person-1} and @code{?person-2} in the
@code{lives_near} rule.  Although using the same pattern variable in two parts
of a query forces the same value to appear in both places, using different
pattern variables does not force different values to appear.  (The values
assigned to different pattern variables may be the same or different.)}

@example
// Rule: same just means equal (identity)
fn same<T: Eq>(x: &T, y: &T) -> bool @{
    x == y
@}
@end example

@noindent
The following rule declares that a person is a ``wheel'' in an organization if
he supervises someone who is in turn a supervisor:

@example
// Rule: a "wheel" supervises someone who supervises others
fn is_wheel(db: &Database, person: &Name) -> bool @{
    db.employees.iter().any(|middle| @{
        middle.supervisor == Some(person.clone())
            && db.employees.iter().any(|e| @{
                e.supervisor == Some(middle.name.clone())
            @})
    @})
@}
@end example

@noindent
The general form of a rule is

@example
// Rule pattern: fn conclusion(...) -> bool @{ body @}
fn rule_name(args: ...) -> bool @{
    // body: conditions that must be satisfied
@}
@end example

@noindent
where @code{⟨}@var{conclusion}@code{⟩} is a pattern and @code{⟨}@var{body}@code{⟩} is any
query.@footnote{We will also allow rules without bodies, as in @code{same}, and
we will interpret such a rule to mean that the rule conclusion is satisfied by
any values of the variables.} We can think of a rule as representing a large
(even infinite) set of assertions, namely all instantiations of the rule
conclusion with variable assignments that satisfy the rule body.  When we
described simple queries (patterns), we said that an assignment to variables
satisfies a pattern if the instantiated pattern is in the data base.  But the
pattern needn't be explicitly in the data base as an assertion.  It can be an
implicit assertion implied by a rule.  For example, the query

@example
// Query: who lives near Ben?
db.employees.iter()
    .filter(|e| lives_near(db, e.name.clone(), ("Bitdiddle", "Ben")))
@end example

@noindent
results in

@example
// Results: people in Slumerville (Ben's town)
// ("Reasoner", "Louis") - Slumerville
// ("Aull", "DeWitt") - Slumerville
@end example

@noindent
To find all computer programmers who live near Ben Bitdiddle, we can ask

@example
// Query: programmers who live near Ben
db.employees.iter()
    .filter(|e| e.job == ["computer", "programmer"])
    .filter(|e| lives_near(db, e.name.clone(), ("Bitdiddle", "Ben")))
@end example

@noindent
As in the case of compound procedures, rules can be used as parts of other
rules (as we saw with the @code{lives_near} rule above) or even be defined
recursively.  For instance, the rule

@example
// Recursive rule: outranked-by (transitive supervisor)
fn outranked_by(db: &Database, staff: &Name, boss: &Name) -> bool @{
    let emp = db.find(staff).unwrap();
    match &emp.supervisor @{
        Some(sup) if sup == boss => true,
        Some(sup) => outranked_by(db, sup, boss),  // Recursive
        None => false,
    @}
@}
@end example

@noindent
says that a staff person is outranked by a boss in the organization if the boss
is the person's supervisor or (recursively) if the person's supervisor is
outranked by the boss.

@quotation
@strong{@anchor{Exercise 4.57}Exercise 4.57:} Define a rule that says that
person 1 can replace person 2 if either person 1 does the same job as person 2
or someone who does person 1's job can also do person 2's job, and if person 1
and person 2 are not the same person. Using your rule, give queries that find
the following:

@enumerate a

@item
all people who can replace Cy D. Fect;

@item
all people who can replace someone who is being paid more than they are,
together with the two salaries.

@end enumerate
@end quotation

@quotation
@strong{@anchor{Exercise 4.58}Exercise 4.58:} Define a rule that says that a
person is a ``big shot'' in a division if the person works in the division but
does not have a supervisor who works in the division.
@end quotation

@quotation
@strong{@anchor{Exercise 4.59}Exercise 4.59:} Ben Bitdiddle has missed one
meeting too many.  Fearing that his habit of forgetting meetings could cost him
his job, Ben decides to do something about it.  He adds all the weekly meetings
of the firm to the Microshaft data base by asserting the following:

@example
// Meeting schedule as data
let meetings = vec![
    ("accounting", ("Monday", "9am")),
    ("administration", ("Monday", "10am")),
    ("computer", ("Wednesday", "3pm")),
    ("administration", ("Friday", "1pm")),
];
@end example

Each of the above assertions is for a meeting of an entire division.  Ben also
adds an entry for the company-wide meeting that spans all the divisions.  All
of the company's employees attend this meeting.

@example
// Company-wide meeting
("whole-company", ("Wednesday", "4pm")),
@end example

@enumerate a

@item
On Friday morning, Ben wants to query the data base for all the meetings that
occur that day.  What query should he use?

@item
Alyssa P. Hacker is unimpressed.  She thinks it would be much more useful to be
able to ask for her meetings by specifying her name.  So she designs a rule
that says that a person's meetings include all @code{whole-company} meetings
plus all meetings of that person's division.  Fill in the body of Alyssa's
rule.

@example
// Rule template for person's meetings
fn meeting_time(db: &Database, person: &Name) -> Vec<(Day, Time)> @{
    let division = db.find(person).unwrap().job[0];
    meetings.iter()
        .filter(|(div, _)| *div == division || *div == "whole-company")
        .map(|(_, time)| time.clone())
        .collect()
@}
@end example

@item
Alyssa arrives at work on Wednesday morning and wonders what meetings she has
to attend that day.  Having defined the above rule, what query should she make
to find this out?

@end enumerate
@end quotation

@quotation
@strong{@anchor{Exercise 4.60}Exercise 4.60:} By giving the query

@example
// Query: who lives near Alyssa?
db.employees.iter()
    .filter(|e| lives_near(db, e.name.clone(), ("Hacker", "Alyssa P")))
@end example

Alyssa P. Hacker is able to find people who live near her, with whom she can
ride to work.  On the other hand, when she tries to find all pairs of people
who live near each other by querying

@example
(lives-near ?person-1 ?person-2)
@end example

@noindent
she notices that each pair of people who live near each other is listed twice;
for example,

@example
(lives-near (Hacker Alyssa P) (Fect Cy D))
(lives-near (Fect Cy D) (Hacker Alyssa P))
@end example

Why does this happen?  Is there a way to find a list of people who live near
each other, in which each pair appears only once?  Explain.
@end quotation

@subsubheading Logic as programs

We can regard a rule as a kind of logical implication: @emph{If} an assignment
of values to pattern variables satisfies the body, @emph{then} it satisfies the
conclusion.  Consequently, we can regard the query language as having the
ability to perform @newterm{logical deductions} based upon the rules.  As an
example, consider the @code{append} operation described at the beginning of
@ref{4.4}.  As we said, @code{append} can be characterized by the
following two rules:

@itemize @bullet

@item
For any list @code{y}, the empty list and @code{y} @code{append} to form
@code{y}.

@item
For any @code{u}, @code{v}, @code{y}, and @code{z}, @code{(cons u v)} and
@code{y} @code{append} to form @code{(cons u z)} if @code{v} and @code{y}
@code{append} to form @code{z}.

@end itemize

@noindent
To express this in our query language, we define two rules for a relation

@example
(append-to-form x y z)
@end example

@noindent
which we can interpret to mean ``@code{x} and @code{y} @code{append} to form
@code{z}'':

@example
(rule (append-to-form () ?y ?y))
(rule (append-to-form (?u . ?v) ?y (?u . ?z))
      (append-to-form ?v ?y ?z))
@end example

@noindent
The first rule has no body, which means that the conclusion holds for any value
of @code{?y}.  Note how the second rule makes use of dotted-tail notation to
name the @code{car} and @code{cdr} of a list.

Given these two rules, we can formulate queries that compute the @code{append}
of two lists:

@example
;;; Query input:
(append-to-form (a b) (c d) ?z)

;;; Query results:
(append-to-form (a b) (c d) (a b c d))
@end example

@noindent
What is more striking, we can use the same rules to ask the question ``Which
list, when @code{append}ed to @code{(a b)}, yields @code{(a b c d)}?''  This is
done as follows:

@example
;;; Query input:
(append-to-form (a b) ?y (a b c d))

;;; Query results:
(append-to-form (a b) (c d) (a b c d))
@end example

@noindent
We can also ask for all pairs of lists that @code{append} to form @code{(a b c
d)}:

@example
;;; Query input:
(append-to-form ?x ?y (a b c d))

;;; Query results:
(append-to-form () (a b c d) (a b c d))
(append-to-form (a) (b c d) (a b c d))
(append-to-form (a b) (c d) (a b c d))
(append-to-form (a b c) (d) (a b c d))
(append-to-form (a b c d) () (a b c d))
@end example

@noindent
The query system may seem to exhibit quite a bit of intelligence in using the
rules to deduce the answers to the queries above.  Actually, as we will see in
the next section, the system is following a well-determined algorithm in
unraveling the rules.  Unfortunately, although the system works impressively in
the @code{append} case, the general methods may break down in more complex
cases, as we will see in @ref{4.4.3}.

@quotation
@strong{@anchor{Exercise 4.61}Exercise 4.61:} The following rules implement a
@code{next-to} relation that finds adjacent elements of a list:

@example
(rule (?x next-to ?y in (?x ?y . ?u)))
(rule (?x next-to ?y in (?v . ?z))
      (?x next-to ?y in ?z))
@end example

What will the response be to the following queries?

@example
(?x next-to ?y in (1 (2 3) 4))
(?x next-to 1 in (2 1 3 1))
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 4.62}Exercise 4.62:} Define rules to implement the
@code{last-pair} operation of @ref{Exercise 2.17}, which returns a list
containing the last element of a nonempty list.  Check your rules on queries
such as @code{(last-pair (3) ?x)}, @code{(last-pair (1 2 3) ?x)} and
@code{(last-pair (2 ?x) (3))}.  Do your rules work correctly on queries such as
@code{(last-pair ?x (3))}?
@end quotation

@quotation
@strong{@anchor{Exercise 4.63}Exercise 4.63:} The following data base (see
Genesis 4) traces the genealogy of the descendants of Ada back to Adam, by way
of Cain:

@example
(son Adam Cain) (son Cain Enoch)
(son Enoch Irad) (son Irad Mehujael)
(son Mehujael Methushael)
(son Methushael Lamech)
(wife Lamech Ada) (son Ada Jabal)
(son Ada Jubal)
@end example

Formulate rules such as ``If @math{S} is the son of @math{f}, and @math{f} is the son of
@math{G}, then @math{S} is the grandson of @math{G}'' and ``If @math{W} is the wife of
@math{M}, and @math{S} is the son of @math{W}, then @math{S} is the son of @math{M}'' (which
was supposedly more true in biblical times than today) that will enable the
query system to find the grandson of Cain; the sons of Lamech; the grandsons of
Methushael.  (See @ref{Exercise 4.69} for some rules to deduce more complicated
relationships.)
@end quotation

@node	4.4.2, 4.4.3, 4.4.1, 4.4
@subsection 질의 시스템의 작동 방식 (How the Query System Works)

@ref{4.4.4}에서는 질의 인터프리터를 프로시저들의 모음으로 구현한 내용을 제시할 것이다.
이 절에서는 저수준 구현 세부 사항과 독립적으로 시스템의 일반적인 구조를 설명하는 개요를 제공한다.
인터프리터의 구현을 설명한 후에는, 인터프리터의 몇 가지 한계와 질의 언어의 논리 연산이 수학적 논리의 연산과 미묘하게 다른 몇 가지 방식을 이해할 수 있는 위치에 있게 될 것이다.

질의 평가자가 데이터베이스의 사실 및 규칙과 질의를 대조하기 위해 일종의 검색을 수행해야 한다는 것은 명백할 것이다.
이를 수행하는 한 가지 방법은 @ref{4.3}의 @code{amb} 평가자를 사용하여 질의 시스템을 비결정적 프로그램으로 구현하는 것이다(@ref{Exercise 4.78} 참조).
또 다른 가능성은 스트림의 도움을 받아 검색을 관리하는 것이다.
우리 구현은 이 두 번째 접근 방식을 따른다.

질의 시스템은 @newterm{패턴 매칭(pattern matching)}과 @newterm{단일화(unification)}라고 불리는 두 가지 중심 연산을 중심으로 구성된다.
우리는 먼저 패턴 매칭을 설명하고 이 연산이 프레임의 스트림 관점에서의 정보 조직과 함께 어떻게 단순 질의와 복합 질의를 모두 구현할 수 있게 해주는지 설명한다.
다음으로 규칙을 구현하는 데 필요한 패턴 매칭의 일반화인 단일화에 대해 논의한다.
마지막으로, @ref{4.1}에서 설명된 인터프리터에 대해 @code{eval}이 표현식을 분류하는 방식과 유사하게 표현식을 분류하는 프로시저를 통해 전체 질의 인터프리터가 어떻게 조립되는지 보여준다.

@subsubheading 패턴 매칭 (Pattern matching)

A @newterm{pattern matcher} is a program that tests whether some datum fits a
specified pattern.  For example, the data list @code{((a b) c (a b))} matches
the pattern @code{(?x c ?x)} with the pattern variable @code{?x} bound to
@code{(a b)}.  The same data list matches the pattern @code{(?x ?y ?z)} with
@code{?x} and @code{?z} both bound to @code{(a b)} and @code{?y} bound to
@code{c}.  It also matches the pattern @code{((?x ?y) c (?x ?y))} with
@code{?x} bound to @code{a} and @code{?y} bound to @code{b}.  However, it does
not match the pattern @code{(?x a ?y)}, since that pattern specifies a list
whose second element is the symbol @code{a}.

The pattern matcher used by the query system takes as inputs a pattern, a
datum, and a @newterm{frame} that specifies bindings for various pattern
variables.  It checks whether the datum matches the pattern in a way that is
consistent with the bindings already in the frame.  If so, it returns the given
frame augmented by any bindings that may have been determined by the match.
Otherwise, it indicates that the match has failed.

For example, using the pattern @code{(?x ?y ?x)} to match @code{(a b a)} given
an empty frame will return a frame specifying that @code{?x} is bound to
@code{a} and @code{?y} is bound to @code{b}.  Trying the match with the same
pattern, the same datum, and a frame specifying that @code{?y} is bound to
@code{a} will fail.  Trying the match with the same pattern, the same datum,
and a frame in which @code{?y} is bound to @code{b} and @code{?x} is unbound
will return the given frame augmented by a binding of @code{?x} to @code{a}.

The pattern matcher is all the mechanism that is needed to process simple
queries that don't involve rules.  For instance, to process the query

@example
(job ?x (computer programmer))
@end example

@noindent
we scan through all assertions in the data base and select those that match the
pattern with respect to an initially empty frame.  For each match we find, we
use the frame returned by the match to instantiate the pattern with a value for
@code{?x}.

@subsubheading Streams of frames

The testing of patterns against frames is organized through the use of streams.
Given a single frame, the matching process runs through the data-base entries
one by one.  For each data-base entry, the matcher generates either a special
symbol indicating that the match has failed or an extension to the frame.  The
results for all the data-base entries are collected into a stream, which is
passed through a filter to weed out the failures.  The result is a stream of
all the frames that extend the given frame via a match to some assertion in the
data base.@footnote{Because matching is generally very expensive, we would like
to avoid applying the full matcher to every element of the data base.  This is
usually arranged by breaking up the process into a fast, coarse match and the
final match.  The coarse match filters the data base to produce a small set of
candidates for the final match.  With care, we can arrange our data base so
that some of the work of coarse matching can be done when the data base is
constructed rather then when we want to select the candidates.  This is called
@newterm{indexing} the data base.  There is a vast technology built around
data-base-indexing schemes.  Our implementation, described in 
@ref{4.4.4}, contains a simple-minded form of such an optimization.}

In our system, a query takes an input stream of frames and performs the above
matching operation for every frame in the stream, as indicated in @ref{Figure 4.4}.  
That is, for each frame in the input stream, the query generates a new
stream consisting of all extensions to that frame by matches to assertions in
the data base.  All these streams are then combined to form one huge stream,
which contains all possible extensions of every frame in the input stream.
This stream is the output of the query.

@float
@anchor{Figure 4.4}
@ifinfo
@strong{Figure 4.4:} A query processes a stream of frames.

@example
                                  output stream
  input stream   +-------------+  of frames,
  of frames      |    query    |  filtered and extended
---------------->|             +------------------------->
                 | (job ?x ?y) |
                 +-------------+
                        ^
                        |
               stream of assertions
                  from data base
@end example
@end ifinfo
@iftex
@image{fig/chap4/Fig4.4a,147mm,,,.std.svg}
@caption{@strong{Figure 4.4:} A query processes a stream of frames.}
@end iftex
@end float

@noindent
To answer a simple query, we use the query with an input stream consisting of a
single empty frame.  The resulting output stream contains all extensions to the
empty frame (that is, all answers to our query).  This stream of frames is then
used to generate a stream of copies of the original query pattern with the
variables instantiated by the values in each frame, and this is the stream that
is finally printed.

@subsubheading Compound queries

The real elegance of the stream-of-frames implementation is evident when we
deal with compound queries.  The processing of compound queries makes use of
the ability of our matcher to demand that a match be consistent with a
specified frame.  For example, to handle the @code{and} of two queries, such as

@example
(and (can_do_job
      ?x
      (computer programmer trainee))
     (job ?person ?x))
@end example

@noindent
(informally, ``Find all people who can do the job of a computer programmer
trainee''), we first find all entries that match the pattern

@example
(can_do_job ?x (computer programmer trainee))
@end example

@noindent
This produces a stream of frames, each of which contains a binding for
@code{?x}.  Then for each frame in the stream we find all entries that match

@example
(job ?person ?x)
@end example

@noindent
in a way that is consistent with the given binding for @code{?x}.  Each such
match will produce a frame containing bindings for @code{?x} and
@code{?person}.  The @code{and} of two queries can be viewed as a series
combination of the two component queries, as shown in @ref{Figure 4.5}.  The
frames that pass through the first query filter are filtered and further
extended by the second query.

@float
@anchor{Figure 4.5}
@ifinfo
@strong{Figure 4.5:} The @code{and} combination of two queries is produced 
by operating on the stream of frames in series.

@example
                +----------------------+
                |       (and A B)      |
  input stream  |                      |  output stream
  of frames     |   +---+       +---+  |  of frames
------------------->| A +------>| B +-------------------->
                |   +---+       +---+  |
                |     ^           ^    |
                |     |           |    |
                |     +-----*-----+    |
                +-----------|----------+
                            |
                        data base
@end example
@end ifinfo
@iftex
@image{fig/chap4/Fig4.5a,143mm,,,.std.svg}
@caption{@strong{Figure 4.5:} The @code{and} combination of two queries is produced by operating on the stream of frames in series.}
@end iftex
@end float

@noindent
@ref{Figure 4.6} shows the analogous method for computing the @code{or} of two
queries as a parallel combination of the two component queries.  The input
stream of frames is extended separately by each query.  The two resulting
streams are then merged to produce the final output stream.

@float
@anchor{Figure 4.6}
@ifinfo
@strong{Figure 4.6:} The @code{or} combination of two queries is produced 
by operating on the stream of frames in parallel and merging the results.

@example
           +---------------------------+
           |          (or A B)         |
           |    +---+                  |
input      | +->| A |------------+     |  output
stream of  | |  +---+            V     |  stream of
frames     | |    ^          +-------+ |  frames
-------------*    |          | merge +--------------->
           | |    |          +-------+ |
           | |    |              ^     |
           | |    |   +---+      |     |
           | +------->| B +------+     |
           |      |   +---+            |
           |      |     ^              |
           |      |     |              |
           |      +--*--+              |
           +---------|-----------------+
                     |
                 data base
@end example
@end ifinfo
@iftex
@image{fig/chap4/Fig4.6a,147mm,,,.std.svg}
@caption{@strong{Figure 4.6:} The @code{or} combination of two queries is produced by operating on the stream of frames in parallel and merging the results.}
@end iftex
@end float

Even from this high-level description, it is apparent that the processing of
compound queries can be slow.  For example, since a query may produce more than
one output frame for each input frame, and each query in an @code{and} gets its
input frames from the previous query, an @code{and} query could, in the worst
case, have to perform a number of matches that is exponential in the number of
queries (see @ref{Exercise 4.76}).@footnote{But this kind of exponential
explosion is not common in @code{and} queries because the added conditions tend
to reduce rather than expand the number of frames produced.} Though systems for
handling only simple queries are quite practical, dealing with complex queries
is extremely difficult.@footnote{There is a large literature on
data-base-management systems that is concerned with how to handle complex
queries efficiently.}

@noindent
From the stream-of-frames viewpoint, the @code{not} of some query acts as a
filter that removes all frames for which the query can be satisfied.  For
instance, given the pattern

@example
(not (job ?x (computer programmer)))
@end example

@noindent
we attempt, for each frame in the input stream, to produce extension frames
that satisfy @code{(job ?x (computer programmer))}.  We remove from the input
stream all frames for which such extensions exist.  The result is a stream
consisting of only those frames in which the binding for @code{?x} does not
satisfy @code{(job ?x (computer programmer))}.  For example, in processing the
query

@example
(and (supervisor ?x ?y)
     (not (job ?x (computer programmer))))
@end example

@noindent
the first clause will generate frames with bindings for @code{?x} and
@code{?y}.  The @code{not} clause will then filter these by removing all frames
in which the binding for @code{?x} satisfies the restriction that @code{?x} is
a computer programmer.@footnote{There is a subtle difference between this
filter implementation of @code{not} and the usual meaning of @code{not} in
mathematical logic.  See @ref{4.4.3}.}

The @code{lisp-value} special form is implemented as a similar filter on frame
streams.  We use each frame in the stream to instantiate any variables in the
pattern, then apply the Lisp predicate.  We remove from the input stream all
frames for which the predicate fails.

@subsubheading 단일화 (Unification)

질의 언어에서 규칙을 다루기 위해, 우리는 주어진 질의 패턴과 일치하는 결론을 가진 규칙들을 찾을 수 있어야 한다.
규칙 결론은 변수를 포함할 수 있다는 점을 제외하면 주장과 같으므로, 우리는 ``패턴''과 ``데이터''가 모두 변수를 포함할 수 있는 패턴 매칭의 일반화인 @newterm{단일화(unification)}가 필요하다.

단일화 도구(unifier)는 각각 상수와 변수를 포함하는 두 개의 패턴을 입력으로 받아, 두 패턴을 동일하게 만들 수 있는 변수들에 대한 값의 대입이 가능한지 결정한다.
만약 그렇다면, 이러한 바인딩을 포함하는 프레임을 반환한다.
예를 들어, @code{(?x a ?y)}와 @code{(?y ?z a)}를 단일화하면 @code{?x}, @code{?y}, @code{?z}가 모두 @code{a}에 바인딩되어야 함을 지정하는 프레임을 반환할 것이다.
반면에, @code{(?x ?y a)}와 @code{(?x b ?y)}를 단일화하려고 하면 실패할 것인데, 왜냐하면 두 패턴을 같게 만들 수 있는 @code{?y}의 값이 없기 때문이다.
(패턴의 두 번째 요소가 같으려면 @code{?y}가 @code{b}여야 하지만; 세 번째 요소가 같으려면 @code{?y}가 @code{a}여야 한다.)
질의 시스템에서 사용되는 단일화 도구는 패턴 매처와 마찬가지로 프레임을 입력으로 받아 이 프레임과 일치하는 단일화를 수행한다.

단일화 알고리즘은 질의 시스템에서 기술적으로 가장 어려운 부분이다.
복잡한 패턴의 경우, 단일화를 수행하는 것이 추론을 요구하는 것처럼 보일 수 있다.
예를 들어 @code{(?x ?x)}와 @code{((a ?y c) (a b ?z))}를 단일화하기 위해, 알고리즘은 @code{?x}가 @code{(a b c)}여야 하고, @code{?y}는 @code{b}여야 하며, @code{?z}는 @code{c}여야 함을 추론해야 한다.
우리는 이 프로세스를 패턴 구성 요소들 사이의 방정식 집합을 푸는 것으로 생각할 수 있다.
일반적으로 이것들은 연립 방정식이며, 이를 풀기 위해 상당한 조작이 필요할 수 있다.@footnote{일방향 패턴 매칭에서, 패턴 변수를 포함하는 모든 방정식은 명시적이며 이미 미지수(패턴 변수)에 대해 풀려 있다.}
예를 들어, @code{(?x ?x)}와 @code{((a ?y c) (a b ?z))}를 단일화하는 것은 다음과 같은 연립 방정식을 지정하는 것으로 생각할 수 있다.

@example
?x = (a ?y c)
?x = (a b ?z)
@end example

@noindent
이 방정식들은 다음을 의미한다.

@example
(a ?y c) = (a b ?z)
@end example

@noindent
이는 다시 다음을 의미하고,

@example
a = a, ?y = b, c = ?z,
@end example

@noindent
결과적으로 다음과 같다.

@example
?x = (a b c)
@end example

@noindent
성공적인 패턴 매칭에서는 모든 패턴 변수가 바인딩되며, 그 값들은 오직 상수만을 포함한다.
이것은 우리가 지금까지 본 단일화의 모든 예에서도 마찬가지이다.
그러나 일반적으로 성공적인 단일화가 변수 값들을 완전히 결정하지 못할 수도 있다; 일부 변수는 바인딩되지 않은 채로 남을 수 있고 다른 변수들은 변수를 포함하는 값에 바인딩될 수 있다.

@code{(?x a)}와 @code{((b ?y) ?z)}의 단일화를 고려해 보자.
우리는 @code{?x = (b ?y)}이고 @code{a = ?z}임을 연역할 수 있지만, @code{?x}나 @code{?y}에 대해 더 이상 풀 수 없다.
단일화는 실패하지 않는데, 왜냐하면 @code{?x}와 @code{?y}에 값을 대입함으로써 두 패턴을 같게 만드는 것이 분명 가능하기 때문이다.
이 매치는 @code{?y}가 가질 수 있는 값을 어떤 방식으로도 제한하지 않으므로, @code{?y}에 대한 바인딩은 결과 프레임에 들어가지 않는다.
하지만 이 매치는 @code{?x}의 값을 제한한다.
@code{?y}가 어떤 값을 갖든, @code{?x}는 @code{(b ?y)}여야 한다.
따라서 @code{?x}를 패턴 @code{(b ?y)}에 바인딩하는 것이 프레임에 추가된다.
만약 @code{?y}의 값이 나중에 결정되어 프레임에 추가된다면(이 프레임과 일치해야 하는 패턴 매칭이나 단일화에 의해), 이전에 바인딩된 @code{?x}는 이 값을 참조하게 될 것이다.@footnote{단일화를 생각하는 또 다른 방법은 그것이 두 입력 패턴의 특수화인 가장 일반적인 패턴을 생성한다는 것이다. 즉, @code{(?x a)}와 @code{((b ?y) ?z)}의 단일화는 @code{((b ?y) a)}이고, 위에서 논의된 @code{(?x a ?y)}와 @code{(?y ?z a)}의 단일화는 @code{(a a a)}이다. 우리 구현의 경우, 단일화의 결과를 패턴보다는 프레임으로 생각하는 것이 더 편리하다.}

@subsubheading 규칙 적용하기 (Applying rules)

단일화는 규칙으로부터 추론을 하는 질의 시스템의 구성 요소에 대한 핵심이다.
이것이 어떻게 달성되는지 보기 위해, 다음과 같이 규칙을 적용하는 것을 포함하는 질의 처리를 고려해 보자.

@example
(lives-near ?x (Hacker Alyssa P))
@end example

@noindent
이 질의를 처리하기 위해, 우리는 먼저 위에 설명된 일반적인 패턴 매치 프로시저를 사용하여 데이터베이스에 이 패턴과 일치하는 주장이 있는지 확인한다. (이 경우에는 없을 것인데, 우리 데이터베이스에는 누가 누구 근처에 사는지에 대한 직접적인 주장이 없기 때문이다.)
다음 단계는 질의 패턴을 각 규칙의 결론과 단일화하려고 시도하는 것이다.
우리는 패턴이 다음 규칙의 결론과 단일화됨을 발견한다.

@example
(rule (lives-near ?person-1 ?person-2)
      (and (address ?person-1
                    (?town . ?rest-1))
           (address ?person-2
                    (?town . ?rest-2))
           (not (same ?person-1 ?person-2))))
@end example

@noindent
그 결과로 @code{?person-2}가 @code{(Hacker Alyssa P)}에 바인딩되고 @code{?x}가 @code{?person-1}에 바인딩되어야 함(동일한 값을 가져야 함)을 지정하는 프레임을 얻는다.
이제 이 프레임에 대해 상대적으로, 우리는 규칙의 본문에 의해 주어진 복합 질의를 평가한다.
성공적인 매치는 @code{?person-1}에 대한 바인딩을 제공함으로써 이 프레임을 확장할 것이고, 결과적으로 @code{?x}에 대한 값을 제공할 것이며, 우리는 이를 사용하여 원래 질의 패턴을 인스턴스화할 수 있다.

일반적으로, 질의 평가자는 일부 패턴 변수에 대한 바인딩을 지정하는 프레임에서 질의 패턴을 확립하려고 시도할 때 규칙을 적용하기 위해 다음 방법을 사용한다.

@itemize @bullet

@item
질의를 규칙의 결론과 단일화하여 성공할 경우 원래 프레임의 확장을 형성한다.

@item
확장된 프레임에 대해 상대적으로, 규칙의 본문에 의해 형성된 질의를 평가한다.

@end itemize

@noindent
이것이 Lisp를 위한 @code{eval}/@code{apply} 평가자에서 프로시저를 적용하는 방법과 얼마나 유사한지 주목하라.

@itemize @bullet

@item
프로시저의 매개변수를 인자에 바인딩하여 원래 프로시저 환경을 확장하는 프레임을 형성한다.

@item
확장된 환경에 대해 상대적으로, 프로시저의 본문에 의해 형성된 표현식을 평가한다.

@end itemize

@noindent
두 평가자 사이의 유사성은 놀랄 일이 아니다.
프로시저 정의가 Lisp에서의 추상화 수단인 것처럼, 규칙 정의는 질의 언어에서의 추상화 수단이다.
각 경우에, 우리는 적절한 바인딩을 만들고 이들에 대해 상대적으로 규칙이나 프로시저 본문을 평가함으로써 추상화를 푼다.

@subsubheading 단순 질의 (Simple queries)

우리는 이 절의 앞부분에서 규칙이 없는 상황에서 단순 질의를 평가하는 방법을 보았다.
이제 규칙을 적용하는 방법을 보았으므로, 규칙과 주장을 모두 사용하여 단순 질의를 평가하는 방법을 설명할 수 있다.

질의 패턴과 프레임 스트림이 주어지면, 우리는 입력 스트림의 각 프레임에 대해 두 개의 스트림을 생성한다.

@itemize @bullet

@item
데이터베이스의 모든 주장과 패턴을 대조하여 얻은 확장된 프레임의 스트림(패턴 매처 사용), 그리고

@item
가능한 모든 규칙을 적용하여 얻은 확장된 프레임의 스트림(단일화 도구 사용).@footnote{단일화는 매칭의 일반화이므로, 우리는 단일화 도구를 사용하여 두 스트림을 모두 생성하도록 시스템을 단순화할 수 있다. 하지만 단순 매처를 사용하여 쉬운 경우를 처리하는 것은 매칭(본격적인 단일화와 대조적으로) 그 자체로 어떻게 유용할 수 있는지 보여준다.}

@end itemize

@noindent
이 두 스트림을 이어붙이면(append) 원래 프레임과 일치하는 방식으로 주어진 패턴이 만족될 수 있는 모든 방법으로 구성된 스트림이 생성된다.
이러한 스트림들(입력 스트림의 각 프레임에 대해 하나씩)은 이제 모두 결합되어 하나의 거대한 스트림을 형성하며, 이 스트림은 원래 입력 스트림의 프레임들 중 임의의 것이 주어진 패턴과 일치하도록 확장될 수 있는 모든 방법으로 구성된다.

@subsubheading 질의 평가자와 드라이버 루프 (The query evaluator and the driver loop)

기저에 깔린 매칭 연산들의 복잡성에도 불구하고, 시스템은 임의의 언어를 위한 평가자와 매우 비슷하게 구성되어 있다.
매칭 연산들을 조정하는 프로시저는 @code{qeval}이라고 불리며, 그것은 Lisp를 위한 @code{eval} 프로시저와 유사한 역할을 한다.
@code{qeval}은 질의와 프레임 스트림을 입력으로 받는다.
그것의 출력은 @ref{Figure 4.4}에 표시된 대로 입력 스트림의 어떤 프레임을 확장하는, 질의 패턴에 대한 성공적인 매치에 대응하는 프레임 스트림이다.
@code{eval}과 마찬가지로, @code{qeval}은 서로 다른 유형의 표현식(질의)을 분류하고 각각에 대해 적절한 프로시저로 디스패치한다.
각 특수 형식(@code{and}, @code{or}, @code{not}, @code{lisp-value})에 대한 프로시저가 하나씩 있고 단순 질의를 위한 프로시저가 하나 있다.

이 장의 다른 평가자들을 위한 @code{driver_loop} 프로시저와 유사한 드라이버 루프는 터미널에서 질의를 읽는다.
각 질의에 대해, 그것은 질의와 단일 빈 프레임으로 구성된 스트림을 가지고 @code{qeval}을 호출한다.
이것은 모든 가능한 매치(빈 프레임에 대한 모든 가능한 확장)의 스트림을 생성할 것이다.
결과 스트림의 각 프레임에 대해, 프레임에서 발견된 변수들의 값을 사용하여 원래 질의를 인스턴스화한다.
이렇게 인스턴스화된 질의들의 스트림이 최종적으로 출력된다.@footnote{우리가 프레임의 리스트가 아니라 스트림을 사용하는 이유는 규칙의 재귀적 적용이 질의를 만족시키는 무한한 수의 값을 생성할 수 있기 때문이다. 스트림에 구현된 지연 평가는 여기서 결정적이다: 시스템은 응답이 유한하든 무한하든 상관없이 응답이 생성되는 대로 하나씩 출력할 것이다.}

드라이버는 또한 입력이 질의가 아니라 데이터베이스에 추가될 주장이나 규칙임을 나타내는 @code{assert!} 특수 명령을 확인한다.
예를 들어,

@example
(assert!
 (job (Bitdiddle Ben)
      (computer wizard)))

(assert!
 (rule (wheel ?person)
       (and (supervisor
             ?middle-manager ?person)
            (supervisor
             ?x ?middle-manager))))
@end example

@node	4.4.3, 4.4.4, 4.4.2, 4.4
@subsection 논리 프로그래밍은 수학적 논리인가? (Is Logic Programming Mathematical Logic?)

질의 언어에서 사용되는 결합 수단은 처음에는 수학적 논리의 연산인 @code{and}, @code{or}, 그리고 @code{not}과 동일해 보일 수 있으며, 질의 언어 규칙의 적용은 실제로 정당한 추론 방법에 의해 달성된다.@footnote{특정 추론 방법이 정당하다는 것은 사소한 주장이 아니다. 참인 전제에서 시작하면 참인 결론만 도출될 수 있음을 증명해야 한다. 규칙 적용으로 표현되는 추론 방법은 @newterm{전건 긍정(modus ponens)}으로, @math{A}가 참이고 @emph{A가 B를 함축한다}가 참이면 @math{B}가 참이라고 결론 내릴 수 있다는 친숙한 추론 방법이다.}
하지만 질의 언어를 수학적 논리와 동일시하는 것은 실제로는 타당하지 않은데, 왜냐하면 질의 언어는 논리적 문장을 절차적으로 해석하는 @newterm{제어 구조(control structure)}를 제공하기 때문이다.
우리는 종종 이 제어 구조를 활용할 수 있다.
예를 들어, 프로그래머의 모든 감독관을 찾기 위해 우리는 논리적으로 동등한 두 가지 형식 중 하나로 질의를 공식화할 수 있다.

@example
(and (job ?x (computer programmer))
     (supervisor ?x ?y))
@end example

@noindent
또는

@example
(and (supervisor ?x ?y)
     (job ?x (computer programmer)))
@end example

@noindent
만약 회사가 프로그래머보다 훨씬 더 많은 감독관을 가지고 있다면(보통의 경우), 두 번째 형식보다는 첫 번째 형식을 사용하는 것이 더 나은데, 왜냐하면 @code{and}의 첫 번째 절에 의해 생성된 각 중간 결과(프레임)에 대해 데이터베이스를 스캔해야 하기 때문이다.

논리 프로그래밍의 목표는 프로그래머에게 계산 문제를 두 개의 별개 문제로 분해하는 기술을 제공하는 것이다: ``무엇''이 계산되어야 하는가와, 이것이 ``어떻게'' 계산되어야 하는가이다.
이것은 계산하고자 하는 무엇이든 설명할 수 있을 만큼 강력하면서도 제어 가능한 절차적 해석을 가질 수 있을 만큼 약한 수학적 논리 문장들의 부분 집합을 선택함으로써 달성된다.
여기서의 의도는, 한편으로는 논리 프로그래밍 언어로 지정된 프로그램이 컴퓨터에 의해 수행될 수 있는 효과적인 프로그램이어야 한다는 것이다.
제어(``어떻게'' 계산할 것인가)는 언어의 평가 순서를 사용함으로써 이루어진다.
우리는 계산이 효과적이고 효율적이라고 간주되는 순서대로 수행되도록 각 절의 순서와 각 절 내부의 하위 목표들의 순서를 정리할 수 있어야 한다.
동시에, 우리는 계산의 결과(``무엇''을 계산할 것인가)를 논리 법칙의 단순한 결과로 볼 수 있어야 한다.

우리 질의 언어는 바로 그러한 절차적으로 해석 가능한 수학적 논리의 부분 집합으로 간주될 수 있다.
주장은 단순한 사실(원자 명제)을 나타낸다.
규칙은 규칙 본문이 성립하는 경우 규칙 결론이 성립한다는 함축을 나타낸다.
규칙은 자연스러운 절차적 해석을 갖는다: 규칙의 결론을 확립하기 위해, 규칙의 본문을 확립하라.
따라서 규칙은 계산을 지정한다.
그러나 규칙은 수학적 논리의 문장으로도 간주될 수 있기 때문에, 우리는 전적으로 수학적 논리 내에서 작업함으로써 동일한 결과를 얻을 수 있다고 주장함으로써 논리 프로그램에 의해 달성된 모든 ``추론''을 정당화할 수 있다.@footnote{우리는 논리 프로그램에 의해 달성된 ``추론''에 대해 말할 때 계산이 종료된다고 가정한다는 점에 동의함으로써 이 진술을 제한해야 한다. 불행하게도, @code{not}과 @code{lisp-value}의 사용 때문에 우리 질의 언어 구현에 대해(그리고 Prolog 및 대부분의 다른 현재 논리 프로그래밍 언어의 프로그램에 대해) 이 제한된 진술조차 거짓이다. 아래에서 설명하겠지만, 질의 언어에서 구현된 @code{not}은 항상 수학적 논리의 @code{not}과 일치하는 것은 아니며, @code{lisp-value}는 추가적인 복잡성을 도입한다. 우리는 단순히 언어에서 @code{not}과 @code{lisp-value}를 제거하고 단순 질의, @code{and}, 그리고 @code{or}만을 사용하여 프로그램을 작성하기로 동의함으로써 수학적 논리와 일치하는 언어를 구현할 수 있다. 그러나 이것은 언어의 표현력을 크게 제한할 것이다. 논리 프로그래밍 연구의 주요 관심사 중 하나는 표현력을 과도하게 희생하지 않으면서 수학적 논리와 더 많은 일관성을 달성하는 방법을 찾는 것이다.}

@subsubheading 무한 루프 (Infinite loops)

논리 프로그램의 절차적 해석의 결과로, 특정 문제를 해결하기 위해 희망 없을 정도로 비효율적인 프로그램을 구성하는 것이 가능하다.
비효율성의 극단적인 경우는 시스템이 연역을 수행하다가 무한 루프에 빠질 때 발생한다.
간단한 예로, 다음을 포함하는 유명한 결혼 데이터베이스를 설정한다고 가정해 보자.

@example
(assert! (married Minnie Mickey))
@end example

@noindent
이제 우리가 다음과 같이 묻는다면

@example
(married Mickey ?who)
@end example

@noindent
우리는 아무런 응답도 받지 못할 것인데, 왜냐하면 시스템은 @math{A}가 @math{B}와 결혼했다면 @math{B}도 @math{A}와 결혼했다는 것을 모르기 때문이다.
그래서 우리는 다음과 같이 규칙을 주장한다.

@example
(assert! (rule (married ?x ?y)
               (married ?y ?x)))
@end example

@noindent
그리고 다시 질의한다.

@example
(married Mickey ?who)
@end example

불행하게도, 이것은 다음과 같이 시스템을 무한 루프로 몰고 갈 것이다.

@itemize @bullet

@item
시스템은 @code{married} 규칙이 적용 가능하다는 것을 발견한다; 즉, 규칙 결론 @code{(married ?x ?y)}는 질의 패턴 @code{(married Mickey ?who)}와 성공적으로 단일화되어 @code{?x}가 @code{Mickey}에 바인딩되고 @code{?y}가 @code{?who}에 바인딩되는 프레임을 생성한다.
따라서 인터프리터는 이 프레임에서 규칙 본문 @code{(married ?y ?x)}를 평가하러 진행한다 --- 사실상, 질의 @code{(married ?who Mickey)}를 처리하는 것이다.

@item
한 가지 답은 데이터베이스의 주장으로 직접 나타난다: @code{(married Minnie Mickey)}.

@item
@code{married} 규칙 또한 적용 가능하므로, 인터프리터는 다시 규칙 본문을 평가하는데, 이번에는 @code{(married Mickey ?who)}와 동등하다.

@end itemize

@noindent
시스템은 이제 무한 루프에 빠졌다.
사실, 시스템이 루프에 들어가기 전에 단순한 답 @code{(married Minnie Mickey)}를 찾을지 여부는 시스템이 데이터베이스의 항목을 확인하는 순서에 관한 구현 세부 사항에 달려 있다.
이것은 발생할 수 있는 루프 종류의 아주 간단한 예이다.
상호 관련된 규칙들의 모음은 예상하기 훨씬 더 어려운 루프로 이어질 수 있으며, 루프의 출현은 @code{and} 내의 절의 순서(@ref{Exercise 4.64} 참조)나 시스템이 질의를 처리하는 순서에 관한 저수준 세부 사항에 의존할 수 있다.@footnote{이것은 논리의 문제가 아니라 우리 인터프리터가 제공하는 논리의 절차적 해석의 문제이다. 우리는 여기서 루프에 빠지지 않는 인터프리터를 작성할 수 있다. 예를 들어, 우리는 깊이 우선 순서보다는 너비 우선 순서로 우리의 주장과 규칙에서 파생될 수 있는 모든 증명을 열거할 수 있다. 그러나 그러한 시스템은 우리 프로그램에서 연역의 순서를 활용하는 것을 더 어렵게 만든다. 그러한 프로그램에 정교한 제어를 구축하려는 한 가지 시도는 @ref{deKleer et al. 1977}에 설명되어 있다. 그러한 심각한 제어 문제로 이어지지 않는 또 다른 기술은 특정 종류의 루프에 대한 탐지기와 같은 특별한 지식을 넣는 것이다 (@ref{Exercise 4.67}). 그러나 연역을 수행할 때 시스템이 무한 경로로 빠지는 것을 확실하게 방지하기 위한 일반적인 체계는 있을 수 없다. 어떤 적절하게 선택된 함수 @math{f}에 대해 ``@math{{P(x)}}가 참임을 보이기 위해, @math{{P(f(x))}}가 참임을 보여라''라는 형태의 사악한 규칙을 상상해 보라.}

@subsubheading @code{not}과 관련된 문제들 (Problems with @code{not})

질의 시스템의 또 다른 특이점은 @code{not}과 관련이 있다.
@ref{4.4.1}의 데이터베이스가 주어졌을 때, 다음 두 질의를 고려해 보자.

@example
(and (supervisor ?x ?y)
     (not (job ?x (computer programmer))))

(and (not (job ?x (computer programmer)))
     (supervisor ?x ?y))
@end example

@noindent
이 두 질의는 동일한 결과를 생성하지 않는다.
첫 번째 질의는 데이터베이스에서 @code{(supervisor ?x ?y)}와 일치하는 모든 항목을 찾는 것으로 시작하여, @code{?x}의 값이 @code{(job ?x (computer programmer))}를 만족시키는 프레임들을 제거함으로써 결과 프레임들을 필터링한다.
두 번째 질의는 들어오는 프레임들을 필터링하여 @code{(job ?x (computer programmer))}를 만족시킬 수 있는 것들을 제거하는 것으로 시작한다.
들어오는 유일한 프레임이 비어 있기 때문에, 시스템은 데이터베이스를 확인하여 @code{(job ?x (computer programmer))}를 만족시키는 패턴이 있는지 확인한다.
일반적으로 이러한 형식의 항목들이 존재하므로, @code{not} 절은 빈 프레임을 걸러내고 빈 프레임 스트림을 반환한다.
결과적으로, 전체 복합 질의는 빈 스트림을 반환한다.

문제는 우리 @code{not} 구현이 실제로는 변수 값들에 대한 필터 역할을 하도록 의도되었다는 것이다.
만약 @code{not} 절이 (위의 예제에서의 @code{?x}처럼) 일부 변수가 바인딩되지 않은 상태로 남아 있는 프레임을 가지고 처리되면, 시스템은 예상치 못한 결과를 생성할 것이다.
@code{lisp-value}의 사용에서도 유사한 문제가 발생한다 --- Lisp 술어는 인자 중 일부가 바인딩되지 않은 경우 작동할 수 없다.
@ref{Exercise 4.77}을 참조하라.

질의 언어의 @code{not}이 수학적 논리의 @code{not}과 다른 훨씬 더 심각한 방식이 있다.
논리에서 우리는 문장 ``not @math{P}''를 @math{P}가 참이 아님을 의미하는 것으로 해석한다.
그러나 질의 시스템에서 ``not @math{P}''는 @math{P}가 데이터베이스의 지식으로부터 연역 가능하지 않음을 의미한다.
예를 들어, @ref{4.4.1}의 인사 데이터베이스가 주어졌을 때, 시스템은 Ben Bitdiddle이 야구 팬이 아니라거나, 밖에 비가 오지 않는다거나, 2 + 2가 4가 아니라는 등의 온갖 @code{not} 문장들을 기꺼이 연역할 것이다.@footnote{질의 @code{(not (baseball-fan (Bitdiddle Ben)))}를 고려해 보자. 시스템은 @code{(baseball-fan (Bitdiddle Ben))}이 데이터베이스에 없음을 발견하므로, 빈 프레임은 패턴을 만족시키지 않고 초기 프레임 스트림에서 걸러지지 않는다. 따라서 질의의 결과는 빈 프레임이며, 이는 입력 질의를 인스턴스화하여 @code{(not (baseball-fan (Bitdiddle Ben)))}을 생성하는 데 사용된다.}
다시 말해, 논리 프로그래밍 언어의 @code{not}은 모든 관련 정보가 데이터베이스에 포함되어 있다는 소위 @newterm{폐쇄 세계 가정(closed world assumption)}을 반영한다.@footnote{@code{not}에 대한 이러한 취급의 논의와 정당화는 @ref{Clark (1978)}의 기사에서 찾을 수 있다.}

@quotation
@strong{@anchor{Exercise 4.64}연습문제 4.64:} Louis Reasoner는 실수로 데이터베이스에서 @code{outranked_by} 규칙(@ref{4.4.1})을 삭제한다. 그가 이를 깨달았을 때, 그는 재빨리 그것을 다시 설치한다. 불행하게도, 그는 규칙을 약간 변경하여 다음과 같이 입력한다.

@example
(rule (outranked-by ?staff-person ?boss)
  (or (supervisor ?staff-person ?boss)
      (and (outranked-by ?middle-manager
                         ?boss)
           (supervisor ?staff-person
                       ?middle-manager))))
@end example

Louis가 이 정보를 시스템에 입력한 직후, DeWitt Aull이 와서 누가 Ben Bitdiddle보다 높은 직급인지 알아내려고 한다. 그는 다음과 같이 질의를 제기한다.

@example
(outranked-by (Bitdiddle Ben) ?who)
@end example

답을 한 후, 시스템은 무한 루프에 빠진다. 왜 그런지 설명하라.
@end quotation

@quotation
@strong{@anchor{Exercise 4.65}연습문제 4.65:} Cy D. Fect는 조직에서 승진할 날을 고대하며, (@ref{4.4.1}의 @code{wheel} 규칙을 사용하여) 모든 거물을 찾는 질의를 한다.

@example
(wheel ?who)
@end example

놀랍게도 시스템은 다음과 같이 응답한다.

@example
;;; 질의 결과:
(wheel (Warbucks Oliver))
(wheel (Bitdiddle Ben))
(wheel (Warbucks Oliver))
(wheel (Warbucks Oliver))
(wheel (Warbucks Oliver))
@end example

왜 Oliver Warbucks가 네 번이나 나열되는가?
@end quotation

@quotation
@strong{@anchor{Exercise 4.66}연습문제 4.66:} Ben은 회사에 대한 통계를 제공하기 위해 질의 시스템을 일반화해 왔다. 예를 들어, 모든 컴퓨터 프로그래머의 총 급여를 찾기 위해 다음과 같이 말할 수 있을 것이다.

@example
(sum ?amount
     (and (job ?x (computer programmer))
          (salary ?x ?amount)))
@end example

일반적으로 Ben의 새로운 시스템은 다음과 같은 형식의 표현식을 허용한다.

@example
(accumulation-function <@var{variable}>
                       <@var{query pattern}>)
@end example

@noindent
여기서 @code{accumulation-function}은 @code{sum}, @code{average}, 또는 @code{maximum} 같은 것들이 될 수 있다. Ben은 이를 구현하는 것이 아주 쉬울 것이라고 생각한다. 그는 단순히 질의 패턴을 @code{qeval}에 공급할 것이다. 이것은 프레임의 스트림을 생성할 것이다. 그런 다음 그는 이 스트림을 스트림의 각 프레임에서 지정된 변수의 값을 추출하는 매핑 함수를 통해 통과시키고, 결과 값 스트림을 누적 함수에 공급할 것이다. Ben이 구현을 완료하고 막 시도해 보려는 찰나, Cy가 지나가다가 여전히 @ref{Exercise 4.65}의 @code{wheel} 질의 결과 때문에 고민하고 있었다. Cy가 Ben에게 시스템의 응답을 보여주었을 때, Ben은 신음하며 말했다. ``오, 안 돼, 내 단순한 누적 방식은 작동하지 않겠어!''

Ben은 방금 무엇을 깨달았는가? 그가 상황을 수습하기 위해 사용할 수 있는 방법을 요약하라.
@end quotation

@quotation
@strong{@anchor{Exercise 4.67}연습문제 4.67:} 본문과 @ref{Exercise 4.64}에서 설명된 것과 같은 종류의 단순 루프를 피하기 위해 질의 시스템에 루프 탐지기를 설치하는 방법을 고안하라. 일반적인 아이디어는 시스템이 현재의 연역 체인에 대한 일종의 기록을 유지해야 하며, 이미 작업 중인 질의를 다시 처리하기 시작하지 않아야 한다는 것이다. 이 기록에 어떤 종류의 정보(패턴과 프레임)가 포함되는지, 그리고 어떻게 확인이 이루어져야 하는지 설명하라. (@ref{4.4.4}에서 질의 시스템 구현의 세부 사항을 공부한 후, 당신의 루프 탐지기를 포함하도록 시스템을 수정하고 싶을 수도 있다.)
@end quotation

@quotation
@strong{@anchor{Exercise 4.68}연습문제 4.68:} 주어진 리스트와 동일한 요소를 역순으로 포함하는 리스트를 반환하는 @ref{Exercise 2.18}의 @code{reverse} 연산을 구현하기 위한 규칙을 정의하라. (힌트: @code{append-to-form}을 사용하라.) 당신의 규칙이 @code{(reverse (1 2 3) ?x)}와 @code{(reverse ?x (1 2 3))} 모두에 답할 수 있는가?
@end quotation

@quotation
@strong{@anchor{Exercise 4.69}연습문제 4.69:} @ref{Exercise 4.63}에서 공식화한 데이터베이스와 규칙들로 시작하여, 손자 관계에 ``증(greats)''을 추가하기 위한 규칙을 고안하라. 이는 시스템이 Irad가 Adam의 증손자라거나, Jabal과 Jubal이 Adam의 고조-고조-고조-고조-고조손자라는 것을 연역할 수 있게 해야 한다. (힌트: 예를 들어 Irad에 대한 사실을 @code{((great grandson) Adam Irad)}로 표현하라. 한 리스트가 @code{grandson}이라는 단어로 끝나는지 결정하는 규칙을 작성하라. 이를 사용하여 @math{?rel}이 @code{grandson}으로 끝나는 리스트인 관계 @code{((great . ?rel) ?x ?y)}를 도출할 수 있게 하는 규칙을 표현하라.) @code{((great grandson) ?g ?ggs)}와 @code{(?relationship Adam Irad)} 같은 질의에 대해 당신의 규칙을 확인하라.
@end quotation

@node	4.4.4, 4.4.4.1, 4.4.3, 4.4
@subsection 질의 시스템 구현하기 (Implementing the Query System)

@ref{4.4.2}절에서는 질의 시스템이 어떻게 작동하는지 설명했다. 이제 시스템의 완전한 구현을 제시함으로써 세부 사항을 채울 것이다.

@menu
* 4.4.4.1::          드라이버 루프와 인스턴스화 (The Driver Loop and Instantiation)
* 4.4.4.2::          평가자 (The Evaluator)
* 4.4.4.3::          패턴 매칭으로 주장 찾기 (Finding Assertions by Pattern Matching)
* 4.4.4.4::          규칙과 단일화 (Rules and Unification)
* 4.4.4.5::          데이터베이스 유지 관리 (Maintaining the Data Base)
* 4.4.4.6::          스트림 연산 (Stream Operations)
* 4.4.4.7::          질의 구문 프로시저 (Query Syntax Procedures)
* 4.4.4.8::          프레임과 바인딩 (Frames and Bindings)
@end menu

@node 4.4.4.1, 4.4.4.2, 4.4.4, 4.4.4
@subsubsection 드라이버 루프와 인스턴스화 (The Driver Loop and Instantiation)

질의 시스템을 위한 드라이버 루프는 반복해서 입력 표현식을 읽는다.
표현식이 데이터베이스에 추가될 규칙이나 주장이면, 그 정보가 추가된다.
그렇지 않으면 표현식은 질의로 간주된다.
드라이버는 이 질의를 평가자 @code{qeval}에 단일 빈 프레임으로 구성된 초기 프레임 스트림과 함께 전달한다.
평가 결과는 데이터베이스에서 발견된 변수 값들로 질의를 만족시켜 생성된 프레임 스트림이다.
이 프레임들은 프레임 스트림에 의해 제공된 값들로 변수들이 인스턴스화된 원래 질의의 복사본들로 구성된 새로운 스트림을 형성하는 데 사용되며, 이 최종 스트림이 터미널에 출력된다:

@example
const INPUT_PROMPT: &str = ";;; Query input:";
const OUTPUT_PROMPT: &str = ";;; Query results:";

fn query_driver_loop(db: &mut Database) @{
    loop @{
        println!("\n@{@}", INPUT_PROMPT);
        let input = read_input();  // 입력을 Query나 Assertion으로 파싱
        match input @{
            Input::Assertion(assertion) => @{
                db.add_assertion(assertion);
                println!("Assertion added to data base.");
            @}
            Input::Rule(rule) => @{
                db.add_rule(rule);
                println!("Rule added to data base.");
            @}
            Input::Query(q) => @{
                println!("@{@}", OUTPUT_PROMPT);
                let initial_frame = Frame::new();
                let frames = qeval(&q, vec![initial_frame], db);
                for frame in frames @{
                    let result = instantiate(&q.pattern(), &frame);
                    println!("@{@}", result);
                @}
            @}
        @}
    @}
@}
@end example

@noindent
입력 표현식에 대한 어떤 처리도 수행하기 전에, 드라이버 루프는 처리를 더 효율적으로 만드는 형태로 그것을 구문적으로 변환한다.
이것은 패턴 변수의 표현을 변경하는 것을 포함한다.
질의가 인스턴스화될 때, 바인딩되지 않은 채로 남아있는 변수들은 출력되기 전에 입력 표현으로 다시 변환된다.

표현식을 인스턴스화하기 위해, 우리는 주어진 프레임의 값으로 표현식 내의 변수들을 대체하여 그것을 복사한다.
값들 자체도 인스턴스화되는데, 왜냐하면 그것들도 변수를 포함할 수 있기 때문이다 (예를 들어, 단일화의 결과로 @code{exp}의 @code{?x}가 @code{?y}에 바인딩되고 @code{?y}가 다시 5에 바인딩되는 경우).

@example
fn instantiate(term: &Term, frame: &Frame) -> Term @{
    match term @{
        Term::Var(v) => @{
            if let Some(value) = frame.get(v) @{
                // 값이 변수를 포함할 수 있으므로 재귀적으로 인스턴스화
                instantiate(value, frame)
            @} else @{
                term.clone()
            @}
        @}
        Term::List(terms) => Term::List(
            terms.iter().map(|t| instantiate(t, frame)).collect()
        ),
        Term::Atom(_) => term.clone(),
    @}
@}
@end example

@noindent
바인딩을 조작하는 프로시저들은 @ref{4.4.4.8}에 정의되어 있다.

@node 4.4.4.2, 4.4.4.3, 4.4.4.1, 4.4.4
@subsubsection 평가자 (The Evaluator)

@code{query_driver_loop}에 의해 호출되는 @code{qeval} 프로시저는 질의 시스템의 기본 평가자이다.
이것은 질의와 프레임 스트림을 입력으로 받아 확장된 프레임 스트림을 반환한다.
Rust에서 우리는 @code{Query} 열거형에 대한 패턴 매칭을 사용하여 각 질의 유형에 적합한 프로시저로 디스패치한다.

@example
pub fn qeval(query: &Query, frames: Vec<Frame>, db: &Database) -> Vec<Frame> @{
    match query @{
        Query::Simple(pattern) => simple_query(pattern, frames, db),
        Query::And(queries) => conjoin(queries, frames, db),
        Query::Or(queries) => disjoin(queries, frames, db),
        Query::Not(query) => negate(query, frames, db),
    @}
@}
@end example

@subsubheading 단순 질의 (Simple queries)

@code{simple_query} 프로시저는 단순 질의를 처리한다.
이것은 단순 질의(패턴)와 프레임 스트림을 인자로 받아, 각 프레임을 질의에 대한 데이터베이스의 모든 매치로 확장하여 형성된 스트림을 반환한다.

@example
fn simple_query(pattern: &Pattern, frames: Vec<Frame>, db: &Database) -> Vec<Frame> @{
    frames
        .into_iter()
        .flat_map(|frame| @{
            let mut results = Vec::new();
            // 모든 주장과 대조하여 매치 시도
            for assertion in db.assertions() @{
                if let Some(new_frame) = pattern_match(pattern, assertion, &frame) @{
                    results.push(new_frame);
                @}
            @}
            // 모든 규칙 적용 시도
            results.extend(apply_rules(pattern, &frame, db));
            results
        @})
        .collect()
@}
@end example

@noindent
입력 스트림의 각 프레임에 대해, 우리는 @code{pattern_match}를 사용하여 패턴을 데이터베이스의 모든 주장과 대조하고 확장된 프레임들의 스트림을 생성하며, @code{apply_rules}를 사용하여 가능한 모든 규칙을 적용하고 또 다른 확장된 프레임 스트림을 생성한다.

@subsubheading 복합 질의 (Compound queries)

@code{And} 질의는 @ref{Figure 4.5}에 설명된 대로 @code{conjoin} 프로시저에 의해 처리된다.
@code{Conjoin}은 연언지(conjuncts)들과 프레임 스트림을 입력으로 받아 확장된 프레임들의 스트림을 반환한다.
먼저, @code{conjoin}은 프레임 스트림을 처리하여 연언의 첫 번째 질의를 만족시키는 모든 가능한 프레임 확장의 스트림을 찾는다.
그런 다음 이것을 새로운 프레임 스트림으로 사용하여 나머지 질의들에 대해 재귀적으로 @code{conjoin}을 적용한다.

@example
fn conjoin(queries: &[Query], frames: Vec<Frame>, db: &Database) -> Vec<Frame> @{
    if queries.is_empty() @{
        return frames;
    @}
    let first_results = qeval(&queries[0], frames, db);
    conjoin(&queries[1..], first_results, db)
@}
@end example

@code{Or} 질의는 @ref{Figure 4.6}에 표시된 대로 비슷하게 처리된다.
@code{or}의 다양한 선언지(disjuncts)들에 대한 출력 스트림은 개별적으로 계산되어 단일 스트림으로 병합된다.

@example
fn disjoin(queries: &[Query], frames: Vec<Frame>, db: &Database) -> Vec<Frame> @{
    queries
        .iter()
        .flat_map(|query| qeval(query, frames.clone(), db))
        .collect()
@}
@end example

@subsubheading 필터 (Filters)

@code{Not}은 @ref{4.4.2}에 개략적으로 설명된 방법에 의해 처리된다.
우리는 입력 스트림의 각 프레임을 확장하여 부정되는 질의를 만족시키려고 시도하며, 확장될 수 없는 경우에만 주어진 프레임을 출력 스트림에 포함시킨다.

@example
fn negate(query: &Query, frames: Vec<Frame>, db: &Database) -> Vec<Frame> @{
    frames
        .into_iter()
        .filter(|frame| @{
            // 질의가 해당 프레임에서 실패하면 프레임은 NOT 필터를 통과한다
            qeval(query, vec![frame.clone()], db).is_empty()
        @})
        .collect()
@}
@end example

@noindent
@code{always_true} 특수 형식은 항상 만족되는 질의를 제공한다.
이것은 그 내용(보통 비어 있음)을 무시하고 입력 스트림의 모든 프레임을 단순히 통과시킨다.

@example
fn always_true(frames: Vec<Frame>) -> Vec<Frame> @{
    frames
@}
@end example

@noindent
@code{not}과 @code{lisp-value}의 구문을 정의하는 선택자들은 @ref{4.4.4.7}에 주어져 있다.

@node 4.4.4.3, 4.4.4.4, 4.4.4.2, 4.4.4
@subsubsection 패턴 매칭으로 주장 찾기 (Finding Assertions by Pattern Matching)

@code{simple_query} (@ref{4.4.4.2})에 의해 호출되는 @code{find_assertions}는 패턴과 프레임을 입력으로 받는다.
이것은 프레임 스트림을 반환하는데, 각각은 주어진 패턴의 데이터베이스 매치에 의해 주어진 프레임을 확장한 것이다.
이것은 @code{fetch_assertions} (@ref{4.4.4.5})를 사용하여 데이터베이스에 있는 모든 주장의 스트림을 가져와서 패턴 및 프레임과 대조하여 확인해야 한다.

@example
fn find_assertions(pattern: &Pattern, frame: &Frame, db: &Database) -> Vec<Frame> @{
    fetch_assertions(pattern, frame, db)
        .into_iter()
        .flat_map(|datum| check_an_assertion(&datum, pattern, frame))
        .collect()
@}
@end example

@noindent
@code{check_an_assertion}은 패턴, 데이터 객체(주장), 그리고 프레임을 인자로 받아 확장된 프레임을 포함하는 단일 요소 스트림이나 매치가 실패할 경우 빈 스트림을 반환한다.

@example
fn check_an_assertion(
    assertion: &Term,
    query_pat: &Pattern,
    query_frame: &Frame
) -> Option<Frame> @{
    pattern_match(query_pat, assertion, query_frame)
@}
@end example

@noindent
기본 패턴 매처는 @code{None}(실패를 나타냄)이나 주어진 프레임의 확장을 반환한다.
매처의 기본 아이디어는 패턴을 데이터와 요소별로 대조하며 패턴 변수에 대한 바인딩을 축적하는 것이다.
패턴과 데이터 객체가 동일하면 매치는 성공하고 지금까지 축적된 바인딩의 프레임을 반환한다.
그렇지 않고 패턴이 변수라면, 우리는 변수를 데이터에 바인딩하여 현재 프레임을 확장하는데, 이것이 프레임에 이미 있는 바인딩과 일치하는 한에서 그렇다.
패턴과 데이터가 모두 쌍이라면, 우리는 (재귀적으로) 패턴의 @code{car}를 데이터의 @code{car}와 대조하여 프레임을 생성하고; 이 프레임에서 다시 패턴의 @code{cdr}을 데이터의 @code{cdr}과 대조한다.
이러한 경우 중 어느 것도 적용되지 않으면 매치는 실패하고 기호 @code{failed}를 반환한다.

@example
fn pattern_match(pattern: &Term, data: &Term, frame: &Frame) -> Option<Frame> @{
    if pattern == data @{
        return Some(frame.clone());
    @}

    match (pattern, data) @{
        (Term::Var(v), _) => extend_if_consistent(v, data, frame),
        (Term::List(p_list), Term::List(d_list)) if p_list.len() == d_list.len() => @{
            let mut current_frame = frame.clone();
            for (p, d) in p_list.iter().zip(d_list.iter()) @{
                current_frame = pattern_match(p, d, &current_frame)?;
            @}
            Some(current_frame)
        @}
        _ => None,
    @}
@}
@end example

@noindent
다음은 새로운 바인딩이 프레임에 이미 있는 바인딩과 일치하는 경우, 새로운 바인딩을 추가하여 프레임을 확장하는 프로시저이다:

@example
fn extend_if_consistent(var: &str, data: &Term, frame: &Frame) -> Option<Frame> @{
    if let Some(binding) = frame.get(var) @{
        pattern_match(binding, data, frame)
    @} else @{
        let mut new_frame = frame.clone();
        new_frame.insert(var.to_string(), data.clone());
        Some(new_frame)
    @}
@}
@end example

@noindent
프레임에 변수에 대한 바인딩이 없다면, 우리는 단순히 변수의 바인딩을 데이터에 추가한다.
그렇지 않으면 우리는 프레임 내에서 데이터를 프레임 내의 변수 값과 대조한다.
저장된 값이 상수만 포함한다면(@code{extend-if-consistent}에 의한 패턴 매칭 중에 저장되었다면 그래야만 한다), 매치는 단순히 저장된 값과 새 값이 같은지 테스트한다.
만약 그렇다면 수정되지 않은 프레임을 반환하고; 그렇지 않다면 실패 표시를 반환한다.
그러나 저장된 값은 단일화 중에 저장되었다면 패턴 변수를 포함할 수도 있다 (@ref{4.4.4.4} 참조).
새 데이터에 대한 저장된 패턴의 재귀적 매치는 이 패턴 내의 변수들에 대한 바인딩을 추가하거나 확인할 것이다.
예를 들어, @code{?x}가 @code{(f ?y)}에 바인딩되어 있고 @code{?y}는 바인딩되지 않은 프레임이 있고, 이 프레임을 @code{?x}가 @code{(f b)}에 바인딩되도록 확장하고 싶다고 가정해보자.
우리는 @code{?x}를 조회하여 그것이 @code{(f ?y)}에 바인딩되어 있음을 발견한다.
이것은 우리가 같은 프레임에서 @code{(f ?y)}를 제안된 새 값 @code{(f b)}와 대조하게 한다.
결국 이 매치는 @code{?y}를 @code{b}에 바인딩하는 것을 추가하여 프레임을 확장한다.
@code{?X}는 @code{(f ?y)}에 바인딩된 채로 남는다.
우리는 저장된 바인딩을 절대 수정하지 않으며 주어진 변수에 대해 하나 이상의 바인딩을 저장하지도 않는다.

@code{extend-if-consistent}가 바인딩을 조작하기 위해 사용하는 프로시저들은 @ref{4.4.4.8}에 정의되어 있다.

@subsubheading 점선 꼬리가 있는 패턴 (Patterns with dotted tails)

패턴이 점(dot) 다음에 패턴 변수를 포함하면, 패턴 변수는 (@ref{Exercise 2.20}에서 설명된 점선 꼬리 표기법에서 기대할 수 있듯이) 데이터 리스트의 다음 요소가 아니라 데이터 리스트의 나머지와 일치한다.
비록 우리가 방금 구현한 패턴 매처가 점을 찾지 않지만, 그것은 우리가 원하는 대로 동작한다.
이는 @code{query-driver_loop}가 질의를 읽고 리스트 구조로 표현하기 위해 사용하는 Lisp @code{read} 원시 함수가 점을 특별한 방식으로 처리하기 때문이다.

@code{read}가 점을 보면, 다음 항목을 리스트의 다음 요소(@code{cdr}이 리스트의 나머지가 될 @code{cons}의 @code{car})로 만드는 대신, 다음 항목을 리스트 구조의 @code{cdr}로 만든다.
예를 들어, 패턴 @code{(computer ?type)}에 대해 @code{read}가 생성하는 리스트 구조는 표현식 @code{(cons 'computer (cons '?type '()))}을 평가하여 구성할 수 있고, @code{(computer . ?type)}에 대한 것은 표현식 @code{(cons 'computer '?type)}을 평가하여 구성할 수 있다.

따라서 @code{pattern-match}가 데이터 리스트와 점이 있는 패턴의 @code{car}와 @code{cdr}을 재귀적으로 비교할 때, 결국 점 뒤의 변수(패턴의 @code{cdr})를 데이터 리스트의 하위 리스트와 대조하여 변수를 그 리스트에 바인딩하게 된다.
예를 들어, 패턴 @code{(computer . ?type)}을 @code{(computer programmer trainee)}와 대조하면 @code{?type}은 리스트 @code{(programmer trainee)}와 일치하게 된다.

@node 4.4.4.4, 4.4.4.5, 4.4.4.3, 4.4.4
@subsubsection 규칙과 단일화 (Rules and Unification)

@code{apply_rules}는 @code{find_assertions} (@ref{4.4.4.3})의 규칙 유사체이다.
이것은 패턴과 프레임을 입력으로 받아, 데이터베이스의 규칙들을 적용하여 확장 프레임들의 스트림을 형성한다.

@example
fn apply_rules(pattern: &Pattern, frame: &Frame, db: &Database) -> Vec<Frame> @{
    let mut results = Vec::new();
    for rule in db.rules() @{
        // 충돌을 피하기 위해 규칙 내의 변수 이름 변경
        let (renamed_conclusion, renamed_body) = rename_rule_variables(rule);
        // 패턴을 규칙 결론과 단일화 시도
        if let Some(unified_frame) = unify(pattern, &renamed_conclusion, frame) @{
            // 단일화된 프레임에서 규칙 본문 평가
            let body_results = qeval(&renamed_body, vec![unified_frame], db);
            results.extend(body_results);
        @}
    @}
    results
@}
@end example

@noindent
@code{apply_a_rule} (위의 @code{apply_rules}에 통합됨)은 @ref{4.4.2}에 개략적으로 설명된 방법을 사용하여 규칙을 적용한다.
먼저, 주어진 프레임 내의 패턴과 규칙 결론을 단일화하여 인자 프레임을 확장한다.
이것이 성공하면, 이 새로운 프레임에서 규칙 본문을 평가한다.

그러나 이 모든 일이 일어나기 전에, 프로그램은 규칙 내의 모든 변수 이름을 고유한 새 이름으로 바꾼다.
그 이유는 서로 다른 규칙 적용에 대한 변수들이 서로 혼동되는 것을 방지하기 위해서이다.

단일화 알고리즘은 두 개의 패턴과 프레임을 입력으로 받아 확장된 프레임이나 @code{None}을 반환하는 프로시저로 구현된다.
단일화 도구는 패턴 매처와 비슷하지만 대칭적이라는 점이 다르다---변수가 매치의 양쪽에 모두 허용된다.

@example
pub fn unify(t1: &Term, t2: &Term, frame: &Frame) -> Option<Frame> @{
    if t1 == t2 @{
        return Some(frame.clone());
    @}
    match (t1, t2) @{
        (Term::Var(v1), _) => extend_if_possible(v1, t2, frame),
        (_, Term::Var(v2)) => extend_if_possible(v2, t1, frame),
        (Term::List(l1), Term::List(l2)) if l1.len() == l2.len() => @{
            let mut current_frame = frame.clone();
            for (term1, term2) in l1.iter().zip(l2.iter()) @{
                match unify(term1, term2, &current_frame) @{
                    Some(new_frame) => current_frame = new_frame,
                    None => return None,
                @}
            @}
            Some(current_frame)
        @}
        _ => None,
    @}
@}
@end example

@noindent
단일화에서, 일방향 패턴 매칭에서와 마찬가지로, 우리는 제안된 프레임 확장이 기존 바인딩과 일치하는 경우에만 수락하고 싶다.
단일화에 사용되는 @code{extend_if_possible} 프로시저는 두 가지 특별한 검사를 제외하고는 패턴 매칭에 사용되는 @code{extend_if_consistent}와 동일하다.
첫 번째 경우는, 우리가 매치하려고 하는 변수가 바인딩되지 않았지만 우리가 매치하려는 값이 그 자체로 (다른) 변수인 경우, 그 값이 바인딩되어 있는지 확인하고 만약 그렇다면 그 값을 매치해야 할 필요가 있다.

두 번째 검사는 변수를 그 변수를 포함하는 패턴에 바인딩하려는 시도를 다룬다 (소위 @newterm{출현 검사(occurs check)}).

@example
fn extend_if_possible(var: &str, val: &Term, frame: &Frame) -> Option<Frame> @{
    if let Some(binding) = frame.get(var) @{
        return unify(binding, val, frame);
    @}
    if let Term::Var(v) = val @{
        if let Some(binding) = frame.get(v) @{
            return unify(&Term::Var(var.to_string()), binding, frame);
        @}
    @}
    if depends_on(val, var, frame) @{
        return None;
    @}
    let mut new_frame = frame.clone();
    new_frame.insert(var.to_string(), val.clone());
    Some(new_frame)
@}
@end example

@noindent
@code{depends_on}은 패턴 변수의 값으로 제안된 표현식이 그 변수에 의존하는지 여부를 테스트하는 술어이다.

@example
fn depends_on(term: &Term, var: &str, frame: &Frame) -> bool @{
    match term @{
        Term::Var(v) => @{
            if v == var @{ return true; @}
            if let Some(binding) = frame.get(v) @{
                return depends_on(binding, var, frame);
            @}
            false
        @}
        Term::List(terms) => terms.iter().any(|t| depends_on(t, var, frame)),
        Term::Atom(_) => false,
    @}
@}
@end example

@node 4.4.4.5, 4.4.4.6, 4.4.4.4, 4.4.4
@subsubsection 데이터베이스 유지 관리 (Maintaining the Data Base)

논리 프로그래밍 언어를 설계할 때 중요한 문제 중 하나는 주어진 패턴을 확인할 때 가능한 한 적은 수의 관련 없는 데이터베이스 항목을 검사하도록 정리하는 것이다.
우리 시스템에서는 주장과 규칙을 @code{Database} 구조체에 저장한다.

@example
pub struct Database @{
    assertions: Vec<Term>,
    rules: Vec<Rule>,
@}

impl Database @{
    pub fn add_assertion(&mut self, assertion: Term) @{
        self.assertions.push(assertion);
    @}

    pub fn add_rule(&mut self, rule: Rule) @{
        self.rules.push(rule);
    @}

    pub fn assertions(&self) -> &[Term] @{
        &self.assertions
    @}

    pub fn rules(&self) -> &[Rule] @{
        &self.rules
    @}
@}
@end example

@noindent
패턴과 일치할 수 있는 주장을 가져오기 위해, 우리는 단순히 모든 주장을 반환할 수 있다.
그러나 효율성을 위해 많은 시스템은 @newterm{인덱싱(indexing)}을 사용하여 작은 후보 집합을 선택한다.

@example
fn fetch_assertions(pattern: &Pattern, frame: &Frame, db: &Database) -> Vec<Frame> @{
    // 단순 구현: 모든 주장 확인
    db.assertions()
        .iter()
        .filter_map(|datum| pattern_match(pattern, datum, frame))
        .collect()
@}
@end example

@noindent
규칙도 비슷하게 저장된다.
@code{car}가 상수 기호인 패턴은 결론이 변수로 시작하는 규칙뿐만 아니라 결론이 동일한 @code{car}를 갖는 규칙과도 일치할 수 있다.

@example
fn fetch_rules(pattern: &Pattern, frame: &Frame, db: &Database) -> Vec<Frame> @{
    // 모든 규칙 적용 시도
    apply_rules(pattern, frame, db)
@}
@end example

@noindent
@code{add_rule_or_assertion}은 @code{query_driver_loop}에 의해 사용되어 정보를 데이터베이스에 추가한다.

@example
fn add_rule_or_assertion(input: Input, db: &mut Database) @{
    match input @{
        Input::Assertion(assertion) => db.add_assertion(assertion),
        Input::Rule(rule) => db.add_rule(rule),
        _ => @{@}
    @}
@}
@end example

@quotation
@strong{@anchor{Exercise 4.70}연습문제 4.70:} @code{add_assertion}과 @code{add_rule} 프로시저에서 @code{let} 바인딩의 목적은 무엇인가? @code{add_assertion}의 다음 구현에 어떤 문제가 있겠는가? 힌트: @ref{3.5.2}에서 1의 무한 스트림 정의를 상기하라: @code{let ones = std::iter::repeat(1);}.

@example
fn add_assertion(assertion: Term, db: &mut Database) @{
    // 데이터베이스가 업데이트되는 지연 스트림이었다면 개념적 오류:
    db.assertions = std::iter::once(assertion).chain(db.assertions);
@}
@end example
@end quotation

@node 4.4.4.6, 4.4.4.7, 4.4.4.5, 4.4.4
@subsubsection 스트림 연산 (Stream Operations)

질의 시스템은 프레임의 흐름을 관리하기 위해 스트림 연산을 사용한다.
Rust에서 우리는 @code{Iterator}의 지연 결합자(lazy combinators)에 의존한다.

@code{Stream-append-delayed}와 @code{interleave-delayed}는 개념적으로 반복자 체이닝(iterator chaining)과 플랫 매핑(flat mapping)에 의해 처리된다.

질의 평가자 전체에서 프로시저를 프레임 스트림에 매핑하고 결과 프레임 스트림들을 결합하는 데 사용되는 @code{Stream-flatmap}은 @ref{2.2.3}에서 일반 리스트에 대해 소개된 @code{flatmap} 프로시저의 스트림 유사체이다.
Rust에서 우리는 단순히 @code{flat_map}을 사용한다.

@example
// Rust에서, stream-flatmap은 Iterator::flat_map에 해당한다
frames.into_iter().flat_map(|frame| @{
    // ... 새로운 프레임 반복자 생성 ...
@})
@end example

@noindent
평가자는 또한 단일 요소로 구성된 스트림을 생성하기 위해 다음의 간단한 프로시저를 사용한다:

@example
fn singleton_stream<T>(x: T) -> impl Iterator<Item = T> @{
    std::iter::once(x)
@}
@end example

@node 4.4.4.7, 4.4.4.8, 4.4.4.6, 4.4.4
@subsubsection 질의 구문 프로시저 (Query Syntax Procedures)

Rust에서 질의 언어의 구문은 @code{Query}와 @code{Term} 열거형에 의해 정의된다.
@code{type}이나 @code{contents}와 같은 리스트 조작 프로시저 대신, 우리는 패턴 매칭을 사용하여 이러한 유형을 구조 분해한다.

@example
// 4.4.4절의 Term과 Query 정의를 참조하라
@end example

@noindent
@code{query_driver_loop} (@ref{4.4.4.1}에서)에 의해 사용되는 다음 프로시저들은 규칙과 주장이 @code{assert!(⟨@var{rule_or_assertion}⟩)} 형태의 표현식에 의해 데이터베이스에 추가됨을 지정한다:

@example
// Rust에서, 우리는 입력을 Input 열거형으로 파싱한다:
enum Input @{
    Assertion(Term),
    Rule(Rule),
    Query(Query),
@}
@end example

@noindent
다음은 @code{and}, @code{or}, 그리고 @code{not} 특수 형식 (@ref{4.4.4.2})에 대한 구문 정의이다.
Rust에서 이것들은 @code{Query} 열거형의 변형들이다:

@example
// Query::And(Vec<Query>)
// Query::Or(Vec<Query>)
// Query::Not(Box<Query>)
@end example

@noindent
규칙의 구문은 @code{Rule} 구조체에 의해 정의된다:

@example
pub struct Rule @{
    pub conclusion: Pattern,
    pub body: Query,
@}
@end example

@noindent
@code{query_driver_loop} (@ref{4.4.4.1})은 @code{query_syntax_process}를 호출하여 표현식 내의 @code{?symbol} 형태를 가진 패턴 변수들을 내부적인 @code{Term::Var} 형식으로 변환한다.
이것은 일반적으로 파서에 의해 처리된다.

@noindent
다음 프로시저들은 규칙의 구문을 정의한다:

@example
// Rust에서, 우리는 규칙 부분에 접근하기 위해 구조체 필드를 사용한다:
// rule.conclusion
// rule.body
@end example

@noindent
@code{query_driver_loop} (@ref{4.4.4.1})은 파싱 함수를 호출하여 표현식 내의 @code{?symbol} 형태를 가진 패턴 변수들을 내부적인 @code{Term::Var} 형식으로 변환한다.
이는 시스템이 표현식이 패턴 변수인지 확인할 때 열거형 변형(variant)을 확인함으로써 질의 처리의 효율성을 높인다.

@example
fn is_var(exp: &Term) -> bool @{
    matches!(exp, Term::Var(_))
@}
@end example

@noindent
고유 변수는 규칙 적용 중에 (@ref{4.4.4.4}에서) 다음 프로시저들을 통해 구성된다.
규칙 적용에 대한 고유 식별자는 숫자로, 규칙이 적용될 때마다 증가한다.

@example
static mut RULE_COUNTER: usize = 0;

fn new_rule_application_id() -> usize @{
    unsafe @{
        RULE_COUNTER += 1;
        RULE_COUNTER
    @}
@}

fn make_new_variable(var: &Term, rule_application_id: usize) -> Term @{
    if let Term::Var(name) = var @{
        Term::Var(format!("@{@}_@{@}", name, rule_application_id))
    @} else @{
        var.clone()
    @}
@}
@end example

@noindent
@code{query_driver_loop}가 답을 출력하기 위해 질의를 인스턴스화할 때, @code{contract_question_mark}를 사용하여 바인딩되지 않은 패턴 변수들을 다시 올바른 출력 형식으로 변환한다.
그 프로시저는 문자열 이름의 단순한 변환으로 구성된다.

@example
// Rust에서, 이것은 Display 구현의 format!에 의해 처리된다
@end example
         (symbol->string (cadr variable))))))
@end example

@node 4.4.4.8, Chapter 5, 4.3, 4.4.4
@subsubsection 프레임과 바인딩 (Frames and Bindings)

우리 Rust 구현에서, 프레임은 효율적인 @math{O(1)} 조회 및 삽입을 제공하는 @code{HashMap<String, Term>}을 사용하여 표현된다.
각 프레임은 변수 이름을 해당 항(term)에 매핑한다:

@example
use std::collections::HashMap;

pub type Frame = HashMap<String, Term>;

// 프레임 확장하기:
fn extend(var: String, val: Term, frame: &Frame) -> Frame @{
    let mut new_frame = frame.clone();
    new_frame.insert(var, val);
    new_frame
@}

// 프레임에서 조회하기:
fn lookup(var: &str, frame: &Frame) -> Option<&Term> @{
    frame.get(var)
@}
@end example

@quotation
@strong{@anchor{Exercise 4.71}연습문제 4.71:} Louis Reasoner는 왜 @code{simple-query}와 @code{disjoin} 프로시저(@ref{4.4.4.2})가 다음과 같이 정의되지 않고 명시적인 @code{delay} 연산을 사용하여 구현되었는지 궁금해한다:

@example
// 지연 없는 단순 질의
fn simple_query(
    query_pattern: &Pattern,
    frame_stream: impl Iterator<Item = Frame>
) -> impl Iterator<Item = Frame> @{
    frame_stream.flat_map(move |frame| @{
        // 인터리브되거나 지연되지 않음!
        find_assertions(query_pattern, &frame, db)
            .chain(apply_rules(query_pattern, &frame, db))
    @})
@}

// 지연 없는 Disjoin
fn disjoin(
    disjuncts: &[Query],
    frame_stream: Vec<Frame>,
    db: &Database
) -> Vec<Frame> @{
    if disjuncts.is_empty() @{
        vec![]
    @} else @{
        let first = qeval(&disjuncts[0], frame_stream.clone(), db);
        let rest = disjoin(&disjuncts[1..], frame_stream, db);
        // 무한 스트림에는 인터리브가 필수적임!
        interleave(first.into_iter(), rest.into_iter()).collect()
    @}
@}
@end example

이러한 더 단순한 정의가 바람직하지 않은 동작으로 이어질 수 있는 질의의 예를 들 수 있는가?
@end quotation

@quotation
@strong{@anchor{Exercise 4.72}연습문제 4.72:} 왜 @code{disjoin}과 @code{stream-flatmap}은 스트림들을 단순히 이어붙이는(append) 대신 인터리브(interleave)하는가? 인터리빙이 더 잘 작동하는 이유를 보여주는 예를 제시하라. (힌트: @ref{3.5.3}에서 왜 우리가 @code{interleave}를 사용했는지 생각해보라.)
@end quotation

@quotation
@strong{@anchor{Exercise 4.73}연습문제 4.73:} 왜 @code{flatten}은 지연 평가를 명시적으로 사용하는가? 다음과 같이 정의하면 무엇이 잘못되겠는가:

@example
fn flatten<I>(stream: I) -> impl Iterator<Item = I::Item::Item>
where
    I: Iterator,
    I::Item: IntoIterator,
@{
    // 스트림이 무한하면 무한 재귀!
    interleave(
        stream.next().unwrap(),
        flatten(stream) // 재귀 호출이 지연되지 않음
    )
@}
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 4.74}연습문제 4.74:} Alyssa P. Hacker는 @code{negate}, @code{lisp-value}, 그리고 @code{find-assertions}에서 더 단순한 버전의 @code{stream-flatmap}을 사용할 것을 제안한다.
그녀는 이 경우 프레임 스트림에 매핑되는 프로시저가 항상 빈 스트림이나 단일 요소 스트림을 생성하므로, 이 스트림들을 결합할 때 인터리빙이 필요하지 않다는 것을 관찰한다.

@enumerate a

@item
Alyssa의 프로그램에서 누락된 표현식을 채워라.

@example
fn simple_stream_flatmap<I, F, B>(s: I, proc: F) -> impl Iterator<Item = B>
where
    I: Iterator,
    F: FnMut(I::Item) -> Option<B>,
@{
    simple_flatten(s.map(proc))
@}

fn simple_flatten<I>(stream: I) -> impl Iterator<Item = I::Item::Item>
where
    I: Iterator,
    I::Item: IntoIterator,
@{
    stream.map(|x| x).flatten() // 단순화된 flatten 로직
@}
@end example

@item
우리가 이런 방식으로 변경하면 질의 시스템의 동작이 변하는가?

@end enumerate
@end quotation

@quotation
@strong{@anchor{Exercise 4.75}연습문제 4.75:} 질의 언어를 위해 @code{unique}라는 새로운 특수 형식을 구현하라. @code{Unique}는 데이터베이스에 지정된 질의를 만족하는 항목이 정확히 하나 있을 때 성공해야 한다. 예를 들어,

@example
(unique (job ?x (computer wizard)))
@end example

@noindent
는 Ben이 유일한 컴퓨터 마법사이므로,

@example
(unique (job (Bitdiddle Ben)
             (computer wizard)))
@end example

@noindent
라는 단일 항목 스트림을 출력해야 하고,

@example
(unique (job ?x (computer programmer)))
@end example

@noindent
는 컴퓨터 프로그래머가 한 명 이상 있으므로 빈 스트림을 출력해야 한다. 게다가,

@example
(and (job ?x ?j)
     (unique (job ?anyone ?j)))
@end example

@noindent
는 한 사람에 의해서만 채워지는 모든 직업과 그 일을 하는 사람들을 나열해야 한다.

@code{unique}를 구현하는 데는 두 부분이 있다. 첫 번째는 이 특수 형식을 처리하는 프로시저를 작성하는 것이고, 두 번째는 @code{qeval}이 그 프로시저로 디스패치하도록 만드는 것이다.
두 번째 부분은 사소한데, 왜냐하면 @code{qeval}이 데이터 주도 방식으로 디스패치하기 때문이다. 당신의 프로시저가 @code{uniquely-asserted}라고 불린다면, 당신이 해야 할 일은

@example
(put 'unique 'qeval uniquely-asserted)
@end example

@noindent
뿐이며, @code{qeval}은 @code{type} (@code{car})이 기호 @code{unique}인 모든 질의에 대해 이 프로시저로 디스패치할 것이다.

진짜 문제는 프로시저 @code{uniquely-asserted}를 작성하는 것이다. 이것은 @code{unique} 질의의 @code{contents} (@code{cdr})와 프레임 스트림을 입력으로 받아야 한다.
스트림의 각 프레임에 대해, 이것은 @code{qeval}을 사용하여 주어진 질의를 만족시키는 프레임의 모든 확장 스트림을 찾아야 한다.
정확히 하나의 항목을 갖지 않는 스트림은 모두 제거되어야 한다.
나머지 스트림들은 다시 전달되어 @code{unique} 질의의 결과인 하나의 큰 스트림으로 축적되어야 한다.
이것은 @code{not} 특수 형식의 구현과 유사하다.

정확히 한 사람을 감독하는 모든 사람을 나열하는 질의를 형성하여 당신의 구현을 테스트하라.
@end quotation

@quotation
@strong{@anchor{Exercise 4.76}연습문제 4.76:} 질의들의 직렬 조합으로서의 @code{and} 구현(@ref{Figure 4.5})은 우아하지만 비효율적인데, 왜냐하면 @code{and}의 두 번째 질의를 처리할 때 첫 번째 질의에 의해 생성된 각 프레임에 대해 데이터베이스를 스캔해야 하기 때문이다.
만약 데이터베이스가 @math{n}개의 요소를 가지고 있고, 일반적인 질의가 @math{n}에 비례하는 수의 출력 프레임(예를 들어 @math{{n \,/\, k}})을 생성한다면, 첫 번째 질의에 의해 생성된 각 프레임에 대해 데이터베이스를 스캔하는 것은 패턴 매처에 대한 @math{{n^2 /\, k}}번의 호출을 필요로 할 것이다.
또 다른 접근 방식은 @code{and}의 두 절을 별도로 처리한 다음, 호환되는 모든 출력 프레임 쌍을 찾는 것이다.
만약 각 질의가 @math{{n \,/\, k}}개의 출력 프레임을 생성한다면, 이는 우리가 @math{{n^2 /\, k^2}}번의 호환성 검사를 수행해야 함을 의미한다 --- 현재 방법에서 요구되는 매치 횟수보다 @math{k}배 적다.

이 전략을 사용하는 @code{and} 구현을 고안하라.
당신은 두 프레임을 입력으로 받아 프레임 내의 바인딩들이 호환되는지 확인하고, 만약 그렇다면 두 바인딩 집합을 병합하는 프레임을 생성하는 프로시저를 구현해야 한다.
이 연산은 단일화와 유사하다.
@end quotation

@quotation
@strong{@anchor{Exercise 4.77}연습문제 4.77:} @ref{4.4.3}에서 우리는 변수가 바인딩되지 않은 프레임에 필터링 연산이 적용될 경우 @code{not}과 @code{lisp-value}가 질의 언어로 하여금 ``잘못된'' 답을 주게 할 수 있음을 보았다.
이 결점을 고칠 방법을 고안하라.
한 가지 아이디어는 연산을 가능하게 할 만큼 충분한 변수가 바인딩될 때만 이행되는 필터링 ``약속(promise)''을 프레임에 덧붙임으로써 필터링을 ``지연된'' 방식으로 수행하는 것이다.
우리는 다른 모든 연산이 수행될 때까지 필터링 수행을 기다릴 수 있다.
그러나 효율성을 위해, 우리는 생성되는 중간 프레임의 수를 줄이기 위해 가능한 한 빨리 필터링을 수행하고 싶다.
@end quotation

@quotation
@strong{@anchor{Exercise 4.78}연습문제 4.78:} 질의 언어를 스트림 프로세스가 아니라 @ref{4.3}의 평가자를 사용하여 구현되는 비결정적 프로그램으로 재설계하라.
이 접근 방식에서, 각 질의는 (모든 답의 스트림이 아니라) 단일 답을 생성할 것이며 사용자는 더 많은 답을 보기 위해 @code{try-again}을 입력할 수 있다.
당신은 우리가 이 절에서 구축한 메커니즘의 많은 부분이 비결정적 검색과 백트래킹에 의해 포섭된다는 것을 알게 될 것이다.
그러나 당신은 또한 당신의 새로운 질의 언어가 여기서 구현된 것과 동작에 있어 미묘한 차이가 있음을 발견할 것이다.
이 차이를 보여주는 예를 찾을 수 있는가?
@end quotation

@quotation
@strong{@anchor{Exercise 4.79}연습문제 4.79:} 우리가 @ref{4.1}에서 Lisp 평가자를 구현했을 때, 우리는 프로시저의 매개변수 사이의 이름 충돌을 피하기 위해 지역 환경을 사용하는 방법을 보았다.
예를 들어,

@example
fn square(x: i64) -> i64 @{ x * x @}

fn sum_of_squares(x: i64, y: i64) -> i64 @{
    square(x) + square(y)
@}

sum_of_squares(3, 4)
@end example

@noindent
를 평가할 때, @code{square}의 @code{x}와 @code{sum_of_squares}의 @code{x} 사이에는 혼동이 없는데, 왜냐하면 우리는 각 프로시저의 본문을 지역 변수에 대한 바인딩을 포함하도록 특별히 구성된 환경에서 평가하기 때문이다.
질의 시스템에서, 우리는 규칙을 적용할 때 이름 충돌을 피하기 위해 다른 전략을 사용했다.
우리는 규칙을 적용할 때마다 고유함이 보장되는 새로운 이름으로 변수 이름을 변경한다.
Lisp 평가자에 대한 유사한 전략은 지역 환경을 없애고 단순히 프로시저를 적용할 때마다 프로시저 본문의 변수 이름을 변경하는 것일 것이다.

이름 변경 대신 환경을 사용하는 규칙 적용 방법을 질의 언어에 구현하라.
당신의 환경 구조를 기반으로 블록 구조 프로시저의 규칙 유사체와 같은 대규모 시스템을 다루기 위한 구성을 질의 언어에 만들 수 있는지 확인하라.
이것 중 어떤 것이 문제 해결의 방법으로서 문맥 안에서 연역을 하는 문제(예: ``만약 내가 @math{P}가 참이라고 가정한다면, 나는 @math{A}와 @math{B}를 연역할 수 있을 것이다.'')와 관련이 있는지 알 수 있는가? (이 문제는 개방형이다. 좋은 답은 아마도 박사 학위 가치가 있을 것이다.)
@end quotation

@node    Chapter 5, 5.1, 4.4, Top
@chapter 레지스터 기계를 이용한 계산 (Computing with Register Machines)

@quotation
나의 목표는 천상의 기계가 신성한 생명체가 아니라 일종의 시계 장치(시계에 영혼이 있다고 믿는 사람은 그 작품에 제작자의 영광을 돌린다)라는 것을 보여주는 것이다. 시계의 모든 운동이 하나의 무게추에 의해 일어나는 것처럼, 거의 모든 다양한 운동이 아주 단순하고 물질적인 힘에 의해 일어나는 한에서 말이다.

---요하네스 케플러 (헤르바르트 폰 호헨부르크에게 보낸 편지, 1605)
@end quotation


@noindent
우리는 프로세스를 연구하고 Lisp로 작성된 프로시저의 관점에서 프로세스를 설명함으로써 이 책을 시작했다.
이러한 프로시저의 의미를 설명하기 위해, 우리는 일련의 평가 모델들을 사용했다: @ref{Chapter 1}의 치환 모델, @ref{Chapter 3}의 환경 모델, 그리고 @ref{Chapter 4}의 메타순환 평가자.
특히 메타순환 평가자에 대한 우리의 조사는 Lisp 같은 언어가 어떻게 해석되는지에 대한 미스터리의 상당 부분을 없애주었다.
그러나 메타순환 평가자조차도 Lisp 시스템의 제어 메커니즘을 명확히 하는 데 실패했기 때문에 중요한 질문들을 답하지 않은 채로 남겨둔다.
예를 들어, 평가자는 하위 표현식의 평가가 어떻게 그 값을 사용하는 표현식에 값을 반환하는지 설명하지 않으며, 일부 재귀 프로시저가 반복 프로세스(즉, 상수 공간을 사용하여 평가됨)를 생성하는 반면 다른 재귀 프로시저는 재귀 프로세스를 생성하는 이유도 설명하지 않는다.
메타순환 평가자 자체가 Lisp 프로그램이고 따라서 기본 Lisp 시스템의 제어 구조를 상속받기 때문에 이러한 질문들은 답이 없는 상태로 남아 있다.
Lisp 평가자의 제어 구조에 대한 더 완전한 설명을 제공하기 위해, 우리는 Lisp 자체보다 더 원시적인 수준에서 작업해야 한다.

이 장에서 우리는 전통적인 컴퓨터의 단계별 작동 관점에서 프로세스를 설명할 것이다.
그러한 컴퓨터, 또는 @newterm{레지스터 기계(register machine)}는 @newterm{레지스터(registers)}라고 불리는 고정된 저장 요소 집합의 내용을 조작하는 @newterm{명령어(instructions)}를 순차적으로 실행한다.
전형적인 레지스터 기계 명령어는 일부 레지스터의 내용에 원시 연산을 적용하고 그 결과를 다른 레지스터에 할당한다.
레지스터 기계에 의해 실행되는 프로세스에 대한 우리의 설명은 전통적인 컴퓨터를 위한 ``기계어'' 프로그램과 매우 비슷해 보일 것이다.
그러나 특정 컴퓨터의 기계어에 초점을 맞추는 대신, 우리는 여러 Lisp 프로시저를 조사하고 각 프로시저를 실행하기 위한 특정 레지스터 기계를 설계할 것이다.
따라서 우리는 기계어 컴퓨터 프로그래머의 관점보다는 하드웨어 아키텍트의 관점에서 우리의 과제에 접근할 것이다.
레지스터 기계를 설계할 때, 우리는 재귀와 같은 중요한 프로그래밍 구성을 구현하기 위한 메커니즘을 개발할 것이다.
우리는 또한 레지스터 기계 설계를 설명하기 위한 언어를 제시할 것이다.
@ref{5.2}에서 우리는 이 설명들을 사용하여 우리가 설계한 기계를 시뮬레이션하는 Lisp 프로그램을 구현할 것이다.

우리 레지스터 기계의 원시 연산 대부분은 매우 간단하다.
예를 들어, 어떤 연산은 두 레지스터에서 가져온 숫자를 더하여 세 번째 레지스터에 저장할 결과를 생성할 수 있다.
그러한 연산은 쉽게 설명되는 하드웨어에 의해 수행될 수 있다.
그러나 리스트 구조를 다루기 위해, 우리는 또한 정교한 저장소 할당 메커니즘을 필요로 하는 메모리 연산 @code{car}, @code{cdr}, 그리고 @code{cons}를 사용할 것이다.
@ref{5.3}에서 우리는 더 기본적인 연산의 관점에서 그것들의 구현을 연구한다.

@ref{5.4}에서는, 레지스터 기계로서 단순 프로시저를 공식화하는 경험을 축적한 후, @ref{4.1}의 메타순환 평가자에 의해 설명된 알고리즘을 수행하는 기계를 설계할 것이다.
이것은 평가자 내의 제어 메커니즘에 대한 명시적인 모델을 제공함으로써 Scheme 표현식이 어떻게 해석되는지에 대한 우리의 이해의 공백을 채울 것이다.
@ref{5.5}에서는 Scheme 프로그램을 평가자 레지스터 기계의 레지스터와 연산으로 직접 실행될 수 있는 명령어 시퀀스로 변환하는 간단한 컴파일러를 연구할 것이다.

@menu
* 5.1::              레지스터 기계 설계 (Designing Register Machines)
* 5.2::              레지스터 기계 시뮬레이터 (A Register-Machine Simulator)
* 5.3::              저장소 할당과 가비지 컬렉션 (Storage Allocation and Garbage Collection)
* 5.4::              명시적 제어 평가자 (The Explicit-Control Evaluator)
* 5.5::              컴파일 (Compilation)
@end menu

@node	5.1, 5.2, Chapter 5, Chapter 5
@section 레지스터 기계 설계 (Designing Register Machines)

레지스터 기계를 설계하기 위해, 우리는 @newterm{데이터 경로(data paths)}(레지스터와 연산)와 이러한 연산의 순서를 정하는 @newterm{컨트롤러(controller)}를 설계해야 한다.
간단한 레지스터 기계 설계의 예를 보여주기 위해, 두 정수의 최대공약수(@abbr{GCD})를 계산하는 데 사용되는 유클리드 알고리즘을 살펴보자.
@ref{1.2.5}에서 보았듯이, 유클리드 알고리즘은 다음 프로시저에 의해 지정된 반복 프로세스에 의해 수행될 수 있다:

@example
fn gcd(a: u64, b: u64) -> u64 @{
    if b == 0 @{
        a
    @} else @{
        gcd(b, a % b)
    @}
@}
@end example

@noindent
이 알고리즘을 수행하는 기계는 두 개의 숫자, @math{a}와 @math{b}를 추적해야 하므로, 이 숫자들을 해당 이름을 가진 두 개의 레지스터에 저장한다고 가정하자.
필요한 기본 연산은 레지스터 @code{b}의 내용이 0인지 테스트하는 것과 레지스터 @code{a}의 내용을 레지스터 @code{b}의 내용으로 나눈 나머지를 계산하는 것이다.
나머지 연산은 복잡한 프로세스이지만, 당분간 우리가 나머지를 계산하는 원시 장치를 가지고 있다고 가정하자.
@abbr{GCD} 알고리즘의 각 주기에서, 레지스터 @code{a}의 내용은 레지스터 @code{b}의 내용으로 대체되어야 하고, @code{b}의 내용은 @code{a}의 이전 내용을 @code{b}의 이전 내용으로 나눈 나머지로 대체되어야 한다.
이러한 대체가 동시에 수행될 수 있다면 편리하겠지만, 레지스터 기계 모델에서는 각 단계에서 하나의 레지스터에만 새 값을 할당할 수 있다고 가정할 것이다.
대체를 수행하기 위해, 우리 기계는 @code{t}라고 부르는 세 번째 ``임시(temporary)'' 레지스터를 사용할 것이다.
(먼저 나머지가 @code{t}에 놓이고, 그 다음 @code{b}의 내용이 @code{a}에 놓이고, 마지막으로 @code{t}에 저장된 나머지가 @code{b}에 놓일 것이다.)

@noindent
우리는 @ref{Figure 5.1}에 표시된 데이터 경로 다이어그램을 사용하여 이 기계에 필요한 레지스터와 연산을 설명할 수 있다.
이 다이어그램에서, 레지스터(@code{a}, @code{b}, 그리고 @code{t})는 직사각형으로 표시된다.
레지스터에 값을 할당하는 각 방법은 데이터 소스에서 레지스터를 가리키는, 머리 뒤에 @code{X}가 있는 화살표로 표시된다.
우리는 @code{X}를 누르면 소스에 있는 값이 지정된 레지스터로 ``흘러 들어가게'' 하는 버튼으로 생각할 수 있다.
각 버튼 옆의 레이블은 우리가 버튼을 참조할 때 사용할 이름이다.
이름은 임의적이며, 기억하기 쉬운 값(mnemonic value)을 갖도록 선택될 수 있다(예를 들어, @code{a<-b}는 레지스터 @code{b}의 내용을 레지스터 @code{a}에 할당하는 버튼을 누르는 것을 나타낸다).
레지스터의 데이터 소스는 다른 레지스터(@code{a<-b} 할당에서처럼), 연산 결과(@code{t<-r} 할당에서처럼), 또는 상수(변경할 수 없는 내장된 값, 데이터 경로 다이어그램에서 상수를 포함하는 삼각형으로 표시됨)가 될 수 있다.

@float
@anchor{Figure 5.1}
@ifinfo
@quotation
@strong{Figure 5.1:} @abbr{GCD} 기계를 위한 데이터 경로.

@example
                              ___
+-----+          +-----+     /   \
|  a  |<--(X)----|  b  +--->|  =  |
+--+--+   a<-b   +-+---+     \___/
   |               |  ^        ^
   +------+   +----+  |        |
          |   |      (X) b<-t  |
       .--+---+--.    |       / \
        \  rem  /     |      / O \
         \_____/      |     +-----+
            |         |
           (X) t<-r   |
            |         |
            V         |
         +-----+      |
         |  t  +------+
         +-----+
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap5/Fig5.1a,105mm,,,.std.svg}
@caption{@strong{Figure 5.1:} @abbr{GCD} 기계를 위한 데이터 경로.}
@end iftex
@end float

상수와 레지스터의 내용으로부터 값을 계산하는 연산은 데이터 경로 다이어그램에서 연산 이름을 포함하는 사다리꼴로 표시된다.
예를 들어, @ref{Figure 5.1}에서 @code{rem}이라고 표시된 상자는 연결된 레지스터 @code{a}와 @code{b}의 내용의 나머지를 계산하는 연산을 나타낸다.
화살표(버튼 없는)는 입력 레지스터와 상수에서 상자로 향하고, 화살표는 연산의 출력 값을 레지스터에 연결한다.
테스트는 테스트 이름을 포함하는 원으로 표시된다.
예를 들어, 우리 @abbr{GCD} 기계는 레지스터 @code{b}의 내용이 0인지 테스트하는 연산을 가지고 있다.
테스트 또한 입력 레지스터와 상수로부터 오는 화살표를 가지고 있지만, 출력 화살표는 없다; 그 값은 데이터 경로보다는 컨트롤러에 의해 사용된다.
전반적으로, 데이터 경로 다이어그램은 기계에 필요한 레지스터와 연산, 그리고 그것들이 어떻게 연결되어야 하는지를 보여준다.
우리가 화살표를 전선으로, @code{X} 버튼을 스위치로 본다면, 데이터 경로 다이어그램은 전기 부품으로 구성될 수 있는 기계의 배선도와 매우 흡사하다.

@noindent
데이터 경로가 실제로 @abbr{GCD}를 계산하려면, 버튼들이 올바른 순서로 눌려야 한다.
우리는 @ref{Figure 5.2}에 설명된 대로 컨트롤러 다이어그램의 관점에서 이 순서를 설명할 것이다.
컨트롤러 다이어그램의 요소들은 데이터 경로 구성 요소들이 어떻게 작동되어야 하는지를 나타낸다.
컨트롤러 다이어그램의 직사각형 상자는 눌러야 할 데이터 경로 버튼을 식별하고, 화살표는 한 단계에서 다음 단계로의 순서를 설명한다.
다이어그램의 다이아몬드는 결정을 나타낸다.
다이아몬드에 식별된 데이터 경로 테스트의 값에 따라 두 순서 화살표 중 하나를 따를 것이다.
우리는 물리적 유추를 통해 컨트롤러를 해석할 수 있다: 다이어그램을 구슬이 구르는 미로라고 생각하라.
구슬이 상자로 굴러 들어가면, 상자에 이름 붙여진 데이터 경로 버튼을 누른다.
구슬이 결정 노드(@code{b} = 0 테스트와 같은)로 굴러 들어가면, 표시된 테스트의 결과에 의해 결정된 경로로 노드를 떠난다.
데이터 경로와 컨트롤러를 함께 보면 @abbr{GCD}를 계산하는 기계를 완전히 설명한다.
우리는 레지스터 @code{a}와 @code{b}에 숫자를 넣은 후, @code{start}라고 표시된 곳에서 컨트롤러(구르는 구슬)를 시작한다.
컨트롤러가 @code{done}에 도달하면, 우리는 레지스터 @code{a}에서 @abbr{GCD} 값을 찾을 것이다.

@float
@anchor{Figure 5.2}
@ifinfo
@quotation
@strong{Figure 5.2:} @abbr{GCD} 기계를 위한 컨트롤러.

@example
     start
       |
       V
      / \ yes
+--->< = >-----> done
|     \ /
|      | no
|      V
|  +------+
|  | t<-r |
|  +---+--+
|      |
|      V
|  +------+
|  | a<-b |
|  +---+--+
|      |
|      V
|  +------+
+--+ b<-t |
   +------+
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap5/Fig5.2,75mm,,,.std.svg}
@caption{@strong{Figure 5.2:} @abbr{GCD} 기계를 위한 컨트롤러.}
@end iftex
@end float

@quotation
@strong{@anchor{Exercise 5.1}연습문제 5.1:} 다음 프로시저에 의해 지정된 반복 알고리즘을 사용하여 팩토리얼을 계산하는 레지스터 기계를 설계하라. 이 기계를 위한 데이터 경로와 컨트롤러 다이어그램을 그려라.

@example
fn factorial(n: u64) -> u64 @{
    fn iter(product: u64, counter: u64) -> u64 @{
        if counter > n @{
            product
        @} else @{
            iter(counter * product, counter + 1)
        @}
    @}
    iter(1, 1)
@}
@end example
@end quotation

@menu
* 5.1.1::            레지스터 기계 기술 언어 (A Language for Describing Register Machines)
* 5.1.2::            기계 설계의 추상화 (Abstraction in Machine Design)
* 5.1.3::            서브루틴 (Subroutines)
* 5.1.4::            스택을 이용한 재귀 구현 (Using a Stack to Implement Recursion)
* 5.1.5::            명령어 요약 (Instruction Summary)
@end menu

@node	5.1.1, 5.1.2, 5.1, 5.1
@subsection 레지스터 기계 기술 언어 (A Language for Describing Register Machines)

데이터 경로 및 컨트롤러 다이어그램은 @abbr{GCD}와 같은 간단한 기계를 표현하는 데는 적절하지만, Lisp 인터프리터와 같은 복잡한 기계를 설명하는 데는 다루기 힘들다.
복잡한 기계를 다룰 수 있게 하기 위해, 우리는 데이터 경로 및 컨트롤러 다이어그램이 제공하는 모든 정보를 텍스트 형식으로 제시하는 언어를 만들 것이다.
우리는 다이어그램을 직접 반영하는 표기법으로 시작할 것이다.

우리는 레지스터와 연산을 설명함으로써 기계의 데이터 경로를 정의한다.
레지스터를 설명하기 위해, 우리는 그것에 이름을 부여하고 그것에 대한 할당을 제어하는 버튼들을 지정한다.
우리는 이 버튼들 각각에 이름을 부여하고 버튼의 제어 하에 레지스터로 들어가는 데이터의 소스를 지정한다.
(소스는 레지스터, 상수, 또는 연산이다.)
연산을 설명하기 위해, 우리는 그것에 이름을 부여하고 입력(레지스터 또는 상수)을 지정한다.

우리는 기계의 컨트롤러를 @newterm{명령어(instructions)} 시퀀스와 시퀀스 내의 @newterm{진입점(entry points)}을 식별하는 @newterm{레이블(labels)}과 함께 정의한다. 명령어는 다음 중 하나이다:

@itemize @bullet

@item
레지스터에 값을 할당하기 위해 누르는 데이터 경로 버튼의 이름. (이것은 컨트롤러 다이어그램의 상자에 해당한다.)

@item
지정된 테스트를 수행하는 @code{test} 명령어.

@item
이전 테스트의 결과에 따라 컨트롤러 레이블로 표시된 위치로 분기하는 조건부 분기(@code{branch} 명령어). (테스트와 분기는 함께 컨트롤러 다이어그램의 다이아몬드에 해당한다.) 테스트가 거짓이면, 컨트롤러는 시퀀스의 다음 명령어로 계속해야 한다. 그렇지 않으면, 컨트롤러는 레이블 다음의 명령어로 계속해야 한다.

@item
실행을 계속할 컨트롤러 레이블을 명명하는 무조건 분기(@code{goto} 명령어).

@end itemize

@noindent
기계는 컨트롤러 명령어 시퀀스의 시작 부분에서 시작하여 실행이 시퀀스의 끝에 도달하면 멈춘다.
분기가 제어 흐름을 변경할 때를 제외하고, 명령어는 나열된 순서대로 실행된다.

@noindent
@ref{Figure 5.3}은 이 방식으로 설명된 @abbr{GCD} 기계를 보여준다.
이 예제는 이 설명의 일반성을 암시할 뿐인데, 왜냐하면 @abbr{GCD} 기계는 매우 단순한 경우이기 때문이다: 각 레지스터는 하나의 버튼만 가지고 있고, 각 버튼과 테스트는 컨트롤러에서 한 번만 사용된다.

@quotation
@strong{@anchor{Figure 5.3}Figure 5.3:} @math{\downarrow} @abbr{GCD} 기계의 명세.

@example
(data-paths
 (registers
  ((name a)
   (buttons ((name a<-b)
             (source (register b)))))
  ((name b)
   (buttons ((name b<-t)
             (source (register t)))))
  ((name t)
   (buttons ((name t<-r)
             (source (operation rem))))))
 (operations
  ((name rem)
   (inputs (register a) (register b)))
  ((name =)
   (inputs (register b) (constant 0)))))
@end example

@noindent
Rust에서, 우리는 이 컨트롤러 명령어들을 다음과 같이 표현한다:

@example
vec![
    Label("test-b".into()),
    Test(Op("=".into(), vec![Reg("b".into()), Const(0)])),
    Branch("gcd-done".into()),
    Assign("t".into(), Op("rem".into(), vec![Reg("a".into()), Reg("b".into())])),
    Assign("a".into(), Reg("b".into())),
    Assign("b".into(), Reg("t".into())),
    Goto(Label("test-b".into())),
    Label("gcd-done".into()),
]
@end example

@end quotation

불행히도, 그러한 설명은 읽기 어렵다.
컨트롤러 명령어를 이해하기 위해 우리는 버튼 이름과 연산 이름의 정의를 끊임없이 다시 참조해야 하며, 버튼이 무엇을 하는지 이해하기 위해 연산 이름의 정의를 참조해야 할 수도 있다.
따라서 우리는 데이터 경로 및 컨트롤러 설명의 정보를 결합하여 한 번에 볼 수 있도록 표기법을 변환할 것이다.

이러한 형태의 설명을 얻기 위해, 우리는 임의의 버튼 및 연산 이름을 그것들의 동작에 대한 정의로 대체할 것이다.
즉, (컨트롤러에서) ``@code{t<-r} 버튼을 눌러라''라고 말하고 별도로 (데이터 경로에서) ``@code{t<-r} 버튼은 @code{rem} 연산의 값을 레지스터 @code{t}에 할당한다''와 ``@code{rem} 연산의 입력은 레지스터 @code{a}와 @code{b}의 내용이다''라고 말하는 대신, 우리는 (컨트롤러에서) ``레지스터 @code{a}와 @code{b}의 내용에 대한 @code{rem} 연산의 값을 레지스터 @code{t}에 할당하는 버튼을 눌러라''라고 말할 것이다.
마찬가지로, (컨트롤러에서) ``@code{=} 테스트를 수행하라''라고 말하고 별도로 (데이터 경로에서) ``@code{=} 테스트는 레지스터 @code{b}의 내용과 상수 0에 대해 작동한다''라고 말하는 대신, 우리는 ``레지스터 @code{b}의 내용과 상수 0에 대해 @code{=} 테스트를 수행하라''라고 말할 것이다.
우리는 데이터 경로 설명을 생략하고 컨트롤러 시퀀스만 남겨둘 것이다.
따라서, @abbr{GCD} 기계는 다음과 같이 설명된다:

@example
vec![
    Label("test-b".into()),
    Test(Op("=".into(), vec![Reg("b".into()), Const(0)])),
    Branch("gcd-done".into()),
    Assign("t".into(), Op("rem".into(), vec![Reg("a".into()), Reg("b".into())])),
    Assign("a".into(), Reg("b".into())),
    Assign("b".into(), Reg("t".into())),
    Goto(Label("test-b".into())),
    Label("gcd-done".into()),
]
@end example

@noindent
@b{Rust:}
@example
use Instruction::*;
use Source::*;
use Target::*;

vec![
    // test-b
    Test(Op("=".into(), vec![Reg("b".into()), Const(0)])),
    Branch("gcd-done".into()),
    Assign("t".into(), Op("rem".into(),
        vec![Reg("a".into()), Reg("b".into())])),
    Assign("a".into(), Reg("b".into())),
    Assign("b".into(), Reg("t".into())),
    Goto(Label("test-b".into())),
    // gcd-done
]
@end example

@noindent
이 설명 형식은 @ref{Figure 5.3}에 예시된 종류보다 읽기 쉽지만, 단점도 있다:

@itemize @bullet

@item
대형 기계의 경우 더 장황한데, 왜냐하면 데이터 경로 요소들에 대한 완전한 설명이 컨트롤러 명령어 시퀀스에서 요소들이 언급될 때마다 반복되기 때문이다. (@abbr{GCD} 예제에서는 각 연산과 버튼이 한 번만 사용되므로 이것이 문제가 되지 않는다.) 게다가, 데이터 경로 설명을 반복하는 것은 기계의 실제 데이터 경로 구조를 모호하게 만든다; 대형 기계의 경우 얼마나 많은 레지스터, 연산, 버튼이 있고 그것들이 어떻게 상호 연결되어 있는지 명확하지 않다.

@item
기계 정의의 컨트롤러 명령어가 Lisp 표현식처럼 보이기 때문에, 그것들이 임의의 Lisp 표현식이 아니라는 것을 잊기 쉽다. 그것들은 오직 합법적인 기계 연산만 표기할 수 있다. 예를 들어, 연산은 다른 연산의 결과가 아니라 상수와 레지스터의 내용에 대해서만 직접 작동할 수 있다.

@end itemize

@noindent
이러한 단점에도 불구하고, 우리는 데이터 경로의 요소와 연결을 이해하는 것보다 컨트롤러를 이해하는 데 더 관심을 가질 것이기 때문에 이 장 전체에서 이 레지스터 기계 언어를 사용할 것이다.
그러나 우리는 실제 기계를 설계하는 데 있어 데이터 경로 설계가 결정적이라는 점을 명심해야 한다.

@quotation
@strong{@anchor{Exercise 5.2}연습문제 5.2:} 레지스터 기계 언어를 사용하여 @ref{Exercise 5.1}의 반복적 팩토리얼 기계를 설명하라.
@end quotation

@subsubheading 액션 (Actions)

우리가 원하는 @abbr{GCD}의 숫자를 입력하고 터미널에 인쇄된 답을 얻을 수 있도록 @abbr{GCD} 기계를 수정해 보자.
우리는 읽고 인쇄할 수 있는 기계를 만드는 방법에 대해서는 논의하지 않을 것이며, (우리가 Scheme에서 @code{read}와 @code{display}를 사용할 때처럼) 그것들이 원시 연산으로 사용 가능하다고 가정할 것이다.@footnote{이 가정은 엄청난 복잡성을 덮어버린다. 보통 Lisp 시스템 구현의 상당 부분은 읽기와 인쇄가 작동하도록 하는 데 바쳐진다.}

@code{Read}는 레지스터에 저장될 수 있는 값을 생성한다는 점에서 우리가 사용해 온 연산들과 비슷하다.
그러나 @code{read}는 어떤 레지스터로부터도 입력을 받지 않는다; 그 값은 우리가 설계하고 있는 기계의 부품 외부에서 일어나는 어떤 것에 의존한다.
우리는 기계의 연산이 그러한 동작을 갖는 것을 허용할 것이며, 따라서 값을 계산하는 다른 어떤 연산과 마찬가지로 @code{read}의 사용을 그리고 표기할 것이다.

반면에 @code{Print}는 우리가 사용해 온 연산들과 근본적인 방식에서 다르다: 그것은 레지스터에 저장될 출력 값을 생성하지 않는다.
그것이 효과를 가지기는 하지만, 이 효과는 우리가 설계하고 있는 기계의 일부에 미치는 것이 아니다.
우리는 이런 종류의 연산을 @newterm{액션(action)}이라고 부를 것이다.
우리는 값을 계산하는 연산을 나타내는 것과 마찬가지로 데이터 경로 다이어그램에서 액션을 나타낼 것인데---액션의 이름을 포함하는 사다리꼴로서이다.
화살표는 임의의 입력(레지스터 또는 상수)에서 액션 상자를 가리킨다.
우리는 또한 액션과 버튼을 연관시킨다.
버튼을 누르면 액션이 발생한다.
컨트롤러가 액션 버튼을 누르게 하기 위해 우리는 @code{perform}이라는 새로운 종류의 명령어를 사용한다.
따라서, 레지스터 @code{a}의 내용을 인쇄하는 액션은 컨트롤러 시퀀스에서 다음 명령어로 표현된다.

@example
(perform (op print) (reg a))
@end example

@noindent
@b{Rust:}
@example
Instruction::Perform(Source::Op(
    "print".into(),
    vec![Source::Reg("a".into())]
))
@end example

@noindent
@ref{Figure 5.4}는 새로운 @abbr{GCD} 기계를 위한 데이터 경로와 컨트롤러를 보여준다.
답을 인쇄한 후 기계를 멈추게 하는 대신, 우리는 기계가 다시 시작하도록 하여 숫자 쌍을 읽고, 그들의 @abbr{GCD}를 계산하고, 결과를 인쇄하는 것을 반복하도록 만들었다.
이 구조는 @ref{Chapter 4}의 인터프리터에서 사용한 드라이버 루프와 비슷하다.

@float
@anchor{Figure 5.4}
@ifinfo
@strong{Figure 5.4:} 입력을 읽고 결과를 인쇄하는 @abbr{GCD} 기계.

@example
                   .--------.
                    \ read /
                     \____/
                       |
               +-------*------+
               |              |
        a<-rd (X)            (X) b<-rd
               |              |
               V              V           ___
            +-----+        +-----+       /   \
            |  a  |<--(X)--+  b  +----->|  =  |
            +-+-+-+  a<-b  +-+---+       \___/
              | |            |  ^          ^
           +--+ +----+    +--+  |          |
           |         |    |    (X) b<-t   / \
           V         V    V     |        / O \
      .---------.  .---------.  |       /_____\
--(X)->\ print /    \  rem  /   |
   P    \_____/      \_____/    |
                        |       |
                       (X) t<-r |
                        |       |
                        V       |
                     +-----+    |
                     |  t  +----+
                     +-----+
@end example

@example
vec![
    Label("gcd-loop".into()),
    Assign("a".into(), Op("read".into(), vec![])),
    Assign("b".into(), Op("read".into(), vec![])),
    Label("test-b".into()),
    Test(Op("=".into(), vec![Reg("b".into()), Const(0)])),
    Branch("gcd-done".into()),
    Assign("t".into(), Op("rem".into(), vec![Reg("a".into()), Reg("b".into())])),
    Assign("a".into(), Reg("b".into())),
    Assign("b".into(), Reg("t".into())),
    Goto(Label("test-b".into())),
    Label("gcd-done".into()),
    Perform(Op("print".into(), vec![Reg("a".into())])),
    Goto(Label("gcd-loop".into())),
]
@end example

@end ifinfo
@iftex
@image{fig/chap5/Fig5.4c,147mm,,,.std.svg}
@caption{@strong{Figure 5.4:} 입력을 읽고 결과를 인쇄하는 @abbr{GCD} 기계.}
@end iftex
@end float

@node	5.1.2, 5.1.3, 5.1.1, 5.1
@subsection 기계 설계의 추상화 (Abstraction in Machine Design)

우리는 종종 실제로는 매우 복잡한 ``원시(primitive)'' 연산을 포함하는 기계를 정의할 것이다.
예를 들어, @ref{5.4}와 @ref{5.5}에서 우리는 Scheme의 환경 조작을 원시 연산으로 취급할 것이다.
그러한 추상화는 우리가 기계의 일부에 대한 세부 사항을 무시하여 설계의 다른 측면에 집중할 수 있게 해주기 때문에 가치가 있다.
그러나 우리가 많은 복잡성을 감추었다고 해서 기계 설계가 비현실적이라는 것을 의미하지는 않는다.
우리는 항상 복잡한 ``원시'' 연산들을 더 단순한 원시 연산들로 대체할 수 있다.

@noindent
@abbr{GCD} 기계를 고려해 보자. 이 기계는 레지스터 @code{a}와 @code{b}의 내용의 나머지를 계산하고 그 결과를 레지스터 @code{t}에 할당하는 명령어를 가지고 있다.
만약 우리가 원시 나머지 연산을 사용하지 않고 @abbr{GCD} 기계를 구성하고 싶다면, 우리는 뺄셈과 같은 더 단순한 연산들의 관점에서 나머지를 계산하는 방법을 지정해야 한다.
실제로, 우리는 다음과 같이 나머지를 찾는 Scheme 프로시저를 작성할 수 있다:

@example
fn remainder(n: i64, d: i64) -> i64 @{
    if n < d @{ n @} else @{ remainder(n - d, d) @}
@}
@end example

따라서 우리는 @abbr{GCD} 기계의 데이터 경로에 있는 나머지 연산을 뺄셈 연산과 비교 테스트로 대체할 수 있다.
@ref{Figure 5.5}는 정교해진 기계의 데이터 경로와 컨트롤러를 보여준다.
@abbr{GCD} 컨트롤러 정의의 명령어

@example
Assign("t".into(), Op("rem".into(), vec![Reg("a".into()), Reg("b".into())]))
@end example

@noindent
는 @ref{Figure 5.6}에 표시된 대로 루프를 포함하는 명령어 시퀀스로 대체된다.

@float
@anchor{Figure 5.5}
@ifinfo
@quotation
@strong{Figure 5.5:} 정교해진 @abbr{GCD} 기계를 위한 데이터 경로와 컨트롤러.

@example
                                    ___
+-----+         +-----+            /   \
|  a  |<--(X)---+  b  +-------*-->|  =  |
+--+--+   a<-b  +-+---+       |    \___/
   |              |  ^        |
  (X) t<-a        |  |        |
   |              | (X) b<-t  |
   V              |  |       _V_
+-----+           |  |      /   \
|  t  +-------*---|--*-----|  <  |
+-----+       |   |         \___/

@noindent
@b{Rust:}
@example
Assign("a".into(), Reg("b".into()))
@end example

   ^          V   V
   |        ---------
  (X) t<-d   \  -  /
   |          --+--
   |            |
   +------------+


   start
     |
     V
    / \ yes            +-------+
+->< = >----> done     | t<-d  |<--+
|   \ /                +---+---+   |
|    | no                  |       |
|    |                     V       |
|    |   +------+         / \ no   |
|    +-->| t<-a +------->< < >-----+

@noindent
@b{Rust:}
@example
Assign("t".into(), Op("rem".into(),
    vec![Reg("a".into()), Reg("b".into())]))
@end example

|        +------+         \ /
|                          | yes
|      +-------------------+
|      V
|  +-------+
|  | a<-b  |
|  +---+---+
|      |
|      V
|  +-------+
+--+ b<-t  |
   +-------+
@end example
@end quotation
@end ifinfo
@iftex
@image{fig/chap5/Fig5.5b,109mm,,,.std.svg}
@caption{@strong{Figure 5.5:} 정교해진 @abbr{GCD} 기계를 위한 데이터 경로와 컨트롤러.}
@end iftex
@end float

@quotation
@strong{@anchor{Figure 5.6}Figure 5.6:} @math{\downarrow} @ref{Figure 5.5}의 @abbr{GCD} 기계를 위한 컨트롤러 명령어 시퀀스.

@example
vec![
    Label("test-b".into()),
    Test(Op("=".into(), vec![Reg("b".into()), Const(0)])),
    Branch("gcd-done".into()),
    Assign("t".into(), Reg("a".into())),
    Label("rem-loop".into()),
    Test(Op("<".into(), vec![Reg("t".into()), Reg("b".into())])),
    Branch("rem-done".into()),
    Assign("t".into(), Op("-".into(), vec![Reg("t".into()), Reg("b".into())])),
    Goto(Label("rem-loop".into())),
    Label("rem-done".into()),
    Assign("a".into(), Reg("b".into())),
    Assign("b".into(), Reg("t".into())),
    Goto(Label("test-b".into())),
    Label("gcd-done".into()),
]
@end example

@noindent
@b{Rust:}
@example
vec![
    // test-b
    Test(Op("=".into(), vec![Reg("b".into()), Const(0)])),
    Branch("gcd-done".into()),
    Assign("t".into(), Reg("a".into())),
    // rem-loop
    Test(Op("<".into(), vec![Reg("t".into()), Reg("b".into())])),
    Branch("rem-done".into()),
    Assign("t".into(), Op("-".into(),
        vec![Reg("t".into()), Reg("b".into())])),
    Goto(Label("rem-loop".into())),
    // rem-done
    Assign("a".into(), Reg("b".into())),
    Assign("b".into(), Reg("t".into())),
    Goto(Label("test-b".into())),
    // gcd-done
]
@end example

@end quotation

@quotation
@strong{@anchor{Exercise 5.3}연습문제 5.3:} @ref{Sec.1.1.7,,1.1.7}에서 설명된 대로 뉴턴 방법을 사용하여 제곱근을 계산하는 기계를 설계하라.

@example
fn sqrt(x: f64) -> f64 @{
    fn good_enough(guess: f64, x: f64) -> bool @{
        (guess * guess - x).abs() < 0.001
    @}
    fn improve(guess: f64, x: f64) -> f64 @{
        (guess + x / guess) / 2.0
    @}
    fn sqrt_iter(guess: f64, x: f64) -> f64 @{
        if good_enough(guess, x) @{
            guess
        @} else @{
            sqrt_iter(improve(guess, x), x)
        @}
    @}
    sqrt_iter(1.0, x)
@}
@end example

@code{good_enough}와 @code{improve} 연산이 원시 연산으로 사용 가능하다고 가정하고 시작하라.
그런 다음 이것들을 산술 연산의 관점에서 확장하는 방법을 보여라.
@code{sqrt} 기계 설계의 각 버전을 데이터 경로 다이어그램을 그리고 레지스터 기계 언어로 컨트롤러 정의를 작성하여 설명하라.
@end quotation

@node	5.1.3, 5.1.4, 5.1.2, 5.1
@subsection 서브루틴 (Subroutines)

계산을 수행하는 기계를 설계할 때, 우리는 종종 구성 요소들을 복제하기보다는 계산의 다른 부분에서 구성 요소들이 공유되도록 배치하는 것을 선호한다.
두 개의 @abbr{GCD} 계산을 포함하는 기계를 고려해 보자---하나는 레지스터 @code{a}와 @code{b} 내용의 @abbr{GCD}를 찾고 다른 하나는 레지스터 @code{c}와 @code{d} 내용의 @abbr{GCD}를 찾는다.
우리는 원시 @code{gcd} 연산이 있다고 가정하고 시작한 다음, 두 개의 @code{gcd} 인스턴스를 더 기본적인 연산의 관점에서 확장할 수 있다.
@ref{Figure 5.7}은 결과 기계의 데이터 경로 중 @abbr{GCD} 부분만 보여주며, 그것들이 기계의 나머지 부분과 어떻게 연결되는지는 보여주지 않는다.
그림은 또한 기계의 컨트롤러 시퀀스의 해당 부분을 보여준다.

@float
@anchor{Figure 5.7}
@ifinfo
@strong{Figure 5.7:} 두 개의 @abbr{GCD} 계산을 포함하는 기계를 위한 데이터 경로와 컨트롤러 시퀀스의 일부.

@example
                            ___                                 ___  
+-----+        +-----+     /   \    +-----+        +-----+     /   \ 
|  a  |<-(X)---+  b  |--->|  =  |   |  c  |<-(X)---+  d  |--->|  =  |
+--+--+  a<-b  ++----+     \___/    +--+--+  c<-d  ++----+     \___/ 
   |            |  ^         ^         |            |  ^         ^   
   `----.   .---'  |         |         `----.   .---'  |         |   
        V   V     (X) b<-t   |              V   V     (X) d<-t   |   
       -------     |        / \            -------     |        / \  
       \ rem /     |       /_0_\           \ rem /     |       /_0_\ 
        --+--      |                        --+--      |             
          |        |                          |        |             
         (X) t<-r  |                         (X) s<-r  |             
          |        |                          |        |             
          V        |                          V        |             
       +-----+     |                       +-----+     |             
       |  t  +-----'                       |  s  +-----'             
       +-----+                             +-----+
@end example

@example
// gcd-1
Label("gcd-1".into()),
Test(Op("=".into(), vec![Reg("b".into()), Const(0)])),
Branch("after-gcd-1".into()),
Assign("t".into(), Op("rem".into(), vec![Reg("a".into()), Reg("b".into())])),
Assign("a".into(), Reg("b".into())),
Assign("b".into(), Reg("t".into())),
Goto(Label("gcd-1".into())),
Label("after-gcd-1".into()),
// ...
// gcd-2
Label("gcd-2".into()),
Test(Op("=".into(), vec![Reg("d".into()), Const(0)])),
Branch("after-gcd-2".into()),
Assign("s".into(), Op("rem".into(), vec![Reg("c".into()), Reg("d".into())])),
Assign("c".into(), Reg("d".into())),
Assign("d".into(), Reg("s".into())),
Goto(Label("gcd-2".into())),
Label("after-gcd-2".into()),
@end example

@end ifinfo
@iftex
@image{fig/chap5/Fig5.7b,145mm,,,.std.svg}
@caption{@strong{Figure 5.7:} 두 개의 @abbr{GCD} 계산을 포함하는 기계를 위한 데이터 경로와 컨트롤러 @w{시퀀스}의 일부.}
@end iftex
@end float

이 기계는 두 개의 나머지 연산 상자와 두 개의 동등성 테스트 상자를 가지고 있다.
만약 중복된 구성 요소들이 나머지 상자처럼 복잡하다면, 이것은 기계를 만드는 경제적인 방법이 아닐 것이다.
우리는 두 @abbr{GCD} 계산에 동일한 구성 요소를 사용함으로써 데이터 경로 구성 요소의 중복을 피할 수 있는데, 단 그렇게 하는 것이 더 큰 기계의 나머지 계산에 영향을 미치지 않아야 한다.
컨트롤러가 @code{gcd-2}에 도달할 때까지 레지스터 @code{a}와 @code{b}의 값이 필요하지 않다면(또는 이 값들을 안전하게 보관하기 위해 다른 레지스터로 옮길 수 있다면), 우리는 기계가 첫 번째뿐만 아니라 두 번째 @abbr{GCD}를 계산할 때도 레지스터 @code{c}와 @code{d} 대신 레지스터 @code{a}와 @code{b}를 사용하도록 변경할 수 있다.
이렇게 하면, 우리는 @ref{Figure 5.8}에 표시된 컨트롤러 시퀀스를 얻는다.

@quotation
@strong{@anchor{Figure 5.8}Figure 5.8:} @math{\downarrow} 두 개의 다른 @abbr{GCD} 계산에 대해 동일한 데이터 경로 구성 요소를 사용하는 기계를 위한 컨트롤러 시퀀스의 일부.

@example
// gcd-1
Label("gcd-1".into()),
Test(Op("=".into(), vec![Reg("b".into()), Const(0)])),
Branch("after-gcd-1".into()),
Assign("t".into(), Op("rem".into(), vec![Reg("a".into()), Reg("b".into())])),
Assign("a".into(), Reg("b".into())),
Assign("b".into(), Reg("t".into())),
Goto(Label("gcd-1".into())),
Label("after-gcd-1".into()),
// ...
// gcd-2
Label("gcd-2".into()),
Test(Op("=".into(), vec![Reg("b".into()), Const(0)])),
Branch("after-gcd-2".into()),
Assign("t".into(), Op("rem".into(), vec![Reg("a".into()), Reg("b".into())])),
Assign("a".into(), Reg("b".into())),
Assign("b".into(), Reg("t".into())),
Goto(Label("gcd-2".into())),
Label("after-gcd-2".into()),
@end example

@end quotation

@noindent
우리는 중복된 데이터 경로 구성 요소를 제거했지만(따라서 데이터 경로는 다시 @ref{Figure 5.1}과 같다), 컨트롤러는 이제 진입점 레이블만 다른 두 개의 @abbr{GCD} 시퀀스를 갖게 되었다.
이 두 시퀀스를 단일 시퀀스---@code{gcd} @newterm{서브루틴(subroutine)}---로 대체하고, 그 끝에서 메인 명령어 시퀀스의 올바른 위치로 다시 분기하도록 하는 것이 더 나을 것이다.
우리는 다음과 같이 이것을 달성할 수 있다: @code{gcd}로 분기하기 전에, 우리는 구별되는 값(0 또는 1과 같은)을 특별한 레지스터 @code{continue}에 넣는다.
@code{gcd} 서브루틴의 끝에서 우리는 @code{continue} 레지스터의 값에 따라 @code{after-gcd-1} 또는 @code{after-gcd-2}로 돌아간다.
@ref{Figure 5.9}는 결과 컨트롤러 시퀀스의 관련 부분을 보여주는데, 여기에는 @code{gcd} 명령어의 단일 사본만 포함된다.

@quotation
@strong{@anchor{Figure 5.9}Figure 5.9:} @math{\downarrow} @ref{Figure 5.8}의 중복된 컨트롤러 시퀀스를 피하기 위해 @code{continue} 레지스터 사용하기.

@example
// gcd
Label("gcd".into()),
Test(Op("=".into(), vec![Reg("b".into()), Const(0)])),
Branch("gcd-done".into()),
Assign("t".into(), Op("rem".into(), vec![Reg("a".into()), Reg("b".into())])),
Assign("a".into(), Reg("b".into())),
Assign("b".into(), Reg("t".into())),
Goto(Label("gcd".into())),
Label("gcd-done".into()),
Test(Op("=".into(), vec![Reg("continue".into()), Const(0)])),
Branch("after-gcd-1".into()),
Goto(Label("after-gcd-2".into())),
// ...
// 첫 번째 장소에서 gcd로 분기하기 전
Assign("continue".into(), Const(0)),
Goto(Label("gcd".into())),
Label("after-gcd-1".into()),
// ...
// gcd의 두 번째 사용 전
Assign("continue".into(), Const(1)),
@end example

@end quotation

@noindent
이것은 작은 문제를 처리하기에는 합리적인 접근 방식이지만, 컨트롤러 시퀀스에 @abbr{GCD} 계산 인스턴스가 많다면 어색할 것이다.
@code{gcd} 서브루틴 후에 실행을 계속할 위치를 결정하기 위해, 우리는 @code{gcd}를 사용하는 모든 장소에 대해 데이터 경로의 테스트와 컨트롤러의 분기 명령어가 필요할 것이다.
서브루틴을 구현하는 더 강력한 방법은 @code{continue} 레지스터가 서브루틴이 끝날 때 실행이 계속되어야 할 컨트롤러 시퀀스 내의 진입점 레이블을 보유하도록 하는 것이다.
이 전략을 구현하려면 데이터 경로와 레지스터 기계의 컨트롤러 사이에 새로운 종류의 연결이 필요하다: 레지스터에서 이 값을 가져와 지정된 진입점에서 실행을 계속하는 데 사용할 수 있는 방식으로 컨트롤러 시퀀스의 레이블을 레지스터에 할당하는 방법이 있어야 한다.

이 능력을 반영하기 위해, 우리는 레지스터 기계 언어의 @code{assign} 명령어를 확장하여 레지스터가 컨트롤러 시퀀스의 레이블(특별한 종류의 상수로서)을 값으로 할당받을 수 있게 할 것이다.
우리는 또한 @code{goto} 명령어를 확장하여 실행이 상수 레이블에 의해 설명된 진입점뿐만 아니라 레지스터의 내용에 의해 설명된 진입점에서 계속될 수 있도록 할 것이다.
이러한 새로운 구성을 사용하여 우리는 @code{continue} 레지스터에 저장된 위치로 분기하여 @code{gcd} 서브루틴을 종료할 수 있다.
이것은 @ref{Figure 5.10}에 표시된 컨트롤러 시퀀스로 이어진다.

@quotation
@strong{@anchor{Figure 5.10}Figure 5.10:} @math{\downarrow} @code{continue} 레지스터에 레이블을 할당하는 것은 @ref{Figure 5.9}에 표시된 전략을 단순화하고 일반화한다.

@example
gcd
 (test (op =) (reg b) (const 0))
 (branch (label gcd-done))
 (assign t (op rem) (reg a) (reg b))
 (assign a (reg b))
 (assign b (reg t))
 (goto (label gcd))
gcd-done
 (goto (reg continue))
  ...
;; gcd를 호출하기 전에,
;; 우리는 gcd가 반환해야 할 레이블을
;; continue에 할당한다.
 (assign continue (label after-gcd-1))
 (goto (label gcd))
after-gcd-1
  ...
;; 여기 gcd에 대한 두 번째 호출이 있다,
;; 다른 계속(continuation)과 함께.
 (assign continue (label after-gcd-2))
 (goto (label gcd))
after-gcd-2
@end example

@end quotation

@noindent
하나 이상의 서브루틴이 있는 기계는 여러 개의 계속(continuation) 레지스터(예: @code{gcd-continue}, @code{factorial-continue})를 사용하거나 모든 서브루틴이 단일 @code{continue} 레지스터를 공유하게 할 수 있다.
공유는 더 경제적이지만, 다른 서브루틴(@code{sub2})을 호출하는 서브루틴(@code{sub1})이 있는 경우 주의해야 한다.
@code{sub1}이 @code{sub2}에 대한 호출을 위해 @code{continue}를 설정하기 전에 @code{continue}의 내용을 다른 레지스터에 저장하지 않는다면, @code{sub1}은 끝났을 때 어디로 가야 할지 모를 것이다.
재귀를 처리하기 위해 다음 절에서 개발된 메커니즘은 중첩된 서브루틴 호출 문제에 대해서도 더 나은 해결책을 제공한다.

@node	5.1.4, 5.1.5, 5.1.3, 5.1
@subsection 스택을 이용한 재귀 구현 (Using a Stack to Implement Recursion)

지금까지 설명한 아이디어들로 우리는 프로세스의 각 상태 변수에 해당하는 레지스터를 가진 레지스터 기계를 지정함으로써 어떤 반복 프로세스든 구현할 수 있다.
기계는 종료 조건이 만족될 때까지 레지스터의 내용을 변경하며 컨트롤러 루프를 반복적으로 실행한다.
컨트롤러 시퀀스의 각 지점에서, 기계의 상태(반복 프로세스의 상태를 나타내는)는 레지스터의 내용(상태 변수의 값)에 의해 완전히 결정된다.

그러나 재귀 프로세스를 구현하려면 추가적인 메커니즘이 필요하다.
우리가 @ref{1.2.1}에서 처음 살펴보았던 팩토리얼을 계산하는 다음 재귀적 방법을 고려해 보자:

@example
fn factorial(n: i64) -> i64 @{
    if n == 1 @{
        1
    @} else @{
        factorial(n - 1) * n
    @}
@}
@end example

@noindent
프로시저에서 알 수 있듯이, @math{{n!}}을 계산하려면 @math{{(n - 1)!}}을 계산해야 한다.
다음 프로시저를 모델로 한 우리의 @abbr{GCD} 기계는

@example
fn gcd(a: u64, b: u64) -> u64 @{
    if b == 0 @{
        a
    @} else @{
        gcd(b, a % b)
    @}
@}
@end example

@noindent
유사하게 또 다른 @abbr{GCD}를 계산해야 했다.
그러나 원래의 계산을 새로운 @abbr{GCD} 계산으로 축소하는 @code{gcd} 프로시저와 하위 문제로 또 다른 팩토리얼을 계산해야 하는 @code{factorial} 사이에는 중요한 차이점이 있다.
@abbr{GCD}에서, 새로운 @abbr{GCD} 계산에 대한 답은 원래 문제에 대한 답이다.
다음 @abbr{GCD}를 계산하기 위해, 우리는 단순히 새로운 인자를 @abbr{GCD} 기계의 입력 레지스터에 넣고 동일한 컨트롤러 시퀀스를 실행함으로써 기계의 데이터 경로를 재사용한다.
기계가 마지막 @abbr{GCD} 문제를 해결하면, 전체 계산을 완료한 것이다.

팩토리얼(또는 어떤 재귀 프로세스)의 경우, 새로운 팩토리얼 하위 문제에 대한 답은 원래 문제에 대한 답이 아니다.
@math{{(n - 1)!}}에 대해 얻은 값은 최종 답을 얻기 위해 @math{n}과 곱해져야 한다.
만약 우리가 @abbr{GCD} 설계를 모방하여 @code{n} 레지스터를 감소시키고 팩토리얼 기계를 다시 실행함으로써 팩토리얼 하위 문제를 해결하려고 시도한다면, 우리는 더 이상 결과에 곱할 @code{n}의 이전 값을 사용할 수 없게 될 것이다.
따라서 우리는 하위 문제에 대해 작업할 두 번째 팩토리얼 기계가 필요하다.
이 두 번째 팩토리얼 계산 자체도 팩토리얼 하위 문제를 가지고 있어 세 번째 팩토리얼 기계를 필요로 하며, 이런 식으로 계속된다.
각 팩토리얼 기계는 그 안에 또 다른 팩토리얼 기계를 포함하므로, 전체 기계는 유사한 기계들의 무한한 중첩을 포함하며 따라서 고정된 유한한 수의 부품으로는 구성될 수 없다.

그럼에도 불구하고, 우리가 기계의 각 중첩된 인스턴스에 대해 동일한 구성 요소를 사용하도록 조치할 수 있다면 팩토리얼 프로세스를 레지스터 기계로 구현할 수 있다.
구체적으로, @math{{n!}}을 계산하는 기계는 @math{{(n - 1)!}}을 계산하는 하위 문제, @math{{(n - 2)!}}에 대한 하위 문제 등등에 대해 작업할 때 동일한 구성 요소를 사용해야 한다.
이것은 그럴듯한데, 팩토리얼 프로세스가 계산을 수행하기 위해 동일한 기계의 복사본이 무제한으로 필요하다고 지시하지만, 주어진 시간에는 이 복사본들 중 하나만 활성 상태여야 하기 때문이다.
기계가 재귀적 하위 문제를 만나면, 메인 문제에 대한 작업을 중단하고, 하위 문제에 대해 작업하기 위해 동일한 물리적 부품을 재사용하고, 그 다음 중단된 계산을 계속할 수 있다.

하위 문제에서 레지스터의 내용은 메인 문제에서와 다를 것이다. (이 경우 @code{n} 레지스터는 감소된다.)
중단된 계산을 계속할 수 있으려면, 기계는 하위 문제가 해결된 후 필요할 레지스터의 내용을 저장하여 중단된 계산을 계속하기 위해 복원할 수 있어야 한다.
팩토리얼의 경우, 우리는 감소된 @code{n} 레지스터의 팩토리얼 계산을 마쳤을 때 복원하기 위해 @code{n}의 이전 값을 저장할 것이다.@footnote{어떤 사람들은 이전 @code{n}을 저장할 필요가 없다고 주장할 수 있다; 그것을 감소시키고 하위 문제를 해결한 후, 이전 값을 복구하기 위해 단순히 증가시킬 수 있기 때문이다. 이 전략은 팩토리얼에 대해서는 효과가 있지만, 일반적으로는 효과가 없다. 왜냐하면 레지스터의 이전 값이 항상 새 값으로부터 계산될 수 있는 것은 아니기 때문이다.}

중첩된 재귀 호출의 깊이에 대한 @emph{선험적(a priori)} 한계가 없으므로, 우리는 임의의 수의 레지스터 값을 저장해야 할 수도 있다.
이 값들은 저장된 순서의 역순으로 복원되어야 하는데, 재귀의 중첩에서는 마지막으로 들어간 하위 문제가 가장 먼저 완료되기 때문이다.
이것은 레지스터 값을 저장하기 위해 @newterm{스택(stack)}, 또는 ``후입선출(last in, first out)'' 데이터 구조의 사용을 지시한다.
우리는 두 종류의 명령어를 추가함으로써 스택을 포함하도록 레지스터 기계 언어를 확장할 수 있다: 값들은 @code{save} 명령어를 사용하여 스택에 놓이고 @code{restore} 명령어를 사용하여 스택에서 복원된다.
일련의 값들이 스택에 @code{save}된 후, 일련의 @code{restore}들은 이 값들을 역순으로 검색할 것이다.@footnote{@ref{5.3}에서 우리는 더 기본적인 연산들의 관점에서 스택을 구현하는 방법을 보게 될 것이다.}

스택의 도움으로, 우리는 각 팩토리얼 하위 문제에 대해 팩토리얼 기계의 데이터 경로의 단일 사본을 재사용할 수 있다.
데이터 경로를 작동시키는 컨트롤러 시퀀스를 재사용하는 데에도 유사한 설계 문제가 있다.
팩토리얼 계산을 재실행하기 위해, 컨트롤러는 반복 프로세스에서처럼 단순히 시작 부분으로 루프백할 수 없다. 왜냐하면 @math{{(n - 1)!}} 하위 문제를 해결한 후 기계는 여전히 결과에 @math{n}을 곱해야 하기 때문이다.
컨트롤러는 @math{{n!}} 계산을 중단하고, @math{{(n - 1)!}} 하위 문제를 해결한 다음, @math{{n!}} 계산을 계속해야 한다.
팩토리얼 계산에 대한 이러한 관점은 @ref{5.1.3}에서 설명된 서브루틴 메커니즘의 사용을 제안한다. 여기서 컨트롤러는 @code{continue} 레지스터를 사용하여 하위 문제를 해결하는 시퀀스 부분으로 이동한 다음 메인 문제에서 중단한 곳에서 계속한다.
따라서 우리는 @code{continue} 레지스터에 저장된 진입점으로 반환하는 팩토리얼 서브루틴을 만들 수 있다.
각 서브루틴 호출 주위에서 우리는 @code{n} 레지스터와 마찬가지로 @code{continue}를 저장하고 복원하는데, 왜냐하면 팩토리얼 계산의 각 ``레벨''이 동일한 @code{continue} 레지스터를 사용할 것이기 때문이다.
즉, 팩토리얼 서브루틴은 하위 문제를 위해 자신을 호출할 때 @code{continue}에 새로운 값을 넣어야 하지만, 하위 문제를 해결하기 위해 자신을 호출한 곳으로 돌아가기 위해서는 이전 값이 필요할 것이다.

@noindent
@ref{Figure 5.11}은 재귀적 @code{factorial} 프로시저를 구현하는 기계의 데이터 경로와 컨트롤러를 보여준다.
기계는 스택과 @code{n}, @code{val}, @code{continue}라고 불리는 세 개의 레지스터를 가지고 있다.
데이터 경로 다이어그램을 단순화하기 위해, 우리는 레지스터 할당 버튼의 이름을 지정하지 않고 스택 연산 버튼(@code{sc}와 @code{sn}은 레지스터 저장, @code{rc}와 @code{rn}은 레지스터 복원)만 지정했다.
기계를 작동시키기 위해, 우리는 팩토리얼을 계산하고자 하는 숫자를 레지스터 @code{n}에 넣고 기계를 시작한다.
기계가 @code{fact-done}에 도달하면, 계산이 완료되고 답은 @code{val} 레지스터에서 찾을 수 있을 것이다.
컨트롤러 시퀀스에서, @code{n}과 @code{continue}는 각 재귀 호출 전에 저장되고 호출에서 반환될 때 복원된다.
호출에서의 반환은 @code{continue}에 저장된 위치로 분기함으로써 달성된다.
@code{Continue}는 기계가 시작될 때 마지막 반환이 @code{fact-done}으로 가도록 초기화된다.
팩토리얼 계산의 결과를 담고 있는 @code{val} 레지스터는 재귀 호출 전에 저장되지 않는데, 왜냐하면 @code{val}의 이전 내용은 서브루틴이 반환된 후에는 유용하지 않기 때문이다.
오직 하위 계산에 의해 생성된 값인 새 값만이 필요하다.

@float
@anchor{Figure 5.11}
@ifinfo
@strong{Figure 5.11:} 재귀적 팩토리얼 기계.

@example
                             ___
                            /   \
    +----------*-----------|  =  |
    |          |            \___/
   (X)         |              ^
    |          |              |
    V          |          +---+---+   sn    +-------+
+-------+      |          |       +---(X)-->|       |
|  val  |<-(X)-|----------+   n   |         | stack |
+-----+-+      |          |       |<--(X)---+       |
  ^   |        |          +-------+   rn    +-+-----+
  |   |        |            ^                 |   ^
 (X)  |        |            |                 |   |
  |   |   +----|--------*  (X)                |  (X) sc
  |   |   |    |        |   |             rc (X)  |
  |   |   |    *----.   |   |                 |   |
  |   V   V    |    V   V   |                 V   |
  |  -------   |   -------  |              +------+-+
  |  \  *  /   |   \  -  /  |              |continue+--> controller
  |   --+--    |    --+--   |              +--------+
  |     |      |      |     |               ^      ^
  +-----+      |      +-----+               |      |
               |                           (X)    (X)
               |                            |      |
              / \                   after- / \    / \  fact-
             /_1_\                  fact  /___\  /___\ done
@end example

@example
vec![
    Assign("continue".into(), Label("fact-done".into())),
    Label("fact-loop".into()),
    Test(Op("=".into(), vec![Reg("n".into()), Const(1)])),
    Branch("base-case".into()),
    Save("continue".into()),
    Save("n".into()),
    Assign("n".into(), Op("-".into(), vec![Reg("n".into()), Const(1)])),
    Assign("continue".into(), Label("after-fact".into())),
    Goto(Label("fact-loop".into())),
    Label("after-fact".into()),
    Restore("n".into()),
    Restore("continue".into()),
    Assign("val".into(), Op("*".into(), vec![Reg("n".into()), Reg("val".into())])),
    Goto(Reg("continue".into())),
    Label("base-case".into()),
    Assign("val".into(), Const(1)),
    Goto(Reg("continue".into())),
    Label("fact-done".into()),
]
@end example

@end ifinfo
@iftex
@image{fig/chap5/Fig5.11b,147mm,,,.std.svg}
@caption{@strong{Figure 5.11:} 재귀적 팩토리얼 기계.}
@end iftex
@end float

비록 원칙적으로 팩토리얼 계산이 무한한 기계를 필요로 하지만, @ref{Figure 5.11}의 기계는 잠재적으로 무제한인 스택을 제외하고는 실제로 유한하다.
그러나 스택의 모든 특정 물리적 구현은 유한한 크기일 것이며, 이것은 기계가 처리할 수 있는 재귀 호출의 깊이를 제한할 것이다.
팩토리얼의 이 구현은 스택으로 보강된 일반 레지스터 기계로서 재귀 알고리즘을 실현하기 위한 일반적인 전략을 보여준다.
재귀적 하위 문제가 발생하면, 우리는 하위 문제가 해결된 후 현재 값이 필요할 레지스터들을 스택에 저장하고, 재귀적 하위 문제를 해결한 다음, 저장된 레지스터들을 복원하고 메인 문제에 대한 실행을 계속한다.
@code{continue} 레지스터는 항상 저장되어야 한다.
저장해야 할 다른 레지스터가 있는지 여부는 특정 기계에 따라 다른데, 모든 재귀 계산이 하위 문제 해결 중에 수정되는 레지스터의 원래 값을 필요로 하는 것은 아니기 때문이다(@ref{Exercise 5.4} 참조).

@subsubheading 이중 재귀 (A double recursion)

우리가 @ref{1.2.2}에서 소개했던 피보나치 수의 트리 재귀 계산인 더 복잡한 재귀 프로세스를 살펴보자:

@example
fn fib(n: u64) -> u64 @{
    if n < 2 @{
        n
    @} else @{
        fib(n - 1) + fib(n - 2)
    @}
@}
@end example

@noindent
팩토리얼과 마찬가지로, 우리는 레지스터 @code{n}, @code{val}, @code{continue}를 가진 레지스터 기계로 재귀적 피보나치 계산을 구현할 수 있다.
이 기계는 팩토리얼을 위한 기계보다 더 복잡한데, 컨트롤러 시퀀스에서 재귀 호출을 수행해야 하는 곳이 두 군데---한 번은 @math{{\text{Fib}(n - 1)}}을 계산하기 위해, 한 번은 @math{{\text{Fib}(n - 2)}}를 계산하기 위해---있기 때문이다.
이 호출들 각각을 설정하기 위해, 우리는 나중에 값이 필요할 레지스터들을 저장하고, @code{n} 레지스터를 우리가 재귀적으로 Fib를 계산해야 할 숫자(@math{{n - 1}} 또는 @math{{n - 2}})로 설정하고, 반환할 메인 시퀀스의 진입점(@code{afterfib-n-1} 또는 @code{afterfib-n-2}, 각각)을 @code{continue}에 할당한다.
그런 다음 우리는 @code{fib-loop}로 간다.
재귀 호출에서 돌아오면, 답은 @code{val}에 있다.
@ref{Figure 5.12}는 이 기계를 위한 컨트롤러 시퀀스를 보여준다.

@quotation
@strong{@anchor{Figure 5.12}Figure 5.12:} @math{\downarrow} 피보나치 수를 계산하는 기계를 위한 컨트롤러.

@example
vec![
    Assign("continue".into(), Label("fib-done".into())),
    Label("fib-loop".into()),
    Test(Op("<".into(), vec![Reg("n".into()), Const(2)])),
    Branch("immediate-answer".into()),
    Save("continue".into()),
    Assign("continue".into(), Label("afterfib-n-1".into())),
    Save("n".into()),
    Assign("n".into(), Op("-".into(), vec![Reg("n".into()), Const(1)])),
    Goto(Label("fib-loop".into())),
    Label("afterfib-n-1".into()),
    Restore("n".into()),
    Restore("continue".into()),
    Assign("n".into(), Op("-".into(), vec![Reg("n".into()), Const(2)])),
    Save("continue".into()),
    Assign("continue".into(), Label("afterfib-n-2".into())),
    Save("val".into()),
    Goto(Label("fib-loop".into())),
    Label("afterfib-n-2".into()),
    Assign("n".into(), Reg("val".into())),
    Restore("val".into()),
    Restore("continue".into()),
    Assign("val".into(), Op("+".into(), vec![Reg("val".into()), Reg("n".into())])),
    Goto(Reg("continue".into())),
    Label("immediate-answer".into()),
    Assign("val".into(), Reg("n".into())),
    Goto(Reg("continue".into())),
    Label("fib-done".into()),
]
@end example

@end quotation

@quotation
@strong{@anchor{Exercise 5.4}연습문제 5.4:} 다음 프로시저들 각각을 구현하는 레지스터 기계를 명시하라. 각 기계에 대해 컨트롤러 명령어 시퀀스를 작성하고 데이터 경로를 보여주는 다이어그램을 그려라.

@enumerate a

@item
재귀적 거듭제곱:

@example
fn expt(b: i64, n: i64) -> i64 @{
    if n == 0 @{
        1
    @} else @{
        b * expt(b, n - 1)
    @}
@}
@end example

@item
반복적 거듭제곱:

@example
fn expt(b: i64, n: i64) -> i64 @{
    fn iter(counter: i64, product: i64) -> i64 @{
        if counter == 0 @{
            product
        @} else @{
            iter(counter - 1, b * product)
        @}
    @}
    iter(n, 1)
@}
@end example

@end enumerate
@end quotation

@quotation
@strong{@anchor{Exercise 5.5}연습문제 5.5:} 팩토리얼과 피보나치 기계를 손으로 시뮬레이션하라. 사소하지 않은 입력(적어도 하나의 재귀 호출 실행이 필요한)을 사용하라. 실행의 각 중요한 지점에서 스택의 내용을 보여라.
@end quotation

@quotation
@strong{@anchor{Exercise 5.6}연습문제 5.6:} Ben Bitdiddle은 피보나치 기계의 컨트롤러 시퀀스에 불필요한 @code{save}와 @code{restore}가 있으며, 이것들을 제거하면 더 빠른 기계를 만들 수 있음을 관찰한다. 이 명령어들은 어디에 있는가?
@end quotation

@node   5.1.5, 5.2, Chapter 5, 5.1
@subsection 명령어 요약 (Instruction Summary)

우리 레지스터 기계 언어의 컨트롤러 명령어는 @code{Inst} 열거형으로 표현된다.
값들은 @code{VExp} (값 표현식) 열거형으로 표현되며, 이는 레지스터 (@code{VExp::Reg}) 또는 상수 (@code{VExp::Const})가 될 수 있다.

@example
// 레지스터에 값 할당
Inst::Assign(target_reg, source_value)

// 연산 수행 (부수 효과만 있음)
Inst::Perform(OpExp @{ op: name, args: vec![...] @})

// 조건 테스트 및 플래그 설정
Inst::Test(OpExp @{ op: predicate, args: vec![...] @})

// 플래그가 참이면 레이블로 분기
Inst::Branch(label_name)

// 무조건 goto
Inst::Goto(GotoDest::Label(label_name))
@end example

@noindent
레이블을 보유하기 위한 레지스터 사용은 @ref{5.1.3}에서 소개되었다:

@example
Inst::Assign(reg_name, VExp::Label(label_name))
Inst::Goto(GotoDest::Reg(reg_name))
@end example

@noindent
스택 사용을 위한 명령어는 @ref{5.1.4}에서 소개되었다:

@example
Inst::Save(reg_name)
Inst::Restore(reg_name)
@end example

@noindent
우리가 사용하는 상수 값들은 숫자, 불리언, 문자열, 기호, 그리고 리스트를 나타낼 수 있는 @code{Value} 열거형으로 감싸져 있다.
예를 들어,@*
@code{Value::String("abc".to_string())}은 문자열 @code{"abc"}이고,@*
@code{Value::Symbol("abc".to_string())}은 기호 @code{abc}이며,@*
@code{Value::Pair(...)}는 리스트이고,@*
@code{Value::Nil}은 빈 리스트이다.

@node	5.2, 5.3, 5.1, Chapter 5
@section 레지스터 기계 시뮬레이터 (A Register-Machine Simulator)

레지스터 기계의 설계를 잘 이해하기 위해, 우리는 우리가 설계한 기계가 예상대로 작동하는지 확인하기 위해 테스트해야 한다.
설계를 테스트하는 한 가지 방법은 @ref{Exercise 5.5}에서처럼 컨트롤러의 작동을 손으로 시뮬레이션하는 것이다.
하지만 이것은 가장 단순한 기계를 제외하고는 매우 지루한 일이다.
이 절에서 우리는 레지스터 기계 언어로 설명된 기계를 위한 시뮬레이터를 구축한다.
시뮬레이터는 @code{Machine} 구조체에 대한 여러 주요 메서드를 갖춘 Rust 프로그램이다:

@quotation

@example
MachineBuilder::new()
    .register(⟨@var{name}⟩)
    .operation(⟨@var{name}⟩, ⟨@var{func}⟩)
    .controller(⟨@var{instructions}⟩)
    .build()
@end example

@noindent
주어진 레지스터, 연산, 그리고 컨트롤러를 가진 기계 모델을 구축하고 반환한다.

@example
machine.set_register(⟨@var{register_name}⟩, ⟨@var{value}⟩)
@end example

@noindent
주어진 기계의 시뮬레이션된 레지스터에 값을 저장한다.

@example
machine.get_register(⟨@var{register_name}⟩)
@end example

@noindent
주어진 기계의 시뮬레이션된 레지스터 내용을 반환한다.

@example
machine.start()
@end example

@noindent
주어진 기계의 실행을 시뮬레이션하며, 컨트롤러 시퀀스의 시작 부분에서 시작하여 시퀀스의 끝에 도달하면 멈춘다.
@end quotation

@noindent
이러한 프로시저들이 어떻게 사용되는지 보여주는 예로, 우리는 @ref{5.1.1}의 @abbr{GCD} 기계 모델이 되도록 @code{gcd-machine}을 다음과 같이 정의할 수 있다:

@example
// Rust에서, 우리는 MachineBuilder를 사용하여 기계를 구축한다:
let mut gcd_machine = MachineBuilder::new()
    .register("a")
    .register("b")
    .register("t")
    .operation("rem", |args| @{
        let a = args[0].as_number();
        let b = args[1].as_number();
        Value::Number(a % b)
    @})
    .operation("=", |args| @{
        Value::Bool(args[0] == args[1])
    @})
    .controller(vec![
        Inst::Label("test-b".to_string()),
        Inst::Test(OpExp::new("=", vec![VExp::Reg("b".to_string()), VExp::Const(Value::Number(0))])),
        Inst::Branch("gcd-done".to_string()),
        Inst::Assign("t".to_string(), VExp::Op(OpExp::new("rem", vec![VExp::Reg("a".to_string()), VExp::Reg("b".to_string())]))),
        Inst::Assign("a".to_string(), VExp::Reg("b".to_string())),
        Inst::Assign("b".to_string(), VExp::Reg("t".to_string())),
        Inst::Goto(GotoDest::Label("test-b".to_string())),
        Inst::Label("gcd-done".to_string()),
    ])
    .build();
@end example

@noindent
@code{make_machine}에 대한 첫 번째 인자는 레지스터 이름들의 리스트이다.
다음 인자는 각 연산 이름과 그 연산을 구현하는(즉, 동일한 입력 값에 대해 동일한 출력 값을 생성하는) Scheme 프로시저를 쌍으로 묶은 테이블(두 요소 리스트들의 리스트)이다.
마지막 인자는 @ref{5.1}에서처럼 레이블과 기계 명령어들의 리스트로서 컨트롤러를 지정한다.

이 기계로 @abbr{GCD}를 계산하기 위해, 우리는 입력 레지스터를 설정하고, 기계를 시작하고, 시뮬레이션이 종료될 때 결과를 검사한다:

@example
gcd_machine.set_register("a", Value::Number(206));
gcd_machine.set_register("b", Value::Number(40));
gcd_machine.start();

gcd_machine.get_register("a")
// => Value::Number(2)
@end example

@noindent
이 계산은 Rust로 작성된 @code{gcd} 프로시저보다 훨씬 느리게 실행될 것인데, 왜냐하면 우리는 @code{assign}과 같은 저수준 기계 명령어를 훨씬 더 복잡한 연산으로 시뮬레이션할 것이기 때문이다.

@quotation
@strong{@anchor{Exercise 5.7}연습문제 5.7:} 시뮬레이터를 사용하여 @ref{Exercise 5.4}에서 설계한 기계들을 테스트하라.

@noindent
@b{Rust (재귀적 팩토리얼 기계):}
@example
vec![
    Assign("continue".into(), Source::Label("fact-done".into())),
    // fact-loop
    Test(Op("=".into(), vec![Reg("n".into()), Const(1)])),
    Branch("base-case".into()),
    Save("continue".into()),
    Save("n".into()),
    Assign("n".into(), Op("-".into(), vec![Reg("n".into()), Const(1)])),
    Assign("continue".into(), Source::Label("after-fact".into())),
    Goto(Label("fact-loop".into())),
    // after-fact
    Restore("n".into()),
    Restore("continue".into()),
    Assign("val".into(), Op("*".into(),
        vec![Reg("n".into()), Reg("val".into())])),
    Goto(Reg("continue".into())),
    // base-case
    Assign("val".into(), Const(1)),
    Goto(Reg("continue".into())),
]
@end example
@end quotation

@menu
* 5.2.1::            The Machine Model
* 5.2.2::            The Assembler
* 5.2.3::            Generating Execution Procedures for Instructions
* 5.2.4::            Monitoring Machine Performance
* 5.2.5::            WebAssembly Backend
@end menu

@node	5.2.1, 5.2.2, 5.2, 5.2
@subsection 기계 모델 (The Machine Model)

@code{make_machine}에 의해 생성된 기계 모델은 @ref{Chapter 3}에서 개발된 메시지 패싱 기술을 사용하여 지역 상태를 가진 프로시저로 표현된다.
이 모델을 구축하기 위해, @code{make_machine}은 먼저 모든 레지스터 기계에 공통적인 기계 모델의 부분들을 구성하기 위해 @code{make_new_machine} 프로시저를 호출하는 것으로 시작한다.
@code{make_new_machine}에 의해 구성된 이 기본 기계 모델은 본질적으로 몇 개의 레지스터와 스택을 담는 컨테이너이며, 컨트롤러 명령어를 하나씩 처리하는 실행 메커니즘을 함께 갖추고 있다.

그 다음 @code{Make_machine}은 정의되는 특정 기계의 레지스터, 연산, 그리고 컨트롤러를 포함하도록 이 기본 모델을 (메시지를 보냄으로써) 확장한다.
먼저 제공된 각 레지스터 이름에 대해 새 기계에 레지스터를 할당하고 지정된 연산을 기계에 설치한다.
그런 다음 @newterm{어셈블러(assembler)}(아래 @ref{5.2.2}에서 설명됨)를 사용하여 컨트롤러 리스트를 새 기계를 위한 명령어로 변환하고 이것들을 기계의 명령어 시퀀스로 설치한다.
@code{Make_machine}은 수정된 기계 모델을 값으로 반환한다.

@example
pub fn make_machine(
    register_names: &[&str],
    operations: Vec<(&str, OpFn)>,
    controller: Vec<Inst>,
) -> Machine @{
    let mut builder = MachineBuilder::new();

    for name in register_names @{
        builder = builder.register(name);
    @}

    for (name, op) in operations @{
        builder = builder.operation(name, op);
    @}

    builder.controller(controller).build()
@}
@end example

@subsubheading 레지스터 (Registers)

우리는 레지스터를 @ref{Chapter 3}에서와 같이 지역 상태를 가진 프로시저로 표현할 것이다.
@code{make_register} 프로시저는 접근하거나 변경할 수 있는 값을 보유하는 레지스터를 생성한다:

@example
pub struct Machine @{
    registers: Vec<Value>,
    register_map: HashMap<String, usize>,
    // ... 다른 필드들
@}

impl Machine @{
    pub fn get_register(&self, name: &str) -> Value @{
        let idx = self.register_map.get(name).expect("Unknown register");
        self.registers[*idx].clone()
    @}

    pub fn set_register(&mut self, name: &str, value: Value) @{
        let idx = self.register_map.get(name).expect("Unknown register");
        self.registers[*idx] = value;
    @}
@}
@end example

@noindent
다음 프로시저들은 레지스터에 접근하는 데 사용된다:

@example
// Rust에서, 우리는 위에서 정의된 Machine 메서드를 통해 레지스터에 직접 접근한다.
@end example

@subsubheading 스택 (The stack)

우리는 또한 스택을 지역 상태를 가진 프로시저로 표현할 수 있다.
@code{make_stack} 프로시저는 스택의 아이템 리스트로 구성된 지역 상태를 가진 스택을 생성한다.
스택은 아이템을 스택에 @code{push}하고, 스택에서 맨 위 아이템을 @code{pop}하여 반환하고, 스택을 비우도록 @code{initialize}하는 요청을 수락한다.

@example
pub struct Stack @{
    data: Vec<Value>,
    pushes: usize,
    max_depth: usize,
@}

impl Stack @{
    pub fn new() -> Self @{
        Stack @{ data: Vec::new(), pushes: 0, max_depth: 0 @}
    @}

    pub fn push(&mut self, value: Value) @{
        self.data.push(value);
        self.pushes += 1;
        if self.data.len() > self.max_depth @{
            self.max_depth = self.data.len();
        @}
    @}

    pub fn pop(&mut self) -> Value @{
        self.data.pop().expect("Empty stack: POP")
    @}

    pub fn initialize(&mut self) @{
        self.data.clear();
        self.pushes = 0;
        self.max_depth = 0;
    @}
@}
@end example

@noindent
다음 프로시저들은 스택에 접근하는 데 사용된다:

@example
// Rust에서, 우리는 기계를 구성하기 위해 MachineBuilder를 사용한다.
// rust-examples/chapter5/src/section_5_2.rs의 구현을 참조하라.
@end example

@subsubheading 기본 기계 (The basic machine)

@code{make_new_machine} 프로시저는 스택, 초기에 비어 있는 명령어 시퀀스, 초기에 스택을 초기화하는 연산을 포함하는 연산 리스트, 그리고 초기에 @code{flag}와 @code{pc}(``프로그램 카운터''를 위한)라는 두 개의 레지스터를 포함하는 @newterm{레지스터 테이블(register table)}로 구성된 지역 상태를 가진 객체를 생성한다.
내부 프로시저 @code{allocate_register}는 레지스터 테이블에 새 항목을 추가하고, 내부 프로시저 @code{lookup_register}는 테이블에서 레지스터를 찾는다.

@noindent
@strong{@anchor{Figure 5.13}Figure 5.13:} @math{\downarrow} 기본 기계 모델을 구현하는 @code{make_new_machine} 프로시저.

@example
impl Machine @{
    pub fn new() -> Self @{
        Machine @{
            registers: Vec::new(),
            register_map: HashMap::new(),
            stack: Stack::new(),
            pc: 0,
            flag: false,
            instructions: Vec::new(),
            operations: HashMap::new(),
            instruction_count: 0,
        @}
    @}

    pub fn start(&mut self) @{
        self.pc = 0;
        self.execute();
    @}

    fn execute(&mut self) @{
        while self.pc < self.instructions.len() @{
            let inst = self.instructions[self.pc].clone();
            self.execute_instruction(inst);
        @}
    @}
@}
@end example

@code{flag} 레지스터는 시뮬레이션된 기계에서 분기를 제어하는 데 사용된다.
@code{Test} 명령어는 테스트의 결과(참 또는 거짓)로 @code{flag}의 내용을 설정한다.
@code{Branch} 명령어는 @code{flag}의 내용을 검사하여 분기할지 여부를 결정한다.

@code{pc} 레지스터는 기계가 실행될 때 명령어의 순서를 결정한다.
이 순서는 내부 프로시저 @code{execute}에 의해 구현된다.
시뮬레이션 모델에서, 각 기계 명령어는 @newterm{명령어 실행 프로시저(instruction execution procedure)}라고 불리는 인자 없는 프로시저를 포함하는 데이터 구조로, 이 프로시저를 호출하면 명령 실행이 시뮬레이션된다.
시뮬레이션이 실행됨에 따라, @code{pc}는 명령어 시퀀스에서 실행될 다음 명령어로 시작하는 위치를 가리킨다.
@code{Execute}는 그 명령어를 가져와서 명령어 실행 프로시저를 호출하여 실행하고, 실행할 명령어가 더 이상 없을 때까지(즉, @code{pc}가 명령어 시퀀스의 끝을 가리킬 때까지) 이 주기를 반복한다.

@noindent
작동의 일부로, 각 명령어 실행 프로시저는 실행될 다음 명령어를 나타내도록 @code{pc}를 수정한다.
@code{Branch}와 @code{goto} 명령어는 @code{pc}가 새로운 목적지를 가리키도록 변경한다.
다른 모든 명령어는 단순히 @code{pc}를 전진시켜 시퀀스의 다음 명령어를 가리키게 한다.
@code{execute}에 대한 각 호출이 다시 @code{execute}를 호출하지만, 명령어 실행 프로시저를 실행하면 @code{pc}의 내용이 변경되므로 이것이 무한 루프를 생성하지 않는다는 것을 관찰하라.

@code{Make_new_machine}은 내부 상태에 대한 메시지 패싱 접근을 구현하는 @code{dispatch} 프로시저를 반환한다.
기계 시작은 @code{pc}를 명령어 시퀀스의 시작으로 설정하고 @code{execute}를 호출함으로써 달성된다는 것에 주목하라.

편의를 위해, 우리는 @ref{5.2}의 시작 부분에 명시된 대로 레지스터 내용을 설정하고 검사하는 프로시저뿐만 아니라 기계의 @code{start} 연산에 대한 대체 절차적 인터페이스를 제공한다:

@lisp
// Rust에서, 이러한 연산들은 Machine 구조체의 메서드로 사용 가능하다:
// machine.start()
// machine.get_register(name)
// machine.set_register(name, value)
@end lisp

@noindent
이러한 프로시저들(@ref{5.2.2}와 @ref{5.2.3}의 많은 프로시저들)은 주어진 기계에서 주어진 이름을 가진 레지스터를 찾기 위해 다음을 사용한다:

@example
// 레지스터 조회는 Machine 구조체의 get_register 메서드에 의해 처리된다.
@end example

@node	5.2.2, 5.2.3, 5.2.1, 5.2
@subsection The Assembler

The assembler transforms the sequence of controller expressions for a machine
into a corresponding list of machine instructions, each with its execution
procedure.  Overall, the assembler is much like the evaluators we studied in
@ref{Chapter 4}---there is an input language (in this case, the
register-machine language) and we must perform an appropriate action for each
type of expression in the language.

The technique of producing an execution procedure for each instruction is just
what we used in @ref{4.1.7} to speed up the evaluator by separating
analysis from runtime execution.  As we saw in @ref{Chapter 4}, much useful
analysis of Scheme expressions could be performed without knowing the actual
values of variables.  Here, analogously, much useful analysis of
register-machine-language expressions can be performed without knowing the
actual contents of machine registers.  For example, we can replace references
to registers by pointers to the register objects, and we can replace references
to labels by pointers to the place in the instruction sequence that the label
designates.

Before it can generate the instruction execution procedures, the assembler must
know what all the labels refer to, so it begins by scanning the controller text
to separate the labels from the instructions.  As it scans the text, it
constructs both a list of instructions and a table that associates each label
with a pointer into that list.  Then the assembler augments the instruction
list by inserting the execution procedure for each instruction.

The @code{assemble} procedure is the main entry to the assembler.  It takes the
controller text and the machine model as arguments and returns the instruction
sequence to be stored in the model.  @code{Assemble} calls
@code{extract_labels} to build the initial instruction list and label table
from the supplied controller text.  The second argument to
@code{extract_labels} is a procedure to be called to process these results:
This procedure uses @code{update_insts} to generate the instruction execution
procedures and insert them into the instruction list, and returns the modified
list.

@example
fn assemble(
    controller: Vec<Inst>,
    register_map: &HashMap<String, usize>,
    operations: &HashMap<String, OpFn>,
) -> Vec<ResolvedInst> @{
    let (insts, labels) = extract_labels(controller);
    update_insts(insts, &labels, register_map, operations)
@}
@end example

@noindent
@code{Extract_labels} takes as arguments a list @code{text} (the sequence of
controller instruction expressions) and a @code{receive} procedure.
@code{Receive} will be called with two values: (1) a list @code{insts} of
instruction data structures, each containing an instruction from @code{text};
and (2) a table called @code{labels}, which associates each label from
@code{text} with the position in the list @code{insts} that the label
designates.

@example
fn extract_labels(text: Vec<Inst>) -> (Vec<Inst>, HashMap<String, usize>) @{
    let mut instructions = Vec::new();
    let mut labels = HashMap::new();

    for inst in text @{
        match inst @{
            Inst::Label(name) => @{
                if labels.contains_key(&name) @{
                    panic!("Multiply defined label: @{@}", name);
                @}
                labels.insert(name, instructions.len());
            @}
            _ => @{
                instructions.push(inst);
            @}
        @}
    @}

    (instructions, labels)
@}
@end example

@noindent
@code{extract_labels} works by sequentially scanning the elements of the
@code{text} and accumulating the @code{instructions} and the @code{labels}.  If an
element is a label, an appropriate entry is added to the
@code{labels} table.  Otherwise the element is accumulated onto the
@code{instructions} list.

@noindent
The assembler performs two passes over the controller text.  In the first pass,
it extracts the labels and records their positions in a table.  In the second
pass, it resolves all references to labels and registers, converting the
symbolic instructions into a more efficient internal representation that uses
numeric indices.

@code{Update_insts} modifies the instruction list to include the resolved
references:

@example
fn update_insts(
    insts: Vec<Inst>,
    labels: &HashMap<String, usize>,
    register_map: &HashMap<String, usize>,
    operations: &HashMap<String, OpFn>,
) -> Vec<ResolvedInst> @{
    insts
        .into_iter()
        .map(|inst| resolve_instruction(inst, labels, register_map))
        .collect()
@}
@end example

@noindent
The machine instruction data structure simply pairs the instruction text with
the corresponding execution procedure.  The execution procedure is not yet
available when @code{extract_labels} constructs the instruction, and is
inserted later by @code{update_insts}.

@example
// In Rust, we use the Inst and ResolvedInst enums to represent instructions.
// See the definitions in section 5.2 source code.
@end example

@noindent
The instruction text is not used by our simulator, but it is handy to keep
around for debugging (see @ref{Exercise 5.16}).

Elements of the label table are entries in a @code{HashMap}:

@example
// In Rust, we use a HashMap to store labels:
let mut labels: HashMap<String, usize> = HashMap::new();
labels.insert(label_name, position);
@end example

@noindent
Entries will be looked up in the table with

@example
fn lookup_label(
    labels: &HashMap<String, usize>,
    label_name: &str
) -> Result<usize, String> @{
    labels.get(label_name)
        .cloned()
        .ok_or_else(|| format!("Undefined label: @{@}", label_name))
@}
@end example

@quotation
@strong{@anchor{Exercise 5.8}Exercise 5.8:} The following register-machine code
is ambiguous, because the label @code{here} is defined more than once:

@example
vec![
    Label("start".into()),
    Goto(Label("here".into())),
    Label("here".into()),
    Assign("a".into(), Const(3)),
    Goto(Label("there".into())),
    Label("here".into()),
    Assign("a".into(), Const(4)),
    Goto(Label("there".into())),
    Label("there".into()),
]
@end example

With the simulator as written, what will the contents of register @code{a} be
when control reaches @code{there}?  Modify the @code{extract_labels} procedure
so that the assembler will signal an error if the same label name is used to
indicate two different locations.
@end quotation

@node	5.2.3, 5.2.4, 5.2.2, 5.2
@subsection Generating Execution Procedures for Instructions

The assembler calls @code{resolve_instruction} to generate the execution
procedure for an instruction.  Like the @code{analyze} procedure in the
evaluator of @ref{4.1.7}, this dispatches on the type of instruction to
generate the appropriate execution procedure.

@example
fn resolve_instruction(
    inst: Inst,
    labels: &HashMap<String, usize>,
    register_map: &HashMap<String, usize>,
) -> ResolvedInst @{
    match inst @{
        Inst::Assign(reg_name, value_exp) => @{
            let target_reg = *register_map.get(&reg_name).expect("Unknown register");
            let value = resolve_value_exp(value_exp, labels, register_map);
            ResolvedInst::Assign @{ target_reg, value @}
        @}
        Inst::Test(op_exp) => @{
            let condition = resolve_op_exp(op_exp, labels, register_map);
            ResolvedInst::Test @{ condition @}
        @}
        Inst::Branch(label_name) => @{
            let destination = *labels.get(&label_name).expect("Undefined label");
            ResolvedInst::Branch @{ destination @}
        @}
        Inst::Goto(dest) => @{
            // ... (goto resolution logic)
            resolve_goto(dest, labels, register_map)
        @}
        Inst::Save(reg_name) => @{
            let reg = *register_map.get(&reg_name).expect("Unknown register");
            ResolvedInst::Save @{ reg @}
        @}
        Inst::Restore(reg_name) => @{
            let reg = *register_map.get(&reg_name).expect("Unknown register");
            ResolvedInst::Restore @{ reg @}
        @}
        Inst::Perform(op_exp) => @{
            let action = resolve_op_exp(op_exp, labels, register_map);
            ResolvedInst::Perform @{ action @}
        @}
        Inst::Label(_) => panic!("Labels should have been filtered out"),
    @}
@}
@end example

@noindent
For each type of instruction in the register-machine language, there is a
generator that builds an appropriate execution procedure.  The details of these
procedures determine both the syntax and meaning of the individual instructions
in the register-machine language.  We use data abstraction to isolate the
detailed syntax of register-machine expressions from the general execution
mechanism, as we did for evaluators in @ref{4.1.2}, by using syntax
procedures to extract and classify the parts of an instruction.

@subsubheading @code{Assign} instructions

The @code{make_assign} procedure handles @code{assign} instructions:

@subsection Executing Instructions

The `execute` method of the machine runs the instruction sequence by calling `execute_instruction` on each instruction. This method dispatches on the type of instruction and performs the appropriate action.

@example
fn execute_instruction(&mut self, inst: ResolvedInst) @{
    match inst @{
        ResolvedInst::Assign @{ target_reg, value @} => @{
            let val = self.eval_value_exp(&value);
            self.registers[target_reg] = val;
            self.pc += 1;
        @}
        ResolvedInst::Test @{ condition @} => @{
            let result = self.eval_value_exp(&condition);
            self.flag = result.as_bool();
            self.pc += 1;
        @}
        ResolvedInst::Branch @{ destination @} => @{
            if self.flag @{
                self.pc = destination;
            @} else @{
                self.pc += 1;
            @}
        @}
        ResolvedInst::Goto @{ destination @} => match destination @{
            GotoDestResolved::Label(dest) => @{
                self.pc = dest;
            @}
            GotoDestResolved::Reg(reg) => @{
                if let Value::InstructionPointer(ip) = self.registers[reg] @{
                    self.pc = ip;
                @} else @{
                    panic!("Goto register must contain instruction pointer");
                @}
            @}
        @},
        ResolvedInst::Save @{ reg @} => @{
            let value = self.registers[reg].clone();
            self.stack.push(value);
            self.pc += 1;
        @}
        ResolvedInst::Restore @{ reg @} => @{
            let value = self.stack.pop();
            self.registers[reg] = value;
            self.pc += 1;
        @}
        ResolvedInst::Perform @{ action @} => @{
            self.eval_value_exp(&action);
            self.pc += 1;
        @}
    @}
@}
@end example

@subsubheading Evaluating value expressions

The `eval_value_exp` method computes the value of a source expression.

@example
fn eval_value_exp(&self, exp: &ResolvedVExp) -> Value @{
    match exp @{
        ResolvedVExp::Const(v) => v.clone(),
        ResolvedVExp::Reg(idx) => self.registers[*idx].clone(),
        ResolvedVExp::Label(ip) => Value::InstructionPointer(*ip),
        ResolvedVExp::Op(op_name, operands) => @{
            let args: Vec<Value> = operands.iter().map(|e| self.eval_value_exp(e)).collect();
            let op = self.operations.get(op_name).expect("Unknown operation");
            op(&args)
        @}
    @}
@}
@end example
@quotation
@strong{@anchor{Exercise 5.9}Exercise 5.9:} The treatment of machine operations
above permits them to operate on labels as well as on constants and the
contents of registers.  Modify the expression-processing procedures to enforce
the condition that operations can be used only with registers and constants.
@end quotation

@quotation
@strong{@anchor{Exercise 5.10}Exercise 5.10:} Design a new syntax for
register-machine instructions and modify the simulator to use your new syntax.
Can you implement your new syntax without changing any part of the simulator
except the syntax procedures in this section?
@end quotation

@quotation
@strong{@anchor{Exercise 5.11}Exercise 5.11:} When we introduced @code{save}
and @code{restore} in @ref{5.1.4}, we didn't specify what would happen
if you tried to restore a register that was not the last one saved, as in the
sequence

@lisp
(save y)
(save x)
(restore y)
@end lisp

There are several reasonable possibilities for the meaning of @code{restore}:

@enumerate a

@item
@code{(restore y)} puts into @code{y} the last value saved on the stack,
regardless of what register that value came from.  This is the way our
simulator behaves.  Show how to take advantage of this behavior to eliminate
one instruction from the Fibonacci machine of @ref{5.1.4} (@ref{Figure 5.12}).

@item
@code{(restore y)} puts into @code{y} the last value saved on the stack, but
only if that value was saved from @code{y}; otherwise, it signals an error.
Modify the simulator to behave this way.  You will have to change @code{save}
to put the register name on the stack along with the value.

@item
@code{(restore y)} puts into @code{y} the last value saved from @code{y}
regardless of what other registers were saved after @code{y} and not restored.
Modify the simulator to behave this way.  You will have to associate a separate
stack with each register.  You should make the @code{initialize_stack}
operation initialize all the register stacks.

@end enumerate
@end quotation

@quotation
@strong{@anchor{Exercise 5.12}Exercise 5.12:} The simulator can be used to help
determine the data paths required for implementing a machine with a given
controller.  Extend the assembler to store the following information in the
machine model:

@itemize

@item
a list of all instructions, with duplicates removed, sorted by instruction type
(@code{assign}, @code{goto}, and so on);

@item
a list (without duplicates) of the registers used to hold entry points (these
are the registers referenced by @code{goto} instructions);

@item
a list (without duplicates) of the registers that are @code{save}d
or @code{restore}d;

@item
for each register, a list (without duplicates) of the sources from which it is
assigned (for example, the sources for register @code{val} in the factorial
machine of @ref{Figure 5.11} are @code{VExp::Const(1)} and @code{VExp::Op(OpExp @{ op: "*", ... @})}).

@end itemize

Extend the message-passing interface to the machine to provide access to this
new information.  To test your analyzer, define the Fibonacci machine from
@ref{Figure 5.12} and examine the lists you constructed.
@end quotation

@quotation
@strong{@anchor{Exercise 5.13}Exercise 5.13:} Modify the simulator so that it
uses the controller sequence to determine what registers the machine has rather
than requiring a list of registers as an argument to @code{make_machine}.
Instead of pre-allocating the registers in @code{make_machine}, you can
allocate them one at a time when they are first seen during assembly of the
instructions.
@end quotation

@node	5.2.4, 5.2.5, 5.2.3, 5.2
@subsection Monitoring Machine Performance

Simulation is useful not only for verifying the correctness of a proposed
machine design but also for measuring the machine's performance.  For example,
we can install in our simulation program a ``meter'' that measures the number
of stack operations used in a computation.  To do this, we modify our simulated
stack to keep track of the number of times registers are saved on the stack and
the maximum depth reached by the stack, and add a message to the stack's
interface that prints the statistics, as shown below.  We also add an operation
to the basic machine model to print the stack statistics, by initializing
@code{the-ops} in @code{make_new_machine} to

@example
machine.operation("initialize_stack", |args| @{
    stack.initialize();
    Value::Ok
@});
machine.operation("print_stack_statistics", |args| @{
    stack.print_statistics();
    Value::Ok
@});
@end example

@noindent
Here is the new version of @code{make_stack}:

@lisp
@lisp
pub struct Stack @{
    data: Vec<Value>,
    pushes: usize,
    max_depth: usize,
@}

impl Stack @{
    pub fn new() -> Self @{
        Stack @{
            data: Vec::new(),
            pushes: 0,
            max_depth: 0,
        @}
    @}

    pub fn push(&mut self, value: Value) @{
        self.data.push(value);
        self.pushes += 1;
        if self.data.len() > self.max_depth @{
            self.max_depth = self.data.len();
        @}
    @}

    pub fn pop(&mut self) -> Value @{
        self.data.pop().expect("Empty stack: POP")
    @}

    pub fn initialize(&mut self) @{
        self.data.clear();
        self.pushes = 0;
        self.max_depth = 0;
    @}

    pub fn print_statistics(&self) @{
        println!("(total-pushes = @{@} maximum-depth = @{@})",
                 self.pushes, self.max_depth);
    @}
@}
@end lisp
@end lisp

@noindent
@ref{Exercise 5.15} through @ref{Exercise 5.19} describe other useful
monitoring and debugging features that can be added to the register-machine
simulator.

@quotation
@strong{@anchor{Exercise 5.14}Exercise 5.14:} Measure the number of pushes and
the maximum stack depth required to compute @math{{n!}} for various small values of
@math{n} using the factorial machine shown in @ref{Figure 5.11}.  From your data
determine formulas in terms of @math{n} for the total number of push operations
and the maximum stack depth used in computing @math{{n!}} for any @math{{n > 1}}. Note
that each of these is a linear function of @math{n} and is thus determined by two
constants.  In order to get the statistics printed, you will have to augment
the factorial machine with instructions to initialize the stack and print the
statistics.  You may want to also modify the machine so that it repeatedly
reads a value for @math{n}, computes the factorial, and prints the result (as we
did for the @abbr{GCD} machine in @ref{Figure 5.4}), so that you will not
have to repeatedly invoke @code{get_register_contents},
@code{set_register_contents}, and @code{start}.
@end quotation

@quotation
@strong{@anchor{Exercise 5.15}Exercise 5.15:} Add @newterm{instruction counting} 
to the register machine simulation.  That is, have the machine model
keep track of the number of instructions executed.  Extend the machine model's
interface to accept a new message that prints the value of the instruction
count and resets the count to zero.
@end quotation

@quotation
@strong{@anchor{Exercise 5.16}Exercise 5.16:} Augment the simulator to provide
for @newterm{instruction tracing}.  That is, before each instruction is
executed, the simulator should print the text of the instruction.  Make the
machine model accept @code{trace-on} and @code{trace-off} messages to turn
tracing on and off.
@end quotation

@quotation
@strong{@anchor{Exercise 5.17}Exercise 5.17:} Extend the instruction tracing of
@ref{Exercise 5.16} so that before printing an instruction, the simulator
prints any labels that immediately precede that instruction in the controller
sequence.  Be careful to do this in a way that does not interfere with
instruction counting (@ref{Exercise 5.15}).  You will have to make the
simulator retain the necessary label information.
@end quotation

@quotation
@strong{@anchor{Exercise 5.18}Exercise 5.18:} Modify the @code{make_register}
procedure of @ref{5.2.1} so that registers can be traced.  Registers
should accept messages that turn tracing on and off.  When a register is
traced, assigning a value to the register should print the name of the
register, the old contents of the register, and the new contents being
assigned.  Extend the interface to the machine model to permit you to turn
tracing on and off for designated machine registers.
@end quotation

@quotation
@strong{@anchor{Exercise 5.19}Exercise 5.19:} Alyssa P. Hacker wants a
@newterm{breakpoint} feature in the simulator to help her debug her machine
designs.  You have been hired to install this feature for her.  She wants to be
able to specify a place in the controller sequence where the simulator will
stop and allow her to examine the state of the machine.  You are to implement a
procedure

@lisp
(set-breakpoint ⟨@var{machine}⟩ ⟨@var{label}⟩ ⟨@var{n}⟩)
@end lisp

@noindent
that sets a breakpoint just before the @math{n^{\text{th}}} instruction after the given
label.  For example,

@lisp
(set-breakpoint gcd-machine 'test-b 4)
@end lisp

@noindent
installs a breakpoint in @code{gcd-machine} just before the assignment to
register @code{a}.  When the simulator reaches the breakpoint it should print
the label and the offset of the breakpoint and stop executing instructions.
Alyssa can then use @code{get_register_contents} and
@code{set_register_contents} to manipulate the state of the simulated machine.
She should then be able to continue execution by saying

@lisp
(proceed-machine ⟨@var{machine}⟩)
@end lisp

She should also be able to remove a specific breakpoint by means of

@lisp
(cancel-breakpoint ⟨@var{machine}⟩ ⟨@var{label}⟩ ⟨@var{n}⟩)
@end lisp

@noindent
or to remove all breakpoints by means of

@lisp
(cancel-all-breakpoints ⟨@var{machine}⟩)
@end lisp
@end quotation
@node 5.2.5, 5.3, 5.2.4, 5.2
@subsection WebAssembly 백엔드 (WebAssembly Backend)

@cindex WebAssembly
@cindex WASM
@cindex portable binary format
@cindex wasm32-unknown-unknown

우리의 레지스터 기계 탐구에서, 우리는 추상적인 계산 프로세스가 어떻게 구체적인 기계 구현으로 구현될 수 있는지 보았다.
WebAssembly (@abbr{WASM})는 Rust와 같은 고수준 프로그래밍 언어와 웹 브라우저에서 임베디드 시스템 및 서버리스 환경에 이르는 다양한 플랫폼의 저수준 실행 환경 사이의 매혹적인 다리를 나타낸다.

@cindex stack machine
WebAssembly는 고수준 언어를 위한 컴파일 대상으로 설계된 @newterm{이식 가능한 이진 명령어 형식(portable binary instruction format)}이다.
우리가 연구해 온 레지스터 기계와 달리, WebAssembly는 근본적으로 @newterm{스택 기계(stack machine)}이다: 그 명령어는 명명된 레지스터 대신 암시적 피연산자 스택에서 작동한다.
이 설계 선택은 명령어 인코딩과 검증을 단순화하면서도 현대적인 JIT(@abbr{JIT}) 컴파일 기술을 통해 효율적인 실행을 가능하게 한다.

우리의 레지스터 기계 개념과 WebAssembly의 스택 기계 모델 사이의 관계는 컴퓨터 아키텍처의 기본 원칙을 조명한다.
레지스터 기계 명령어가 ``레지스터 @code{r1}과 @code{r2}의 내용을 더해서 결과를 @code{r3}에 저장하라''라고 말할 수 있는 반면, 동등한 WebAssembly 명령어 시퀀스는 두 값을 피연산자 스택에 푸시한 다음 두 피연산자를 팝하고 결과를 푸시하는 @code{add} 명령어를 실행할 것이다.

@subsubheading Rust를 WebAssembly로 컴파일하기 (Compiling Rust to WebAssembly)

@cindex wasm32-unknown-unknown target
Rust의 WebAssembly 컴파일 대상 지원은 비용 없는 추상화와 플랫폼 독립성에 대한 언어의 헌신을 보여주는 전형적인 예이다.
@code{wasm32-unknown-unknown} 타겟은 특정 운영 체제나 런타임 환경을 가정하지 않고 WebAssembly 런타임이 있는 모든 환경에서 실행될 수 있는 @abbr{WASM} 바이너리를 생성한다.

Rust 프로그램을 WebAssembly로 컴파일하려면, 먼저 컴파일 타겟을 추가한다:

@example
$ rustup target add wasm32-unknown-unknown
@end example

@noindent
그런 다음 다음과 같이 컴파일할 수 있다:

@example
$ cargo build --target wasm32-unknown-unknown --release
@end example

@noindent
이것은 @file{target/wasm32-unknown-unknown/release/} 디렉토리에 @file{.wasm} 파일을 생성한다.
팩토리얼을 계산하는 이 간단한 Rust 함수를 고려해 보자:

@example
#[no_mangle]
pub extern "C" fn factorial(n: u32) -> u32 @{
    match n @{
        0 | 1 => 1,
        n => n * factorial(n - 1),
    @}
@}
@end example

@noindent
@code{#[no_mangle]} 속성은 Rust의 이름 맹글링(name mangling)을 방지하여 함수가 JavaScript나 다른 WebAssembly 호스트에서 호출될 수 있도록 보장한다.
@code{extern "C"}는 호출 규약을 지정하여 함수가 WebAssembly 외부 함수 인터페이스와 호환되도록 만든다.

@subsubheading wasm-bindgen과의 JavaScript 상호 운용성 (JavaScript Interoperability with wasm-bindgen)

@cindex wasm-bindgen
@cindex JavaScript interop
원시(raw) WebAssembly는 숫자 타입(@code{i32}, @code{i64}, @code{f32}, @code{f64})만 사용할 수 있지만, 실제 애플리케이션은 더 풍부한 데이터 교환을 필요로 한다.
@code{wasm-bindgen}은 복잡한 타입과 작업하는 데 필요한 JavaScript 및 Rust 글루 코드를 자동으로 생성하여 이 간극을 메운다.

먼저, @file{Cargo.toml}에 종속성을 추가한다:

@example
[dependencies]
wasm-bindgen = "0.2"

[lib]
crate-type = ["cdylib"]
@end example

@noindent
이제 더 정교한 함수를 작성할 수 있다:

@example
use wasm_bindgen::prelude::*;

#[wasm_bindgen]
pub fn greet(name: &str) -> String @{
    format!("Hello, @{@}!", name)
@}

#[wasm_bindgen]
pub struct Calculator @{
    accumulator: f64,
@}

#[wasm_bindgen]
impl Calculator @{
    #[wasm_bindgen(constructor)]
    pub fn new() -> Calculator @{
        Calculator @{ accumulator: 0.0 @}
    @}

    pub fn add(&mut self, value: f64) -> f64 @{
        self.accumulator += value;
        self.accumulator
    @}

    pub fn get_value(&self) -> f64 @{
        self.accumulator
    @}
@}
@end example

@noindent
@code{wasm_bindgen} 매크로는 자동으로 JavaScript 바인딩을 생성하여, 이러한 함수와 타입을 JavaScript에서 자연스럽게 사용할 수 있게 한다:

@example
@group
import init, @{ greet, Calculator @} from './my_wasm_module.js';

await init();

console.log(greet("WebAssembly"));  // "Hello, WebAssembly!"

const calc = new Calculator();
calc.add(10);
calc.add(32);
console.log(calc.get_value());  // 42
@end group
@end example

@subsubheading wasm-pack 개발 워크플로우 (The wasm-pack Development Workflow)

@cindex wasm-pack
@code{wasm-pack}은 Rust로 생성된 WebAssembly를 생성, 빌드, 패키징하는 전체 워크플로우를 처리하는 포괄적인 빌드 도구를 제공한다:

@example
$ cargo install wasm-pack
$ wasm-pack build --target web
@end example

@noindent
이 명령은:

@enumerate
@item
Rust 코드를 WebAssembly로 컴파일한다
@item
TypeScript 타입 정의를 생성한다
@item
JavaScript 래퍼 모듈을 생성한다
@item
@file{.wasm} 바이너리를 최적화한다
@item
npm 호환 패키지를 생성한다
@end enumerate

@noindent
@code{--target} 플래그는 여러 출력 형식을 지원한다:

@itemize @bullet
@item @code{web} — 브라우저 직접 사용을 위한 ES 모듈
@item @code{bundler} — webpack, Rollup, 또는 Parcel용
@item @code{nodejs} — Node.js 환경용
@item @code{no-modules} — 전통적인 스크립트 태그
@end itemize

@subsubheading WebAssembly 시스템 인터페이스 (WASI) (WebAssembly System Interface (WASI))

@cindex WASI
@cindex WebAssembly System Interface
브라우저의 WebAssembly는 샌드박스화되어 있고 보안에 중점을 두지만, 서버 측 및 임베디드 애플리케이션은 파일, 네트워크 소켓, 환경 변수, 난수 생성과 같은 시스템 리소스에 대한 접근이 필요하다.
@newterm{WebAssembly 시스템 인터페이스(WebAssembly System Interface)} (@abbr{WASI})는 시스템 접근에 대한 표준화된, 기능 기반(capability-based) 접근 방식을 제공한다.

@cindex wasm32-wasi target
@code{wasm32-wasi} 타겟을 사용하여, 우리는 운영 체제와 상호 작용하는 Rust 프로그램을 컴파일할 수 있다:

@example
$ rustup target add wasm32-wasi
$ cargo build --target wasm32-wasi
@end example

@noindent
표준 입력에서 읽고 표준 출력으로 쓰는 프로그램을 고려해 보자:

@example
use std::io::@{self, BufRead, Write@};

fn main() -> io::Result<()> @{
    let stdin = io::stdin();
    let mut stdout = io::stdout();

    for line in stdin.lock().lines() @{
        let line = line?;
        writeln!(stdout, "Echo: @{@}", line)?;
    @}

    Ok(())
@}
@end example

@noindent
이 프로그램은 @abbr{WASI} WebAssembly로 컴파일되며 Wasmtime이나 Wasmer와 같은 런타임으로 실행할 수 있다:

@example
$ wasmtime target/wasm32-wasi/release/echo.wasm
@end example

@noindent
이 프로그램은 런타임의 기능 모델에 의해 정의된 보안 제약 내에서 @abbr{I/O}에 대한 완전한 접근 권한을 갖는다.

@subsubheading WebAssembly 메모리 모델 (WebAssembly Memory Model)

@cindex linear memory
@cindex memory model
WebAssembly의 메모리 모델을 이해하면 레지스터 기계에서의 메모리 관리에 대한 우리의 이전 논의(@ref{5.3})와의 연결이 명확해진다.
WebAssembly는 @newterm{선형 메모리(linear memory)}—동적으로 커질 수 있지만 단일 인스턴스 내에서는 결코 줄어들지 않는 연속적이고 바이트 주소 지정 가능한 배열—를 제공한다.

가비지 컬렉션 환경과 달리, WebAssembly에는 내장된 메모리 관리가 없다. 메모리 할당과 해제는 컴파일된 코드에 의해 명시적으로 처리되어야 한다.
Rust가 WebAssembly로 컴파일될 때, 자체 할당자 구현(일반적으로 @code{wee_alloc} 또는 @code{dlmalloc})을 포함하여, Rust의 소유권 시스템을 위한 메모리 관리 기반을 제공한다.

선형 메모리는 JavaScript에 노출되어 효율적인 데이터 공유를 가능하게 한다:

@example
#[wasm_bindgen]
pub fn sum_array(data: &[f64]) -> f64 @{
    data.iter().sum()
@}
@end example

@noindent
JavaScript에서 타입 배열(typed array)로 호출될 때, @code{wasm-bindgen}은 데이터를 WebAssembly의 선형 메모리로 복사하고, 처리한 다음, 결과를 반환한다—모두 최소한의 오버헤드로 수행된다.

@subsubheading 크기 최적화 (Size Optimization)

@cindex code size optimization
@cindex wasm-opt
WebAssembly의 과제 중 하나는, 특히 웹 배포의 경우, 코드 크기이다.
네트워크를 통해 코드를 다운로드할 때 모든 바이트가 중요하다.
Rust는 WebAssembly 바이너리 크기를 줄이기 위한 여러 메커니즘을 제공한다:

@strong{Cargo 프로필 최적화:}

@example
[profile.release]
opt-level = "z"      # 크기에 대해 최적화
lto = true           # 링크 시간 최적화 활성화
codegen-units = 1    # 더 나은 최적화를 위해 병렬성 감소
strip = true         # 디버그 심볼 제거
@end example

@noindent
@strong{@code{wasm-opt} 사용하기:}

Binaryen 툴킷의 @code{wasm-opt} 도구는 WebAssembly 전용 최적화를 수행한다:

@example
$ wasm-opt -Oz -o optimized.wasm original.wasm
@end example

@noindent
@code{-Oz} 플래그는 크기에 대해 공격적으로 최적화하며, 종종 컴파일러 단독으로 달성하는 것보다 바이너리 크기를 20-30% 더 줄인다.

@strong{패닉 인프라 제거하기:}

@example
#[cfg(target_arch = "wasm32")]
#[panic_handler]
fn panic(_info: &core::panic::PanicInfo) -> ! @{
    core::arch::wasm32::unreachable()
@}
@end example

@noindent
프로덕션에서 패닉이 절대 발생해서는 안 되는 애플리케이션의 경우, 이것은 패닉 포맷팅 및 언와인딩 장치를 제거하여 상당한 공간을 절약한다.

@subsubheading 성능 특성 (Performance Characteristics)

@cindex WASM performance
WebAssembly의 성능 특성은 AOT(Ahead-of-Time) 및 JIT(Just-in-Time) 컴파일을 위한 타겟으로서의 설계를 반영한다:

@itemize @bullet
@item
@strong{네이티브에 가까운 속도:} 현대 @abbr{JIT} 컴파일러는 계산 집약적 작업 부하에 대해 네이티브 성능의 80-95%를 달성한다
@item
@strong{예측 가능한 성능:} JavaScript와 달리, @abbr{WASM} 코드는 최적화 해제(deoptimization)나 타입 불안정성으로 고통받지 않는다
@item
@strong{빠른 인스턴스화:} 스트리밍 컴파일은 전체 모듈이 다운로드되기 전에 코드 실행을 가능하게 한다
@item
@strong{효율적인 메모리 접근:} 경계 검사가 수행되지만 중복 검사를 제거하도록 최적화 가능
@end itemize

@noindent
스택 기계 아키텍처는 겉보기에 레지스터 기계보다 덜 효율적인 것처럼 보이지만, 표준 컴파일러 최적화 기술을 통해 효율적인 네이티브 코드로 컴파일된다.
스택 기계의 추상화는 성능을 유지하면서 검증을 단순화하고 구현 유연성을 제공한다.

@subsubheading WebAssembly와 레지스터 기계 (WebAssembly and Register Machines)

WebAssembly의 스택 기계와 우리의 레지스터 기계 사이의 대조는 추상 기계의 설계 공간에서 서로 다른 지점을 예시한다. 스택 기계는 다음을 제공한다:

@itemize @bullet
@item
@strong{압축된 인코딩:} 레지스터 피연산자를 지정할 필요가 없음
@item
@strong{간단한 검증:} 스택 깊이를 정적으로 결정할 수 있음
@item
@strong{구현 유연성:} @abbr{JIT} 컴파일러가 자유롭게 레지스터에 매핑할 수 있음
@end itemize

@noindent
레지스터 기계는 다음을 제공한다:

@itemize @bullet
@item
@strong{직접적인 하드웨어 매핑:} 물리적 프로세서 아키텍처에 더 가까움
@item
@strong{명시적 데이터 흐름:} 레지스터 이름이 의존성을 명확하게 함
@item
@strong{최적화 기회:} 명시적 단계로서의 레지스터 할당
@end itemize

@noindent
현대 WebAssembly 구현은 스택 연산을 레지스터 기반 네이티브 코드로 컴파일하며, 이는 추상 기계의 선택이 구현 전략을 제약하지 않음을 보여준다.
스택 기계는 (텍스트 형식에서) 사람이 읽을 수 있고 (바이너리 형식에서) 기계 효율적인 중간 표현의 역할을 한다.

@quotation
@strong{@anchor{Exercise 5.20a}연습문제 5.20a:} @math{n}번째 피보나치 수를 계산하는 Rust 함수를 작성하고 WebAssembly로 컴파일하라.
JavaScript에서 이 함수를 호출하고 결과를 표시하는 @abbr{HTML} 페이지를 만들어라.
@code{fibonacci(40)}을 계산하는 데 있어 Rust/WebAssembly 구현과 순수 JavaScript 구현의 실행 시간을 측정하고 비교하라.
관찰된 성능 차이의 원인은 무엇인가?
@end quotation

@quotation
@strong{@anchor{Exercise 5.21a}연습문제 5.21a:} WebAssembly 명령어의 하위 집합(@code{i32.const}, @code{i32.add}, @code{i32.mul}, @code{local.get}, @code{local.set})을 실행할 수 있는 간단한 스택 기계 시뮬레이터를 Rust로 구현하라.
시뮬레이터를 WebAssembly로 컴파일하여 ``Rust로 작성되고 WebAssembly로 컴파일된 WebAssembly 인터프리터''를 만들어라.
@code{wasm-bindgen}을 사용하여 시뮬레이터의 @code{execute} 함수를 JavaScript에 노출시켜, WebAssembly 명령어 시퀀스를 공급하고 결과를 관찰할 수 있게 하라.
이 연습문제는 추상화의 본질과 인터프리터와 그들이 해석하는 언어 사이의 관계에 대해 무엇을 드러내는가?
@end quotation


@node	5.3, 5.4, 5.2.5, Chapter 5
@section 저장소 할당과 가비지 컬렉션 (Storage Allocation and Garbage Collection)

@ref{5.4}에서 우리는 레지스터 기계로서 Scheme 평가자를 구현하는 방법을 보여줄 것이다.
논의를 단순화하기 위해, 우리는 레지스터 기계가 리스트 구조 데이터를 조작하는 기본 연산들이 원시(primitive)인 @newterm{리스트 구조 메모리(list-structured memory)}를 갖출 수 있다고 가정할 것이다.
그러한 메모리의 존재를 가정하는 것은 Scheme 인터프리터의 제어 메커니즘에 집중할 때 유용한 추상화이지만, 이는 현대 컴퓨터의 실제 원시 데이터 연산에 대한 현실적인 관점을 반영하지 않는다.
언어 구현이 어떻게 작동하는지에 대한 더 완전한 그림을 얻으려면, 우리는 기존 컴퓨터 메모리와 호환되는 방식으로 리스트 구조가 어떻게 표현될 수 있는지 조사해야 한다.

리스트 구조를 구현할 때 고려해야 할 두 가지 사항이 있다.
첫 번째는 순전히 표현의 문제이다: 전형적인 컴퓨터 메모리의 저장 및 주소 지정 기능만을 사용하여 쌍(pair)의 ``상자와 포인터(box-and-pointer)'' 구조를 어떻게 표현할 것인가.
두 번째 문제는 계산이 진행됨에 따른 메모리 관리와 관련이 있다.
동적 언어의 작동은 새로운 데이터 객체를 지속적으로 생성하는 능력에 결정적으로 의존한다.
여기에는 해석되는 프로시저에 의해 명시적으로 생성된 객체뿐만 아니라 환경 및 인자 리스트와 같이 인터프리터 자체에 의해 생성된 구조도 포함된다.
무한한 양의 빠르게 주소 지정 가능한 메모리가 있는 컴퓨터에서는 새로운 데이터 객체의 지속적인 생성이 문제가 되지 않겠지만, 컴퓨터 메모리는 유한한 크기로만 사용할 수 있다(안타깝게도).
따라서 동적 시스템은 무한한 메모리의 환상을 지원하기 위해 @newterm{자동 저장소 할당(automatic storage allocation)} 기능을 제공한다.
데이터 객체가 더 이상 필요하지 않을 때, 할당된 메모리는 자동으로 재활용되어 새로운 데이터 객체를 구성하는 데 사용된다.
그러한 자동 저장소 할당을 제공하기 위한 다양한 기술이 있다.
이 절에서 논의할 방법은 @newterm{가비지 컬렉션(garbage collection)}이라고 한다.
@menu
* 5.3.1::            Memory as Vectors
* 5.3.2::            Maintaining the Illusion of Infinite Memory
* 5.3.3::            Ownership as Compile-Time Garbage Collection
@end menu

@node	5.3.1, 5.3.2, 5.3, 5.3
@subsection 벡터로서의 메모리 (Memory as Vectors)

전통적인 컴퓨터 메모리는 각각 정보 조각을 포함할 수 있는 칸(cubbyholes)의 배열로 생각할 수 있다.
각 칸에는 @newterm{주소(address)} 또는 @newterm{위치(location)}라고 불리는 고유한 이름이 있다.
전형적인 메모리 시스템은 두 가지 원시 연산을 제공한다: 지정된 위치에 저장된 데이터를 가져오는 것과 지정된 위치에 새로운 데이터를 할당하는 것.
메모리 주소는 일련의 칸들에 대한 순차적 접근을 지원하기 위해 증가될 수 있다.
더 일반적으로, 많은 중요한 데이터 연산은 메모리 주소가 데이터로 취급되어 메모리 위치에 저장되고 기계 레지스터에서 조작될 것을 요구한다.
리스트 구조의 표현은 그러한 @newterm{주소 산술(address arithmetic)}의 한 가지 응용이다.

컴퓨터 메모리를 모델링하기 위해, 우리는 @newterm{벡터(vector)}라는 새로운 종류의 데이터 구조를 사용한다.
추상적으로, 벡터는 정수 인덱스를 통해 개별 요소에 접근할 수 있는 복합 데이터 객체이며, 접근 시간은 인덱스와 무관하다.@footnote{우리는 메모리를 항목들의 리스트로 표현할 수도 있다. 그러나 이 경우 접근 시간은 인덱스와 무관하지 않으며, 리스트의 @math{n}번째 요소에 접근하려면 @math{{n - 1}}번의 @code{cdr} 연산이 필요하다.}
메모리 연산을 설명하기 위해, 우리는 벡터를 조작하는 데 표준 Rust와 유사한 인덱싱을 사용한다:

@itemize @bullet

@item
@code{v[n]}은 벡터 @code{v}의 @math{n}번째 요소를 반환한다.

@item
@code{v[n] = value} sets the @math{n^{\text{th}}} element of the vector @code{v} to the designated value.

@end itemize

@noindent
For example, if @code{v} is a vector, then @code{v[5]} gets the
fifth entry in the vector @code{v} and @code{v[5] = 7} changes the
value of the fifth entry of the vector @code{v} to 7.@footnote{For
completeness, we should specify a @code{make-vector} operation that constructs
vectors.  However, in the present application we will use vectors only to model
fixed divisions of the computer memory.}  For computer memory, this access can
be implemented through the use of address arithmetic to combine a @newterm{base address} 
that specifies the beginning location of a vector in memory with an
@newterm{index} that specifies the offset of a particular element of the
vector.

@subsubheading Representing Lisp data

We can use vectors to implement the basic pair structures required for a
list-structured memory.  Let us imagine that computer memory is divided into
two vectors: @code{the-cars} and @code{the-cdrs}.  We will represent list
structure as follows: A pointer to a pair is an index into the two vectors.
The @code{car} of the pair is the entry in @code{the-cars} with the designated
index, and the @code{cdr} of the pair is the entry in @code{the-cdrs} with the
designated index.  We also need a representation for objects other than pairs
(such as numbers and symbols) and a way to distinguish one kind of data from
another.  There are many methods of accomplishing this, but they all reduce to
using @newterm{typed pointers}, that is, to extending the notion of ``pointer''
to include information on data type.@footnote{This is precisely the same
``tagged data'' idea we introduced in @ref{Chapter 2} for dealing with generic
operations.  Here, however, the data types are included at the primitive
machine level rather than constructed through the use of lists.} The data type
enables the system to distinguish a pointer to a pair (which consists of the
``pair'' data type and an index into the memory vectors) from pointers to other
kinds of data (which consist of some other data type and whatever is being used
to represent data of that type).  Two data objects are considered to be the
same (@code{eq?}) if their pointers are identical.@footnote{Type information
may be encoded in a variety of ways, depending on the details of the machine on
which the Lisp system is to be implemented.  The execution efficiency of Lisp
programs will be strongly dependent on how cleverly this choice is made, but it
is difficult to formulate general design rules for good choices.  The most
straightforward way to implement typed pointers is to allocate a fixed set of
bits in each pointer to be a @newterm{type field} that encodes the data type.
Important questions to be addressed in designing such a representation include
the following: How many type bits are required?  How large must the vector
indices be?  How efficiently can the primitive machine instructions be used to
manipulate the type fields of pointers?  Machines that include special hardware
for the efficient handling of type fields are said to have @newterm{tagged architectures}.} 
@ref{Figure 5.14} illustrates the use of this method to
represent the list @code{((1 2) 3 4)}, whose box-and-pointer diagram is also
shown.  We use letter prefixes to denote the data-type information.  Thus, a
pointer to the pair with index 5 is denoted @code{p5}, the empty list is
denoted by the pointer @code{e0}, and a pointer to the number 4 is denoted
@code{n4}.  In the box-and-pointer diagram, we have indicated at the lower left
of each pair the vector index that specifies where the @code{car} and
@code{cdr} of the pair are stored.  The blank locations in @code{the-cars} and
@code{the-cdrs} may contain parts of other list structures (not of interest
here).

@float
@anchor{Figure 5.14}
@ifinfo
@strong{Figure 5.14:} Box-and-pointer and memory-vector representations of the list @code{((1 2) 3 4)}.

@example
               +---+---+               +---+---+    +---+---+
((1 2) 3 4) -->| * | *-+-------------->| * | *-+--->| * | / |
               +-|-+---+               +-|-+---+    +-|-+---+
              1  |                    2  |         4  |
                 V                       V            V
               +---+---+    +---+---+  +---+        +---+
               | * | *-+--->| * | / |  | 3 |        | 4 |
               +-|-+---+    +-|-+---+  +---+        +---+
              5  |         7  |
                 V            V
               +---+        +---+
               | 1 |        | 2 |
               +---+        +---+

   Index   0    1    2    3    4    5    6    7    8    ...
         +----+----+----+----+----+----+----+----+----+----
the-cars |    | p5 | n3 |    | n4 | n1 |    | n2 |    | ...
         +----+----+----+----+----+----+----+----+----+----
the-cdrs |    | p2 | p4 |    | e0 | p7 |    | e0 |    | ...
         +----+----+----+----+----+----+----+----+----+----
@end example
@end ifinfo
@iftex
@image{fig/chap5/Fig5.14b,137mm,,,.std.svg}
@caption{@strong{Figure 5.14:} Box-and-pointer and memory-vector representations of the list @code{((1 2) 3 4)}.}
@end iftex
@end float

@noindent
A pointer to a number, such as @code{n4}, might consist of a type indicating
numeric data together with the actual representation of the number
4.@footnote{This decision on the representation of numbers determines whether
@code{eq?}, which tests equality of pointers, can be used to test for equality
of numbers.  If the pointer contains the number itself, then equal numbers will
have the same pointer.  But if the pointer contains the index of a location
where the number is stored, equal numbers will be guaranteed to have equal
pointers only if we are careful never to store the same number in more than one
location.}  To deal with numbers that are too large to be represented in the
fixed amount of space allocated for a single pointer, we could use a distinct
@newterm{bignum} data type, for which the pointer designates a list in which

@noindent
@b{Rust (memory structure):}
@example
pub struct Memory @{
    pub the_cars: Vec<Value>,
    pub the_cdrs: Vec<Value>,
    pub free: usize,
    capacity: usize,
@}

impl Memory @{
    pub fn new(capacity: usize) -> Self @{
        Memory @{
            the_cars: vec![Value::Nil; capacity],
            the_cdrs: vec![Value::Nil; capacity],
            free: 0,
            capacity,
        @}
    @}
@}
@end example

the parts of the number are stored.@footnote{This is just like writing a number
as a sequence of digits, except that each ``digit'' is a number between 0 and
the largest number that can be stored in a single pointer.}

A symbol might be represented as a typed pointer that designates a sequence of
the characters that form the symbol's printed representation.  This sequence is
constructed by the Lisp reader when the character string is initially
encountered in input.  Since we want two instances of a symbol to be recognized
as the ``same'' symbol by @code{eq?} and we want @code{eq?} to be a simple test
for equality of pointers, we must ensure that if the reader sees the same
character string twice, it will use the same pointer (to the same sequence of
characters) to represent both occurrences.  To accomplish this, the reader
maintains a table, traditionally called the @newterm{obarray}, of all the
symbols it has ever encountered.  When the reader encounters a character string
and is about to construct a symbol, it checks the obarray to see if it has ever
before seen the same character string.  If it has not, it uses the characters
to construct a new symbol (a typed pointer to a new character sequence) and
enters this pointer in the obarray.  If the reader has seen the string before,
it returns the symbol pointer stored in the obarray.  This process of replacing
character strings by unique pointers is called @newterm{interning} symbols.

@subsubheading Implementing the primitive list operations

Given the above representation scheme, we can replace each ``primitive'' list
operation of a register machine with one or more primitive vector operations.
We will use two registers, @code{the-cars} and @code{the-cdrs}, to identify the
memory vectors, and will assume that @code{vector-ref} and @code{vector-set!}
are available as primitive operations.  We also assume that numeric operations
on pointers (such as incrementing a pointer, using a pair pointer to index a
vector, or adding two numbers) use only the index portion of the typed pointer.

For example, we can make a register machine support the instructions

@lisp
(assign ⟨@var{reg₁}⟩ (op car) (reg ⟨@var{reg₂}⟩))
(assign ⟨@var{reg₁}⟩ (op cdr) (reg ⟨@var{reg₂}⟩))
@end lisp

@noindent
if we implement these, respectively, as

@lisp
(assign ⟨@var{reg₁}⟩ 
        (op vector-ref)
        (reg the-cars)
        (reg ⟨@var{reg₂}⟩))
(assign ⟨@var{reg₁}⟩
        (op vector-ref)
        (reg the-cdrs)
        (reg ⟨@var{reg₂}⟩))
@end lisp

@noindent
The instructions

@lisp
(perform (op set_car) (reg ⟨@var{reg₁}⟩) (reg ⟨@var{reg₂}⟩))
(perform (op set_cdr) (reg ⟨@var{reg₁}⟩) (reg ⟨@var{reg₂}⟩))
@end lisp

@noindent
are implemented as

@lisp
(perform (op vector-set!)
         (reg the-cars)
         (reg ⟨@var{reg₁}⟩)
         (reg ⟨@var{reg₂}⟩))
(perform (op vector-set!)
         (reg the-cdrs)
         (reg ⟨@var{reg₁}⟩)
         (reg ⟨@var{reg₂}⟩))
@end lisp

@noindent
@code{Cons} is performed by allocating an unused index and storing the
arguments to @code{cons} in @code{the-cars} and @code{the-cdrs} at that indexed
vector position.  We presume that there is a special register, @code{free},
that always holds a pair pointer containing the next available index, and that
we can increment the index part of that pointer to find the next free
location.@footnote{There are other ways of finding free storage.  For example,
we could link together all the unused pairs into a @newterm{free list}.  Our
free locations are consecutive (and hence can be accessed by incrementing a
pointer) because we are using a compacting garbage collector, as we will see in
@ref{5.3.2}.}  For example, the instruction

@lisp
(assign ⟨@var{reg₁}⟩
        (op cons)
        (reg ⟨@var{reg₂}⟩)
        (reg ⟨@var{reg₃}⟩))
@end lisp

@noindent
is implemented as the following sequence of vector operations:@footnote{This is
essentially the implementation of @code{cons} in terms of @code{set_car} (or similar mutator) and
@code{set_cdr} (or similar mutator), as described in @ref{3.3.1}.  The operation
@code{get-new-pair} used in that implementation is realized here by the
@code{free} pointer.}

@lisp
(perform (op vector-set!)
         (reg the-cars)
         (reg free)
         (reg ⟨@var{reg₂}⟩))
(perform (op vector-set!)
         (reg the-cdrs)
         (reg free)
         (reg ⟨@var{reg₃}⟩))
(assign ⟨@var{reg₁}⟩ (reg free))
(assign free (op +) (reg free) (const 1))
@end lisp

@noindent
The @code{eq?} operation

@lisp
(op eq?) (reg ⟨@var{reg₁}⟩) (reg ⟨@var{reg₂}⟩)
@end lisp

@noindent
simply tests the equality of all fields in the registers, and predicates such
as @code{pair?}, @code{null?}, @code{symbol?}, and @code{number?} need only
check the type field.

@subsubheading Implementing stacks

Although our register machines use stacks, we need do nothing special here,
since stacks can be modeled in terms of lists.  The stack can be a list of the
saved values, pointed to by a special register @code{the-stack}.  Thus, 
@code{(save ⟨@var{reg}⟩)} can be implemented as

@lisp
(assign the-stack 
        (op cons)
        (reg ⟨@var{reg}⟩)
        (reg the-stack))
@end lisp

@noindent
Similarly, @code{(restore ⟨@var{reg}⟩)} can be implemented as

@lisp
(assign ⟨@var{reg}⟩ (op car) (reg the-stack))
(assign the-stack (op cdr) (reg the-stack))
@end lisp

@noindent
and @code{(perform (op initialize_stack))} can be implemented as


@noindent
@b{Rust (car/cdr operations):}
@example
pub fn car(&self, pair: &Value) -> Result<&Value, &'static str> @{
    match pair @{
        Value::Pair(index) => Ok(&self.the_cars[*index]),
        _ => Err("Not a pair"),
    @}
@}

pub fn cdr(&self, pair: &Value) -> Result<&Value, &'static str> @{
    match pair @{
        Value::Pair(index) => Ok(&self.the_cdrs[*index]),
        _ => Err("Not a pair"),
    @}
@}
@end example

@lisp
(assign the-stack (const ()))
@end lisp

@noindent
These operations can be further expanded in terms of the vector operations
given above.  In conventional computer architectures, however, it is usually
advantageous to allocate the stack as a separate vector.  Then pushing and
popping the stack can be accomplished by incrementing or decrementing an index
into that vector.

@quotation
@strong{@anchor{Exercise 5.20}Exercise 5.20:} Draw the box-and-pointer
representation and the memory-vector representation (as in @ref{Figure 5.14})
of the list structure produced by

@example
let x = cons(1, 2);
let y = list(x.clone(), x.clone());
@end example

@noindent
with the @code{free} pointer initially @code{p1}.  What is the final value of
@code{free}?  What pointers represent the values of @code{x} and @code{y}?
@end quotation

@quotation
@strong{@anchor{Exercise 5.21}Exercise 5.21:} Implement register machines for
the following procedures.  Assume that the list-structure memory operations are
available as machine primitives.

@enumerate a

@item
Recursive @code{count-leaves}:

@example
fn count_leaves(tree: &Value) -> i64 @{
    match tree @{
        Value::Nil => 0,
        Value::Pair(car, cdr) => @{
            count_leaves(car) + count_leaves(cdr)
        @}
        _ => 1,
    @}
@}
@end example

@item
Recursive @code{count-leaves} with explicit counter:

@example
fn count_leaves(tree: &Value) -> i64 @{
    fn count_iter(tree: &Value, n: i64) -> i64 @{
        match tree @{
            Value::Nil => n,
            Value::Pair(car, cdr) => @{
                count_iter(cdr, count_iter(car, n))
            @}
            _ => n + 1,
        @}
    @}
    count_iter(tree, 0)
@}
@end example
@end enumerate
@end quotation

@quotation
@strong{@anchor{Exercise 5.22}Exercise 5.22:} @ref{Exercise 3.12} of 
@ref{3.3.1} presented an @code{append} procedure that appends two lists to form
a new list and an @code{append!} procedure that splices two lists together.
Design a register machine to implement each of these procedures.  Assume that
the list-structure memory operations are available as primitive operations.
@end quotation

@node	5.3.2, 5.3.3, 5.3.1, 5.3
@subsection Maintaining the Illusion of Infinite Memory

The representation method outlined in @ref{5.3.1} solves the problem of
implementing list structure, provided that we have an infinite amount of
memory.  With a real computer we will eventually run out of free space in which
to construct new pairs.@footnote{This may not be true eventually, because
memories may get large enough so that it would be impossible to run out of free
memory in the lifetime of the computer.  For example, there are about
@math{{3\cdot10^{13}}} microseconds in a year, so if we were to @code{cons} once per
microsecond we would need about @math{10^{15}} cells of memory to build a machine that
could operate for 30 years without running out of memory.  That much memory
seems absurdly large by today's standards, but it is not physically impossible.
On the other hand, processors are getting faster and a future computer may have
large numbers of processors operating in parallel on a single memory, so it may
be possible to use up memory much faster than we have postulated.}  However,
most of the pairs generated in a typical computation are used only to hold
intermediate results.  After these results are accessed, the pairs are no
longer needed---they are @newterm{garbage}.  For instance, the computation

@example
(0..=n)
    .filter(|&x| x % 2 != 0)
    .sum::<i64>()
@end example

@noindent
constructs two iterators: the enumeration and the result of filtering the
enumeration.  When the accumulation is complete, these objects are no longer
needed, and any memory allocated by them can be reclaimed.  If we can arrange to
collect all the garbage periodically, and if this turns out to recycle memory
at about the same rate at which we construct new pairs, we will have preserved
the illusion that there is an infinite amount of memory.

In order to recycle pairs, we must have a way to determine which allocated
pairs are not needed (in the sense that their contents can no longer influence
the future of the computation).  The method we shall examine for accomplishing
this is known as @newterm{garbage collection}.  Garbage collection is based on
the observation that, at any moment in a Lisp interpretation, the only objects
that can affect the future of the computation are those that can be reached by
some succession of @code{car} and @code{cdr} operations starting from the
pointers that are currently in the machine registers.@footnote{We assume here
that the stack is represented as a list as described in @ref{5.3.1}, so
that items on the stack are accessible via the pointer in the stack register.}
Any memory cell that is not so accessible may be recycled.

There are many ways to perform garbage collection.  The method we shall examine
here is called @newterm{stop-and-copy}.  The basic idea is to divide memory
into two halves: ``working memory'' and ``free memory.''  When @code{cons}
constructs pairs, it allocates these in working memory.  When working memory is
full, we perform garbage collection by locating all the useful pairs in working
memory and copying these into consecutive locations in free memory.  (The
useful pairs are located by tracing all the @code{car} and @code{cdr} pointers,
starting with the machine registers.)  Since we do not copy the garbage, there
will presumably be additional free memory that we can use to allocate new
pairs.  In addition, nothing in the working memory is needed, since all the
useful pairs in it have been copied.  Thus, if we interchange the roles of
working memory and free memory, we can continue processing; new pairs will be
allocated in the new working memory (which was the old free memory).  When this
is full, we can copy the useful pairs into the new free memory (which was the
old working memory).@footnote{This idea was invented and first implemented by
Minsky, as part of the implementation of Lisp for the PDP-1 at the
@abbr{MIT} Research Laboratory of Electronics.  It was further developed by
@ref{Fenichel and Yochelson (1969)} for use in the Lisp implementation for the
Multics time-sharing system.  Later, @ref{Baker (1978)} developed a ``real-time''
version of the method, which does not require the computation to stop during
garbage collection.  Baker's idea was extended by Hewitt, Lieberman, and Moon
(see @ref{Lieberman and Hewitt 1983}) to take advantage of the fact that some
structure is more volatile and other structure is more permanent.

An alternative commonly used garbage-collection technique is the
@newterm{mark-sweep} method.  This consists of tracing all the structure
accessible from the machine registers and marking each pair we reach.  We then
scan all of memory, and any location that is unmarked is ``swept up'' as
garbage and made available for reuse.  A full discussion of the mark-sweep
method can be found in @ref{Allen 1978}.

The Minsky-Fenichel-Yochelson algorithm is the dominant algorithm in use for
large-memory systems because it examines only the useful part of memory.  This
is in contrast to mark-sweep, in which the sweep phase must check all of
memory.  A second advantage of stop-and-copy is that it is a
@newterm{compacting} garbage collector.  That is, at the end of the
garbage-collection phase the useful data will have been moved to consecutive
memory locations, with all garbage pairs compressed out.  This can be an
extremely important performance consideration in machines with virtual memory,
in which accesses to widely separated memory addresses may require extra paging
operations.}

@subsubheading Implementation of a stop-and-copy garbage collector

We now use our register-machine language to describe the stop-and-copy
algorithm in more detail.  We will assume that there is a register called
@code{root} that contains a pointer to a structure that eventually points at
all accessible data.  This can be arranged by storing the contents of all the
machine registers in a pre-allocated list pointed at by @code{root} just before
starting garbage collection.@footnote{This list of registers does not include
the registers used by the storage-allocation system---@code{root},
@code{the-cars}, @code{the-cdrs}, and the other registers that will be
introduced in this section.} We also assume that, in addition to the current
working memory, there is free memory available into which we can copy the
useful data.  The current working memory consists of vectors whose base
addresses are in registers called @code{the-cars} and @code{the-cdrs}, and the
free memory is in registers called @code{new-cars} and @code{new-cdrs}.

Garbage collection is triggered when we exhaust the free cells in the current
working memory, that is, when a @code{cons} operation attempts to increment the
@code{free} pointer beyond the end of the memory vector.  When the
garbage-collection process is complete, the @code{root} pointer will point into
the new memory, all objects accessible from the @code{root} will have been
moved to the new memory, and the @code{free} pointer will indicate the next
place in the new memory where a new pair can be allocated.  In addition, the
roles of working memory and new memory will have been interchanged---new pairs
will be constructed in the new memory, beginning at the place indicated by
@code{free}, and the (previous) working memory will be available as the new
memory for the next garbage collection.  @ref{Figure 5.15} shows the
arrangement of memory just before and just after garbage collection.

@float
@anchor{Figure 5.15}
@ifinfo
@strong{Figure 5.15:} Reconfiguration of memory by the garbage-collection process.

@example
             Just before garbage collection

         +------------------------------------+
the-cars |                                    | working
         | mixture of useful data and garbage | memory
the-cdrs |                                    |
         +------------------------------------+
                                            ^
                                            | free

         +------------------------------------+
new-cars |                                    | free   
         |            free memory             | memory
new-cdrs |                                    |
         +------------------------------------+

             Just after garbage collection

         +------------------------------------+
new-cars |                                    | new  
         |          discarded memory          | free  
new-cdrs |                                    | memory
         +------------------------------------+

         +------------------+-----------------+
the-cars |                  |                 | new
         |   useful data    |    free area    | working
the-cdrs |                  |                 | memory
         +------------------+-----------------+
                              ^
                              | free
@end example
@end ifinfo
@iftex
@image{fig/chap5/Fig5.15c,142mm,,,.std.svg}
@caption{@strong{Figure 5.15:} Reconfiguration of memory by the garbage-collection process.}
@end iftex
@end float

@noindent
The state of the garbage-collection process is controlled by maintaining two
pointers: @code{free} and @code{scan}.  These are initialized to point to the
beginning of the new memory.  The algorithm begins by relocating the pair
pointed at by @code{root} to the beginning of the new memory.  The pair is
copied, the @code{root} pointer is adjusted to point to the new location, and
the @code{free} pointer is incremented.  In addition, the old location of the
pair is marked to show that its contents have been moved.  This marking is done
as follows: In the @code{car} position, we place a special tag that signals
that this is an already-moved object.  (Such an object is traditionally called
a @newterm{broken heart}.)@footnote{The term @emph{broken heart} was coined by
David Cressey, who wrote a garbage collector for MDL, a dialect of Lisp
developed at @abbr{MIT} during the early 1970s.}  In the @code{cdr} position
we place a @newterm{forwarding address} that points at the location to which
the object has been moved.

After relocating the root, the garbage collector enters its basic cycle.  At
each step in the algorithm, the @code{scan} pointer (initially pointing at the
relocated root) points at a pair that has been moved to the new memory but
whose @code{car} and @code{cdr} pointers still refer to objects in the old
memory.  These objects are each relocated, and the @code{scan} pointer is
incremented.  To relocate an object (for example, the object indicated by the
@code{car} pointer of the pair we are scanning) we check to see if the object
has already been moved (as indicated by the presence of a broken-heart tag in
the @code{car} position of the object).  If the object has not already been
moved, we copy it to the place indicated by @code{free}, update @code{free},
set up a broken heart at the object's old location, and update the pointer to
the object (in this example, the @code{car} pointer of the pair we are
scanning) to point to the new location.  If the object has already been moved,
its forwarding address (found in the @code{cdr} position of the broken heart)
is substituted for the pointer in the pair being scanned.  Eventually, all
accessible objects will have been moved and scanned, at which point the
@code{scan} pointer will overtake the @code{free} pointer and the process will
terminate.

We can specify the stop-and-copy algorithm as a sequence of instructions for a
register machine.  The basic step of relocating an object is accomplished by a
subroutine called @code{relocate-old-result-in-new}.  This subroutine gets its
argument, a pointer to the object to be relocated, from a register named
@code{old}.  It relocates the designated object (incrementing @code{free} in
the process), puts a pointer to the relocated object into a register called
@code{new}, and returns by branching to the entry point stored in the register
@code{relocate-continue}.  To begin garbage collection, we invoke this
subroutine to relocate the @code{root} pointer, after initializing @code{free}
and @code{scan}.  When the relocation of @code{root} has been accomplished, we
install the new pointer as the new @code{root} and enter the main loop of the
garbage collector.

@lisp
begin-garbage-collection
  (assign free (const 0))
  (assign scan (const 0))
  (assign old (reg root))
  (assign relocate-continue 
          (label reassign-root))
  (goto (label relocate-old-result-in-new))
reassign-root
  (assign root (reg new))
  (goto (label gc-loop))
@end lisp


@noindent
@b{Rust (stop-and-copy GC relocate):}
@example
fn relocate(&mut self, value: Value) -> Result<Value, &'static str> @{
    match value @{
        Value::Pair(old_index) => @{
            // Check if already relocated (broken heart)
            if let Value::BrokenHeart(new_index) =
                self.working.the_cars[old_index] @{
                return Ok(Value::Pair(new_index));
            @}

            // Copy to new memory
            let car = self.working.the_cars[old_index].clone();
            let cdr = self.working.the_cdrs[old_index].clone();
            let new_index = self.free_space.free;

            self.free_space.the_cars[new_index] = car;
            self.free_space.the_cdrs[new_index] = cdr;
            self.free_space.free += 1;

            // Mark with broken heart
            self.working.the_cars[old_index] =
                Value::BrokenHeart(new_index);

            Ok(Value::Pair(new_index))
        @}
        _ => Ok(value),  // Non-pairs unchanged
    @}
@}
@end example

@noindent
In the main loop of the garbage collector we must determine whether there are
any more objects to be scanned.  We do this by testing whether the @code{scan}
pointer is coincident with the @code{free} pointer.  If the pointers are equal,
then all accessible objects have been relocated, and we branch to
@code{gc-flip}, which cleans things up so that we can continue the interrupted
computation.  If there are still pairs to be scanned, we call the relocate
subroutine to relocate the @code{car} of the next pair (by placing the
@code{car} pointer in @code{old}).  The @code{relocate-continue} register is
set up so that the subroutine will return to update the @code{car} pointer.

@lisp
// gc-loop
Label("gc-loop".into()),
Test(Op("=".into(), vec![Reg("scan".into()), Reg("free".into())])),
Branch("gc-flip".into()),
Assign("old".into(), Op("vector-ref".into(), 
    vec![Reg("new-cars".into()), Reg("scan".into())])),
Assign("relocate-continue".into(), Label("update-car".into())),
Goto(Label("relocate-old-result-in-new".into())),

@noindent
@b{Rust (GC structure):}
@example
pub struct StopAndCopyGC @{
    working: Memory,
    free_space: Memory,
    roots: Vec<Value>,
@}

impl StopAndCopyGC @{
    pub fn collect(&mut self) -> Result<(), &'static str> @{
        self.free_space = Memory::new(self.working.capacity);
        let mut scan = 0;

        // Relocate roots
        for root in &mut self.roots @{
            *root = self.relocate(root.clone())?;
        @}

        // Scan and relocate
        while scan < self.free_space.free @{
            // ... relocate car/cdr ...
            scan += 1;
        @}

        std::mem::swap(&mut self.working, &mut self.free_space);
        Ok(())
    @}
@}
@end example

@end lisp

@noindent
At @code{update-car}, we modify the @code{car} pointer of the pair being
scanned, then proceed to relocate the @code{cdr} of the pair.  We return to
@code{update-cdr} when that relocation has been accomplished.  After relocating
and updating the @code{cdr}, we are finished scanning that pair, so we continue
with the main loop.

@lisp
update-car
  (perform (op vector-set!)
           (reg new-cars)
           (reg scan)
           (reg new))
  (assign  old 
           (op vector-ref)
           (reg new-cdrs)
           (reg scan))
  (assign  relocate-continue
           (label update-cdr))
  (goto (label relocate-old-result-in-new))
update-cdr
  (perform (op vector-set!)
           (reg new-cdrs)
           (reg scan)
           (reg new))
  (assign  scan (op +) (reg scan) (const 1))
  (goto (label gc-loop))
@end lisp

@noindent
The subroutine @code{relocate-old-result-in-new} relocates objects as follows:
If the object to be relocated (pointed at by @code{old}) is not a pair, then we
return the same pointer to the object unchanged (in @code{new}).  (For example,
we may be scanning a pair whose @code{car} is the number 4.  If we represent
the @code{car} by @code{n4}, as described in @ref{5.3.1}, then we want
the ``relocated'' @code{car} pointer to still be @code{n4}.)  Otherwise, we
must perform the relocation.  If the @code{car} position of the pair to be
relocated contains a broken-heart tag, then the pair has in fact already been
moved, so we retrieve the forwarding address (from the @code{cdr} position of
the broken heart) and return this in @code{new}.  If the pointer in @code{old}
points at a yet-unmoved pair, then we move the pair to the first free cell in
new memory (pointed at by @code{free}) and set up the broken heart by storing a
broken-heart tag and forwarding address at the old location.
@code{Relocate-old-result-in-new} uses a register @code{oldcr} to hold the
@code{car} or the @code{cdr} of the object pointed at by
@code{old}.@footnote{The garbage collector uses the low-level predicate
@code{pointer-to-pair?} instead of the list-structure @code{pair?}  operation
because in a real system there might be various things that are treated as
pairs for garbage-collection purposes.  For example, in a Scheme system that
conforms to the @abbr{IEEE} standard a procedure object may be implemented
as a special kind of ``pair'' that doesn't satisfy the @code{pair?} predicate.
For simulation purposes, @code{pointer-to-pair?} can be implemented as
@code{pair?}.}

@lisp
relocate-old-result-in-new
  (test (op pointer-to-pair?) (reg old))
  (branch (label pair))
  (assign new (reg old))
  (goto (reg relocate-continue))
pair
  (assign  oldcr 
           (op vector-ref)
           (reg the-cars)
           (reg old))
  (test (op broken-heart?) (reg oldcr))
  (branch  (label already-moved))
  (assign  new (reg free)) @r{; new location for pair}
  @r{;; Update @code{free} pointer.}
  (assign free (op +) (reg free) (const 1))
  @r{;; Copy the @code{car} and @code{cdr} to new memory.}
  (perform (op vector-set!)
           (reg new-cars)
           (reg new)
           (reg oldcr))
  (assign  oldcr 
           (op vector-ref)
           (reg the-cdrs)
           (reg old))
  (perform (op vector-set!)
           (reg new-cdrs)
           (reg new)
           (reg oldcr))
  @r{;; Construct the broken heart.}
  (perform (op vector-set!)
           (reg the-cars)
           (reg old)
           (const broken-heart))
  (perform (op vector-set!)
           (reg the-cdrs)
           (reg old)
           (reg new))
  (goto (reg relocate-continue))
already-moved
  (assign  new
           (op vector-ref)
           (reg the-cdrs)
           (reg old))
  (goto (reg relocate-continue))
@end lisp

@noindent
At the very end of the garbage-collection process, we interchange the role of
old and new memories by interchanging pointers: interchanging @code{the-cars}
with @code{new-cars}, and @code{the-cdrs} with @code{new-cdrs}.  We will then
be ready to perform another garbage collection the next time memory runs out.

@lisp
gc-flip
  (assign temp (reg the-cdrs))
  (assign the-cdrs (reg new-cdrs))
  (assign new-cdrs (reg temp))
  (assign temp (reg the-cars))
  (assign the-cars (reg new-cars))
  (assign new-cars (reg temp))
@end lisp

@node 5.3.3, 5.4, 5.3.2, 5.3
@subsection Ownership as Compile-Time Garbage Collection

@cindex ownership system
@cindex compile-time memory management
@cindex RAII
@cindex deterministic cleanup

In @ref{5.3.1} and @ref{5.3.2}, we explored the mechanisms by which dynamic
languages maintain the illusion of infinite memory through garbage collection.
These runtime systems automatically reclaim memory that is no longer needed,
freeing programmers from explicit memory management. However, this convenience
comes at a cost: unpredictable pause times, runtime overhead, and the need for
sophisticated algorithms to track object liveness.

Rust takes a radically different approach: it performs garbage collection at
@emph{compile time} through its @newterm{ownership system}. Rather than
tracking object lifetimes at runtime, the Rust compiler statically verifies
that every allocation has a clear owner and that memory is reclaimed
deterministically when that owner goes out of scope. This section explores how
ownership achieves the safety guarantees of garbage collection without its
runtime costs.

@subsubheading Resource Acquisition Is Initialization (RAII)

@cindex RAII
@cindex resource management
@cindex scope-based cleanup
The foundation of Rust's memory management is @newterm{Resource Acquisition Is
Initialization} (@abbr{RAII}), a principle borrowed from C++ but enforced with
mathematical rigor. The core idea is deceptively simple: tie resource lifetime
to scope. When a value is created, its resource is acquired; when the value
goes out of scope, the resource is automatically released.

Consider a simple example:

@example
fn process_file() -> std::io::Result<()> @{
    let file = std::fs::File::open("data.txt")?;
    // Use file...
    // File is automatically closed here when `file` goes out of scope
    Ok(())
@}
@end example

@noindent
Unlike garbage-collected languages where the file handle might remain open until
the next collection cycle, Rust guarantees that the file is closed exactly at
the closing brace. This determinism is crucial for managing limited resources
like file handles, network connections, and locks.

The mechanism behind this automatic cleanup is the @code{Drop} trait:

@example
pub trait Drop @{
    fn drop(&mut self);
@}
@end example

@noindent
When a value goes out of scope, Rust automatically calls its @code{drop} method.
For @code{File}, this method closes the file handle. For @code{Vec<T>}, it
deallocates the heap buffer. For more complex types, @code{drop} recursively
cleans up all owned resources.

@subsubheading The Drop Trait and Deterministic Cleanup

@cindex Drop trait
@cindex destructor
@cindex cleanup semantics
Let's implement a simple type to understand @code{Drop} semantics:

@example
struct Transaction @{
    id: u64,
    committed: bool,
@}

impl Transaction @{
    fn new(id: u64) -> Self @{
        println!("Starting transaction @{@}", id);
        Transaction @{ id, committed: false @}
    @}

    fn commit(&mut self) @{
        println!("Committing transaction @{@}", self.id);
        self.committed = true;
    @}
@}

impl Drop for Transaction @{
    fn drop(&mut self) @{
        if !self.committed @{
            println!("Rolling back transaction @{@}", self.id);
        @}
    @}
@}
@end example

@noindent
Now observe the behavior:

@example
fn example() @{
    let mut tx1 = Transaction::new(1);
    tx1.commit();

    let tx2 = Transaction::new(2);
    // tx2 is never committed
@}  // Both transactions are dropped here
@end example

@noindent
Output:

@example
Starting transaction 1
Committing transaction 1
Starting transaction 2
Rolling back transaction 2
@end example

@noindent
The cleanup happens in reverse order of creation (stack unwinding), and it
happens @emph{precisely} when the values go out of scope—no waiting for a
garbage collector, no finalizers that might never run. This predictability
makes @abbr{RAII} suitable for managing critical resources with strict lifetime
requirements.

@subsubheading Zero Runtime Overhead

@cindex zero-cost abstraction
@cindex runtime overhead
@cindex performance
Contrast this with garbage collection (@ref{5.3.2}). A copying garbage collector
must:

@enumerate
@item
Periodically scan the heap to identify live objects
@item
Copy live objects to a new memory region
@item
Update all pointers to reflect new locations
@item
Pause program execution during collection
@end enumerate

@noindent
These operations impose runtime costs that scale with heap size and object count.
In contrast, Rust's ownership system operates entirely at compile time. The
generated machine code contains simple deallocation instructions at scope exits:

@example
@group
// Rust source
fn example() @{
    let vec = vec![1, 2, 3, 4, 5];
    println!("Sum: @{@}", vec.iter().sum::<i32>());
@}

// Simplified assembly (conceptual)
example:
    call    vec_allocate      // Allocate heap buffer
    call    println
    call    vec_deallocate    // Deallocate heap buffer
    ret
@end group
@end example

@noindent
There is no runtime system, no stop-the-world pauses, no memory overhead for
tracking metadata. The only cost is the deallocation itself—work that must be
done regardless of the memory management strategy.

This zero-overhead property extends beyond simple allocations. Consider a
complex data structure:

@example
struct Database @{
    connection_pool: Vec<Connection>,
    cache: HashMap<String, Value>,
    metrics: Arc<Mutex<Metrics>>,
@}
@end example

@noindent
When a @code{Database} is dropped, the compiler generates code to recursively
drop each field in declaration order. No runtime traversal is needed—the
structure of cleanup mirrors the structure of the type, determined entirely at
compile time.

@subsubheading When Runtime Management Is Still Needed

@cindex reference counting
@cindex Rc
@cindex Arc
@cindex shared ownership
While ownership handles most memory management, some scenarios require runtime
flexibility. Rust provides @newterm{reference-counted} types for these cases:

@itemize @bullet
@item @code{Rc<T>} — Single-threaded reference counting
@item @code{Arc<T>} — Thread-safe atomic reference counting
@end itemize

@noindent
These types use runtime counting to manage shared ownership:

@example
use std::rc::Rc;

#[derive(Debug)]
struct Node @{
    value: i32,
    next: Option<Rc<Node>>,
@}

fn build_shared_list() -> (Rc<Node>, Rc<Node>) @{
    let tail = Rc::new(Node @{ value: 3, next: None @});

    let middle = Rc::new(Node @{
        value: 2,
        next: Some(Rc::clone(&tail)),
    @});

    let head = Rc::new(Node @{
        value: 1,
        next: Some(Rc::clone(&middle)),
    @});

    // Both paths share the tail node
    (head, middle)
@}
@end example

@noindent
@code{Rc} maintains a count of active references. When the count reaches zero,
the resource is deallocated. This is still deterministic—deallocation happens
precisely when the last reference is dropped—but the decision requires runtime
information.

Critically, reference counting is @emph{opt-in}. The default is move semantics
with static ownership. Only when you explicitly use @code{Rc} or @code{Arc} do
you incur the overhead of reference counting. This contrasts with garbage
collected languages where all objects carry the overhead of runtime tracking.

@subsubheading Comparison: Garbage Collection vs. Ownership

@cindex GC vs ownership
@cindex memory management tradeoffs
The trade-offs between garbage collection and ownership reveal different points
in the design space:

@multitable @columnfractions .25 .35 .40
@headitem Property @tab Garbage Collection @tab Ownership
@item Memory reclamation
@tab Automatic, runtime
@tab Automatic, compile-time
@item Timing
@tab Non-deterministic
@tab Deterministic (scope-based)
@item Overhead
@tab Memory + CPU for @abbr{GC}
@tab Compile time only
@item Pause times
@tab Unpredictable
@tab None (no runtime @abbr{GC})
@item Cycles
@tab Handled automatically
@tab Require @code{Rc}/weak refs
@item Shared ownership
@tab Natural
@tab Explicit (@code{Rc}/@code{Arc})
@item Learning curve
@tab Gentle
@tab Steep
@item Resource management
@tab Finalizers (unreliable)
@tab @abbr{RAII} (guaranteed)
@end multitable

@noindent
Garbage collection excels in scenarios where:

@itemize @bullet
@item Complex object graphs with frequent sharing
@item Prototyping and rapid iteration
@item Applications where pause times are acceptable
@item Programs with abundant memory
@end itemize

@noindent
Ownership excels where:

@itemize @bullet
@item Predictable latency is critical (real-time systems, game engines)
@item Memory is constrained (embedded systems)
@item Resource management beyond memory (files, locks, transactions)
@item Maximum performance is required
@end itemize

@subsubheading The Zero-Cost Abstraction Philosophy

@cindex zero-cost abstraction
@cindex abstraction without overhead
Rust's ownership system embodies the @newterm{zero-cost abstraction} principle:
what you don't use, you don't pay for; what you do use, you couldn't hand-code
any better.

Consider this high-level code using iterators:

@example
fn sum_of_squares(data: &[i32]) -> i32 @{
    data.iter()
        .map(|x| x * x)
        .sum()
@}
@end example

@noindent
Despite the abstraction layers (iterator, closure, map combinator), this
compiles to a tight loop with no heap allocation, no virtual dispatch, and no
runtime overhead:

@example
@group
// Conceptual assembly output
sum_of_squares:
    xor    eax, eax          ; sum = 0
.loop:
    mov    ecx, [rsi]        ; load element
    imul   ecx, ecx          ; square it
    add    eax, ecx          ; add to sum
    add    rsi, 4            ; next element
    dec    rdi               ; decrement count
    jnz    .loop             ; continue if not zero
    ret
@end group
@end example

@noindent
The ownership system enables this because the compiler knows:

@itemize @bullet
@item The slice @code{&[i32]} cannot be modified during iteration
@item No allocation is needed for the iterator or closure
@item The closure cannot escape or outlive the slice
@item All bounds checks can be elided (the iterator guarantees safety)
@end itemize

@noindent
These guarantees, proven at compile time, allow aggressive optimization without
sacrificing safety.

@subsubheading Ownership as a Type System for Aliasing

@cindex aliasing
@cindex borrowing
@cindex mutable references
At a deeper level, ownership is a @newterm{type system for aliasing control}.
The fundamental insight is that most bugs involving memory arise from
unsynchronized mutable aliasing—multiple references to the same data where at
least one can mutate it.

Rust's borrowing rules eliminate this:

@example
// Either ONE mutable reference...
let mut data = vec![1, 2, 3];
let r = &mut data;
r.push(4);

// ...OR any number of immutable references
let data = vec![1, 2, 3];
let r1 = &data;
let r2 = &data;
println!("@{:?@} @{:?@}", r1, r2);

// But NEVER both simultaneously (compile error)
let mut data = vec![1, 2, 3];
let r1 = &data;
let r2 = &mut data;  // ERROR: cannot borrow as mutable
@end example

@noindent
This rule, enforced at compile time, prevents entire classes of bugs:

@itemize @bullet
@item Iterator invalidation
@item Data races
@item Use-after-free
@item Double-free
@item Null pointer dereference
@end itemize

@noindent
Where garbage collection prevents memory errors through runtime tracking,
ownership prevents them through compile-time verification. The result is
memory safety without garbage collection—a property once thought impossible.

@quotation
@strong{@anchor{Exercise 5.22a}Exercise 5.22a:} Implement a simple arena allocator
in Rust using @abbr{RAII} principles. Your @code{Arena} type should own a
large buffer and provide a @code{alloc} method that hands out non-overlapping
slices of that buffer. When the @code{Arena} is dropped, all allocated memory
should be reclaimed at once. Compare the performance of your arena allocator to
individual @code{Box} allocations for creating 10,000 small objects. What are
the safety trade-offs of arena allocation, and how does Rust's lifetime system
ensure that references into the arena don't outlive the arena itself?
@end quotation

@quotation
@strong{@anchor{Exercise 5.23a}Exercise 5.23a:} Implement a simple graph structure
using @code{Rc<RefCell<T>>} to allow cycles. Create a cycle (A points to B, B
points to C, C points to A) and observe that the memory is not reclaimed when
you drop the initial references. Then modify your implementation to use
@code{Rc<T>} with @code{Weak<T>} references to break cycles, ensuring proper
cleanup. Instrument your @code{Drop} implementations to verify when cleanup
occurs. What does this reveal about the relationship between ownership, reference
counting, and garbage collection? When would you prefer Rust's manual cycle
management over a garbage collector's automatic cycle detection?
@end quotation

@node	5.4, 5.5, 5.3.3, Chapter 5
@section 명시적 제어 평가자 (The Explicit-Control Evaluator)

@ref{5.1}에서 우리는 간단한 Scheme 프로그램을 레지스터 기계의 기술로 변환하는 방법을 보았다.
이제 우리는 더 복잡한 프로그램인 @ref{4.1.1}--@ref{4.1.4}의 메타순환 평가자에 대해 이 변환을 수행할 것이다. 이는 Scheme 인터프리터의 동작이 @code{eval}과 @code{apply} 프로시저의 관점에서 어떻게 기술될 수 있는지를 보여준다.
우리가 이 절에서 개발하는 @newterm{명시적 제어 평가자(explicit-control evaluator)}는 평가 프로세스에서 사용되는 기본 프로시저 호출 및 인자 전달 메커니즘이 레지스터와 스택에 대한 연산의 관점에서 어떻게 기술될 수 있는지를 보여준다.
또한, 명시적 제어 평가자는 기존 컴퓨터의 네이티브 기계어와 매우 유사한 스타일로 작성된 동적 언어 인터프리터의 구현으로 사용될 수 있다.
평가자는 @ref{5.2}의 레지스터 기계 시뮬레이터에 의해 실행될 수 있다.

@subsubheading 레지스터와 연산 (Registers and operations)

명시적 제어 평가자를 설계할 때, 우리는 레지스터 기계에서 사용될 연산을 지정해야 한다.
우리는 @code{Expr::Quote} 및 @code{Expr::Lambda}와 같은 열거형 변형을 사용하여 메타순환 평가자를 추상 구문의 관점에서 설명했다.
레지스터 기계를 구현할 때, 우리는 이러한 프로시저를 기본 메모리 연산의 시퀀스로 확장하고, 이러한 연산을 레지스터 기계에 구현할 수 있다.
그러나 이렇게 하면 평가자가 매우 길어져 세부 사항으로 인해 기본 구조가 모호해질 것이다.
설명을 명확하게 하기 위해, 우리는 @ref{4.1.2}에 주어진 구문 프로시저와 @ref{4.1.3} 및 @ref{4.1.4}에 주어진 환경 및 기타 런타임 데이터를 표현하기 위한 프로시저를 레지스터 기계의 원시 연산으로 포함할 것이다.

우리의 평가자 레지스터 기계는 스택과 7개의 레지스터를 포함한다: @code{exp}, @code{env}, @code{val}, @code{continue}, @code{proc}, @code{argl}, 그리고 @code{unev}.
@code{Exp}는 평가할 표현식을 유지하는 데 사용되고, @code{env}는 평가가 수행될 환경을 포함한다.
평가가 끝나면, @code{val}은 지정된 환경에서 표현식을 평가하여 얻은 값을 포함한다.
@code{continue} 레지스터는 @ref{5.1.4}에서 설명한 대로 재귀를 구현하는 데 사용된다.
레지스터 @code{proc}, @code{argl}, 그리고 @code{unev}는 조합을 평가하는 데 사용된다.

Rust에서, 우리는 @code{current_label} 열거형 변형에 기초하여 디스패치하는 @code{run} 루프로 컨트롤러를 구현한다. 각 명령어 또는 명령어 시퀀스는 @code{EvaluatorMachine} 구조체의 메서드로 구현된다.

@menu
* 5.4.1::            The Core of the Explicit-Control Evaluator
* 5.4.2::            Sequence Evaluation and Tail Recursion
* 5.4.2a::           SIMD and Auto-Vectorization
* 5.4.3::            Conditionals, Assignments, and Definitions
* 5.4.4::            Running the Evaluator
@end menu

@node	5.4.1, 5.4.2, 5.4, 5.4
@subsection 명시적 제어 평가자의 핵심 (The Core of the Explicit-Control Evaluator)

평가자의 중심 요소는 @code{eval_dispatch}에서 시작하는 명령어 시퀀스이다.
이것은 @ref{4.1.1}에서 설명한 메타순환 평가자의 @code{eval} 프로시저에 해당한다.
컨트롤러가 @code{eval_dispatch}에서 시작할 때, 그것은 @code{env}에 의해 지정된 환경에서 @code{exp}에 의해 지정된 표현식을 평가한다.
평가가 완료되면, 컨트롤러는 @code{continue}에 저장된 진입점으로 이동하고, @code{val} 레지스터는 표현식의 값을 보유하게 된다.
Rust에서, 우리는 @code{Label} 열거형에 대한 @code{match}를 사용하여 이 디스패치를 구현한다:

@example
fn eval_dispatch(&mut self) -> Result<(), String> @{
    let exp = self.exp.clone().ok_or("No expression in exp register")?;

    match exp @{
        Expr::Number(_) | Expr::Bool(_) | Expr::String(_) | Expr::Nil => @{
            self.current_label = Label::EvSelfEval;
        @}
        Expr::Symbol(_) => @{
            self.current_label = Label::EvVariable;
        @}
        Expr::Quote(_) => @{
            self.current_label = Label::EvQuoted;
        @}
        Expr::Lambda @{ .. @} => @{
            self.current_label = Label::EvLambda;
        @}
        Expr::If @{ .. @} => @{
            self.current_label = Label::EvIf;
        @}
        Expr::Definition @{ .. @} => @{
            self.current_label = Label::EvDefinition;
        @}
        Expr::Begin(_) => @{
            self.current_label = Label::EvBegin;
        @}
        Expr::Application @{ .. @} => @{
            self.current_label = Label::EvApplication;
        @}
        _ => @{
            self.error = Some(format!("Unknown expression type: @{:?@}", exp));
            self.current_label = Label::Error;
        @}
    @}
    Ok(())
@}
@end example

@subsubheading 단순 표현식 평가하기 (Evaluating simple expressions)

숫자와 문자열(자체 평가됨), 변수, 인용(quotations), 그리고 @code{lambda} 표현식은 평가할 하위 표현식이 없다.
이들에 대해, 평가자는 단순히 올바른 값을 @code{val} 레지스터에 놓고 @code{continue}에 의해 지정된 진입점에서 실행을 계속한다.
단순 표현식의 평가는 다음 컨트롤러 코드에 의해 수행된다:

@example
fn ev_self_eval(&mut self) -> Result<(), String> @{
    let exp = self.exp.clone().ok_or("No expression")?;
    self.val = Some(match exp @{
        Expr::Number(n) => Value::Number(n),
        Expr::Bool(b) => Value::Bool(b),
        Expr::String(s) => Value::String(s),
        Expr::Nil => Value::Nil,
        _ => return Err("Not self-evaluating".into()),
    @});
    self.current_label = self.continue_reg;
    Ok(())
@}

fn ev_variable(&mut self) -> Result<(), String> @{
    let var = match self.exp.clone() @{
        Some(Expr::Symbol(s)) => s,
        _ => return Err("Expected symbol".into()),
    @};
    self.val = Some(self.env.lookup(&var).cloned()
        .ok_or_else(|| format!("Unbound variable: @{@}", var))?);
    self.current_label = self.continue_reg;
    Ok(())
@}

fn ev_quoted(&mut self) -> Result<(), String> @{
    let quoted = match self.exp.clone() @{
        Some(Expr::Quote(inner)) => *inner,
        _ => return Err("Expected quote".into()),
    @};
    self.val = Some(self.expr_to_value(quoted));
    self.current_label = self.continue_reg;
    Ok(())
@}

fn ev_lambda(&mut self) -> Result<(), String> @{
    let (params, body) = match self.exp.clone() @{
        Some(Expr::Lambda @{ params, body @}) => (params, body),
        _ => return Err("Expected lambda".into()),
    @};
    self.val = Some(Value::Procedure @{
        params, body, env: self.env.clone(), self_name: None,
    @});
    self.current_label = self.continue_reg;
    Ok(())
@}
@end example

@noindent
@code{ev_lambda}가 표현식의 @code{params}와 @code{body}를 사용하여 현재 환경을 캡처하는 프로시저 객체를 구성하는 방법을 관찰하라.

@subsubheading 프로시저 적용 평가하기 (Evaluating procedure applications)

프로시저 적용은 연산자와 피연산자를 포함하는 조합으로 지정된다.
연산자는 그 값이 프로시저인 하위 표현식이고, 피연산자는 그 값이 프로시저가 적용되어야 할 인자인 하위 표현식이다.
메타순환 @code{eval}은 조합의 각 요소를 평가하기 위해 자신을 재귀적으로 호출한 다음, 결과를 @code{apply}에 전달하여 실제 프로시저 적용을 수행함으로써 적용을 처리한다.
명시적 제어 평가자도 같은 일을 한다; 이러한 재귀적 호출은 @code{current_label}을 @code{Label::EvalDispatch}로 설정하고, 재귀 호출이 반환된 후 복원될 레지스터를 저장하기 위해 스택을 사용함으로써 구현된다.

우리는 나중에 평가된 피연산자에 적용될 프로시저를 생성하기 위해 연산자를 평가함으로써 적용의 평가를 시작한다.
연산자를 평가하기 위해, 우리는 그것을 @code{exp} 레지스터로 이동하고 @code{eval_dispatch}로 간다.
@code{env} 레지스터의 환경은 이미 연산자를 평가하기 위한 올바른 환경이다.
그러나 우리는 나중에 피연산자를 평가하기 위해 @code{env}가 필요하므로 저장한다.
우리는 또한 피연산자를 @code{unev}로 추출하고 이것을 스택에 저장한다.
우리는 연산자가 평가된 후 @code{eval_dispatch}가 @code{ev_appl_did_operator}에서 재개되도록 @code{continue}를 설정한다.
그러나 먼저, 우리는 적용 후에 어디서 계속할지 컨트롤러에게 알려주는 @code{continue}의 이전 값을 저장한다.

@example
fn ev_application(&mut self) -> Result<(), String> @{
    let (operator, operands) = match self.exp.clone() @{
        Some(Expr::Application @{ operator, operands @}) => (operator, operands),
        _ => return Err("Expected application".into()),
    @};
    self.save(StackFrame::Continue(self.continue_reg));
    self.save(StackFrame::Env(self.env.clone()));
    self.unev = operands;
    self.save(StackFrame::Unev(self.unev.clone()));
    self.exp = Some(*operator);
    self.continue_reg = Label::EvApplDidOperator;
    self.current_label = Label::EvalDispatch;
    Ok(())
@}
@end example

@noindent
연산자 하위 표현식 평가에서 돌아오면, 우리는 조합의 피연산자를 평가하고 결과 인자를 @code{argl}에 유지되는 리스트에 누적하도록 진행한다.
먼저 평가되지 않은 피연산자와 환경을 복원한다.
우리는 @code{argl}을 빈 리스트로 초기화한다.
그런 다음 연산자를 평가하여 생성된 프로시저를 @code{proc} 레지스터에 할당한다.
피연산자가 없으면, 바로 @code{apply_dispatch}로 간다.
그렇지 않으면 @code{proc}을 스택에 저장하고 인자 평가 루프를 시작한다:

@example
fn ev_appl_did_operator(&mut self) -> Result<(), String> @{
    self.restore_unev()?;
    self.restore_env()?;
    self.argl = Vec::new();
    self.proc = self.val.clone();
    if self.unev.is_empty() @{
        self.current_label = Label::ApplyDispatch;
    @} else @{
        self.save(StackFrame::Proc(self.proc.clone().unwrap()));
        self.current_label = Label::EvApplOperandLoop;
    @}
    Ok(())
@}
@end example

@noindent
인자 평가 루프의 각 주기는 @code{unev}의 리스트에서 피연산자를 평가하고 결과를 @code{argl}에 누적한다.
피연산자를 평가하기 위해, 우리는 그것을 @code{exp} 레지스터에 넣고 인자 누적 단계에서 실행이 재개되도록 @code{continue}를 설정한 후 @code{eval_dispatch}로 간다.
하지만 먼저 지금까지 누적된 인자들(@code{argl}에 유지됨), 환경(@code{env}에 유지됨), 그리고 평가될 남은 피연산자들(@code{unev}에 유지됨)을 저장한다.
마지막 피연산자의 평가에 대해서는 @code{ev_appl_last_arg}에서 처리되는 특수 사례가 만들어진다.

@example
fn ev_appl_operand_loop(&mut self) -> Result<(), String> @{
    self.save(StackFrame::Argl(self.argl.clone()));
    self.exp = Some(self.unev[0].clone());
    if self.unev.len() == 1 @{
        self.current_label = Label::EvApplLastArg;
    @} else @{
        self.save(StackFrame::Env(self.env.clone()));
        self.save(StackFrame::Unev(self.unev.clone()));
        self.continue_reg = Label::EvApplAccumulateArg;
        self.current_label = Label::EvalDispatch;
    @}
    Ok(())
@}
@end example

@noindent
피연산자가 평가되면, 그 값은 @code{argl}에 유지되는 리스트에 누적된다.
그런 다음 피연산자는 @code{unev}의 평가되지 않은 피연산자 리스트에서 제거되고, 인자 평가가 계속된다.

@example
fn ev_appl_accumulate_arg(&mut self) -> Result<(), String> @{
    self.restore_unev()?;
    self.restore_env()?;
    self.restore_argl()?;
    self.argl.push(self.val.clone().ok_or("No value")?);
    self.unev = self.unev[1..].to_vec();
    self.current_label = Label::EvApplOperandLoop;
    Ok(())
@}
@end example

@noindent
마지막 인자의 평가는 다르게 처리된다.
마지막 피연산자가 평가된 후에는 환경이나 평가되지 않은 피연산자 리스트가 필요하지 않으므로 @code{eval_dispatch}로 가기 전에 이들을 저장할 필요가 없다.
따라서, 우리는 평가에서 특수 진입점 @code{ev_appl_accum_last_arg}로 돌아오며, 여기서는 인자 리스트를 복원하고, 새 인자를 누적하고, 저장된 프로시저를 복원하고, 적용을 수행하러 간다.@footnote{마지막 피연산자를 특별히 처리하는 최적화는 @newterm{evlis 꼬리 재귀(evlis tail recursion)}로 알려져 있다(@ref{Wand 1980} 참조). 만약 첫 번째 피연산자의 평가도 특수 사례로 만든다면 인자 평가 루프에서 좀 더 효율적일 수 있다. 이것은 첫 번째 피연산자를 평가한 후에 @code{argl} 초기화를 연기할 수 있게 하여, 이 경우 @code{argl}을 저장하는 것을 피할 수 있게 한다. @ref{5.5}의 컴파일러는 이 최적화를 수행한다. (@ref{5.5.3}의 @code{construct_arglist} 프로시저와 비교하라.)}

@lisp
ev_appl_last_arg
  (assign continue 
          (label ev_appl_accum_last_arg))
  (goto (label eval_dispatch))
ev_appl_accum_last_arg
  (restore argl)
  (assign argl 
          (op adjoin_arg)
          (reg val)
          (reg argl))
  (restore proc)
  (goto (label apply_dispatch))
@end lisp

@noindent
인자 평가 루프의 세부 사항은 인터프리터가 조합의 피연산자를 평가하는 순서를 결정한다(예: 왼쪽에서 오른쪽 또는 오른쪽에서 왼쪽---@ref{Exercise 3.8} 참조).
이 순서는 메타순환 평가자에 의해 결정되지 않으며, 메타순환 평가자는 구현된 기본 Scheme으로부터 제어 구조를 상속받는다.@footnote{메타순환 평가자에서 피연산자 평가 순서는 @ref{4.1.1}의 @code{list_of_values} 프로시저에서 @code{cons}에 대한 인자 평가 순서에 의해 결정된다(@ref{Exercise 4.1} 참조).}
@code{first-operand} 선택자(@code{ev_appl_operand_loop}에서 @code{unev}로부터 연속적인 피연산자를 추출하는 데 사용됨)가 @code{car}로 구현되고 @code{rest-operands} 선택자가 @code{cdr}로 구현되기 때문에, 명시적 제어 평가자는 조합의 피연산자를 왼쪽에서 오른쪽 순서로 평가할 것이다.

@subsubheading 프로시저 적용 (Procedure application)

진입점 @code{apply_dispatch}는 메타순환 평가자의 @code{apply} 프로시저에 해당한다.
우리가 @code{apply_dispatch}에 도달할 때쯤이면, @code{proc} 레지스터는 적용할 프로시저를 포함하고 @code{argl}은 적용되어야 할 평가된 인자 리스트를 포함한다.
@code{continue}의 저장된 값(원래 @code{eval_dispatch}에 전달되어 @code{ev_application}에서 저장됨)은 스택에 있으며, 이는 프로시저 적용 결과와 함께 어디로 돌아갈지 알려준다.
적용이 완료되면, 컨트롤러는 저장된 @code{continue}에 의해 지정된 진입점으로 이동하며, 적용 결과는 @code{val}에 있다.
메타순환 @code{apply}와 마찬가지로, 고려해야 할 두 가지 경우가 있다.
적용될 프로시저는 원시이거나 복합 프로시저이다.

@example
// apply-dispatch
Label("apply-dispatch".into()),
match self.proc.as_ref().unwrap() @{
    Value::Primitive(_) => @{ self.current_label = Label::PrimitiveApply; @}
    Value::Procedure @{ .. @} => @{ self.current_label = Label::CompoundApply; @}
    _ => @{ self.current_label = Label::UnknownProcedureType; @}
@}
@end example

@noindent
우리는 각 원시가 @code{argl}에서 인자를 얻고 결과를 @code{val}에 놓도록 구현되었다고 가정한다.
기계가 원시를 처리하는 방법을 지정하려면, 우리는 각 원시를 구현하기 위한 컨트롤러 명령어 시퀀스를 제공하고 @code{primitive_apply}가 @code{proc}의 내용에 의해 식별된 원시를 위한 명령어로 디스패치하도록 조정해야 할 것이다.
우리는 원시의 세부 사항보다는 평가 프로세스의 구조에 관심이 있으므로, 대신 @code{proc}의 프로시저를 @code{argl}의 인자에 적용하는 @code{apply_primitive_procedure} 연산을 사용할 것이다.
@ref{5.2}의 시뮬레이터로 평가자를 시뮬레이션하기 위해, 우리는 @code{apply_primitive_procedure} 프로시저를 사용하며, 이것은 @ref{4.1.4}의 메타순환 평가자에서 했던 것처럼 기본 Scheme 시스템을 호출하여 적용을 수행한다.
원시 적용 값을 계산한 후, 우리는 @code{continue}를 복원하고 지정된 진입점으로 간다.

@lisp
primitive_apply
  (assign val (op apply_primitive_procedure)
              (reg proc)
              (reg argl))
  (restore continue)
  (goto (reg continue))
@end lisp

@noindent
복합 프로시저를 적용하기 위해, 우리는 메타순환 평가자와 똑같이 진행한다.
우리는 프로시저의 매개변수를 인자에 바인딩하는 프레임을 구성하고, 이 프레임을 사용하여 프로시저가 전달한 환경을 확장하며, 이 확장된 환경에서 프로시저의 본문을 형성하는 표현식 시퀀스를 평가한다.
아래 @ref{5.4.2}에서 설명된 @code{Ev-sequence}는 시퀀스의 평가를 처리한다.

@lisp
compound_apply
  (assign unev 
          (op procedure_parameters)
          (reg proc))
  (assign env
          (op procedure_environment)
          (reg proc))
  (assign env
          (op extend_environment)
          (reg unev)
          (reg argl)
          (reg env))
  (assign unev
          (op procedure_body)
          (reg proc))
  (goto (label ev_sequence))
@end lisp

@noindent
@code{Compound-apply}는 인터프리터에서 @code{env} 레지스터에 새 값이 할당되는 유일한 곳이다.
메타순환 평가자에서와 마찬가지로, 새 환경은 프로시저가 전달한 환경과 인자 리스트 및 바인딩될 해당 변수 리스트로부터 구성된다.

@node	5.4.2, 5.4.2a, 5.4.1, 5.4
@subsection 시퀀스 평가와 꼬리 재귀 (Sequence Evaluation and Tail Recursion)

명시적 제어 평가자의 @code{ev_sequence} 부분은 메타순환 평가자의 @code{eval_sequence} 프로시저와 유사하다.
이것은 프로시저 본문이나 명시적 @code{begin} 표현식 내의 표현식 시퀀스를 처리한다.

명시적 @code{begin} 표현식은 평가할 표현식 시퀀스를 @code{unev}에 놓고, @code{continue}를 스택에 저장하고, @code{ev_sequence}로 점프함으로써 평가된다.

@lisp
ev_begin
  (assign unev
          (op begin_actions)
          (reg exp))
  (save continue)
  (goto (label ev_sequence))
@end lisp

@noindent
프로시저 본문의 암시적 시퀀스는 @code{compound_apply}에서 @code{ev_sequence}로 점프함으로써 처리되는데, 이때 @code{continue}는 이미 @code{ev_application}에서 저장되어 스택에 있다.

@code{ev_sequence}와 @code{ev_sequence_continue}의 항목들은 시퀀스의 각 표현식을 차례로 평가하는 루프를 형성한다.
평가되지 않은 표현식의 리스트는 @code{unev}에 유지된다.
각 표현식을 평가하기 전에, 우리는 시퀀스에서 평가할 추가 표현식이 있는지 확인한다.
있다면, 우리는 (@code{unev}에 있는) 나머지 평가되지 않은 표현식과 이것들이 평가되어야 할 (@code{env}에 있는) 환경을 저장하고, 표현식을 평가하기 위해 @code{eval_dispatch}를 호출한다.
저장된 두 레지스터는 이 평가에서 반환될 때 @code{ev_sequence_continue}에서 복원된다.

시퀀스의 마지막 표현식은 진입점 @code{ev_sequence_last_exp}에서 다르게 처리된다.
이것 다음에는 평가할 표현식이 더 이상 없으므로, @code{eval_dispatch}로 가기 전에 @code{unev}나 @code{env}를 저장할 필요가 없다.
전체 시퀀스의 값은 마지막 표현식의 값이므로, 마지막 표현식의 평가 후에는 (@code{ev_application}이나 @code{ev_begin}에 의해 저장되었던) 현재 스택에 있는 진입점에서 계속하는 것 외에는 할 일이 없다.
@code{eval_dispatch}가 여기로 돌아오도록 @code{continue}를 설정하고 스택에서 @code{continue}를 복원하여 그 진입점에서 계속하는 대신, 우리는 @code{eval_dispatch}로 가기 전에 스택에서 @code{continue}를 복원하여 @code{eval_dispatch}가 표현식을 평가한 후 그 진입점에서 계속하도록 한다.

@example
// ev-sequence
Label("ev-sequence".into()),
Assign("exp".into(), Op("first-exp".into(), vec![Reg("unev".into())])),
Test(Op("is-last-exp".into(), vec![Reg("unev".into())])),
Branch("ev-sequence-last-exp".into()),
Save("unev".into()),
Save("env".into()),
Assign("continue".into(), Label("ev-sequence-continue".into())),
Goto(Label("eval-dispatch".into())),
Label("ev-sequence-continue".into()),
Restore("env".into()),
Restore("unev".into()),
Assign("unev".into(), Op("rest-exps".into(), vec![Reg("unev".into())])),
Goto(Label("ev-sequence".into())),
Label("ev-sequence-last-exp".into()),
Restore("continue".into()),
Goto(Label("eval-dispatch".into())),
@end example

@subsubheading 꼬리 재귀 (Tail recursion)

@ref{Chapter 1}에서 우리는 다음과 같은 프로시저에 의해 설명되는 프로세스가

@example
fn sqrt_iter(guess: f64, x: f64) -> f64 @{
    if good_enough(guess, x) @{
        guess
    @} else @{
        sqrt_iter(improve(guess, x), x)
    @}
@}
@end example

@noindent
반복적 프로세스라고 말했다.
비록 프로시저가 구문상으로는 재귀적(자신을 통해 정의됨)이지만, 평가자가 @code{sqrt-iter}에 대한 한 호출에서 다음 호출로 넘어갈 때 정보를 저장하는 것이 논리적으로 필요하지 않다.@footnote{@ref{5.1}에서 우리는 스택이 없는 레지스터 기계로 그러한 프로세스를 구현하는 방법을 보았다; 프로세스의 상태는 고정된 레지스터 집합에 저장되었다.}
@code{sqrt-iter}와 같은 프로시저를 계속 자신을 호출함에 따라 증가하는 저장소를 요구하지 않고 실행할 수 있는 평가자를 @newterm{꼬리 재귀적(tail-recursive)} 평가자라고 한다.
@ref{Chapter 4}의 메타순환 평가자 구현은 평가자가 꼬리 재귀적인지 여부를 명시하지 않는데, 그 평가자는 기본 Scheme으로부터 상태 저장 메커니즘을 상속받기 때문이다.
그러나 명시적 제어 평가자를 사용하면, 우리는 프로시저 호출이 언제 스택에 정보의 순 축적을 유발하는지 보기 위해 평가 프로세스를 추적할 수 있다.

우리 평가자는 꼬리 재귀적이다. 왜냐하면 시퀀스의 마지막 표현식을 평가하기 위해 스택에 아무런 정보도 저장하지 않고 @code{eval_dispatch}로 직접 이동하기 때문이다.
따라서, 시퀀스의 마지막 표현식을 평가하는 것---비록 그것이 프로시저 호출이라 할지라도(@code{sqrt-iter}에서처럼, 프로시저 본문의 마지막 표현식인 @code{if} 표현식이 @code{sqrt-iter}에 대한 호출로 축소되는 경우)---은 스택에 어떤 정보도 축적되게 하지 않을 것이다.@footnote{@code{ev_sequence}에서의 이 꼬리 재귀 구현은 많은 컴파일러에서 사용되는 잘 알려진 최적화 기술의 한 종류이다. 프로시저 호출로 끝나는 프로시저를 컴파일할 때, 호출을 호출되는 프로시저의 진입점으로의 점프로 대체할 수 있다. 이 전략을 우리가 이 절에서 한 것처럼 인터프리터에 내장하면 언어 전체에 걸쳐 균일하게 최적화를 제공한다.}

만약 우리가 이 경우에 정보를 저장할 필요가 없다는 사실을 활용할 생각을 하지 못했다면, 우리는 시퀀스의 모든 표현식을 같은 방식으로 처리하여 @code{eval_sequence}를 구현했을 수도 있다---레지스터를 저장하고, 표현식을 평가하고, 돌아와서 레지스터를 복원하고, 모든 표현식이 평가될 때까지 이것을 반복한다:@footnote{우리는 @code{no-more-exps?}를 다음과 같이 정의할 수 있다:

@example
fn is_no_more_exps(seq: &[Expr]) -> bool @{
    seq.is_empty()
@}
@end example
}

@example
// ev-sequence (꼬리 재귀적이지 않음)
Label("ev-sequence".into()),
Test(Op("no-more-exps?".into(), vec![Reg("unev".into())])),
Branch("ev-sequence-end".into()),
Assign("exp".into(), Op("first-exp".into(), vec![Reg("unev".into())])),
Save("unev".into()),
Save("env".into()),
Assign("continue".into(), Label("ev-sequence-continue".into())),
Goto(Label("eval-dispatch".into())),
Label("ev-sequence-continue".into()),
Restore("env".into()),
Restore("unev".into()),
Assign("unev".into(), Op("rest-exps".into(), vec![Reg("unev".into())])),
Goto(Label("ev-sequence".into())),
Label("ev-sequence-end".into()),
Restore("continue".into()),
Goto(Reg("continue".into())),
@end example

@noindent
이것은 시퀀스 평가를 위한 이전 코드에 대한 사소한 변경처럼 보일 수 있다: 유일한 차이점은 우리가 시퀀스의 마지막 표현식에 대해서도 다른 표현식들과 마찬가지로 저장-복원 주기를 거친다는 것이다.
인터프리터는 여전히 어떤 표현식에 대해서도 동일한 값을 줄 것이다.
그러나 이 변경은 꼬리 재귀적 구현에 치명적이다. 왜냐하면 우리는 이제 시퀀스의 마지막 표현식을 평가한 후에 (쓸모없는) 레지스터 저장을 취소하기 위해 돌아와야 하기 때문이다.
이러한 추가 저장은 프로시저 호출이 중첩되는 동안 누적될 것이다.
결과적으로, @code{sqrt-iter}와 같은 프로세스는 상수 공간을 요구하는 대신 반복 횟수에 비례하는 공간을 요구할 것이다.
이 차이는 중요할 수 있다.
예를 들어, 꼬리 재귀를 사용하면 무한 루프를 오직 프로시저 호출 메커니즘만을 사용하여 표현할 수 있다:

@example
fn count(n: i64) -> ! @{
    println!("@{@}", n);
    count(n + 1)
@}
@end example

@noindent
꼬리 재귀가 없다면, 그러한 프로시저는 결국 스택 공간이 부족해질 것이며, 진정한 반복을 표현하려면 프로시저 호출 이외의 다른 제어 메커니즘이 필요할 것이다.

@node 5.4.2a, 5.4.3, 5.4.2, 5.4
@subsection SIMD와 자동 벡터화 (SIMD and Auto-Vectorization)

@cindex SIMD
@cindex vectorization
@cindex data parallelism
@cindex parallel processing

시퀀스 연산과 꼬리 재귀에 대한 우리의 탐구(@ref{5.4.2})에서, 우리는 제어 흐름과 스택 관리가 프로그램 실행에 미치는 영향에 초점을 맞추었다.
하지만 현대 프로세서는 성능의 또 다른 차원을 제공한다: @abbr{SIMD} (단일 명령어, 다중 데이터, Single Instruction, Multiple Data) 연산을 통한 @newterm{데이터 병렬성(data parallelism)}.
꼬리 재귀가 재귀적 시퀀스를 효율적인 루프로 변환하는 반면, @abbr{SIMD}는 스칼라 루프를 여러 데이터 요소를 동시에 처리하는 병렬 연산으로 변환한다.

@abbr{SIMD}는 x86의 @abbr{AVX-512}부터 ARM의 @abbr{NEON} 및 RISC-V의 벡터 확장에 이르기까지 현대 프로세서의 근본적인 아키텍처 기능을 나타낸다.
@abbr{SIMD}를 이해하는 것은 순차적 계산에 대한 우리의 추상 모델과, 명령어 수준에서 코어 수준 병렬성에 이르기까지 모든 수준에서 병렬성이 존재하는 현대 하드웨어의 현실 사이의 간극을 조명한다.

@subsubheading SIMD란 무엇인가? (What Is SIMD?)

@cindex vector operations
@cindex parallel arithmetic
단일 명령어, 다중 데이터(SIMD)는 단일 명령어를 사용하여 여러 데이터 요소에 동일한 연산을 병렬로 적용하는 것을 의미한다.
한 번에 하나의 숫자를 처리하는 대신, @abbr{SIMD} 명령어는 숫자의 @emph{벡터(vectors)}에 대해 작동한다.

두 부동 소수점 숫자 배열을 더하는 것을 고려해 보자:

@example
@group
// 스칼라 코드 (한 번에 한 요소)
fn add_scalar(a: &[f32], b: &[f32], result: &mut [f32]) @{
    for i in 0..a.len() @{
        result[i] = a[i] + b[i];
    @}
@}
@end group
@end example

@noindent
현대 하드웨어에서, 이것은 한 번에 4개 또는 8개의 요소로 처리될 수 있다:

@example
@group
// 개념적 SIMD 코드 (여러 요소를 동시에)
// [a0, a1, a2, a3] + [b0, b1, b2, b3] = [c0, c1, c2, c3]
// 네 개의 덧셈이 모두 병렬로 발생한다
@end group
@end example

@noindent
속도 향상은 벡터 너비에 비례한다: 128비트 @abbr{SSE} 벡터로 4배, 256비트 @abbr{AVX2}로 8배, 또는 512비트 @abbr{AVX-512}로 16배.
이 병렬성은 @emph{무료}이다—단일 명령어가 많은 일을 한다.

@subsubheading Rust의 portable_simd (Rust's portable_simd)

@cindex portable_simd
@cindex std::simd
@cindex platform independence
Rust의 @code{std::simd} 모듈(이전의 @code{portable_simd}, Edition 2024에서 안정화됨)은 플랫폼 독립적인 @abbr{SIMD} 프로그래밍을 제공한다.
컴파일러는 제네릭 @abbr{SIMD} 연산을 각 대상 아키텍처에서 사용 가능한 최적의 명령어 세트로 매핑한다.

먼저, @file{Cargo.toml}에서 @abbr{SIMD}를 활성화한다:

@example
[dependencies]
# std::simd는 Edition 2024에서 안정화됨

[profile.release]
opt-level = 3
codegen-units = 1
lto = true
@end example

@noindent
이제 이식 가능한 @abbr{SIMD} 코드를 작성할 수 있다:

@example
use std::simd::@{f32x8, Simd@};

fn add_vectors(a: &[f32], b: &[f32], result: &mut [f32]) @{
    let chunks = a.len() / 8;

    // 한 번에 8개 요소 처리
    for i in 0..chunks @{
        let idx = i * 8;

        // 8개의 f32를 SIMD 레지스터로 로드
        let va = Simd::<f32, 8>::from_slice(&a[idx..]);
        let vb = Simd::<f32, 8>::from_slice(&b[idx..]);

        // 병렬 덧셈
        let vc = va + vb;

        // 결과 저장
        vc.copy_to_slice(&mut result[idx..]);
    @}

    // 나머지 요소 처리
    for i in (chunks * 8)..a.len() @{
        result[i] = a[i] + b[i];
    @}
@}
@end example

@noindent
@code{f32x8} 타입은 8개의 32비트 부동 소수점 숫자의 벡터를 나타낸다.
이 타입에 대한 연산은 병렬 @abbr{SIMD} 명령어로 컴파일된다.
x86-64에서, @code{va + vb} 덧셈은 8개의 부동 소수점 숫자에 대해 동시에 작동하는 단일 @code{vaddps} 명령어가 된다.

@subsubheading SIMD 타입과 연산 (SIMD Types and Operations)

@cindex SIMD types
@cindex vector width
Rust는 다양한 너비와 요소 타입의 @abbr{SIMD} 벡터를 제공한다:

@example
use std::simd::*;

// 부동 소수점 벡터
let a: f32x4  = Simd::splat(1.0);  // [1.0, 1.0, 1.0, 1.0]
let b: f64x2  = Simd::from_array([2.0, 3.0]);

// 정수 벡터
let c: i32x8  = Simd::from_array([1, 2, 3, 4, 5, 6, 7, 8]);
let d: u64x4  = Simd::splat(42);

// 일반적인 연산은 요소별로 작동한다
let sum = a + Simd::splat(2.0);     // [3.0, 3.0, 3.0, 3.0]
let prod = c * Simd::splat(2);       // [2, 4, 6, 8, 10, 12, 14, 16]
let max_vals = c.simd_max(Simd::splat(5));  // 최소 5로 고정(clamp)
@end example

@noindent
제네릭 @code{Simd<T, N>} 타입은 타입 @code{T}인 @code{N}개의 레인(lanes)을 갖는다.
@code{f32x4}와 같은 타입 별칭은 일반적인 크기에 대해 제공된다.
너비 @code{N}은 2의 거듭제곱이어야 하며 대상 아키텍처에서 지원되어야 한다 (일반적으로 2, 4, 8, 16, 32, 또는 64).

산술 외에도, @abbr{SIMD}는 다음을 지원한다:

@example
// 비교는 마스크 벡터를 생성한다
let mask = a.simd_gt(Simd::splat(0.0));  // 요소별 > 0

// 마스크된 선택 (삼항 연산자와 유사)
let result = mask.select(a, Simd::splat(0.0));  // max(a, 0)

// 축소 (Reductions)
let sum: f32 = a.reduce_sum();
let max: f32 = a.reduce_max();
let all_positive = a.simd_gt(Simd::splat(0.0)).all();
@end example

@subsubheading 자동 벡터화: 컴파일러가 대신 해줄 때 (Auto-Vectorization: When the Compiler Does It for You)

@cindex auto-vectorization
@cindex compiler optimization
@cindex LLVM
명시적 @abbr{SIMD}는 완전한 제어를 제공하지만, 현대 컴파일러는 종종 스칼라 코드를 자동으로 벡터화할 수 있다.
Rust의 @abbr{LLVM} 백엔드는 벡터화 가능한 패턴을 인식하는 정교한 자동 벡터화 패스를 포함한다.

이 간단한 스칼라 코드를 고려해 보자:

@example
pub fn scale_array(data: &mut [f32], factor: f32) @{
    for x in data.iter_mut() @{
        *x *= factor;
    @}
@}
@end example

@noindent
최적화가 활성화되면(@code{-C opt-level=3}), 컴파일러는 자동으로 @abbr{SIMD} 명령어를 생성한다:

@example
@group
; 어셈블리 출력 (x86-64, 개념적)
scale_array:
    vbroadcastss ymm0, xmm0    ; 인자를 8-wide로 브로드캐스트
.loop:
    vmulps       ymm1, ymm0, [rsi]  ; 한 번에 8개의 부동 소수점 곱하기
    vmovups      [rsi], ymm1        ; 결과 저장
    add          rsi, 32            ; 8 * 4 바이트 전진
    cmp          rsi, rdx
    jne          .loop
@end group
@end example

@noindent
컴파일러는 루프 패턴을 인식하고 @abbr{AVX} 명령어를 사용하여 반복당 8개의 부동 소수점을 처리하는 코드를 자동으로 생성했다.

자동 벡터화는 다음과 같은 경우 가장 잘 작동한다:

@itemize @bullet
@item
루프가 반복 간에 데이터 의존성을 갖지 않을 때
@item
접근 패턴이 규칙적이고 연속적일 때
@item
반복 횟수가 알려져 있거나 제한되어 있을 때
@item
연산이 @abbr{SIMD} 친화적일 때 (산술, 논리, 최소/최대)
@end itemize

@subsubheading 벡터화 친화적인 코드 작성하기 (Writing Vectorization-Friendly Code)

@cindex vectorization patterns
@cindex performance optimization
모든 코드가 쉽게 벡터화되는 것은 아니다. 무엇이 자동 벡터화를 돕고(또는 방해하는지) 이해하면 명시적 @abbr{SIMD} 없이도 더 빠른 코드를 작성할 수 있다:

@strong{좋음: 평탄하고 연속적인 반복 (Flat, contiguous iteration)}

@example
// 잘 벡터화됨
fn sum_positive(data: &[f32]) -> f32 @{
    data.iter()
        .copied()
        .filter(|&x| x > 0.0)
        .sum()
@}
@end example

@noindent
@strong{나쁨: 복잡한 제어 흐름 (Complex control flow)}

@example
// 벡터화하기 어려움 (요소별 분기)
fn complex_logic(data: &[f32]) -> f32 @{
    let mut sum = 0.0;
    for &x in data @{
        if x > 0.0 @{
            if x < 10.0 @{
                sum += x * 2.0;
            @} else @{
                sum += x.sqrt();
            @}
        @}
    @}
    sum
@}
@end example

@noindent
@strong{좋음: 마스크를 사용한 분기 없음 (Branchless with masks)}

@example
// 마스킹을 사용한 벡터화 가능 버전
fn complex_logic_vectorizable(data: &[f32]) -> f32 @{
    data.iter()
        .map(|&x| @{
            let doubled = x * 2.0;
            let sqrted = x.sqrt();
            let use_sqrt = x >= 10.0;
            let result = if use_sqrt @{ sqrted @} else @{ doubled @};
            if x > 0.0 @{ result @} else @{ 0.0 @}
        @})
        .sum()
@}
@end example

@noindent
@strong{작은 함수에는 @code{#[inline]} 사용하기:}

@example
#[inline]
fn process(x: f32) -> f32 @{
    x * x + 2.0 * x + 1.0
@}

pub fn apply(data: &mut [f32]) @{
    for x in data.iter_mut() @{
        *x = process(*x);  // 인라인화된 후 벡터화됨
    @}
@}
@end example

@subsubheading SIMD 개선 벤치마킹 (Benchmarking SIMD Improvements)

@cindex benchmarking
@cindex performance measurement
@cindex criterion
@abbr{SIMD} 이점을 확인하려면 @code{criterion}으로 벤치마크하라:

@example
use criterion::@{black_box, criterion_group, criterion_main, Criterion@};

fn bench_dot_product(c: &mut Criterion) @{
    let a: Vec<f32> = (0..10000).map(|i| i as f32).collect();
    let b: Vec<f32> = (0..10000).map(|i| (i * 2) as f32).collect();

    c.bench_function("dot_scalar", |bencher| @{
        bencher.iter(|| @{
            dot_product_scalar(black_box(&a), black_box(&b))
        @})
    @});

    c.bench_function("dot_simd", |bencher| @{
        bencher.iter(|| @{
            dot_product_simd(black_box(&a), black_box(&b))
        @})
    @});
@}

fn dot_product_scalar(a: &[f32], b: &[f32]) -> f32 @{
    a.iter().zip(b).map(|(x, y)| x * y).sum()
@}

fn dot_product_simd(a: &[f32], b: &[f32]) -> f32 @{
    use std::simd::f32x8;

    let mut sum = f32x8::splat(0.0);
    let chunks = a.len() / 8;

    for i in 0..chunks @{
        let idx = i * 8;
        let va = f32x8::from_slice(&a[idx..]);
        let vb = f32x8::from_slice(&b[idx..]);
        sum += va * vb;  // 융합 곱셈-덧셈 (Fused multiply-add)
    @}

    sum.reduce_sum() +
        a[chunks * 8..]
            .iter()
            .zip(&b[chunks * 8..])
            .map(|(x, y)| x * y)
            .sum::<f32>()
@}

criterion_group!(benches, bench_dot_product);
criterion_main!(benches);
@end example

@noindent
전형적인 결과는 4-8배의 속도 향상을 보여준다:

@example
dot_scalar    time:   [8.234 µs 8.267 µs 8.305 µs]
dot_simd      time:   [1.045 µs 1.052 µs 1.061 µs]
                      ↑ 7.8× faster
@end example

@subsubheading 시퀀스 연산과의 연결 (Connection to Sequence Operations)

@cindex sequence processing
@cindex functional programming
@cindex iterator combinators
우리가 이 책 전체에서 사용해 온 반복자 조합기(@code{map}, @code{filter}, @code{fold})는 @abbr{SIMD}와 아름답게 구성된다.
핵심 통찰은 @abbr{SIMD} 자체가 데이터 시퀀스를 병렬로 조작하는 시퀀스 처리의 한 형태라는 것이다.

슬라이스에 대한 @code{map}을 고려해 보자:

@example
// 개념적 변환
data.iter().map(|&x| x * 2.0).collect()

// 순차적 실행: [a, b, c, d] → [2a, 2b, 2c, 2d]
// 각 요소가 한 번에 하나씩 처리됨

// SIMD 실행: [a, b, c, d] → [2a, 2b, 2c, 2d]
// 모든 요소가 동시에 처리됨
@end example

@noindent
연산은 동일하며 실행 전략만 다르다.
이 연결은 깊다: 많은 @abbr{SIMD} 알고리즘은 함수형 프로그래밍 패턴을 반영한다:

@example
// Map
vec.iter().map(|&x| x * 2.0)
↔
Simd::splat(2.0) * simd_vec

// Filter (마스크 사용)
vec.iter().filter(|&&x| x > 0.0)
↔
mask.select(simd_vec, Simd::splat(0.0))

// Reduce
vec.iter().sum()
↔
simd_vec.reduce_sum()
@end example

@noindent
순차적 반복자 연산과 병렬 @abbr{SIMD} 연산 사이의 대응은 근본적인 통일성을 드러낸다: 둘 다 시퀀스에 대한 대량 연산을 표현하는 방법이다.
@abbr{SIMD}는 ``이 연산을 모든 요소에 적용하라''는 @code{map}의 본질을 하드웨어로 구현한 것이다.

@subsubheading 실제 세계에서의 SIMD (SIMD in the Real World)

@cindex applications
@cindex use cases
@abbr{SIMD}는 규칙적이고 데이터 병렬적인 계산을 포함하는 영역에서 극적인 속도 향상을 달성한다:

@itemize @bullet
@item
@strong{이미지 처리:} 필터, 변환, 색 공간 변환
@item
@strong{신호 처리:} @abbr{FFT}, 컨볼루션, 상관 관계
@item
@strong{선형 대수:} 행렬 곱셈, 벡터 연산 (@abbr{BLAS})
@item
@strong{압축:} 허프만 코딩, DEFLATE, 비디오 코덱
@item
@strong{암호화:} 블록 암호, 해싱 (부채널 안전할 때)
@item
@strong{기계 학습:} 추론, 훈련, 활성화 함수
@end itemize

@noindent
@code{nalgebra}(선형 대수)와 @code{image}(이미지 처리) 같은 라이브러리는 내부적으로 @abbr{SIMD}를 광범위하게 사용하여, 저수준 최적화로 뒷받침되는 고수준 추상화를 제공한다.

@subsubheading 한계와 주의사항 (Limitations and Caveats)

@cindex SIMD limitations
@cindex portability
강력하지만, @abbr{SIMD}에는 한계가 있다:

@strong{불규칙한 데이터 패턴:} 흩어진 메모리 접근 패턴은 벡터화를 방해한다.
구조체 배열(@abbr{AoS})보다 배열 구조체(@abbr{SoA}) 레이아웃이 종종 더 잘 벡터화된다:

@example
// 구조체 배열 (AoS) - SIMD에 좋지 않음
struct Point @{ x: f32, y: f32, z: f32 @}
let points: Vec<Point> = ...;

// 배열 구조체 (SoA) - SIMD에 좋음
struct Points @{
    x: Vec<f32>,
    y: Vec<f32>,
    z: Vec<f32>,
@}
@end example

@noindent
@strong{Branching:} Heavy branching within vectorized loops reduces benefits.
Modern @abbr{SIMD} has masked operations, but they still execute both paths.

@strong{Small datasets:} Overhead of @abbr{SIMD} setup can exceed benefits for
small inputs. Always benchmark.

@strong{Portability:} While @code{std::simd} is portable, not all vector widths
are available on all platforms. Feature detection may be needed:

@example
#[cfg(target_feature = "avx2")]
fn fast_path(data: &[f32]) -> f32 @{
    // Use 256-bit SIMD
@}

#[cfg(not(target_feature = "avx2"))]
fn fast_path(data: &[f32]) -> f32 @{
    // Fallback to scalar or 128-bit SIMD
@}
@end example

@quotation
@strong{@anchor{Exercise 5.24a}Exercise 5.24a:} Implement three versions of a
function that normalizes a vector (divides each element by the magnitude): (1) a
scalar version using iterators, (2) an explicitly vectorized version using
@code{std::simd}, and (3) a version designed to trigger auto-vectorization.
Benchmark all three with @code{criterion} for vectors of length 1,000, 10,000,
and 100,000. Use @code{cargo asm} or @code{cargo llvm-ir} to inspect the
generated assembly. How does the compiler's auto-vectorized code compare to your
explicit @abbr{SIMD} implementation? What patterns in your code helped or
hindered auto-vectorization?
@end quotation

@quotation
@strong{@anchor{Exercise 5.25a}Exercise 5.25a:} The classic problem of computing
the Mandelbrot set is embarrassingly parallel at the pixel level but involves
complex iteration with early exit conditions. Implement a Mandelbrot set
renderer using @abbr{SIMD} to compute multiple pixels simultaneously. The
challenge is handling the variable iteration count—different points escape at
different times. Experiment with two strategies: (1) using @abbr{SIMD} masks to
``turn off'' lanes that have escaped, continuing until all lanes finish, and (2)
processing points in batches sorted by their expected iteration count. Which
approach is faster? How does the performance compare to a scalar implementation?
What does this teach you about the interaction between control flow and data
parallelism?
@end quotation

@node	5.4.3, 5.4.4, 5.4.2a, 5.4
@subsection 조건문, 대입, 그리고 정의 (Conditionals, Assignments, and Definitions)

메타순환 평가자와 마찬가지로, 특수 형식은 표현식의 조각들을 선택적으로 평가하여 처리된다.
@code{if} 표현식의 경우, 우리는 술어를 평가하고, 술어의 값에 따라 결과절을 평가할지 대안절을 평가할지 결정해야 한다.

술어를 평가하기 전에, 우리는 나중에 결과절이나 대안절을 추출할 수 있도록 @code{if} 표현식 자체를 저장한다.
또한 나중에 결과절이나 대안절을 평가하기 위해 필요할 환경을 저장하고, @code{if}의 값을 기다리고 있는 표현식의 평가로 돌아가기 위해 필요할 @code{continue}를 저장한다.

@lisp
ev_if
  (save exp)   @r{; 나중을 위해 표현식을 저장}
  (save env)
  (save continue)
  (assign continue (label ev_if_decide))
  (assign exp (op if_predicate) (reg exp))
  @r{; 술어를 평가:}
  (goto (label eval_dispatch))  
@end lisp

@noindent
술어를 평가하고 돌아오면, 우리는 그것이 참인지 거짓인지 테스트하고, 결과에 따라 결과절이나 대안절을 @code{exp}에 놓고 @code{eval_dispatch}로 간다.
여기서 @code{env}와 @code{continue}를 복원하면 @code{eval_dispatch}가 올바른 환경을 갖고 @code{if} 표현식의 값을 받을 올바른 위치에서 계속하도록 설정된다는 점에 주목하라.

@example
// ev-if-decide
Label("ev-if-decide".into()),
Restore("continue".into()),
Restore("env".into()),
Restore("exp".into()),
Test(Op("is-true".into(), vec![Reg("val".into())])),
Branch("ev-if-consequent".into()),
Label("ev-if-alternative".into()),
Assign("exp".into(), Op("if-alternative".into(), vec![Reg("exp".into())])),
Goto(Label("eval-dispatch".into())),
Label("ev-if-consequent".into()),
Assign("exp".into(), Op("if-consequent".into(), vec![Reg("exp".into())])),
Goto(Label("eval-dispatch".into())),
@end example

@subsubheading 대입과 정의 (Assignments and definitions)

대입은 @code{ev_assignment}에 의해 처리되는데, @code{exp}에 대입 표현식이 있는 상태로 @code{eval_dispatch}에서 여기에 도달한다.
@code{ev_assignment}에 있는 코드는 먼저 표현식의 값 부분을 평가하고 그런 다음 환경에 새 값을 설치한다.
@code{Set-variable-value!}가 기계 연산으로 사용 가능하다고 가정한다.

@lisp
ev_assignment
  (assign unev 
          (op assignment_variable)
          (reg exp))
  (save unev)   @r{; 나중을 위해 변수 저장}
  (assign exp
          (op assignment_value)
          (reg exp))
  (save env)
  (save continue)
  (assign continue
          (label ev_assignment_1))
  @r{; 대입 값을 평가:}
  (goto (label eval_dispatch))  
ev_assignment_1
  (restore continue)
  (restore env)
  (restore unev)
  (perform (op set_variable_value)
           (reg unev)
           (reg val)
           (reg env))
  (assign val
          (const ok))
  (goto (reg continue))
@end lisp

@noindent
정의도 비슷한 방식으로 처리된다:

@lisp
ev_definition
  (assign unev 
          (op definition_variable)
          (reg exp))
  (save unev)   @r{; 나중을 위해 변수 저장}
  (assign exp 
          (op definition_value)
          (reg exp))
  (save env)
  (save continue)
  (assign continue (label ev_definition_1))
  @r{; 정의 값을 평가:}
  (goto (label eval_dispatch))  
ev_definition_1
  (restore continue)
  (restore env)
  (restore unev)
  (perform (op define_variable)
           (reg unev)
           (reg val)
           (reg env))
  (assign val (const ok))
  (goto (reg continue))
@end lisp

@quotation
@strong{@anchor{Exercise 5.23}연습문제 5.23:} @code{cond}, @code{let} 등과 같은 파생된 표현식을 처리하도록 평가자를 확장하라(@ref{4.1.2} 참조).
@code{cond_to_if}와 같은 구문 변환기가 기계 연산으로 사용 가능하다고 가정하고 ``속임수''를 써도 된다.@footnote{이것은 실제로 속임수가 아니다. 처음부터 구축된 실제 구현에서, 우리는 실행 전에 실행되는 구문 단계에서 @code{cond_to_if}와 같은 소스 수준 변환을 수행하는 Scheme 프로그램을 해석하기 위해 우리의 명시적 제어 평가자를 사용할 것이다.}
@end quotation

@quotation
@strong{@anchor{Exercise 5.24}연습문제 5.24:} @code{cond}를 @code{if}로 축소하지 않고 새로운 기본 특수 형식으로 구현하라.
참인 것을 찾을 때까지 연속적인 @code{cond} 절의 술어를 테스트하는 루프를 구성한 다음, 절의 행동을 평가하기 위해 @code{ev_sequence}를 사용해야 할 것이다.
@end quotation

@quotation
@strong{@anchor{Exercise 5.25}연습문제 5.25:} @ref{4.2}의 지연 평가자에 기초하여 정규 순서 평가를 사용하도록 평가자를 수정하라.
@end quotation

@node	5.4.4, 5.5, 5.3, 5.4
@subsection 평가자 실행하기 (Running the Evaluator)

명시적 제어 평가자의 구현으로 우리는 @ref{Chapter 1}에서 시작하여 평가 프로세스의 더 정밀한 모델을 연속적으로 탐구해 온 개발의 끝에 도달했다.
우리는 비교적 비공식적인 치환 모델로 시작하여, @ref{Chapter 3}에서 이를 환경 모델로 확장하여 상태와 변화를 다룰 수 있게 했다.
@ref{Chapter 4}의 메타순환 평가자에서, 우리는 Scheme 자체를 언어로 사용하여 표현식 평가 중에 구성되는 환경 구조를 더 명시적으로 만들었다.
이제, 레지스터 기계를 통해, 우리는 저장소 관리, 인자 전달, 제어에 대한 평가자의 메커니즘을 면밀히 살펴보았다.
각각의 새로운 설명 수준에서, 우리는 이전의 덜 정밀한 평가 처리에서는 명확하지 않았던 문제를 제기하고 모호함을 해결해야 했다.
명시적 제어 평가자의 동작을 이해하기 위해, 우리는 그것을 시뮬레이션하고 성능을 모니터링할 수 있다.

우리는 평가자 기계에 드라이버 루프를 설치할 것이다.
이것은 @ref{4.1.4}의 @code{driver_loop} 프로시저의 역할을 한다.
평가자는 반복적으로 프롬프트를 출력하고, 표현식을 읽고, @code{eval_dispatch}로 가서 표현식을 평가하고, 결과를 출력할 것이다.
다음 명령어들은 명시적 제어 평가자의 컨트롤러 시퀀스의 시작 부분을 형성한다:@footnote{우리는 여기서 @code{read}와 다양한 출력 연산이 원시 기계 연산으로 사용 가능하다고 가정하는데, 이는 시뮬레이션에는 유용하지만 실제로는 완전히 비현실적이다. 이것들은 실제로 매우 복잡한 연산이다. 실제로는 장치와 단일 문자를 주고받는 것과 같은 저수준 입출력 연산을 사용하여 구현될 것이다.

@code{get_global_environment} 연산을 지원하기 위해 우리는 다음을 정의한다

@lisp
let global_env = setup_environment();

fn get_global_environment() -> Environment @{
    global_env.clone()
@}
@end lisp
}

@lisp
read_eval_print_loop
  (perform (op initialize_stack))
  (perform (op prompt_for_input)
           (const ";;; EC-Eval input:"))
  (assign exp (op read))
  (assign env (op get_global_environment))
  (assign continue (label print_result))
  (goto (label eval_dispatch))
print_result
  (perform (op announce_output)
           (const ";;; EC-Eval value:"))
  (perform (op user_print) (reg val))
  (goto (label read_eval_print_loop))
@end lisp

@noindent
프로시저에서 오류가 발생하면(@code{apply_dispatch}에서 표시된 ``알 수 없는 프로시저 유형 오류''와 같은), 오류 메시지를 출력하고 드라이버 루프로 돌아간다.@footnote{인터프리터가 처리했으면 하는 다른 오류들이 있지만, 이것들은 그리 간단하지 않다. @ref{Exercise 5.30}을 참조하라.}

@lisp
unknown_expression_type
  (assign 
   val
   (const unknown_expression_type_error))
  (goto (label signal_error))
unknown_procedure_type
  @r{; 스택 정리 (@code{apply_dispatch}로부터):}
  (restore continue)    
  (assign 
   val
   (const unknown_procedure_type_error))
  (goto (label signal_error))
signal_error
  (perform (op user_print) (reg val))
  (goto (label read_eval_print_loop))
@end lisp

@noindent
시뮬레이션의 목적을 위해, 우리는 드라이버 루프를 통과할 때마다 스택을 초기화하는데, 왜냐하면 오류(정의되지 않은 변수와 같은)가 평가를 중단시킨 후에 스택이 비어 있지 않을 수 있기 때문이다.@footnote{우리는 오류 후에만 스택 초기화를 수행할 수도 있지만, 드라이버 루프에서 수행하는 것이 아래에서 설명할 평가자의 성능을 모니터링하는 데 편리할 것이다.}

우리가 @ref{5.4.1}--@ref{5.4.4}에서 제시된 모든 코드 조각을 결합하면, @ref{5.2}의 레지스터 기계 시뮬레이터를 사용하여 실행할 수 있는 평가자 기계 모델을 생성할 수 있다.

@lisp
let mut eceval = make_machine(
    vec!["exp", "env", "val", "proc", "argl", "continue", "unev"],
    eceval_operations,
    vec![
        Inst::Label("read_eval_print_loop".to_string()),
        // ... 위에 주어진 전체 기계 컨트롤러 ...
    ],
);
@end lisp

@noindent
우리는 평가자가 원시로 사용하는 연산을 시뮬레이션하기 위해 Scheme 프로시저를 정의해야 한다.
이것들은 @ref{4.1}에서 메타순환 평가자를 위해 사용했던 것과 같은 프로시저들이며, @ref{5.4} 전체에 걸쳐 각주에서 정의된 몇 가지 추가적인 것들과 함께 사용된다.

@lisp
let eceval_operations = vec![
    ("is_self_evaluating", is_self_evaluating),
    // ... eceval 기계를 위한 전체 연산 리스트 ...
];
@end lisp

@noindent
마지막으로, 전역 환경을 초기화하고 평가자를 실행할 수 있다:

@lisp
let global_env = setup_environment();

eceval.start();

@i{;;; EC-Eval input:}
fn append(x, y) @{
    if x.is_null() @{ y @} else @{ cons(x.car(), append(x.cdr(), y)) @}
@}

@i{;;; EC-Eval value:}
@i{ok}

@i{;;; EC-Eval input:}
append(list("a", "b", "c"), list("d", "e", "f"))

@i{;;; EC-Eval value:}
@i{(a b c d e f)}
@end lisp

@noindent
물론, 이런 방식으로 표현식을 평가하는 것은 Scheme에 직접 입력했을 때보다 훨씬 오래 걸릴 것이다. 왜냐하면 여러 수준의 시뮬레이션이 포함되기 때문이다.
우리의 표현식은 명시적 제어 평가자 기계에 의해 평가되고 있는데, 이 기계는 Scheme 프로그램에 의해 시뮬레이션되고 있으며, 이 Scheme 프로그램 자체는 Scheme 인터프리터에 의해 평가되고 있다.

@subsubheading 평가자 성능 모니터링 (Monitoring the performance of the evaluator)

시뮬레이션은 평가자 구현을 안내하는 강력한 도구가 될 수 있다.
시뮬레이션은 레지스터 기계 설계의 변형을 탐색하는 것뿐만 아니라 시뮬레이션된 평가자의 성능을 모니터링하는 것도 쉽게 만든다.
예를 들어, 성능의 중요한 요소 중 하나는 평가자가 스택을 얼마나 효율적으로 사용하는가이다.
우리는 스택 사용에 대한 통계를 수집하는 시뮬레이터 버전(@ref{5.2.4})으로 평가자 레지스터 기계를 정의하고, 통계를 출력하기 위해 평가자의 @code{print_result} 진입점에 명령어를 추가함으로써 다양한 표현식을 평가하는 데 필요한 스택 연산의 수를 관찰할 수 있다:

@lisp
print_result
  @r{; 추가된 명령어:}
  (perform (op print_stack_statistics))
  (perform (op announce_output)
           (const ";;; EC-Eval value:"))
  @r{…} @r{; 이전과 동일}
@end lisp

@noindent
평가자와의 상호 작용은 이제 다음과 같이 보인다:

@lisp
@i{;;; EC-Eval input:}
fn factorial(n) @{
    if n == 1 @{ 1 @} else @{ factorial(n - 1) * n @}
@}
@i{(total-pushes = 3, maximum-depth = 3)}

@i{;;; EC-Eval value:}
@i{ok}

@i{;;; EC-Eval input:}
factorial(5)
@i{(total-pushes = 144, maximum-depth = 28)}

@i{;;; EC-Eval value:}
@i{120}
@end lisp

@noindent
평가자의 드라이버 루프는 각 상호 작용의 시작 부분에서 스택을 다시 초기화하므로, 출력된 통계는 이전 표현식을 평가하는 데 사용된 스택 연산만을 참조한다는 점에 유의하라.

@quotation
@strong{@anchor{Exercise 5.26}연습문제 5.26:} 모니터링된 스택을 사용하여 평가자의 꼬리 재귀 속성을 탐구하라(@ref{5.4.2}).
평가자를 시작하고 @ref{1.2.1}의 반복적 @code{factorial} 프로시저를 정의하라:

@lisp
fn factorial(n: u64) -> u64 @{
    fn iter(product: u64, counter: u64) -> u64 @{
        if counter > n @{
            product
        @} else @{
            iter(counter * product, counter + 1)
        @}
    @}
    iter(1, 1)
@}
@end lisp

@math{n}의 몇 가지 작은 값으로 프로시저를 실행하라.
각 값에 대해 @math{{n!}}을 계산하는 데 필요한 최대 스택 깊이와 푸시 횟수를 기록하라.

@enumerate a

@item
당신은 @math{{n!}}을 평가하는 데 필요한 최대 깊이가 @math{n}과 무관하다는 것을 발견할 것이다. 그 깊이는 얼마인가?

@item
데이터로부터 @math{{n \ge 1}}인 @math{{n!}}을 평가하는 데 사용된 총 푸시 연산 횟수에 대한 @math{n}에 관한 공식을 결정하라.
사용된 연산의 수는 @math{n}의 선형 함수이며 따라서 두 상수에 의해 결정된다는 점에 유의하라.

@end enumerate
@end quotation

@quotation
@strong{@anchor{Exercise 5.27}연습문제 5.27:} @ref{Exercise 5.26}과의 비교를 위해, 팩토리얼을 재귀적으로 계산하는 다음 프로시저의 동작을 탐구하라:

@example
fn factorial(n: i64) -> i64 @{
    if n == 1 @{ 1 @} else @{ factorial(n - 1) * n @}
@}
@end example

모니터링된 스택으로 이 프로시저를 실행하여, @math{n}의 함수로서, @math{{n \ge 1}}에 대해 @math{{n!}}을 평가하는 데 사용된 스택의 최대 깊이와 총 푸시 횟수를 결정하라. (다시 말하지만, 이 함수들은 선형일 것이다.)
@math{n}에 관한 적절한 표현식으로 다음 표를 채워 실험을 요약하라:
@ifinfo

@noindent
@b{Rust (evaluator core):}
@example
pub fn eval(expr: &Expr, env: Rc<Environment>) -> Result<Value, String> @{
    match expr @{
        Expr::Number(n) => Ok(Value::Number(*n)),
        Expr::Symbol(name) => env.borrow().lookup(name)
            .ok_or_else(|| format!("Unbound variable: @{@}", name)),
        Expr::Lambda @{ params, body @} => Ok(Value::Procedure @{
            params: params.clone(),
            body: body.clone(),
            env: env.clone(),
        @}),
        Expr::If @{ predicate, consequent, alternative @} => @{
            if eval(predicate, env.clone())?.is_true() @{
                eval(consequent, env)
            @} else @{
                eval(alternative, env)
            @}
        @}
        Expr::Application @{ operator, operands @} => @{
            let proc = eval(operator, env.clone())?;
            let args: Result<Vec<_>, _> = operands.iter()
                .map(|e| eval(e, env.clone()))
                .collect();
            apply(proc, args?)
        @}
        // ... 다른 경우들 ...
    @}
@}
@end example


@example
               최대 깊이           푸시 횟수

재귀적
팩토리얼

반복적
팩토리얼
@end example

@end ifinfo
@tex
\[ % :82:

\begin{array}{l|l|l}
                	& \text{Maximum} 	& \text{Number of} 	\\
                	& \text{depth} 	        & \text{pushes} 	\\
\hline
\text{Recursive} 	&	                &  \\
\text{factorial} 	&  	                &  \\
\hline
\text{Iterative} 	&               	&  \\
\text{factorial} 	&  	                & 
\end{array}
\]
@end tex
최대 깊이는 계산을 수행하는 데 평가자가 사용하는 공간의 양을 나타내는 척도이며, 푸시 횟수는 필요한 시간과 잘 상관된다.
@end quotation

@quotation
@strong{@anchor{Exercise 5.28}연습문제 5.28:} 평가자가 더 이상 꼬리 재귀적이지 않도록 @ref{5.4.2}에서 설명한 대로 @code{eval_sequence}를 변경하여 평가자의 정의를 수정하라.
@ref{Exercise 5.26}과 @ref{Exercise 5.27}의 실험을 다시 실행하여 @code{factorial} 프로시저의 두 버전 모두 이제 입력에 선형적으로 증가하는 공간을 요구함을 보여라.
@end quotation

@quotation
@strong{@anchor{Exercise 5.29}연습문제 5.29:} 트리 재귀적 피보나치 계산에서 스택 연산을 모니터링하라:

@example
fn fib(n: u64) -> u64 @{
    if n < 2 @{ n @} else @{ fib(n - 1) + fib(n - 2) @}
@}
@end example

@enumerate a

@item
@math{{n \ge 2}}에 대해 @math{{\text{Fib}(n)}}을 계산하는 데 필요한 스택의 최대 깊이에 대한 @math{n}에 관한 공식을 제시하라. 힌트: @ref{1.2.2}에서 우리는 이 프로세스가 사용하는 공간이 @math{n}에 선형적으로 증가한다고 주장했다.

@item
@math{{n \ge 2}}에 대해 @math{{\text{Fib}(n)}}을 계산하는 데 사용된 총 푸시 횟수에 대한 공식을 제시하라. 당신은 푸시 횟수(사용된 시간과 잘 상관됨)가 @math{n}에 따라 기하급수적으로 증가함을 발견해야 한다. 힌트: @math{{S(n)}}을 @math{{\text{Fib}(n)}}을 계산하는 데 사용된 푸시 횟수라고 하자. 당신은 @math{{S(n)}}을 @math{{S(n - 1)}}, @math{{S(n - 2)}}, 그리고 @math{n}과 무관한 어떤 고정된 ``오버헤드'' 상수 @math{k}로 표현하는 공식이 있다고 주장할 수 있어야 한다. 공식을 제시하고 @math{k}가 무엇인지 말하라. 그런 다음 @math{{S(n)}}이 @math{{a\cdot\text{Fib}(n + 1) + b}}로 표현될 수 있음을 보이고 @math{a}와 @math{b}의 값을 제시하라.

@end enumerate
@end quotation

@quotation
@strong{@anchor{Exercise 5.30}연습문제 5.30:} 우리 평가자는 현재 두 가지 종류의 오류---알 수 없는 표현식 유형과 알 수 없는 프로시저 유형---만 잡아서 신호한다.
다른 오류들은 우리를 평가자 읽기-평가-출력 루프 밖으로 내보낼 것이다.
우리가 레지스터 기계 시뮬레이터를 사용하여 평가자를 실행할 때, 이러한 오류들은 기본 Scheme 시스템에 의해 잡힌다.
이것은 사용자 프로그램이 오류를 범할 때 컴퓨터가 충돌하는 것과 유사하다.@footnote{유감스럽게도, 이것은 C와 같은 전통적인 컴파일러 기반 언어 시스템의 정상적인 상태이다. @abbr{UNIX}(tm)에서 시스템은 ``코어 덤프(dumps core)''를 하고, @abbr{DOS}/Windows(tm)에서는 긴장증(catatonic) 상태가 된다. 매킨토시(tm)는 폭발하는 폭탄 그림을 표시하고 컴퓨터를 재부팅할 기회를 제공한다---운이 좋다면 말이다.} 실제 오류 시스템을 작동하게 만드는 것은 큰 프로젝트이지만, 여기 관련된 것을 이해하기 위해 노력할 가치가 충분하다.

@enumerate a

@item
바인딩되지 않은 변수에 접근하려는 시도와 같이 평가 프로세스에서 발생하는 오류는 조회 연산이 어떤 사용자 변수의 가능한 값도 될 수 없는 구별되는 조건 코드를 반환하도록 변경함으로써 잡을 수 있다.
평가자는 이 조건 코드를 테스트한 다음 @code{signal_error}로 가기 위해 필요한 작업을 수행할 수 있다.
평가자에서 그러한 변경이 필요한 모든 곳을 찾아 수정하라. 이것은 많은 작업이다.

@item
훨씬 더 나쁜 것은 0으로 나누려고 시도하거나 기호의 @code{car}를 추출하려고 시도하는 것과 같이 원시 프로시저를 적용함으로써 신호되는 오류를 처리하는 문제이다.
전문적으로 작성된 고품질 시스템에서, 각 원시 적용은 원시의 일부로서 안전성을 검사받는다.
예를 들어, @code{car}에 대한 모든 호출은 먼저 인자가 쌍인지 확인할 수 있다.
인자가 쌍이 아니라면, 적용은 평가자에게 구별되는 조건 코드를 반환하고, 평가자는 실패를 보고할 것이다.
우리는 각 원시 프로시저가 적용 가능성을 확인하고 실패 시 적절한 구별되는 조건 코드를 반환하도록 함으로써 레지스터 기계 시뮬레이터에서 이것을 마련할 수 있다. 그러면 평가자의 @code{primitive_apply} 코드가 조건 코드를 확인하고 필요한 경우 @code{signal_error}로 갈 수 있다. 이 구조를 구축하고 작동하게 하라. 이것은 주요 프로젝트이다.

@end enumerate
@end quotation

@node	5.5, References, 5.4, Chapter 5
@section 컴파일 (Compilation)

@ref{5.4}의 명시적 제어 평가자는 Scheme 프로그램을 해석하는 컨트롤러를 가진 레지스터 기계이다.
이 절에서 우리는 컨트롤러가 Scheme 인터프리터가 아닌 레지스터 기계에서 Scheme 프로그램을 실행하는 방법을 볼 것이다.

명시적 제어 평가자 기계는 범용적이다---이것은 Scheme으로 기술될 수 있는 어떤 계산 프로세스도 수행할 수 있다.
평가자의 컨트롤러는 원하는 계산을 수행하기 위해 데이터 경로의 사용을 조직한다.
따라서, 평가자의 데이터 경로는 범용적이다: 적절한 컨트롤러가 주어지면, 이것들은 우리가 원하는 어떤 계산도 수행하기에 충분하다.@footnote{이것은 이론적인 진술이다. 우리는 평가자의 데이터 경로가 범용 컴퓨터를 위한 특별히 편리하거나 효율적인 데이터 경로 집합이라고 주장하는 것이 아니다. 예를 들어, 그것들은 고성능 부동 소수점 계산이나 비트 벡터를 집중적으로 조작하는 계산을 구현하는 데에는 별로 좋지 않다.}

상업용 범용 컴퓨터는 효율적이고 편리한 범용 데이터 경로 집합을 구성하는 레지스터와 연산의 모음을 중심으로 조직된 레지스터 기계이다.
범용 기계를 위한 컨트롤러는 우리가 사용해 온 것과 같은 레지스터 기계 언어를 위한 인터프리터이다.
이 언어를 기계의 @newterm{네이티브 언어(native language)} 또는 간단히 @newterm{기계어(machine language)}라고 부른다.
기계어로 작성된 프로그램은 기계의 데이터 경로를 사용하는 명령어의 시퀀스이다.
예를 들어, 명시적 제어 평가자의 명령어 시퀀스는 특수 목적 인터프리터 기계를 위한 컨트롤러라기보다는 범용 컴퓨터를 위한 기계어 프로그램으로 생각할 수 있다.

고수준 언어와 레지스터 기계 언어 사이의 간극을 메우는 데는 두 가지 일반적인 전략이 있다.
명시적 제어 평가자는 해석(interpretation) 전략을 예시한다.
기계의 네이티브 언어로 작성된 인터프리터는 기계가 평가를 수행하는 기계의 네이티브 언어와 다를 수 있는 언어(@newterm{소스 언어(source language)}라고 함)로 작성된 프로그램을 실행하도록 구성한다.
소스 언어의 원시 프로시저는 주어진 기계의 네이티브 언어로 작성된 서브루틴 라이브러리로 구현된다.
해석될 프로그램(@newterm{소스 프로그램(source program)}이라고 함)은 데이터 구조로 표현된다.
인터프리터는 이 데이터 구조를 순회하며 소스 프로그램을 분석한다.
그렇게 하면서, 라이브러리에서 적절한 원시 서브루틴을 호출하여 소스 프로그램의 의도된 동작을 시뮬레이션한다.

이 절에서 우리는 @newterm{컴파일(compilation)}이라는 대안적인 전략을 탐구한다.
주어진 소스 언어와 기계에 대한 컴파일러는 소스 프로그램을 기계의 네이티브 언어로 작성된 동등한 프로그램(@newterm{목적 프로그램(object program)}이라고 함)으로 번역한다.
우리가 이 절에서 구현하는 컴파일러는 Scheme으로 작성된 프로그램을 명시적 제어 평가자 기계의 데이터 경로를 사용하여 실행될 명령어 시퀀스로 번역한다.@footnote{사실, 컴파일된 코드를 실행하는 기계는 인터프리터 기계보다 더 간단할 수 있는데, 왜냐하면 우리는 @code{exp}와 @code{unev} 레지스터를 사용하지 않을 것이기 때문이다. 인터프리터는 평가되지 않은 표현식의 조각을 유지하기 위해 이것들을 사용했다. 그러나 컴파일러를 사용하면, 이러한 표현식들은 레지스터 기계가 실행할 컴파일된 코드에 내장된다. 같은 이유로, 우리는 표현식 구문을 다루는 기계 연산이 필요하지 않다. 그러나 컴파일된 코드는 명시적 제어 평가자 기계에 나타나지 않았던 몇 가지 추가적인 기계 연산(컴파일된 프로시저 객체를 나타내기 위한)을 사용할 것이다.}

해석과 비교하여, 컴파일은 프로그램 실행의 효율성을 크게 높일 수 있는데, 이는 아래 컴파일러 개요에서 설명할 것이다.
반면에, 인터프리터는 대화형 프로그램 개발 및 디버깅을 위한 더 강력한 환경을 제공하는데, 왜냐하면 실행 중인 소스 프로그램을 런타임에 검사하고 수정할 수 있기 때문이다.
또한, 전체 원시 라이브러리가 존재하기 때문에, 디버깅 중에 새 프로그램을 구성하고 시스템에 추가할 수 있다.

컴파일과 해석의 상호 보완적인 장점을 고려하여, 현대적인 프로그램 개발 환경은 혼합 전략을 추구한다.
Lisp 인터프리터는 일반적으로 해석된 프로시저와 컴파일된 프로시저가 서로 호출할 수 있도록 조직된다.
이것은 프로그래머가 디버깅된 것으로 추정되는 프로그램 부분을 컴파일하여 컴파일의 효율성 이점을 얻으면서, 대화형 개발 및 디버깅의 흐름 속에 있는 프로그램 부분에 대해서는 해석 실행 모드를 유지할 수 있게 해준다.
@ref{5.5.7}에서, 컴파일러를 구현한 후, 우리는 통합된 인터프리터-컴파일러 개발 시스템을 생산하기 위해 컴파일러를 인터프리터와 인터페이스하는 방법을 보여줄 것이다.

@subsubheading 컴파일러 개요 (An overview of the compiler)

우리의 컴파일러는 구조와 수행하는 기능 모두에서 우리의 인터프리터와 매우 유사하다.
따라서, 컴파일러가 표현식을 분석하는 데 사용하는 메커니즘은 인터프리터가 사용하는 것과 유사할 것이다.
더욱이, 컴파일된 코드와 해석된 코드를 쉽게 인터페이스하기 위해, 우리는 컴파일러가 인터프리터와 동일한 레지스터 사용 관례를 따르는 코드를 생성하도록 설계할 것이다:
환경은 @code{env} 레지스터에 유지되고, 인자 리스트는 @code{argl}에 누적되며, 적용될 프로시저는 @code{proc}에 있고, 프로시저는 답을 @code{val}에 반환하며, 프로시저가 반환해야 할 위치는 @code{continue}에 유지될 것이다.

Rust에서, 우리 컴파일러의 기본 데이터 구조는 @code{InstructionSeq}인데, 이것은 기계 명령어뿐만 아니라 어떤 레지스터가 필요하고 어떤 레지스터가 수정되는지에 대한 정보도 포함한다:

@example
pub struct InstructionSeq @{
    pub needs: HashSet<Register>,
    pub modifies: HashSet<Register>,
    pub statements: Vec<Instruction>,
@}
@end example

이 명시적인 추적은 컴파일러가 불필요한 스택 연산을 피함으로써 최적화된 코드를 생성할 수 있게 해준다.
일반적으로, 컴파일러는 소스 프로그램을 동일한 소스 프로그램을 평가할 때 인터프리터가 수행할 것과 본질적으로 같은 레지스터 연산을 수행하는 목적 프로그램으로 번역한다.

이 설명은 초보적인 컴파일러를 구현하기 위한 전략을 제안한다:
우리는 인터프리터가 하는 것과 같은 방식으로 표현식을 순회한다.
인터프리터가 표현식을 평가할 때 수행할 레지스터 명령어를 만나면, 우리는 명령어를 실행하는 대신 시퀀스에 누적한다.
결과 명령어 시퀀스가 목적 코드가 될 것이다.
해석에 대한 컴파일의 효율성 이점을 관찰하라.
인터프리터가 표현식---예를 들어 @code{(f 84 96)}---을 평가할 때마다, 표현식을 분류하고(이것이 프로시저 적용임을 발견하고) 피연산자 리스트의 끝을 테스트하는(두 개의 피연산자가 있음을 발견하는) 작업을 수행한다.
컴파일러를 사용하면, 표현식은 컴파일 타임에 명령어 시퀀스가 생성될 때 단 한 번만 분석된다.
컴파일러가 생성한 목적 코드는 연산자와 두 피연산자를 평가하고, 인자 리스트를 조립하고, (@code{argl}에 있는) 인자에 (@code{proc}에 있는) 프로시저를 적용하는 명령어만 포함한다.

이것은 우리가 @ref{4.1.7}의 분석 평가자에서 구현한 것과 같은 종류의 최적화이다.
그러나 컴파일된 코드에는 효율성을 얻을 수 있는 더 많은 기회가 있다.
인터프리터가 실행될 때, 그것은 언어의 어떤 표현식에도 적용될 수 있어야 하는 프로세스를 따른다.
반면, 컴파일된 코드의 주어진 세그먼트는 어떤 특정 표현식을 실행하기 위한 것이다.
이것은 큰 차이를 만들 수 있는데, 예를 들어 레지스터를 저장하기 위한 스택 사용에서 그렇다.
인터프리터가 표현식을 평가할 때, 그것은 어떤 우발 상황에도 대비해야 한다.
하위 표현식을 평가하기 전에, 인터프리터는 나중에 필요할 모든 레지스터를 저장하는데, 왜냐하면 하위 표현식이 임의의 평가를 요구할 수 있기 때문이다.
반면 컴파일러는 처리하고 있는 특정 표현식의 구조를 활용하여 불필요한 스택 연산을 피하는 코드를 생성할 수 있다.

일례로, 조합 @code{(f 84 96)}을 고려해 보자.
인터프리터가 조합의 연산자를 평가하기 전에, 나중에 값이 필요할 피연산자와 환경을 포함하는 레지스터를 저장하여 이 평가를 준비한다.
그런 다음 인터프리터는 연산자를 평가하여 @code{val}에 결과를 얻고, 저장된 레지스터를 복원한 다음, 마지막으로 결과를 @code{val}에서 @code{proc}으로 이동한다.
그러나 우리가 다루는 특정 표현식에서 연산자는 기호 @code{f}이며, 그 평가는 레지스터를 변경하지 않는 기계 연산 @code{lookup_variable_value}에 의해 수행된다.
우리가 이 절에서 구현하는 컴파일러는 이 사실을 활용하여 다음 명령어를 사용하여 연산자를 평가하는 코드를 생성할 것이다

@lisp
(assign proc 
        (op lookup_variable_value)
        (const f)
        (reg env))
@end lisp

@noindent
이 코드는 불필요한 저장 및 복원을 피할 뿐만 아니라 조회의 값을 @code{proc}에 직접 할당한다. 반면 인터프리터는 결과를 @code{val}에 얻은 다음 이것을 @code{proc}으로 이동할 것이다.

컴파일러는 또한 환경에 대한 접근을 최적화할 수 있다.
코드를 분석했으므로, 컴파일러는 많은 경우 특정 변수가 어느 프레임에 위치할지 알 수 있으며, @code{lookup_variable_value} 검색을 수행하는 대신 해당 프레임에 직접 접근할 수 있다.
우리는 @ref{5.5.6}에서 그러한 변수 접근을 구현하는 방법을 논의할 것이다.
그러나 그때까지는 위에서 설명한 종류의 레지스터 및 스택 최적화에 초점을 맞출 것이다.
일반적인 @code{apply} 메커니즘을 사용하는 대신 원시 연산을 ``인라인''으로 코딩하는 것과 같이 컴파일러가 수행할 수 있는 다른 많은 최적화가 있다(@ref{Exercise 5.38} 참조); 그러나 우리는 여기서 이것들을 강조하지 않을 것이다.
이 절의 주요 목표는 단순화된(하지만 여전히 흥미로운) 맥락에서 컴파일 프로세스를 설명하는 것이다.

@menu
* 5.5.1::            Structure of the Compiler
* 5.5.2::            Compiling Expressions
* 5.5.3::            Compiling Combinations
* 5.5.4::            Combining Instruction Sequences
* 5.5.5::            An Example of Compiled Code
* 5.5.6::            Lexical Addressing
* 5.5.7::            Interfacing Compiled Code to the Evaluator
@end menu

@node	5.5.1, 5.5.2, 5.5, 5.5
@subsection 컴파일러의 구조 (Structure of the Compiler)

@ref{4.1.7}에서 우리는 분석과 실행을 분리하기 위해 원래의 메타순환 인터프리터를 수정했다.
우리는 각 표현식을 분석하여 환경을 인자로 받아 필요한 연산을 수행하는 실행 프로시저를 생성했다.
우리 컴파일러에서, 우리는 본질적으로 동일한 분석을 수행할 것이다.
그러나 실행 프로시저를 생성하는 대신, 우리는 레지스터 기계에서 실행될 명령어 시퀀스를 생성할 것이다.

프로시저 @code{compile}은 컴파일러의 최상위 디스패치이다.
이것은 @ref{4.1.1}의 @code{eval} 프로시저, @ref{4.1.7}의 @code{analyze} 프로시저, 그리고 @ref{5.4.1}의 명시적 제어 평가자의 @code{eval_dispatch} 진입점에 해당한다.
인터프리터와 마찬가지로 컴파일러는 @ref{4.1.2}에 정의된 표현식 구문 프로시저를 사용한다.@footnote{그러나, 우리 컴파일러는 Scheme 프로그램이며, 표현식을 조작하는 데 사용하는 구문 프로시저는 메타순환 평가자와 함께 사용되는 실제 Scheme 프로시저라는 점에 주목하라. 반면 명시적 제어 평가자의 경우, 우리는 동등한 구문 연산이 레지스터 기계의 연산으로 사용 가능하다고 가정했다. (물론, 우리가 Scheme에서 레지스터 기계를 시뮬레이션할 때, 우리는 레지스터 기계 시뮬레이션에서 실제 Scheme 프로시저를 사용했다.)}
@code{Compile}은 컴파일할 표현식의 구문 유형에 대해 사례 분석을 수행한다.
각 유형의 표현식에 대해, 이것은 전문화된 @newterm{코드 생성기(code generator)}로 디스패치한다:

@lisp
pub fn compile(expr: &Expr, target: Register, linkage: &Linkage) -> InstructionSeq @{
    match expr @{
        Expr::Number(_) | Expr::String(_) => compile_self_evaluating(expr, target, linkage),
        Expr::Quote(_) => compile_quoted(expr, target, linkage),
        Expr::Symbol(_) => compile_variable(expr, target, linkage),
        Expr::Set @{ .. @} => compile_assignment(expr, target, linkage),
        Expr::Define @{ .. @} => compile_definition(expr, target, linkage),
        Expr::If @{ .. @} => compile_if(expr, target, linkage),
        Expr::Lambda @{ .. @} => compile_lambda(expr, target, linkage),
        Expr::Begin(exprs) => compile_sequence(exprs, target, linkage),
        Expr::Cond(clauses) => @{
            // cond를 중첩된 if로 변환
            let if_expr = cond_to_if(clauses);
            compile(&if_expr, target, linkage)
        @}
        Expr::Application @{ .. @} => compile_application(expr, target, linkage),
    @}
@}
@end lisp

@subsubheading 타겟과 링키지 (Targets and linkages)

@code{Compile}과 그것이 호출하는 코드 생성기들은 컴파일할 표현식 외에도 두 개의 인자를 받는다.
@newterm{타겟(target)}이 있는데, 이는 컴파일된 코드가 표현식의 값을 반환할 레지스터를 지정한다.
또한 @newterm{링키지 기술자(linkage descriptor)}가 있는데, 이는 표현식의 컴파일 결과로 나온 코드가 실행을 마쳤을 때 어떻게 진행해야 하는지를 설명한다.
링키지 기술자는 코드가 다음 세 가지 중 하나를 수행하도록 요구할 수 있다:

@itemize @bullet

@item
시퀀스의 다음 명령어로 계속한다 (이것은 링키지 기술자 @code{next}에 의해 지정된다),

@item
컴파일 중인 프로시저에서 반환한다 (이것은 링키지 기술자 @code{return}에 의해 지정된다), 또는

@item
명명된 진입점으로 점프한다 (이것은 지정된 레이블을 링키지 기술자로 사용하여 지정된다).

@end itemize

@noindent
예를 들어, @code{val} 레지스터를 타겟으로 하고 @code{next} 링키지로 표현식 @code{5}(자체 평가됨)를 컴파일하면 다음 명령어가 생성되어야 한다

@lisp
(assign val (const 5))
@end lisp

@noindent
동일한 표현식을 @code{return} 링키지로 컴파일하면 다음 명령어가 생성되어야 한다

@lisp
(assign val (const 5))
(goto (reg continue))
@end lisp

@noindent
첫 번째 경우, 실행은 시퀀스의 다음 명령어로 계속될 것이다.
두 번째 경우, 우리는 프로시저 호출에서 반환할 것이다.
두 경우 모두, 표현식의 값은 타겟 @code{val} 레지스터에 놓일 것이다.

@subsubheading 명령어 시퀀스와 스택 사용 (Instruction sequences and stack usage)

각 코드 생성기는 표현식에 대해 생성한 목적 코드를 포함하는 @newterm{명령어 시퀀스(instruction sequence)}를 반환한다.
복합 표현식에 대한 코드 생성은 구성 요소 표현식에 대한 더 간단한 코드 생성기들의 출력을 결합함으로써 달성된다. 이는 복합 표현식의 평가가 구성 요소 표현식들을 평가함으로써 달성되는 것과 같다.

명령어 시퀀스를 결합하는 가장 간단한 방법은 @code{append_instruction_sequences}라는 프로시저이다.
이것은 순차적으로 실행될 임의의 수의 명령어 시퀀스를 인자로 받는다; 이것은 그것들을 덧붙여서 결합된 시퀀스를 반환한다.
즉, 만약 @math{{⟨\kern0.1em seq_1⟩}}과 @math{{⟨\kern0.1em seq_2⟩}}가 명령어 시퀀스라면, 다음을 평가하면

@lisp
(append-instruction-sequences ⟨@var{seq₁}⟩ ⟨@var{seq₂}⟩)
@end lisp

@noindent
@b{Rust (명령어 시퀀스 덧붙이기):}
@example
pub fn append_instruction_sequences(
    seq1: InstructionSeq,
    seq2: InstructionSeq
) -> InstructionSeq @{
    let mut needs = seq1.needs.clone();
    needs.extend(
        seq2.needs.difference(&seq1.modifies).cloned()
    );

    let mut modifies = seq1.modifies.clone();
    modifies.extend(seq2.modifies.iter().cloned());

    let mut statements = seq1.statements;
    statements.extend(seq2.statements);

    InstructionSeq @{ needs, modifies, statements @}
@}
@end example

@noindent
다음 시퀀스를 생성한다

@lisp
⟨@var{seq₁}⟩
⟨@var{seq₂}⟩
@end lisp

@noindent
레지스터를 저장해야 할 수도 있을 때마다, 컴파일러의 코드 생성기들은 명령어 시퀀스를 결합하는 더 미묘한 방법인 @code{preserving}을 사용한다.
@code{Preserving}은 세 개의 인자를 받는다: 레지스터 집합과 순차적으로 실행될 두 개의 명령어 시퀀스.
이것은 두 번째 시퀀스의 실행을 위해 필요하다면 집합에 있는 각 레지스터의 내용이 첫 번째 시퀀스의 실행 동안 보존되는 방식으로 시퀀스를 덧붙인다.
즉, 만약 첫 번째 시퀀스가 레지스터를 수정하고 두 번째 시퀀스가 실제로 레지스터의 원래 내용을 필요로 한다면, @code{preserving}은 시퀀스를 덧붙이기 전에 첫 번째 시퀀스 주위에 레지스터의 @code{save}와 @code{restore}를 감싼다.
그렇지 않으면, @code{preserving}은 단순히 덧붙여진 명령어 시퀀스를 반환한다.
따라서, 예를 들어,
@code{(preserving (list ⟨@var{reg₁}⟩ ⟨@var{reg₂}⟩) ⟨@var{seg₁}⟩ ⟨@var{seg₂}⟩)}는
@math{{⟨\kern0.1em seq_1⟩}}과 @math{{⟨\kern0.1em seq_2⟩}}가
@math{{⟨\kern0.1em reg_1⟩}}과 @math{{⟨\kern0.1em reg_2⟩}}를 어떻게 사용하는지에 따라 다음 네 가지 명령어 시퀀스 중 하나를 생성한다:
@ifinfo

@smallexample
<seq_1> | (save <reg_1>)    | (save <reg_2>)    | (save <reg_2>)
<seq_2> | <seq_1>           | <seq_1>           | (save <reg_1>)
        | (restore <reg_1>) | (restore <reg_2>) | <seq_1>
        | <seq_2>           | <seq_2>           | (restore <reg_1>)
        |                   |                   | (restore <reg_2>)
        |                   |                   | <seq_2>
@end smallexample

@end ifinfo
@tex
\[ % :83:

\begin{array}{l|l|l|l}
⟨\kern0.1em{seq_1}⟩                     &
\text{(save}                            &
\text{(save}                            &
\text{(save} \kern1ex ⟨\kern0.1em{reg_2}⟩\text{)}    \\

⟨\kern0.1em{seq_2}⟩  		        &
\kern1ex ⟨\kern0.1em{reg_1}⟩\text{)}    &
\kern1ex ⟨\kern0.1em{reg_2}⟩\text{)}    &
\text{(save} \kern1ex ⟨\kern0.1em{reg_1}⟩\text{)}    \\

                                        &
⟨\kern0.1em{seq_1}⟩                     &
⟨\kern0.1em{seq_1}⟩                     &
⟨\kern0.1em{seq_1}⟩                                  \\

                                        &
\text{(restore}                         &
\text{(restore}                         &
\text{(restore} \kern1ex ⟨\kern0.1em{reg_1}⟩\text{)} \\

                                        &
\kern1ex ⟨\kern0.1em{reg_1}⟩\text{)}    &
\kern1ex ⟨\kern0.1em{reg_2}⟩\text{)}    &
\text{(restore} \kern1ex ⟨\kern0.1em{reg_2}⟩\text{)} \\

                                        &
⟨\kern0.1em{seq_2}⟩                     &
⟨\kern0.1em{seq_2}⟩                     &
⟨\kern0.1em{seq_2}⟩
\end{array}
\]
@end tex

@noindent
명령어 시퀀스를 결합하기 위해 @code{preserving}을 사용함으로써 컴파일러는 불필요한 스택 연산을 피한다.
이것은 또한 @code{save}와 @code{restore} 명령어를 생성할지 여부의 세부 사항을 @code{preserving} 프로시저 내에 격리하여, 개별 코드 생성기를 작성할 때 발생하는 관심사와 분리한다.
실제로 코드 생성기에서는 @code{save}나 @code{restore} 명령어가 명시적으로 생성되지 않는다.

원칙적으로, 우리는 명령어 시퀀스를 단순히 명령어의 리스트로 표현할 수 있다.
그러면 @code{Append-instruction-sequences}는 일반적인 리스트 @code{append}를 수행하여 명령어 시퀀스를 결합할 수 있을 것이다.
그러나 그러면 @code{preserving}은 복잡한 연산이 될 것인데, 왜냐하면 시퀀스가 레지스터를 어떻게 사용하는지 결정하기 위해 각 명령어 시퀀스를 분석해야 하기 때문이다.
@code{Preserving}은 복잡할 뿐만 아니라 비효율적일 것인데, 왜냐하면 명령어 시퀀스 인자들이 @code{preserving} 호출에 의해 구성되었을 수도 있고, 이 경우 그 부분들은 이미 분석되었음에도 불구하고 각 인자를 분석해야 하기 때문이다.
이러한 반복적인 분석을 피하기 위해 우리는 각 명령어 시퀀스에 레지스터 사용에 대한 정보를 연관시킬 것이다.
우리가 기본 명령어 시퀀스를 구성할 때 우리는 이 정보를 명시적으로 제공할 것이며, 명령어 시퀀스를 결합하는 프로시저는 구성 요소 시퀀스와 연관된 정보로부터 결합된 시퀀스에 대한 레지스터 사용 정보를 도출할 것이다.

명령어 시퀀스는 세 가지 정보를 포함할 것이다:

@itemize @bullet

@item
시퀀스의 명령어가 실행되기 전에 초기화되어야 하는 레지스터 집합 (이 레지스터들은 시퀀스에 의해 @newterm{필요(needed)}하다고 한다),

@item
시퀀스의 명령어에 의해 값이 수정되는 레지스터 집합, 그리고

@item
시퀀스의 실제 명령어 (@newterm{문(statements)}이라고도 함).

@end itemize

@noindent
우리는 명령어 시퀀스를 세 부분의 리스트로 표현할 것이다.
따라서 명령어 시퀀스를 위한 생성자는 다음과 같다

@lisp
pub struct InstructionSeq @{
    pub needs: HashSet<Register>,
    pub modifies: HashSet<Register>,
    pub statements: Vec<Instruction>,
@}

impl InstructionSeq @{
    pub fn new(
        needs: HashSet<Register>,
        modifies: HashSet<Register>,
        statements: Vec<Instruction>,
    ) -> Self @{
        Self @{ needs, modifies, statements @}
    @}

    pub fn empty() -> Self @{
        Self::new(HashSet::new(), HashSet::new(), Vec::new())
    @}
@}
@end lisp

@noindent
예를 들어, 현재 환경에서 변수 @code{x}의 값을 조회하여 결과를 @code{val}에 할당하고 반환하는 두 명령어 시퀀스는 레지스터 @code{env}와 @code{continue}가 초기화되어 있어야 하며, 레지스터 @code{val}을 수정한다.
따라서 이 시퀀스는 다음과 같이 구성될 것이다

@lisp
(make_instruction_sequence
 '(env continue)
 '(val)
 '((assign val
           (op lookup_variable_value)
           (const x)
           (reg env))
   (goto (reg continue))))
@end lisp

@noindent
우리는 때때로 문이 없는 명령어 시퀀스를 구성해야 한다:

@lisp
// Rust에서는 InstructionSeq::empty()를 사용한다
@end lisp

@noindent
명령어 시퀀스를 결합하는 프로시저는 @ref{5.5.4}에 나와 있다.

@quotation
@strong{@anchor{Exercise 5.31}연습문제 5.31:} 프로시저 적용을 평가할 때, 명시적 제어 평가자는 항상 연산자 평가 주위에서 @code{env} 레지스터를 저장하고 복원하며, 각 피연산자(마지막 것 제외) 평가 주위에서 @code{env}를 저장하고 복원하며, 각 피연산자 평가 주위에서 @code{argl}을 저장하고 복원하며, 피연산자 시퀀스 평가 주위에서 @code{proc}을 저장하고 복원한다.
다음 각 조합에 대해, 이러한 @code{save}와 @code{restore} 연산 중 어떤 것이 불필요하며 따라서 컴파일러의 @code{preserving} 메커니즘에 의해 제거될 수 있는지 말하라:

@lisp
(f 'x 'y)
((f) 'x 'y)
(f (g 'x) y)
(f (g 'x) 'y)
@end lisp
@end quotation

@quotation
@strong{@anchor{Exercise 5.32}연습문제 5.32:} @code{preserving} 메커니즘을 사용하여, 컴파일러는 연산자가 기호인 경우 조합의 연산자 평가 주위에서 @code{env}를 저장하고 복원하는 것을 피할 것이다.
우리는 또한 그러한 최적화를 평가자에 구축할 수 있다.
실제로, @ref{5.4}의 명시적 제어 평가자는 이미 피연산자가 없는 조합을 특수 사례로 처리함으로써 유사한 최적화를 수행한다.

@enumerate a

@item
연산자가 기호인 조합을 별도의 표현식 클래스로 인식하고, 이러한 표현식을 평가할 때 이 사실을 활용하도록 명시적 제어 평가자를 확장하라.

@item
Alyssa P. Hacker는 평가자가 점점 더 많은 특수 사례를 인식하도록 확장함으로써 컴파일러의 모든 최적화를 통합할 수 있으며, 이것이 컴파일의 이점을 완전히 없앨 것이라고 제안한다.
이 아이디어에 대해 어떻게 생각하는가?

@end enumerate
@end quotation

@node	5.5.2, 5.5.3, 5.5.1, 5.5
@subsection 표현식 컴파일하기 (Compiling Expressions)

이 절과 다음 절에서는 @code{compile} 프로시저가 디스패치하는 코드 생성기를 구현한다.

@subsubheading 링키지 코드 컴파일하기 (Compiling linkage code)

일반적으로, 각 코드 생성기의 출력은 필요한 링키지를 구현하는 (@code{compile_linkage} 프로시저에 의해 생성된) 명령어로 끝난다.
만약 링키지가 @code{return}이면 우리는 명령어 @code{(goto (reg continue))}를 생성해야 한다.
이것은 @code{continue} 레지스터를 필요로 하며 어떤 레지스터도 수정하지 않는다.
만약 링키지가 @code{next}이면 우리는 어떤 추가 명령어도 포함할 필요가 없다.
그렇지 않고 링키지가 레이블이면, 우리는 해당 레이블로의 @code{goto}를 생성하며, 이는 어떤 레지스터도 필요로 하거나 수정하지 않는 명령어이다.@footnote{이 프로시저는 리스트를 구성하는 데 편리한 @newterm{백쿼트(backquote)} (또는 @newterm{준인용(quasiquote)})라는 Lisp 기능을 사용한다. 리스트 앞에 백쿼트 기호를 붙이는 것은 그것을 인용하는 것과 매우 비슷하지만, 쉼표로 표시된 리스트 내의 모든 것은 평가된다는 점이 다르다.

예를 들어, @code{linkage}의 값이 기호 @code{branch25}라면, 표현식

@lisp
`((goto (label ,linkage)))
@end lisp

은 다음 리스트로 평가된다

@lisp
((goto (label branch25))) 
@end lisp

마찬가지로, @code{x}의 값이 리스트 @code{(a b c)}라면

@lisp
`(1 2 ,(car x)) 
@end lisp

은 다음 리스트로 평가된다

@lisp
(1 2 a)
@end lisp
}

@lisp
fn compile_linkage(linkage: &Linkage) -> InstructionSeq @{
    match linkage @{
        Linkage::Return => InstructionSeq::new(
            HashSet::from([Register::Continue]),
            HashSet::new(),
            vec![Instruction::Goto @{
                destination: Box::new(InstructionValue::Reg(Register::Continue)),
            @}],
        ),
        Linkage::Next => InstructionSeq::empty(),
        Linkage::Label(label) => InstructionSeq::new(
            HashSet::new(),
            HashSet::new(),
            vec![Instruction::Goto @{
                destination: Box::new(InstructionValue::Label(label.clone())),
            @}],
        ),
    @}
@}
@end lisp

@noindent
링키지 코드는 @code{continue} 레지스터를 @code{preserving}함으로써 명령어 시퀀스에 덧붙여지는데, 왜냐하면 @code{return} 링키지는 @code{continue} 레지스터를 필요로 할 것이기 때문이다: 만약 주어진 명령어 시퀀스가 @code{continue}를 수정하고 링키지 코드가 그것을 필요로 한다면, @code{continue}는 저장되고 복원될 것이다.

@lisp
fn end_with_linkage(linkage: &Linkage, seq: InstructionSeq) -> InstructionSeq @{
    preserving(&[Register::Continue], seq, compile_linkage(linkage))
@}
@end lisp

@subsubheading 단순 표현식 컴파일하기 (Compiling simple expressions)

자체 평가 표현식, 인용, 변수에 대한 코드 생성기는 필요한 값을 타겟 레지스터에 할당한 다음 링키지 기술자에 의해 지정된 대로 진행하는 명령어 시퀀스를 구성한다.

@lisp
fn compile_self_evaluating(expr: &Expr, target: Register, linkage: &Linkage) -> InstructionSeq @{
    let value = match expr @{
        Expr::Number(n) => Value::Number(*n),
        Expr::String(s) => Value::String(s.clone()),
        _ => panic!("자체 평가 표현식이 아님"),
    @};

    let seq = InstructionSeq::new(
        HashSet::new(),
        HashSet::from([target]),
        vec![Instruction::Assign @{
            target,
            source: Box::new(InstructionValue::Const(value)),
        @}],
    );

    end_with_linkage(linkage, seq)
@}

fn compile_quoted(expr: &Expr, target: Register, linkage: &Linkage) -> InstructionSeq @{
    let quoted_value = match expr @{
        Expr::Quote(e) => expr_to_value(e),
        _ => panic!("인용 표현식이 아님"),
    @};

    let seq = InstructionSeq::new(
        HashSet::new(),
        HashSet::from([target]),
        vec![Instruction::Assign @{
            target,
            source: Box::new(InstructionValue::Const(quoted_value)),
        @}],
    );

    end_with_linkage(linkage, seq)
@}

fn compile_variable(expr: &Expr, target: Register, linkage: &Linkage) -> InstructionSeq @{
    let var_name = match expr @{
        Expr::Symbol(name) => name.clone(),
        _ => panic!("변수가 아님"),
    @};

    let seq = InstructionSeq::new(
        HashSet::from([Register::Env]),
        HashSet::from([target]),
        vec![Instruction::Assign @{
            target,
            source: Box::new(InstructionValue::Op @{
                name: "lookup-variable-value".to_string(),
                args: vec![
                    InstructionValue::Const(Value::Symbol(var_name)),
                    InstructionValue::Reg(Register::Env),
                ],
            @}),
        @}],
    );

    end_with_linkage(linkage, seq)
@}
@end lisp

@noindent
이 모든 할당 명령어는 타겟 레지스터를 수정하며, 변수를 조회하는 명령어는 @code{env} 레지스터를 필요로 한다.

대입과 정의는 인터프리터에서와 거의 비슷하게 처리된다.
우리는 변수에 할당될 값을 계산하는 코드를 재귀적으로 생성하고, 변수를 실제로 설정하거나 정의하고 전체 표현식의 값(기호 @code{ok})을 타겟 레지스터에 할당하는 두 명령어 시퀀스를 그 뒤에 덧붙인다.
재귀적 컴파일은 타겟 @code{val}과 링키지 @code{next}를 가지므로 코드는 결과를 @code{val}에 넣고 그 뒤에 덧붙여진 코드로 계속할 것이다.
덧붙이는 작업은 @code{env}를 보존하면서 수행되는데, 왜냐하면 변수를 설정하거나 정의하는 데 환경이 필요하고 변수 값에 대한 코드는 레지스터를 임의의 방식으로 수정할 수 있는 복잡한 표현식의 컴파일일 수 있기 때문이다.

@lisp
fn compile_assignment(expr: &Expr, target: Register, linkage: &Linkage) -> InstructionSeq @{
    let (var_name, value_expr) = match expr @{
        Expr::Set @{ name, value @} => (name.clone(), value.as_ref()),
        _ => panic!("대입이 아님"),
    @};

    let get_value_code = compile(value_expr, Register::Val, &Linkage::Next);

    let set_code = InstructionSeq::new(
        HashSet::from([Register::Env, Register::Val]),
        HashSet::from([target]),
        vec![
            Instruction::Perform @{
                operation: Box::new(InstructionValue::Op @{
                    name: "set-variable-value!".to_string(),
                    args: vec![
                        InstructionValue::Const(Value::Symbol(var_name)),
                        InstructionValue::Reg(Register::Val),
                        InstructionValue::Reg(Register::Env),
                    ],
                @}),
            @},
            Instruction::Assign @{
                target,
                source: Box::new(InstructionValue::Const(Value::Ok)),
            @},
        ],
    );

    end_with_linkage(
        linkage,
        preserving(&[Register::Env], get_value_code, set_code),
    )
@}

fn compile_definition(expr: &Expr, target: Register, linkage: &Linkage) -> InstructionSeq @{
    let (var_name, value_expr) = match expr @{
        Expr::Define @{ name, value @} => (name.clone(), value.as_ref()),
        _ => panic!("정의가 아님"),
    @};

    let get_value_code = compile(value_expr, Register::Val, &Linkage::Next);

    let define_code = InstructionSeq::new(
        HashSet::from([Register::Env, Register::Val]),
        HashSet::from([target]),
        vec![
            Instruction::Perform @{
                operation: Box::new(InstructionValue::Op @{
                    name: "define-variable!".to_string(),
                    args: vec![
                        InstructionValue::Const(Value::Symbol(var_name)),
                        InstructionValue::Reg(Register::Val),
                        InstructionValue::Reg(Register::Env),
                    ],
                @}),
            @},
            Instruction::Assign @{
                target,
                source: Box::new(InstructionValue::Const(Value::Ok)),
            @},
        ],
    );

    end_with_linkage(
        linkage,
        preserving(&[Register::Env], get_value_code, define_code),
    )
@}
@end lisp

@noindent
덧붙여진 두 명령어 시퀀스는 @code{env}와 @code{val}을 필요로 하며 타겟을 수정한다.
우리가 이 시퀀스를 위해 @code{env}를 보존하지만 @code{val}은 보존하지 않는다는 점에 유의하라. 왜냐하면 @code{get-value-code}는 이 시퀀스에서 사용하기 위해 결과를 명시적으로 @code{val}에 넣도록 설계되었기 때문이다.
(사실, 만약 우리가 @code{val}을 보존했다면 버그가 생겼을 것인데, 왜냐하면 이것은 @code{get-value-code}가 실행된 직후에 @code{val}의 이전 내용을 복원하게 했을 것이기 때문이다.)

@subsubheading 조건식 컴파일하기 (Compiling conditional expressions)

주어진 타겟과 링키지로 컴파일된 @code{if} 표현식에 대한 코드는 다음과 같은 형태를 갖는다

@example
⟨@emph{술어의 컴파일, 타겟 val, 링키지 next}⟩
Test(Op("is-false".into(), vec![Reg(Val)])),
Branch("false-branch".into()),
// true-branch
⟨@emph{결과절의 컴파일, 주어진 타겟과 주어진 링키지 또는 after-if}⟩
// false-branch
Label("false-branch".into()),
⟨@emph{대안절의 컴파일, 주어진 타겟과 링키지}⟩
// after-if
Label("after-if".into()),
@end example

@noindent
이 코드를 생성하기 위해, 우리는 술어, 결과절, 대안절을 컴파일하고, 결과 코드를 술어 결과를 테스트하는 명령어 및 참과 거짓 분기와 조건문의 끝을 표시하는 새로 생성된 레이블과 결합한다.@footnote{우리는 위에서 보여준 것처럼 단순히 레이블 @code{true_branch}, @code{false_branch}, @code{after_if}를 사용할 수 없는데, 왜냐하면 프로그램에 하나 이상의 @code{if}가 있을 수 있기 때문이다. 컴파일러는 레이블을 생성하기 위해 프로시저 @code{make_label}을 사용한다. @code{Make-label}은 기호를 인자로 받아 주어진 기호로 시작하는 새 기호를 반환한다. 예를 들어, @code{(make_label 'a)}에 대한 연속적인 호출은 @code{a1}, @code{a2} 등을 반환할 것이다. @code{Make-label}은 다음과 같이 쿼리 언어에서 고유한 변수 이름을 생성하는 것과 유사하게 구현될 수 있다:

@example
use std::sync::atomic::@{AtomicUsize, Ordering@};

static LABEL_COUNTER: AtomicUsize = AtomicUsize::new(0);

fn new_label_number() -> usize @{
    LABEL_COUNTER.fetch_add(1, Ordering::SeqCst)
@}

fn make_label(name: &str) -> String @{
    format!("@{@}-@{@}", name, new_label_number())
@}
@end example
}

이 코드 배치에서, 우리는 테스트가 거짓이면 참 분기를 우회하여 분기해야 한다.
유일한 약간의 복잡함은 참 분기에 대한 링키지가 어떻게 처리되어야 하는지에 있다.
만약 조건문에 대한 링키지가 @code{return}이거나 레이블이라면, 참 분기와 거짓 분기는 둘 다 이 동일한 링키지를 사용할 것이다.
만약 링키지가 @code{next}라면, 참 분기는 거짓 분기에 대한 코드를 우회하여 조건문의 끝에 있는 레이블로 점프하는 것으로 끝난다.

@lisp
fn compile_if(expr: &Expr, target: Register, linkage: &Linkage) -> InstructionSeq @{
    let (predicate, consequent, alternative) = match expr @{
        Expr::If @{
            predicate,
            consequent,
            alternative,
        @} => (
            predicate.as_ref(),
            consequent.as_ref(),
            alternative.as_ref(),
        ),
        _ => panic!("if 표현식이 아님"),
    @};

    let t_branch = make_label("true-branch");
    let f_branch = make_label("false-branch");
    let after_if = make_label("after-if");

    let consequent_linkage = if linkage == &Linkage::Next @{
        Linkage::Label(after_if.clone())
    @} else @{
        linkage.clone()
    @};

    let p_code = compile(predicate, Register::Val, &Linkage::Next);
    let c_code = compile(consequent, target, &consequent_linkage);
    let a_code = compile(alternative, target, linkage);

    let test_code = InstructionSeq::new(
        HashSet::from([Register::Val]),
        HashSet::new(),
        vec![
            Instruction::Test @{
                condition: Box::new(InstructionValue::Op @{
                    name: "false?".to_string(),
                    args: vec![InstructionValue::Reg(Register::Val)],
                @}),
            @},
            Instruction::Branch @{
                label: f_branch.clone(),
            @},
        ],
    );

    let branches = parallel_instruction_sequences(
        append_instruction_sequences(
            InstructionSeq::new(
                HashSet::new(),
                HashSet::new(),
                vec![Instruction::Label @{ name: t_branch @}],
            ),
            c_code,
        ),
        append_instruction_sequences(
            InstructionSeq::new(
                HashSet::new(),
                HashSet::new(),
                vec![Instruction::Label @{ name: f_branch @}],
            ),
            a_code,
        ),
    );

    let after_if_label = InstructionSeq::new(
        HashSet::new(),
        HashSet::new(),
        vec![Instruction::Label @{ name: after_if @}],
    );

    preserving(
        &[Register::Env, Register::Continue],
        p_code,
        append_sequences(vec![test_code, branches, after_if_label]),
    )
@}
@end lisp

@noindent
@code{Env}는 술어 코드 주위에서 보존되는데, 왜냐하면 참 분기와 거짓 분기에서 필요할 수 있기 때문이다. @code{continue}는 보존되는데, 왜냐하면 그 분기들의 링키지 코드에서 필요할 수 있기 때문이다.
참 분기와 거짓 분기에 대한 코드(순차적으로 실행되지 않음)는 @ref{5.5.4}에서 설명된 특수 결합기 @code{parallel_instruction_sequences}를 사용하여 덧붙여진다.

@code{cond}는 파생된 표현식이므로, 컴파일러가 이를 처리하기 위해 해야 할 일은 @code{cond_to_if} 변환기(@ref{4.1.2}에서)를 적용하고 결과 @code{if} 표현식을 컴파일하는 것뿐이다.

@subsubheading 시퀀스 컴파일하기 (Compiling sequences)

(프로시저 본문이나 명시적 @code{begin} 표현식으로부터의) 시퀀스 컴파일은 그 평가와 평행을 이룬다.
시퀀스의 각 표현식은 컴파일된다---마지막 표현식은 시퀀스에 대해 지정된 링키지로, 다른 표현식들은 링키지 @code{next}(시퀀스의 나머지를 실행하기 위해)로.
개별 표현식에 대한 명령어 시퀀스는 단일 명령어 시퀀스를 형성하기 위해 덧붙여지며, 이때 @code{env}(시퀀스의 나머지를 위해 필요함)와 @code{continue}(시퀀스의 끝에서 링키지를 위해 필요할 수 있음)는 보존된다.

@lisp
fn compile_sequence(exprs: &[Expr], target: Register, linkage: &Linkage) -> InstructionSeq @{
    if exprs.is_empty() @{
        InstructionSeq::empty()
    @} else if exprs.len() == 1 @{
        compile(&exprs[0], target, linkage)
    @} else @{
        preserving(
            &[Register::Env, Register::Continue],
            compile(&exprs[0], target, &Linkage::Next),
            compile_sequence(&exprs[1..], target, linkage),
        )
    @}
@}
@end lisp

@subsubheading @code{lambda} 표현식 컴파일하기 (Compiling @code{lambda} expressions)

@code{Lambda} 표현식은 프로시저를 구성한다.
@code{lambda} 표현식에 대한 목적 코드는 다음과 같은 형태를 가져야 한다

@lisp
⟨@emph{프로시저 객체를 구성하여 타겟 레지스터에 할당}⟩
⟨@var{linkage}⟩
@end lisp

@noindent
우리가 @code{lambda} 표현식을 컴파일할 때, 우리는 또한 프로시저 본문에 대한 코드를 생성한다.
비록 본문은 프로시저 구성 시점에 실행되지 않지만, 그것을 @code{lambda}에 대한 코드 바로 뒤에 목적 코드에 삽입하는 것이 편리하다.
만약 @code{lambda} 표현식에 대한 링키지가 레이블이거나 @code{return}이면, 이것은 괜찮다.
그러나 링키지가 @code{next}라면, 우리는 본문 뒤에 삽입되는 레이블로 점프하는 링키지를 사용하여 프로시저 본문에 대한 코드를 건너뛰어야 할 것이다.
따라서 목적 코드는 다음과 같은 형태를 갖는다

@lisp
⟨@emph{프로시저 객체를 구성하여 타겟 레지스터에 할당}⟩
 ⟨@emph{주어진 링키지에 대한 코드}⟩ @emph{또는} 
  @code{(goto (label after_lambda))}
 ⟨@emph{프로시저 본문의 컴파일}⟩
after_lambda
@end lisp

@noindent
@code{Compile_lambda}는 프로시저 객체를 구성하는 코드와 그 뒤에 오는 프로시저 본문에 대한 코드를 생성한다.
프로시저 객체는 런타임에 현재 환경(정의 시점의 환경)을 컴파일된 프로시저 본문의 진입점(새로 생성된 레이블)과 결합하여 구성될 것이다.@footnote{@anchor{Footnote 323} 우리는 @ref{4.1.3}에서 설명된 복합 프로시저를 위한 구조와 유사하게, 컴파일된 프로시저를 표현하기 위한 데이터 구조를 구현하는 기계 연산이 필요하다:

@lisp
// Rust에서, `Value::Procedure` 변형(또는 `CompiledProcedure` 구조체)이
// 진입점과 환경을 보유한다.
// 5.2절의 `Value` 열거형 정의를 참조하라.
@end lisp
}

@lisp
fn compile_lambda(expr: &Expr, target: Register, linkage: &Linkage) -> InstructionSeq @{
    let (params, body) = match expr @{
        Expr::Lambda @{ params, body @} => (params, body),
        _ => panic!("람다 표현식이 아님"),
    @};

    let proc_entry = make_label("entry");
    let after_lambda = make_label("after-lambda");

    let lambda_linkage = if linkage == &Linkage::Next @{
        Linkage::Label(after_lambda.clone())
    @} else @{
        linkage.clone()
    @};

    let make_proc = InstructionSeq::new(
        HashSet::from([Register::Env]),
        HashSet::from([target]),
        vec![Instruction::Assign @{
            target,
            source: Box::new(InstructionValue::Op @{
                name: "make-compiled-procedure".to_string(),
                args: vec![
                    InstructionValue::Label(proc_entry.clone()),
                    InstructionValue::Reg(Register::Env),
                ],
            @}),
        @}],
    );

    let proc_body = compile_lambda_body(params, body, &proc_entry);

    let after_lambda_label = InstructionSeq::new(
        HashSet::new(),
        HashSet::new(),
        vec![Instruction::Label @{ name: after_lambda @}],
    );

    append_sequences(vec![
        tack_on_instruction_sequence(end_with_linkage(&lambda_linkage, make_proc), proc_body),
        after_lambda_label,
    ])
@}
@end lisp

@noindent
@code{Compile_lambda}는 프로시저 본문을 @code{lambda} 표현식 코드에 덧붙이기 위해 @code{append_instruction_sequences}(@ref{5.5.4}) 대신 특수 결합기 @code{tack_on_instruction_sequence}를 사용한다. 왜냐하면 본문은 결합된 시퀀스가 입력될 때 실행될 명령어 시퀀스의 일부가 아니기 때문이다; 오히려, 그것은 단지 그것을 두기에 편리한 장소였기 때문에 시퀀스에 있는 것이다.

@code{Compile_lambda_body}는 프로시저 본문에 대한 코드를 구성한다.
이 코드는 진입점을 위한 레이블로 시작한다.
다음에는 런타임 평가 환경을 프로시저 본문을 평가하기 위한 올바른 환경---즉, 프로시저가 호출될 때의 인자에 대한 형식 매개변수의 바인딩을 포함하도록 확장된 프로시저의 정의 환경---으로 전환하게 하는 명령어가 온다.
그 후에는 프로시저 본문을 구성하는 표현식 시퀀스에 대한 코드가 온다.
시퀀스는 링키지 @code{return}과 타겟 @code{val}로 컴파일되어 @code{val}에 프로시저 결과를 가지고 프로시저에서 반환하는 것으로 끝날 것이다.

@lisp
fn compile_lambda_body(params: &[String], body: &[Expr], entry_label: &str) -> InstructionSeq @{
    let param_list = params
        .iter()
        .map(|p| Value::Symbol(p.clone()))
        .collect::<Vec<_>>();

    let entry = InstructionSeq::new(
        HashSet::from([Register::Env, Register::Proc, Register::Argl]),
        HashSet::from([Register::Env]),
        vec![
            Instruction::Label @{
                name: entry_label.to_string(),
            @},
            Instruction::Assign @{
                target: Register::Env,
                source: Box::new(InstructionValue::Op @{
                    name: "compiled-procedure-env".to_string(),
                    args: vec![InstructionValue::Reg(Register::Proc)],
                @}),
            @},
            Instruction::Assign @{
                target: Register::Env,
                source: Box::new(InstructionValue::Op @{
                    name: "extend-environment".to_string(),
                    args: vec![
                        InstructionValue::Const(Value::Symbol(format!("@{:?@}", param_list))),
                        InstructionValue::Reg(Register::Argl),
                        InstructionValue::Reg(Register::Env),
                    ],
                @}),
            @},
        ],
    );

    append_instruction_sequences(
        entry,
        compile_sequence(body, Register::Val, &Linkage::Return),
    )
@}
@end lisp

@node	5.5.3, 5.5.4, 5.5.2, 5.5
@subsection 조합 컴파일하기 (Compiling Combinations)

컴파일 프로세스의 본질은 프로시저 적용의 컴파일이다.
주어진 타겟과 링키지로 컴파일된 조합에 대한 코드는 다음과 같은 형태를 갖는다

@lisp
⟨@emph{연산자의 컴파일, 타겟 @code{proc}, 링키지 @code{next}}⟩
⟨@emph{피연산자 평가 및 @code{argl}에 인자 리스트 구성}⟩
⟨@emph{주어진 타겟과 링키지로 프로시저 호출 컴파일}⟩
@end lisp

@noindent
레지스터 @code{env}, @code{proc}, 그리고 @code{argl}은 연산자와 피연산자의 평가 중에 저장되고 복원되어야 할 수도 있다.
이것은 컴파일러에서 @code{val} 이외의 타겟이 지정되는 유일한 곳임에 유의하라.

필요한 코드는 @code{compile_application}에 의해 생성된다.
이것은 연산자를 재귀적으로 컴파일하여 적용될 프로시저를 @code{proc}에 넣는 코드를 생성하고, 피연산자들을 컴파일하여 적용의 개별 피연산자를 평가하는 코드를 생성한다.
피연산자에 대한 명령어 시퀀스는 (@code{construct_arglist}에 의해) @code{argl}에 인자 리스트를 구성하는 코드와 결합되며, 결과 인자 리스트 코드는 프로시저 코드 및 프로시저 호출을 수행하는 코드(@code{compile_procedure_call}에 의해 생성됨)와 결합된다.
코드 시퀀스를 덧붙일 때, @code{env} 레지스터는 연산자 평가 주위에서 보존되어야 하고(왜냐하면 연산자 평가가 @code{env}를 수정할 수 있는데, 피연산자를 평가하는 데 필요하기 때문이다), @code{proc} 레지스터는 인자 리스트 구성 주위에서 보존되어야 한다(왜냐하면 피연산자 평가가 @code{proc}을 수정할 수 있는데, 실제 프로시저 적용에 필요하기 때문이다).
@code{Continue} 또한 전체에 걸쳐 보존되어야 하는데, 왜냐하면 프로시저 호출의 링키지에 필요하기 때문이다.

@lisp
fn compile_application(expr: &Expr, target: Register, linkage: &Linkage) -> InstructionSeq @{
    let (operator, operands) = match expr @{
        Expr::Application @{ operator, operands @} => (operator.as_ref(), operands),
        _ => panic!("적용이 아님"),
    @};

    let proc_code = compile(operator, Register::Proc, &Linkage::Next);
    let operand_codes: Vec<InstructionSeq> = operands
        .iter()
        .map(|operand| compile(operand, Register::Val, &Linkage::Next))
        .collect();

    preserving(
        &[Register::Env, Register::Continue],
        proc_code,
        preserving(
            &[Register::Proc, Register::Continue],
            construct_arglist(operand_codes),
            compile_procedure_call(target, linkage),
        ),
    )
@}
@end lisp

@noindent
인자 리스트를 구성하는 코드는 각 피연산자를 @code{val}로 평가한 다음 그 값을 @code{argl}에 누적되는 인자 리스트에 @code{cons}할 것이다.
우리는 인자들을 순서대로 @code{argl}에 @code{cons}하므로, 마지막 인자부터 시작하여 첫 번째 인자로 끝나야 한다. 그래야 결과 리스트에서 인자들이 첫 번째부터 마지막 순서로 나타난다.
이 평가 시퀀스를 설정하기 위해 @code{argl}을 빈 리스트로 초기화하는 명령어를 낭비하는 대신, 우리는 첫 번째 코드 시퀀스가 초기 @code{argl}을 구성하도록 만든다.
따라서 인자 리스트 구성의 일반적인 형태는 다음과 같다:

@lisp
⟨@emph{마지막 피연산자의 컴파일, 타겟 @code{val}}⟩
(assign argl (op list) (reg val))
⟨@emph{다음 피연산자의 컴파일, 타겟 @code{val}}⟩
(assign argl (op cons) (reg val) (reg argl))
@r{…}
⟨@emph{첫 번째 피연산자의 컴파일, 타겟 @code{val}}⟩
(assign argl (op cons) (reg val) (reg argl))
@end lisp

@noindent
@code{Argl}은 첫 번째를 제외한 각 피연산자 평가 주위에서 보존되어야 하고(그래야 지금까지 누적된 인자가 손실되지 않는다), @code{env}는 마지막을 제외한 각 피연산자 평가 주위에서 보존되어야 한다(후속 피연산자 평가에 사용하기 위해).

이 인자 코드를 컴파일하는 것은 약간 까다로운데, 평가될 첫 번째 피연산자의 특별한 처리와 @code{argl} 및 @code{env}를 다른 곳에서 보존해야 할 필요성 때문이다.
@code{construct_arglist} 프로시저는 개별 피연산자를 평가하는 코드를 인자로 받는다.
피연산자가 전혀 없다면, 그것은 단순히 다음 명령어를 내보낸다

@lisp
(assign argl (const ()))
@end lisp

@noindent
그렇지 않으면, @code{construct_arglist}는 마지막 인자로 @code{argl}을 초기화하는 코드를 생성하고, 나머지 인자들을 평가하여 순서대로 @code{argl}에 추가하는 코드를 덧붙인다.
인자들을 마지막에서 첫 번째 순서로 처리하기 위해, 우리는 @code{compile_application}이 제공한 순서에서 피연산자 코드 시퀀스 리스트를 뒤집어야 한다.

@lisp
fn construct_arglist(operand_codes: Vec<InstructionSeq>) -> InstructionSeq @{
    if operand_codes.is_empty() @{
        InstructionSeq::new(
            HashSet::new(),
            HashSet::from([Register::Argl]),
            vec![Instruction::Assign @{
                target: Register::Argl,
                source: Box::new(InstructionValue::Const(Value::Nil)),
            @}],
        )
    @} else @{
        let mut reversed_codes = operand_codes;
        reversed_codes.reverse();

        let code_to_get_last_arg = append_instruction_sequences(
            reversed_codes[0].clone(),
            InstructionSeq::new(
                HashSet::from([Register::Val]),
                HashSet::from([Register::Argl]),
                vec![Instruction::Assign @{
                    target: Register::Argl,
                    source: Box::new(InstructionValue::Op @{
                        name: "list".to_string(),
                        args: vec![InstructionValue::Reg(Register::Val)],
                    @}),
                @}],
            ),
        );

        if reversed_codes.len() == 1 @{
            code_to_get_last_arg
        @} else @{
            preserving(
                &[Register::Env],
                code_to_get_last_arg,
                code_to_get_rest_args(&reversed_codes[1..]),
            )
        @}
    @}
@}

fn code_to_get_rest_args(operand_codes: &[InstructionSeq]) -> InstructionSeq @{
    let code_for_next_arg = preserving(
        &[Register::Argl],
        operand_codes[0].clone(),
        InstructionSeq::new(
            HashSet::from([Register::Val, Register::Argl]),
            HashSet::from([Register::Argl]),
            vec![Instruction::Assign @{
                target: Register::Argl,
                source: Box::new(InstructionValue::Op @{
                    name: "cons".to_string(),
                    args: vec![
                        InstructionValue::Reg(Register::Val),
                        InstructionValue::Reg(Register::Argl),
                    ],
                @}),
            @}],
        ),
    );

    if operand_codes.len() == 1 @{
        code_for_next_arg
    @} else @{
        preserving(
            &[Register::Env],
            code_for_next_arg,
            code_to_get_rest_args(&operand_codes[1..]),
        )
    @}
@}
@end lisp

@subsubheading 프로시저 적용하기 (Applying procedures)

조합의 요소를 평가한 후, 컴파일된 코드는 @code{proc}에 있는 프로시저를 @code{argl}에 있는 인자에 적용해야 한다.
이 코드는 본질적으로 @ref{4.1.1}의 메타순환 평가자의 @code{apply} 프로시저 또는 @ref{5.4.1}의 명시적 제어 평가자의 @code{apply_dispatch} 진입점과 동일한 디스패치를 수행한다.
이것은 적용할 프로시저가 원시 프로시저인지 컴파일된 프로시저인지 확인한다.
원시 프로시저의 경우, @code{apply_primitive_procedure}를 사용한다; 컴파일된 프로시저를 어떻게 처리하는지는 곧 보게 될 것이다.
프로시저 적용 코드는 다음과 같은 형태를 갖는다:

@example
Test(Op("is-primitive-procedure".into(), vec![Reg(Proc)])),
Branch("primitive-branch".into()),
// compiled-branch
⟨@emph{주어진 타겟과 적절한 링키지로 컴파일된 프로시저를 적용하는 코드}⟩
// primitive-branch
Label("primitive-branch".into()),
Assign(target, Op("apply-primitive-procedure".into(), 
    vec![Reg(Proc), Reg(Argl)])),
⟨@var{linkage}⟩
Label("after-call".into()),
@end example

@noindent
컴파일된 분기는 원시 분기를 건너뛰어야 함을 관찰하라.
따라서 원래 프로시저 호출에 대한 링키지가 @code{next}였다면, 복합 분기는 원시 분기 뒤에 삽입된 레이블로 점프하는 링키지를 사용해야 한다. (이것은 @code{compile_if}에서 참 분기에 사용된 링키지와 유사하다.)

@lisp
fn compile_procedure_call(target: Register, linkage: &Linkage) -> InstructionSeq @{
    let primitive_branch = make_label("primitive-branch");
    let compiled_branch = make_label("compiled-branch");
    let after_call = make_label("after-call");

    let compiled_linkage = if linkage == &Linkage::Next @{
        Linkage::Label(after_call.clone())
    @} else @{
        linkage.clone()
    @};

    let test_code = InstructionSeq::new(
        HashSet::from([Register::Proc]),
        HashSet::new(),
        vec![
            Instruction::Test @{
                condition: Box::new(InstructionValue::Op @{
                    name: "primitive-procedure?".to_string(),
                    args: vec![InstructionValue::Reg(Register::Proc)],
                @}),
            @},
            Instruction::Branch @{
                label: primitive_branch.clone(),
            @},
        ],
    );

    let compiled_case = append_instruction_sequences(
        InstructionSeq::new(
            HashSet::new(),
            HashSet::new(),
            vec![Instruction::Label @{
                name: compiled_branch,
            @}],
        ),
        compile_proc_appl(target, &compiled_linkage),
    );

    let primitive_case = append_instruction_sequences(
        InstructionSeq::new(
            HashSet::new(),
            HashSet::new(),
            vec![Instruction::Label @{
                name: primitive_branch,
            @}],
        ),
        end_with_linkage(
            linkage,
            InstructionSeq::new(
                HashSet::from([Register::Proc, Register::Argl]),
                HashSet::from([target]),
                vec![Instruction::Assign @{
                    target,
                    source: Box::new(InstructionValue::Op @{
                        name: "apply-primitive-procedure".to_string(),
                        args: vec![
                            InstructionValue::Reg(Register::Proc),
                            InstructionValue::Reg(Register::Argl),
                        ],
                    @}),
                @}],
            ),
        ),
    );

    let after_call_label = InstructionSeq::new(
        HashSet::new(),
        HashSet::new(),
        vec![Instruction::Label @{ name: after_call @}],
    );

    append_sequences(vec![
        test_code,
        parallel_instruction_sequences(compiled_case, primitive_case),
        after_call_label,
    ])
@}
@end lisp

@noindent
원시 및 복합 분기는 @code{compile_if}의 참 및 거짓 분기와 마찬가지로 일반적인 @code{append_instruction_sequences}가 아니라 @code{parallel_instruction_sequences}를 사용하여 덧붙여지는데, 왜냐하면 이것들은 순차적으로 실행되지 않을 것이기 때문이다.

@subsubheading 컴파일된 프로시저 적용하기 (Applying compiled procedures)

프로시저 적용을 처리하는 코드는 컴파일러에서 가장 미묘한 부분인데, 비록 생성되는 명령어 시퀀스가 매우 짧더라도 그렇다.
컴파일된 프로시저(@code{compile_lambda}에 의해 구성됨)는 진입점을 갖는데, 이는 프로시저 코드가 시작하는 곳을 지정하는 레이블이다.
이 진입점의 코드는 @code{val}에 결과를 계산하고 @code{(goto (reg continue))} 명령어를 실행하여 반환한다.
따라서, 주어진 타겟과 링키지로 컴파일된 프로시저 적용을 위한 코드(@code{compile_proc_appl}에 의해 생성됨)는 링키지가 레이블인 경우 다음과 같을 것으로 예상할 수 있다

@lisp
(assign continue 
        (label proc_return))
 (assign val
         (op compiled_procedure_entry)
         (reg proc))
 (goto (reg val))
proc_return
 (assign ⟨@var{target}⟩ 
         (reg val))   @r{; 타겟이 @code{val}이 아닌 경우 포함됨}
 (goto (label ⟨@var{linkage}⟩))   @r{; 링키지 코드}
@end lisp

@noindent
또는 링키지가 @code{return}인 경우 다음과 같다.

@lisp
(save continue)
 (assign continue 
         (label proc_return))
 (assign val 
         (op compiled_procedure_entry)
         (reg proc))
 (goto (reg val))
proc_return
 (assign ⟨@var{target}⟩
         (reg val))   @r{; 타겟이 @code{val}이 아닌 경우 포함됨}
 (restore continue)
 (goto (reg continue))   @r{; 링키지 코드}
@end lisp

@noindent
이 코드는 프로시저가 레이블 @code{proc_return}으로 돌아오도록 @code{continue}를 설정하고 프로시저의 진입점으로 점프한다.
@code{proc_return}의 코드는 프로시저의 결과를 @code{val}에서 타겟 레지스터로 이동하고(필요한 경우) 링키지에 의해 지정된 위치로 점프한다.
(링키지는 항상 @code{return} 또는 레이블인데, 왜냐하면 @code{compile_procedure_call}이 복합 프로시저 분기에 대한 @code{next} 링키지를 @code{after_call} 레이블로 대체하기 때문이다.)

사실, 타겟이 @code{val}이 아니라면, 이것이 바로 우리 컴파일러가 생성할 코드이다.@footnote{실제로 우리는 타겟이 @code{val}이 아니고 링키지가 @code{return}일 때 오류를 신호하는데, 우리가 @code{return} 링키지를 요청하는 유일한 곳은 프로시저를 컴파일할 때이고, 우리의 관례는 프로시저가 값을 @code{val}에 반환한다는 것이기 때문이다.}
그러나 보통 타겟은 @code{val}이므로(컴파일러가 다른 레지스터를 지정하는 유일한 경우는 연산자의 평가를 @code{proc}으로 타겟팅할 때이다), 프로시저 결과는 타겟 레지스터에 직접 놓이며 그것을 복사하는 특별한 위치로 돌아올 필요가 없다.
대신, 우리는 프로시저가 호출자의 링키지에 의해 지정된 장소로 직접 ``반환''되도록 @code{continue}를 설정함으로써 코드를 단순화한다:

@lisp
⟨@emph{링키지에 대해 @code{continue} 설정}⟩
(assign val 
        (op compiled_procedure_entry)
        (reg proc))
(goto (reg val))
@end lisp

@noindent
링키지가 레이블이면, 우리는 프로시저가 그 레이블로 돌아오도록 @code{continue}를 설정한다.
(즉, 프로시저가 끝날 때의 @code{(goto (reg continue))}는 위의 @code{proc_return}에 있는 @code{(goto (label ⟨@var{linkage}⟩))}와 동등해진다.)

@lisp
(assign continue 
        (label ⟨@var{linkage}⟩))
(assign val
        (op compiled_procedure_entry)
        (reg proc))
(goto (reg val))
@end lisp

@noindent
링키지가 @code{return}이면, 우리는 @code{continue}를 전혀 설정할 필요가 없다: 그것은 이미 원하는 위치를 담고 있다.
(즉, 프로시저가 끝날 때의 @code{(goto (reg continue))}는 @code{proc_return}에 있는 @code{(goto (reg continue))}가 갔을 곳으로 바로 간다.)

@lisp
(assign val
        (op compiled_procedure_entry)
        (reg proc))
(goto (reg val))
@end lisp

@noindent
@code{return} 링키지의 이 구현으로, 컴파일러는 꼬리 재귀 코드를 생성한다.
프로시저 본문의 마지막 단계로서 프로시저를 호출하는 것은 스택에 어떤 정보도 저장하지 않고 직접 이동을 수행한다.

대신 우리가 @code{val}이 아닌 타겟에 대해 위에서 보여준 것처럼 @code{return} 링키지와 @code{val} 타겟을 가진 프로시저 호출의 경우를 처리했다고 가정해 보자.
이것은 꼬리 재귀를 파괴할 것이다.
우리 시스템은 여전히 어떤 표현식에 대해서도 같은 값을 줄 것이다.
그러나 우리가 프로시저를 호출할 때마다, 우리는 @code{continue}를 저장하고 (쓸모없는) 저장을 취소하기 위해 호출 후에 돌아올 것이다.
이러한 추가 저장은 프로시저 호출이 중첩되는 동안 누적될 것이다.@footnote{컴파일러가 꼬리 재귀 코드를 생성하게 만드는 것은 간단한 아이디어처럼 보일 수 있다. 그러나 C와 Pascal을 포함한 일반적인 언어를 위한 대부분의 컴파일러는 이렇게 하지 않으며, 따라서 이러한 언어들은 프로시저 호출만으로 반복 프로세스를 표현할 수 없다. 이러한 언어에서 꼬리 재귀의 어려움은 그 구현이 프로시저 인자와 지역 변수뿐만 아니라 반환 주소를 저장하기 위해 스택을 사용한다는 것이다. 이 책에서 설명된 Scheme 구현은 인자와 변수를 가비지 컬렉션될 메모리에 저장한다. 변수와 인자에 스택을 사용하는 이유는 그렇지 않으면 필요하지 않을 가비지 컬렉션의 필요성을 피하기 위함이며, 일반적으로 더 효율적이라고 믿어지기 때문이다. 정교한 Lisp 컴파일러는 사실 꼬리 재귀를 파괴하지 않고 인자에 스택을 사용할 수 있다. (설명은 @ref{Hanson 1990} 참조.) 애초에 스택 할당이 가비지 컬렉션보다 실제로 더 효율적인지에 대한 논쟁도 있지만, 세부 사항은 컴퓨터 아키텍처의 미세한 점에 달려 있는 것 같다. (이 문제에 대한 반대 견해는 @ref{Appel 1987}과 @ref{Miller and Rozas 1994} 참조.)}

@code{Compile-proc-appl}은 타겟이 @code{val}인지와 링키지가 @code{return}인지에 따라 네 가지 경우를 고려하여 위의 프로시저 적용 코드를 생성한다.
프로시저 본문을 실행하면 레지스터가 임의의 방식으로 변경될 수 있으므로 명령어 시퀀스가 모든 레지스터를 수정한다고 선언되는 것을 관찰하라.@footnote{@code{all_regs} 변수는 모든 레지스터 이름의 리스트에 바인딩된다:

@lisp
pub const ALL_REGS: &[Register] = &[
    Register::Env,
    Register::Proc,
    Register::Val,
    Register::Argl,
    Register::Continue,
];
@end lisp
}
또한 타겟 @code{val}과 링키지 @code{return}인 경우의 코드 시퀀스가 @code{continue}를 필요로 한다고 선언된 것에 주목하라: 비록 두 명령어 시퀀스에서 @code{continue}가 명시적으로 사용되지는 않지만, 우리는 컴파일된 프로시저에 들어갈 때 @code{continue}가 올바른 값을 가지고 있는지 확인해야 한다.

@lisp
fn compile_proc_appl(target: Register, linkage: &Linkage) -> InstructionSeq @{
    let all_regs_set: HashSet<Register> = ALL_REGS.iter().copied().collect();

    match (target, linkage) @{
        (Register::Val, Linkage::Return) => @{
            // 꼬리 호출 최적화: 프로시저로 바로 점프
            InstructionSeq::new(
                HashSet::from([Register::Proc, Register::Continue]),
                all_regs_set,
                vec![
                    Instruction::Assign @{
                        target: Register::Val,
                        source: Box::new(InstructionValue::Op @{
                            name: "compiled-procedure-entry".to_string(),
                            args: vec![InstructionValue::Reg(Register::Proc)],
                        @}),
                    @},
                    Instruction::Goto @{
                        destination: Box::new(InstructionValue::Reg(Register::Val)),
                    @},
                ],
            )
        @}
        (Register::Val, _) => @{
            // continue를 링키지 타겟으로 설정하고 점프
            let continue_target = match linkage @{
                Linkage::Label(label) => InstructionValue::Label(label.clone()),
                _ => panic!("val 타겟에 대한 유효하지 않은 링키지"),
            @};

            InstructionSeq::new(
                HashSet::from([Register::Proc]),
                all_regs_set,
                vec![
                    Instruction::Assign @{
                        target: Register::Continue,
                        source: Box::new(continue_target),
                    @},
                    Instruction::Assign @{
                        target: Register::Val,
                        source: Box::new(InstructionValue::Op @{
                            name: "compiled-procedure-entry".to_string(),
                            args: vec![InstructionValue::Reg(Register::Proc)],
                        @}),
                    @},
                    Instruction::Goto @{
                        destination: Box::new(InstructionValue::Reg(Register::Val)),
                    @},
                ],
            )
        @}
        (_, Linkage::Return) => @{
            panic!("타겟 != val 인 Return 링키지는 지원하지 않음");
        @}
        (_, _) => @{
            // 레이블 링키지가 있는 비-val 타겟
            let proc_return = make_label("proc-return");
            let linkage_label = match linkage @{
                Linkage::Label(label) => label.clone(),
                _ => panic!("유효하지 않은 링키지"),
            @};

            InstructionSeq::new(
                HashSet::from([Register::Proc]),
                all_regs_set,
                vec![
                    Instruction::Assign @{
                        target: Register::Continue,
                        source: Box::new(InstructionValue::Label(proc_return.clone())),
                    @},
                    Instruction::Assign @{
                        target: Register::Val,
                        source: Box::new(InstructionValue::Op @{
                            name: "compiled-procedure-entry".to_string(),
                            args: vec![InstructionValue::Reg(Register::Proc)],
                        @}),
                    @},
                    Instruction::Goto @{
                        destination: Box::new(InstructionValue::Reg(Register::Val)),
                    @},
                    Instruction::Label @{ name: proc_return @},
                    Instruction::Assign @{
                        target,
                        source: Box::new(InstructionValue::Reg(Register::Val)),
                    @},
                    Instruction::Goto @{
                        destination: Box::new(InstructionValue::Label(linkage_label)),
                    @},
                ],
            )
        @}
    @}
@}
@end lisp

@node	5.5.4, 5.5.5, 5.5.3, 5.5
@subsection 명령어 시퀀스 결합하기 (Combining Instruction Sequences)

이 절에서는 명령어 시퀀스가 어떻게 표현되고 결합되는지에 대한 세부 사항을 설명한다.
@ref{5.5.1}에서 명령어 시퀀스가 필요한 레지스터, 수정된 레지스터, 그리고 실제 명령어의 리스트로 표현된다는 것을 상기하라.
우리는 또한 레이블(기호)을 어떤 레지스터도 필요로 하거나 수정하지 않는 명령어 시퀀스의 퇴화된 경우로 간주할 것이다.
따라서 명령어 시퀀스에 의해 필요하고 수정되는 레지스터를 결정하기 위해 우리는 선택자를 사용한다

@lisp
// Rust에서는 InstructionSeq 구조체의 메서드를 사용한다:
// seq.needs_register(reg)
// seq.modifies_register(reg)
@end lisp

@noindent
이러한 술어와 선택자의 관점에서, 우리는 컴파일러 전체에서 사용되는 다양한 명령어 시퀀스 결합기를 구현할 수 있다.

기본 결합기는 @code{append_instruction_sequences}이다.
이것은 순차적으로 실행될 임의의 수의 명령어 시퀀스를 인자로 받아, 모든 시퀀스의 문장들이 함께 덧붙여진 문장을 갖는 명령어 시퀀스를 반환한다.
미묘한 점은 결과 시퀀스에 의해 필요하고 수정되는 레지스터를 결정하는 것이다.
이것은 시퀀스들 중 어느 하나에 의해 수정되는 레지스터들을 수정한다; 이것은 첫 번째 시퀀스가 실행되기 전에 초기화되어야 하는 레지스터들(첫 번째 시퀀스에 의해 필요한 레지스터들)과, 그 앞의 시퀀스들에 의해 초기화(수정)되지 않은 다른 시퀀스들에 의해 필요한 레지스터들을 필요로 한다.

시퀀스들은 @code{append_2_sequences}에 의해 한 번에 두 개씩 덧붙여진다.
이것은 두 개의 명령어 시퀀스 @code{seq1}과 @code{seq2}를 받아, 문장이 @code{seq1}의 문장 뒤에 @code{seq2}의 문장이 오고, 수정된 레지스터가 @code{seq1}이나 @code{seq2}에 의해 수정된 레지스터들이며, 필요한 레지스터가 @code{seq1}에 의해 필요한 레지스터와 @code{seq1}에 의해 수정되지 않은 @code{seq2}에 의해 필요한 레지스터들인 명령어 시퀀스를 반환한다.
(집합 연산의 관점에서, 새로운 필요한 레지스터 집합은 @code{seq1}에 의해 필요한 레지스터 집합과 @code{seq2}에 의해 필요한 레지스터 집합에서 @code{seq1}에 의해 수정된 레지스터 집합을 뺀 차집합의 합집합이다.)
따라서 @code{append_instruction_sequences}는 다음과 같이 구현된다:

@lisp
fn append_instruction_sequences(seq1: InstructionSeq, seq2: InstructionSeq) -> InstructionSeq @{
    let needs = set_union(&seq1.needs, &set_difference(&seq2.needs, &seq1.modifies));
    let modifies = set_union(&seq1.modifies, &seq2.modifies);
    let mut statements = seq1.statements;
    statements.extend(seq2.statements);
    InstructionSeq::new(needs, modifies, statements)
@}

fn append_sequences(seqs: Vec<InstructionSeq>) -> InstructionSeq @{
    seqs.into_iter()
        .reduce(append_instruction_sequences)
        .unwrap_or_else(InstructionSeq::empty)
@}
@end lisp

@noindent
이 프로시저는 @ref{2.3.3}에서 설명된 (순서 없는) 집합 표현과 유사하게 리스트로 표현된 집합을 조작하기 위한 몇 가지 간단한 연산을 사용한다:

@lisp
// Rust에서는 HashSet 연산을 사용한다:
fn set_union(s1: &HashSet<Register>, s2: &HashSet<Register>) -> HashSet<Register> @{
    s1.union(s2).copied().collect()
@}

fn set_difference(s1: &HashSet<Register>, s2: &HashSet<Register>) -> HashSet<Register> @{
    s1.difference(s2).copied().collect()
@}
@end lisp

@noindent
두 번째 주요 명령어 시퀀스 결합기인 @code{Preserving}은 레지스터 리스트 @code{regs}와 순차적으로 실행될 두 개의 명령어 시퀀스 @code{seq1}과 @code{seq2}를 받는다.
이것은 @code{seq1}의 문장 뒤에 @code{seq2}의 문장이 오고, @code{regs}에 있는 레지스터 중 @code{seq1}에 의해 수정되지만 @code{seq2}에 의해 필요한 레지스터를 보호하기 위해 @code{seq1} 주위에 적절한 @code{save}와 @code{restore} 명령어를 갖는 명령어 시퀀스를 반환한다.
이를 달성하기 위해, @code{preserving}은 먼저 필요한 @code{save}들, 그 뒤에 @code{seq1}의 문장들, 그 뒤에 필요한 @code{restore}들을 갖는 시퀀스를 생성한다.
이 시퀀스는 @code{seq1}에 의해 필요한 레지스터 외에도 저장되고 복원되는 레지스터들을 필요로 하며, 저장되고 복원되는 것들을 제외하고 @code{seq1}에 의해 수정되는 레지스터들을 수정한다.
이 확장된 시퀀스와 @code{seq2}는 그런 다음 일반적인 방식으로 덧붙여진다.
다음 프로시저는 보존되어야 할 레지스터 리스트를 따라 내려가며 이 전략을 재귀적으로 구현한다:@footnote{@code{preserving}이 세 개의 인자로 @code{append}를 호출한다는 점에 유의하라. 이 책에 나온 @code{append}의 정의는 두 개의 인자만 받지만, Scheme은 일반적으로 임의의 수의 인자를 받는 @code{append} 프로시저를 제공한다.}

@lisp
fn preserving(regs: &[Register], seq1: InstructionSeq, seq2: InstructionSeq) -> InstructionSeq @{
    if regs.is_empty() @{
        return append_instruction_sequences(seq1, seq2);
    @}

    let first_reg = regs[0];
    let rest_regs = &regs[1..];

    if seq1.modifies_register(first_reg) && seq2.needs_register(first_reg) @{
        // 이 레지스터를 저장하고 복원해야 함
        let mut needs = seq1.needs.clone();
        needs.insert(first_reg);

        let modifies = set_difference(&seq1.modifies, &HashSet::from([first_reg]));

        let mut statements = vec![Instruction::Save @{
            register: first_reg,
        @}];
        statements.extend(seq1.statements);
        statements.push(Instruction::Restore @{
            register: first_reg,
        @});

        let protected_seq1 = InstructionSeq::new(needs, modifies, statements);
        preserving(rest_regs, protected_seq1, seq2)
    @} else @{
        // 이 레지스터에 대한 저장/복원 필요 없음
        preserving(rest_regs, seq1, seq2)
    @}
@}
@end lisp

@noindent
또 다른 시퀀스 결합기인 @code{tack_on_instruction_sequence}는 @code{compile_lambda}가 프로시저 본문을 다른 시퀀스에 덧붙이는 데 사용된다.
프로시저 본문은 결합된 시퀀스의 일부로 실행될 ``인라인'' 상태가 아니기 때문에, 그것의 레지스터 사용은 그것이 임베드된 시퀀스의 레지스터 사용에 영향을 미치지 않는다.
따라서 우리는 그것을 다른 시퀀스에 덧붙일 때 프로시저 본문의 필요하고 수정된 레지스터 집합을 무시한다.

@lisp
fn tack_on_instruction_sequence(seq: InstructionSeq, body: InstructionSeq) -> InstructionSeq @{
    let mut statements = seq.statements;
    statements.extend(body.statements);
    InstructionSeq::new(seq.needs, seq.modifies, statements)
@}
@end lisp

@noindent
@code{Compile_if}와 @code{compile_procedure_call}은 테스트 뒤에 오는 두 가지 대안 분기를 덧붙이기 위해 @code{parallel_instruction_sequences}라는 특수 결합기를 사용한다.
두 분기는 결코 순차적으로 실행되지 않을 것이다; 테스트의 특정 평가에 대해, 한 분기 또는 다른 분기가 입력될 것이다.
이 때문에, 두 번째 분기에 의해 필요한 레지스터는 첫 번째 분기에 의해 수정되더라도 결합된 시퀀스에 의해 여전히 필요하다.

@lisp
fn parallel_instruction_sequences(
    seq1: InstructionSeq,
    seq2: InstructionSeq,
) -> InstructionSeq @{
    let needs = set_union(&seq1.needs, &seq2.needs);
    let modifies = set_union(&seq1.modifies, &seq2.modifies);
    let mut statements = seq1.statements;
    statements.extend(seq2.statements);
    InstructionSeq::new(needs, modifies, statements)
@}
@end lisp

@node	5.5.5, 5.5.6, 5.5.4, 5.5
@subsection 컴파일된 코드의 예 (An Example of Compiled Code)

이제 컴파일러의 모든 요소를 보았으므로, 컴파일된 코드의 예를 통해 이것들이 어떻게 결합되는지 살펴보자.
우리는 @code{compile}을 호출하여 재귀적 @code{factorial} 프로시저의 정의를 컴파일할 것이다:

@lisp
// 팩토리얼 정의 컴파일
let factorial_def = Expr::Define @{
    name: "factorial".to_string(),
    value: Box::new(Expr::Lambda @{
        params: vec!["n".to_string()],
        body: vec![Expr::If @{
            predicate: Box::new(Expr::Application @{
                operator: Box::new(Expr::Symbol("=".to_string())),
                operands: vec![Expr::Symbol("n".to_string()), Expr::Number(1)],
            @}),
            consequent: Box::new(Expr::Number(1)),
            alternative: Box::new(Expr::Application @{
                operator: Box::new(Expr::Symbol("*".to_string())),
                operands: vec![
                    Expr::Application @{
                        operator: Box::new(Expr::Symbol("factorial".to_string())),
                        operands: vec![Expr::Application @{
                            operator: Box::new(Expr::Symbol("-".to_string())),
                            operands: vec![Expr::Symbol("n".to_string()), Expr::Number(1)],
                        @}],
                    @},
                    Expr::Symbol("n".to_string()),
                ],
            @}),
        @}],
    @}),
@};

let seq = compile(&factorial_def, Register::Val, &Linkage::Next);
@end lisp

@noindent
우리는 정의 표현식의 값이 @code{val} 레지스터에 놓여야 한다고 지정했다.
우리는 정의를 실행한 후 컴파일된 코드가 무엇을 하든 상관하지 않으므로, 링키지 기술자로 @code{next}를 선택한 것은 임의적이다.

@code{Compile}은 표현식이 정의임을 확인하고, @code{compile_definition}을 호출하여 할당될 값을 계산하는 코드(@code{val}을 타겟으로 함), 정의를 설치하는 코드, 정의의 값(@code{ok} 기호임)을 타겟 레지스터에 넣는 코드, 그리고 마지막으로 링키지 코드를 컴파일한다.
@code{Env}는 값을 계산하는 코드 주위에서 보존되는데, 왜냐하면 정의를 설치하는 데 필요하기 때문이다.
링키지가 @code{next}이므로, 이 경우에는 링키지 코드가 없다.
따라서 컴파일된 코드의 뼈대는 다음과 같다

@example
⟨@emph{값을 계산하는 코드가 env를 수정하면 env 저장}⟩
  ⟨@emph{정의 값의 컴파일, 타겟 val, 링키지 next}⟩
  ⟨@emph{위에서 저장했다면 env 복원}⟩
  Perform(Op("define-variable".into(),
           vec![VExp::Const(Value::Symbol("factorial".into())),
                VExp::Reg(Register::Val),
                VExp::Reg(Register::Env)])),
  Assign(Register::Val, VExp::Const(Value::Ok))
@end example

@noindent
변수 @code{factorial}에 대한 값을 생성하기 위해 컴파일되어야 할 표현식은 팩토리얼을 계산하는 프로시저가 값인 @code{lambda} 표현식이다.
@code{Compile}은 @code{compile_lambda}를 호출하여 이를 처리하는데, 이는 프로시저 본문을 컴파일하고, 이를 새로운 진입점으로 레이블링하고, 새 진입점의 프로시저 본문과 런타임 환경을 결합하여 결과를 @code{val}에 할당하는 명령어를 생성한다.
그런 다음 시퀀스는 컴파일된 프로시저 코드를 건너뛰는데, 이 코드는 이 지점에 삽입된다.
프로시저 코드 자체는 프로시저의 정의 환경을 형식 매개변수 @code{n}을 프로시저 인자에 바인딩하는 프레임으로 확장하는 것으로 시작한다.
그 다음 실제 프로시저 본문이 온다.
변수 값에 대한 이 코드는 @code{env} 레지스터를 수정하지 않으므로, 위에 표시된 선택적 @code{save}와 @code{restore}는 생성되지 않는다.
(@code{entry2}에 있는 프로시저 코드는 이 시점에서 실행되지 않으므로, 그것의 @code{env} 사용은 관련이 없다.)
따라서 컴파일된 코드의 뼈대는 다음과 같이 된다

@example
  Assign(Register::Val, Op("make-compiled-procedure".into(),
              vec![VExp::Label("entry2".into()),
                   VExp::Reg(Register::Env)])),
  Goto(GotoDest::Label("after-lambda1".into())),
Label("entry2".into()),
  Assign(Register::Env, Op("compiled-procedure-env".into(),
              vec![VExp::Reg(Register::Proc)])),
  Assign(Register::Env, Op("extend-environment".into(),
              vec![VExp::Const(Value::Symbol("n".into())),
                   VExp::Reg(Register::Argl),
                   VExp::Reg(Register::Env)])),
  ⟨@emph{프로시저 본문의 컴파일}⟩
Label("after-lambda1".into()),
  Perform(Op("define-variable".into(),
           vec![VExp::Const(Value::Symbol("factorial".into())),
                VExp::Reg(Register::Val), 
                VExp::Reg(Register::Env)])),
  Assign(Register::Val, VExp::Const(Value::Ok))
@end example

@noindent
프로시저 본문은 항상 (@code{compile_lambda_body}에 의해) 타겟 @code{val}과 링키지 @code{return}을 가진 시퀀스로 컴파일된다.
이 경우 시퀀스는 단일 @code{if} 표현식으로 구성된다:

@example
if n == 1 @{
    1
@} else @{
    factorial(n - 1) * n
@}
@end example

@noindent
@code{Compile_if}는 먼저 술어를 계산하는 코드(@code{val}을 타겟으로 함)를 생성하고, 결과를 확인한 다음, 술어가 거짓이면 참 분기를 우회하여 분기한다.
@code{Env}와 @code{continue}는 술어 코드 주위에서 보존되는데, @code{if} 표현식의 나머지를 위해 필요할 수 있기 때문이다.
@code{if} 표현식은 프로시저 본문을 구성하는 시퀀스의 마지막 표현식(이자 유일한 표현식)이므로, 그 타겟은 @code{val}이고 링키지는 @code{return}이다. 따라서 참 분기와 거짓 분기는 모두 타겟 @code{val}과 링키지 @code{return}으로 컴파일된다.
(즉, 조건문의 값, 즉 어느 한 분기에 의해 계산된 값이 프로시저의 값이다.)

@example
⟨@emph{술어에 의해 수정되고 분기에서 필요하다면 continue, env 저장}⟩
  ⟨@emph{술어의 컴파일, 타겟 val, 링키지 next}⟩
  ⟨@emph{위에서 저장했다면 continue, env 복원}⟩
  Test(Op("is-false".into(), vec![Reg(Val)])),
  Branch("false-branch4".into()),
// true-branch5
  ⟨@emph{참 분기의 컴파일, 타겟 val, 링키지 return}⟩
// false-branch4
Label("false-branch4".into()),
  ⟨@emph{거짓 분기의 컴파일, 타겟 val, 링키지 return}⟩
Label("after-if3".into()),
@end example

@noindent
술어 @code{(= n 1)}은 프로시저 호출이다.
이것은 연산자(기호 @code{=})를 조회하고 이 값을 @code{proc}에 넣는다.
그런 다음 인자 @code{1}과 @code{n}의 값을 @code{argl}에 조립한다.
그런 다음 이것은 @code{proc}이 원시 프로시저를 포함하는지 복합 프로시저를 포함하는지 테스트하고, 이에 따라 원시 분기나 복합 분기로 디스패치한다.
두 분기 모두 @code{after_call} 레이블에서 재개된다.
연산자와 피연산자의 평가 주위에 레지스터를 보존해야 하는 요구 사항은 레지스터 저장을 초래하지 않는데, 이 경우 그러한 평가는 해당 레지스터를 수정하지 않기 때문이다.

@example
  Assign(Proc, Op("lookup-variable-value".into(),
               vec![VExp::Const(Value::Symbol("=".into())), 
                    VExp::Reg(Env)])),
  Assign(Val, VExp::Const(Value::Number(1))),
  Assign(Argl, Op("list".into(), vec![VExp::Reg(Val)])),
  Assign(Val, Op("lookup-variable-value".into(),
              vec![VExp::Const(Value::Symbol("n".into())),
                   VExp::Reg(Env)])),
  Assign(Argl, Op("cons".into(), vec![VExp::Reg(Val), VExp::Reg(Argl)])),
  Test(Op("is-primitive-procedure".into(), vec![Reg(Proc)])),
  Branch("primitive-branch17".into()),
// compiled-branch16
Label("compiled-branch16".into()),
  Assign(Continue, Label("after-call15".into())),
  Assign(Val, Op("compiled-procedure-entry".into(),
              vec![VExp::Reg(Proc)])),
  Goto(GotoDest::Reg(Val)),
// primitive-branch17
Label("primitive-branch17".into()),
  Assign(Val, Op("apply-primitive-procedure".into(),
              vec![VExp::Reg(Proc),
                   VExp::Reg(Argl)])),
Label("after-call15".into()),
@end example

@noindent
상수 1인 참 분기는 타겟 @code{val}과 링키지 @code{return}으로 컴파일되어 다음과 같이 된다

@example
Assign(Val, VExp::Const(Value::Number(1))),
Goto(Reg(Continue)),
@end example

@noindent
거짓 분기에 대한 코드는 또 다른 프로시저 호출인데, 여기서 프로시저는 기호 @code{*}의 값이고, 인자는 @code{n}과 또 다른 프로시저 호출(@code{factorial} 호출)의 결과이다.
이 호출들은 각각 @code{proc}과 @code{argl} 및 자체 원시 및 복합 분기를 설정한다.
@ref{Figure 5.17}은 @code{factorial} 프로시저 정의의 전체 컴파일을 보여준다.
위에서 보여진 술어 주위의 @code{continue}와 @code{env}에 대한 가능한 @code{save}와 @code{restore}가 실제로 생성된다는 점에 주목하라. 왜냐하면 이 레지스터들은 술어 내의 프로시저 호출에 의해 수정되고 분기의 프로시저 호출과 @code{return} 링키지에 필요하기 때문이다.

@quotation
@strong{@anchor{Figure 5.17}Figure 5.17:} @math{\downarrow} @code{factorial} 프로시저 정의의 컴파일.

@example
vec![
    // 프로시저를 구성하고 코드를 건너뜀
    Assign(Val, Op("make-compiled-procedure".into(), 
        vec![Label("entry2".into()), Reg(Env)])),
    Goto(Label("after-lambda1".into())),
// entry2
Label("entry2".into()),
    Assign(Env, Op("compiled-procedure-env".into(), vec![Reg(Proc)])),
    Assign(Env, Op("extend-environment".into(), 
        vec![Const(Symbol("n".into())), Reg(Argl), Reg(Env)])),
    // 실제 프로시저 본문 시작
    Save(Continue),
    Save(Env),
    // (= n 1) 계산
    Assign(Proc, Op("lookup-variable-value".into(), 
        vec![Const(Symbol("=".into())), Reg(Env)])),
    Assign(Val, Const(1)),
    Assign(Argl, Op("list".into(), vec![Reg(Val)])),
    Assign(Val, Op("lookup-variable-value".into(), 
        vec![Const(Symbol("n".into())), Reg(Env)])),
    Assign(Argl, Op("cons".into(), vec![Reg(Val), Reg(Argl)])),
    Test(Op("is-primitive-procedure".into(), vec![Reg(Proc)])),
    Branch("primitive-branch17".into()),
// compiled-branch16
Label("compiled-branch16".into()),
    Assign(Continue, Label("after-call15".into())),
    Assign(Val, Op("compiled-procedure-entry".into(), vec![Reg(Proc)])),
    Goto(Reg(Val)),
// primitive-branch17
Label("primitive-branch17".into()),
    Assign(Val, Op("apply-primitive-procedure".into(), 
        vec![Reg(Proc), Reg(Argl)])),
// after-call15
Label("after-call15".into()),
    Restore(Env),
    Restore(Continue),
    Test(Op("is-false".into(), vec![Reg(Val)])),
    Branch("false-branch4".into()),
// true-branch5
Label("true-branch5".into()),
    Assign(Val, Const(1)),
    Goto(Reg(Continue)),
// false-branch4
Label("false-branch4".into()),
    // (* (factorial (- n 1)) n) 계산
    Assign(Proc, Op("lookup-variable-value".into(), 
        vec![Const(Symbol("*".into())), Reg(Env)])),
    Save(Continue),
    Save(Proc),
    Assign(Val, Op("lookup-variable-value".into(), 
        vec![Const(Symbol("n".into())), Reg(Env)])),
    Assign(Argl, Op("list".into(), vec![Reg(Val)])),
    Save(Argl),
    // (factorial (- n 1)) 계산
    Assign(Proc, Op("lookup-variable-value".into(), 
        vec![Const(Symbol("factorial".into())), Reg(Env)])),
    Save(Proc),
    // (- n 1) 계산
    Assign(Proc, Op("lookup-variable-value".into(), 
        vec![Const(Symbol("-".into())), Reg(Env)])),
    Assign(Val, Const(1)),
    Assign(Argl, Op("list".into(), vec![Reg(Val)])),
    Assign(Val, Op("lookup-variable-value".into(), 
        vec![Const(Symbol("n".into())), Reg(Env)])),
    Assign(Argl, Op("cons".into(), vec![Reg(Val), Reg(Argl)])),
    Test(Op("is-primitive-procedure".into(), vec![Reg(Proc)])),
    Branch("primitive-branch8".into()),
// compiled-branch7
Label("compiled-branch7".into()),
    Assign(Continue, Label("after-call6".into())),
    Assign(Val, Op("compiled-procedure-entry".into(), vec![Reg(Proc)])),
    Goto(Reg(Val)),
// primitive-branch8
Label("primitive-branch8".into()),
    Assign(Val, Op("apply-primitive-procedure".into(), 
        vec![Reg(Proc), Reg(Argl)])),
// after-call6
Label("after-call6".into()),
    Assign(Argl, Op("list".into(), vec![Reg(Val)])),
    Restore(Proc),
    Test(Op("is-primitive-procedure".into(), vec![Reg(Proc)])),
    Branch("primitive-branch11".into()),
// compiled-branch10
Label("compiled-branch10".into()),
    Assign(Continue, Label("after-call9".into())),
    Assign(Val, Op("compiled-procedure-entry".into(), vec![Reg(Proc)])),
    Goto(Reg(Val)),
// primitive-branch11
Label("primitive-branch11".into()),
    Assign(Val, Op("apply-primitive-procedure".into(), 
        vec![Reg(Proc), Reg(Argl)])),
// after-call9
Label("after-call9".into()),
    Restore(Argl),
    Assign(Argl, Op("cons".into(), vec![Reg(Val), Reg(Argl)])),
    Restore(Proc),
    Restore(Continue),
    // * 적용
    Test(Op("is-primitive-procedure".into(), vec![Reg(Proc)])),
    Branch("primitive-branch14".into()),
// compiled-branch13
Label("compiled-branch13".into()),
    Assign(Val, Op("compiled-procedure-entry".into(), vec![Reg(Proc)])),
    Goto(Reg(Val)),
// primitive-branch14
Label("primitive-branch14".into()),
    Assign(Val, Op("apply-primitive-procedure".into(), 
        vec![Reg(Proc), Reg(Argl)])),
    Goto(Reg(Continue)),
// after-call12, after-if3, after-lambda1
Label("after-lambda1".into()),
    Perform(Op("define-variable".into(), 
        vec![Const(Symbol("factorial".into())), Reg(Val), Reg(Env)])),
    Assign(Val, Const(Value::Ok)),
]
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 5.33}연습문제 5.33:} 위에서 주어진 것과 약간 다른 다음 팩토리얼 프로시저 정의를 고려해 보자:

@example
fn factorial_alt(n: i64) -> i64 @{
    if n == 1 @{
        1
    @} else @{
        n * factorial_alt(n - 1)
    @}
@}
@end example

이 프로시저를 컴파일하고 결과 코드를 @code{factorial}에 대해 생성된 코드와 비교하라.
발견한 차이점을 설명하라.
두 프로그램 중 하나가 다른 것보다 더 효율적으로 실행되는가?
@end quotation

@quotation
@strong{@anchor{Exercise 5.34}연습문제 5.34:} 반복적 팩토리얼 프로시저를 컴파일하라

@example
fn factorial(n: u64) -> u64 @{
    fn iter(product: u64, counter: u64) -> u64 @{
        if counter > n @{
            product
        @} else @{
            iter(counter * product, counter + 1)
        @}
    @}
    iter(1, 1)
@}
@end example

결과 코드에 주석을 달아, 하나는 스택 공간을 쌓고 다른 하나는 상수 스택 공간에서 실행되게 만드는 @code{factorial}의 반복적 버전과 재귀적 버전 코드 사이의 본질적인 차이를 보여라.
@end quotation

@quotation
@strong{@anchor{Exercise 5.35}연습문제 5.35:} @ref{Figure 5.18}에 표시된 코드를 생성하기 위해 어떤 표현식이 컴파일되었는가?
@end quotation

@quotation
@strong{@anchor{Figure 5.18}Figure 5.18:} @math{\downarrow} 컴파일러 출력의 예. @ref{Exercise 5.35} 참조.

@lisp
vec![
    Assign(Val, Op("make-compiled-procedure".into(), 
        vec![Label("entry16".into()), Reg(Env)])),
    Goto(Label("after-lambda15".into())),
// entry16
Label("entry16".into()),
    Assign(Env, Op("compiled-procedure-env".into(), vec![Reg(Proc)])),
    Assign(Env, Op("extend-environment".into(), 
        vec![Const(Value::Symbol("x".into())), Reg(Argl), Reg(Env)])),
    Assign(Proc, Op("lookup-variable-value".into(), 
        vec![Const(Value::Symbol("+".into())), Reg(Env)])),
    Save(Continue), Save(Proc), Save(Env),
    Assign(Proc, Op("lookup-variable-value".into(), 
        vec![Const(Value::Symbol("g".into())), Reg(Env)])),
    Save(Proc),
    Assign(Proc, Op("lookup-variable-value".into(), 
        vec![Const(Value::Symbol("+".into())), Reg(Env)])),
    Assign(Val, Const(Value::Number(2))),
    Assign(Argl, Op("list".into(), vec![Reg(Val)])),
    Assign(Val, Op("lookup-variable-value".into(), 
        vec![Const(Value::Symbol("x".into())), Reg(Env)])),
    Assign(Argl, Op("cons".into(), vec![Reg(Val), Reg(Argl)])),
    Test(Op("is-primitive-procedure".into(), vec![Reg(Proc)])),
    Branch("primitive-branch19".into()),
// compiled-branch18
Label("compiled-branch18".into()),
    Assign(Continue, Label("after-call17".into())),
    Assign(Val, Op("compiled-procedure-entry".into(), vec![Reg(Proc)])),
    Goto(Reg(Val)),
// primitive-branch19
Label("primitive-branch19".into()),
    Assign(Val, Op("apply-primitive-procedure".into(), vec![Reg(Proc), Reg(Argl)])),
// after-call17
Label("after-call17".into()),
    Assign(Argl, Op("list".into(), vec![Reg(Val)])),
    Restore(Proc),
    Test(Op("is-primitive-procedure".into(), vec![Reg(Proc)])),
    Branch("primitive-branch22".into()),
// compiled-branch21
Label("compiled-branch21".into()),
    Assign(Continue, Label("after-call20".into())),
    Assign(Val, Op("compiled-procedure-entry".into(), vec![Reg(Proc)])),
    Goto(Reg(Val)),
// primitive-branch22
Label("primitive-branch22".into()),
    Assign(Val, Op("apply-primitive-procedure".into(), vec![Reg(Proc), Reg(Argl)])),
// after-call20
Label("after-call20".into()),
    Assign(Argl, Op("list".into(), vec![Reg(Val)])),
    Restore(Env),
    Assign(Val, Op("lookup-variable-value".into(), 
        vec![Const(Value::Symbol("x".into())), Reg(Env)])),
    Assign(Argl, Op("cons".into(), vec![Reg(Val), Reg(Argl)])),
    Restore(Proc),
    Restore(Continue),
    Test(Op("is-primitive-procedure".into(), vec![Reg(Proc)])),
    Branch("primitive-branch25".into()),
// compiled-branch24
Label("compiled-branch24".into()),
    Assign(Val, Op("compiled-procedure-entry".into(), vec![Reg(Proc)])),
    Goto(Reg(Val)),
// primitive-branch25
Label("primitive-branch25".into()),
    Assign(Val, Op("apply-primitive-procedure".into(), vec![Reg(Proc), Reg(Argl)])),
    Goto(Reg(Continue)),
// after-call23
Label("after-lambda15".into()),
    Perform(Op("define-variable".into(), 
        vec![Const(Value::Symbol("f".into())), Reg(Val), Reg(Env)])),
    Assign(Val, Const(Value::Ok)),
]
@end lisp
@end quotation

@quotation
@strong{@anchor{Exercise 5.36}연습문제 5.36:} 우리 컴파일러는 조합의 피연산자에 대해 어떤 평가 순서를 생성하는가?
왼쪽에서 오른쪽인가, 오른쪽에서 왼쪽인가, 아니면 다른 순서인가?
컴파일러의 어디에서 이 순서가 결정되는가?
다른 평가 순서를 생성하도록 컴파일러를 수정하라. (@ref{5.4.1}의 명시적 제어 평가자에 대한 평가 순서 논의를 참조하라.)
피연산자 평가 순서를 변경하는 것이 인자 리스트를 구성하는 코드의 효율성에 어떤 영향을 미치는가?
@end quotation

@quotation
@strong{@anchor{Exercise 5.37}연습문제 5.37:} 스택 사용을 최적화하기 위한 컴파일러의 @code{preserving} 메커니즘을 이해하는 한 가지 방법은 이 아이디어를 사용하지 않을 경우 어떤 추가 연산이 생성될지 보는 것이다.
@code{preserving}이 항상 @code{save}와 @code{restore} 연산을 생성하도록 수정하라.
몇 가지 간단한 표현식을 컴파일하고 생성된 불필요한 스택 연산을 식별하라.
코드를 @code{preserving} 메커니즘이 온전할 때 생성된 코드와 비교하라.
@end quotation

@quotation
@strong{@anchor{Exercise 5.38}연습문제 5.38:} 우리 컴파일러는 불필요한 스택 연산을 피하는 데는 영리하지만, 언어의 원시 프로시저에 대한 호출을 기계가 제공하는 원시 연산의 관점에서 컴파일하는 데 있어서는 전혀 영리하지 않다.
예를 들어, @code{(+ a 1)}을 계산하기 위해 얼마나 많은 코드가 컴파일되는지 고려해 보자: 코드는 @code{argl}에 인자 리스트를 설정하고, (@code{+} 기호를 환경에서 조회하여 찾은) 원시 덧셈 프로시저를 @code{proc}에 넣고, 프로시저가 원시인지 복합인지 테스트한다.
컴파일러는 항상 테스트를 수행하는 코드와 원시 및 복합 분기에 대한 코드(그중 하나만 실행됨)를 생성한다.
우리는 원시를 구현하는 컨트롤러의 부분을 보여주지 않았지만, 이러한 명령어들은 기계의 데이터 경로에 있는 원시 산술 연산을 사용할 것이라고 가정한다.
만약 컴파일러가 원시를 @newterm{오픈 코드(open-code)}할 수 있다면---즉, 이러한 원시 기계 연산을 직접 사용하는 코드를 생성할 수 있다면---얼마나 더 적은 코드가 생성될지 고려해 보자.
@code{(+ a 1)} 표현식은 다음과 같이 간단한 것으로 컴파일될 수 있다@footnote{우리는 여기서 소스 언어 프로시저와 기계 연산을 모두 나타내기 위해 동일한 기호 @code{+}를 사용했다. 일반적으로 소스 언어의 원시와 기계의 원시 사이에는 일대일 대응이 없을 것이다.}

@lisp
(assign val (op lookup_variable_value) 
            (const a) 
            (reg env))
(assign val (op +)
            (reg val)
            (const 1))
@end lisp

이 연습문제에서 우리는 선택된 원시의 오픈 코딩을 지원하도록 컴파일러를 확장할 것이다.
일반적인 프로시저 적용 코드 대신 이러한 원시 프로시저 호출에 대해 특수 목적 코드가 생성될 것이다.
이를 지원하기 위해, 우리는 기계에 특수 인자 레지스터 @code{arg1}과 @code{arg2}를 추가할 것이다.
기계의 원시 산술 연산은 @code{arg1}과 @code{arg2}에서 입력을 받을 것이다.
결과는 @code{val}, @code{arg1}, 또는 @code{arg2}에 놓일 수 있다.

컴파일러는 소스 프로그램에서 오픈 코딩된 원시의 적용을 인식할 수 있어야 한다.
우리는 @code{compile} 프로시저의 디스패치를 증강하여 현재 인식하는 예약어(특수 형식) 외에도 이러한 원시의 이름을 인식하도록 할 것이다.@footnote{원시를 예약어로 만드는 것은 일반적으로 나쁜 생각인데, 왜냐하면 사용자가 이러한 이름을 다른 프로시저에 다시 바인딩할 수 없기 때문이다. 게다가, 사용 중인 컴파일러에 예약어를 추가하면, 이 이름을 가진 프로시저를 정의하는 기존 프로그램이 작동을 멈출 것이다. 이 문제를 피하는 방법에 대한 아이디어는 @ref{Exercise 5.44}를 참조하라.} 각 특수 형식에 대해 우리 컴파일러는 코드 생성기를 가지고 있다.
이 연습문제에서 우리는 오픈 코딩된 원시를 위한 코드 생성기 패밀리를 구성할 것이다.

@enumerate a

@item
오픈 코딩된 원시는 특수 형식과 달리 피연산자를 모두 평가해야 한다.
모든 오픈 코딩 코드 생성기에서 사용할 코드 생성기 @code{spread_arguments}를 작성하라.
@code{Spread-arguments}는 피연산자 리스트를 받아 주어진 피연산자를 연속적인 인자 레지스터로 타겟팅하여 컴파일해야 한다.
피연산자가 오픈 코딩된 원시에 대한 호출을 포함할 수 있으므로, 피연산자 평가 중에 인자 레지스터를 보존해야 한다는 점에 유의하라.

@item
원시 프로시저 @code{=}, @code{*}, @code{-}, @code{+} 각각에 대해, 해당 연산자와 타겟, 링키지 기술자를 가진 조합을 받아 인자를 레지스터에 펼친(spread) 다음 주어진 타겟과 링키지로 연산을 수행하는 코드를 생성하는 코드 생성기를 작성하라.
두 개의 피연산자를 가진 표현식만 처리하면 된다.
@code{compile}이 이 코드 생성기들로 디스패치하도록 만들라.

@item
새 컴파일러를 @code{factorial} 예제에서 시도해 보라.
결과 코드를 오픈 코딩 없이 생성된 결과와 비교하라.

@item
@code{+}와 @code{*}에 대한 코드 생성기를 확장하여 임의의 수의 피연산자를 가진 표현식을 처리할 수 있도록 하라.
두 개 이상의 피연산자를 가진 표현식은 각각 두 개의 입력만 갖는 연산 시퀀스로 컴파일되어야 할 것이다.

@end enumerate
@end quotation

@node	5.5.6, 5.5.7, 5.5.5, 5.5
@subsection 어휘 주소 지정 (Lexical Addressing)

컴파일러가 수행하는 가장 일반적인 최적화 중 하나는 변수 조회의 최적화이다.
우리가 지금까지 구현한 컴파일러는 평가자 기계의 @code{lookup_variable_value} 연산을 사용하는 코드를 생성한다.
이 연산은 런타임 환경을 통해 프레임별로 바깥쪽으로 작업하면서 현재 바인딩된 각 변수와 비교하여 변수를 검색한다.
프레임이 깊게 중첩되어 있거나 변수가 많으면 이 검색은 비용이 많이 들 수 있다.
예를 들어, 다음에 의해 반환되는 프로시저의 적용에서 표현식 @code{(* x y z)}를 평가하는 동안 @code{x}의 값을 찾는 문제를 고려해 보자

@example
@{
    let x = 3;
    let y = 4;
    |a, b, c, d, e| @{
        let y = a * b * x;
        let z = c + d + x;
        x * y * z
    @}
@}
@end example

@noindent
이 표현식은 중첩된 스코프를 포함한다. 변수들은 일련의 환경에 바인딩된다. 예를 들어, @code{x * y * z}가 평가될 때, @code{x}는 가장 바깥쪽 스코프에서 발견되고, @code{y}와 @code{z}는 가장 안쪽 스코프에 있다.

@code{let} 표현식은 개념적으로 즉시 실행되는 클로저와 동등하므로, 이 표현식은 다음과 동등하다:

@example
(|x, y| @{
    |a, b, c, d, e| @{
        (|y, z| @{
            x * y * z
        @})(a * b * x, c * d * x)
    @}
@})(3, 4)
@end example

@noindent
@code{lookup_variable_value}가 @code{x}를 검색할 때마다, 기호 @code{x}가 (첫 번째 프레임의) @code{y}나 @code{z}와 같지 않고, (두 번째 프레임의) @code{a}, @code{b}, @code{c}, @code{d}, 또는 @code{e}와 같지 않음을 결정해야 한다.
우리는 당분간 우리 프로그램이 정의를 사용하지 않는다고 가정할 것이다---변수는 @code{lambda}를 통해서만 바인딩된다.
우리 언어는 어휘적으로 스코프가 지정되므로(lexically scoped), 어떤 표현식에 대한 런타임 환경은 표현식이 나타나는 프로그램의 어휘적 구조와 평행한 구조를 갖게 될 것이다.@footnote{내부 정의를 허용하는 경우에는, 그것들을 스캔해 내지 않는 한 이것은 사실이 아니다. @ref{Exercise 5.43} 참조.}
따라서 컴파일러는 위 표현식을 분석할 때, 프로시저가 적용될 때마다 @code{(* x y z)}의 변수 @code{x}가 현재 프레임에서 두 프레임 밖의 프레임에서 첫 번째 변수로 발견될 것임을 알 수 있다.

우리는 환경과 @newterm{어휘 주소(lexical address)}를 인자로 받는 새로운 종류의 변수 조회 연산 @code{lexical_address_lookup}을 발명함으로써 이 사실을 활용할 수 있다.
어휘 주소는 두 개의 숫자로 구성된다: 몇 개의 프레임을 건너뛸지 지정하는 @newterm{프레임 번호(frame number)}와 해당 프레임에서 몇 번째 변수를 건너뛸지 지정하는 @newterm{변위 번호(displacement number)}.
@code{Lexical-address-lookup}은 현재 환경에 상대적인 해당 어휘 주소에 저장된 변수의 값을 생성할 것이다.
만약 우리가 @code{lexical_address_lookup} 연산을 우리 기계에 추가한다면, 우리는 컴파일러가 @code{lookup_variable_value} 대신 이 연산을 사용하여 변수를 참조하는 코드를 생성하도록 만들 수 있다.
마찬가지로, 우리의 컴파일된 코드는 @code{set_variable_value} 대신 새로운 @code{lexical_address_set} 연산을 사용할 수 있다.

그러한 코드를 생성하기 위해, 컴파일러는 참조를 컴파일하려는 변수의 어휘 주소를 결정할 수 있어야 한다.
프로그램 내 변수의 어휘 주소는 코드의 어디에 있는지에 따라 달라진다.
예를 들어, 다음 프로그램에서 표현식 @code{⟨}@var{e1}@code{⟩} 내의 @code{x}의 주소는 (2, 0)이다---두 프레임 뒤, 프레임의 첫 번째 변수.
그 시점에서 @code{y}는 주소 (0, 0)에 있고 @code{c}는 주소 (1, 2)에 있다.
표현식 @code{⟨}@var{e2}@code{⟩}에서 @code{x}는 (1, 0)에, @code{y}는 (1, 1)에, @code{c}는 (0, 2)에 있다.

@example
(|x, y| @{
    |a, b, c, d, e| @{
        (|y, z| @{
            ⟨@var{e1}⟩
        @})(⟨@var{e2}⟩, c + d + x)
    @}
@})(3, 4)
@end example

@noindent
컴파일러가 어휘 주소 지정을 사용하는 코드를 생성하는 한 가지 방법은 @newterm{컴파일 타임 환경(compile-time environment)}이라는 데이터 구조를 유지하는 것이다.
이것은 특정 변수 접근 연산이 실행될 때 런타임 환경의 어느 프레임의 어느 위치에 어떤 변수가 있을지 추적한다.
컴파일 타임 환경은 프레임들의 리스트이며, 각 프레임은 변수들의 리스트를 포함한다.
(물론 값은 컴파일 타임에 계산되지 않으므로 변수에 바인딩된 값은 없을 것이다.)
컴파일 타임 환경은 @code{compile}의 추가 인자가 되며 각 코드 생성기로 전달된다.
@code{compile}에 대한 최상위 호출은 빈 컴파일 타임 환경을 사용한다.
@code{lambda} 본문이 컴파일될 때, @code{compile_lambda_body}는 컴파일 타임 환경을 프로시저의 매개변수를 포함하는 프레임으로 확장하여, 본문을 구성하는 시퀀스가 그 확장된 환경으로 컴파일되도록 한다.
컴파일의 각 지점에서, @code{compile_variable}과 @code{compile_assignment}는 적절한 어휘 주소를 생성하기 위해 컴파일 타임 환경을 사용한다.

@ref{Exercise 5.39}부터 @ref{Exercise 5.43}까지는 어휘 조회를 컴파일러에 통합하기 위해 어휘 주소 지정 전략의 이 스케치를 완료하는 방법을 설명한다.
@ref{Exercise 5.44}는 컴파일 타임 환경의 또 다른 용도를 설명한다.

@quotation
@strong{@anchor{Exercise 5.39}연습문제 5.39:} 새 조회 연산을 구현하는 프로시저 @code{lexical_address_lookup}을 작성하라.
이것은 두 개의 인자---어휘 주소와 런타임 환경---를 받아 지정된 어휘 주소에 저장된 변수의 값을 반환해야 한다.
@code{Lexical-address-lookup}은 변수의 값이 기호 @code{*unassigned*}인 경우 오류를 신호해야 한다.@footnote{이것은 우리가 내부 정의를 제거하기 위해 스캔 방법을 구현할 경우(@ref{Exercise 5.43}) 변수 조회에 필요한 수정 사항이다. 우리는 어휘 주소 지정이 작동하려면 이러한 정의를 제거해야 할 것이다.} 또한 지정된 어휘 주소에 있는 변수의 값을 변경하는 연산을 구현하는 프로시저 @code{lexical_address_set}을 작성하라.
@end quotation

@quotation
@strong{@anchor{Exercise 5.40}연습문제 5.40:} 위에서 설명한 대로 컴파일 타임 환경을 유지하도록 컴파일러를 수정하라.
즉, @code{compile}과 다양한 코드 생성기에 compile_time_environment 인자를 추가하고, @code{compile_lambda_body}에서 이를 확장하라.
@end quotation

@quotation
@strong{@anchor{Exercise 5.41}연습문제 5.41:} 변수와 컴파일 타임 환경을 인자로 받아 해당 환경에 대한 변수의 어휘 주소를 반환하는 프로시저 @code{find_variable}을 작성하라.
예를 들어, 위에서 보여준 프로그램 조각에서 표현식 @code{⟨}@var{e1}@code{⟩}의 컴파일 동안 컴파일 타임 환경은 @code{((y z) (a b c d e) (x y))}이다.
@code{Find-variable}은 다음을 생성해야 한다

@example
find_variable("c", &[["y", "z"], ["a", "b", "c", "d", "e"], ["x", "y"]])
@i{Some((1, 2))}

find_variable("x", &[["y", "z"], ["a", "b", "c", "d", "e"], ["x", "y"]])
@i{Some((2, 0))}

find_variable("w", &[["y", "z"], ["a", "b", "c", "d", "e"], ["x", "y"]])
@i{None}
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 5.42}연습문제 5.42:} @ref{Exercise 5.41}의 @code{find_variable}을 사용하여 @code{compile_variable}과 @code{compile_assignment}를 다시 작성하여 어휘 주소 명령어를 출력하도록 하라.
@code{find_variable}이 @code{not-found}를 반환하는 경우(즉, 변수가 컴파일 타임 환경에 없는 경우), 코드 생성기가 이전처럼 평가자 연산을 사용하여 바인딩을 검색하도록 해야 한다.
(컴파일 타임에 발견되지 않는 변수가 있을 수 있는 유일한 장소는 전역 환경인데, 이것은 런타임 환경의 일부이지만 컴파일 타임 환경의 일부는 아니다.@footnote{어휘 주소는 전역 환경의 변수에 접근하는 데 사용될 수 없는데, 왜냐하면 이러한 이름은 언제든지 대화식으로 정의되고 재정의될 수 있기 때문이다. @ref{Exercise 5.43}에서와 같이 내부 정의가 스캔되어 나가면, 컴파일러가 보는 유일한 정의는 최상위 수준의 정의이며, 이는 전역 환경에 작용한다. 정의의 컴파일은 정의된 이름이 컴파일 타임 환경에 입력되게 하지 않는다.} 따라서 원한다면, 평가자 연산이 @code{env}에서 발견된 전체 런타임 환경을 검색하는 대신 연산 @code{(op get_global_environment)}로 얻을 수 있는 전역 환경을 직접 보게 할 수 있다.)
이 절의 시작 부분에 있는 중첩 @code{lambda} 조합과 같은 몇 가지 간단한 사례에 대해 수정된 컴파일러를 테스트하라.
@end quotation

@quotation
@strong{@anchor{Exercise 5.43}연습문제 5.43:} 우리는 @ref{4.1.6}에서 블록 구조에 대한 내부 정의가 ``진짜'' 정의로 간주되어서는 안 된다고 주장했다.
오히려, 프로시저 본문은 정의되는 내부 변수들이 일반적인 @code{lambda} 변수로서 설치되고 @code{set!}을 사용하여 올바른 값으로 초기화되는 것처럼 해석되어야 한다.
@ref{4.1.6}과 @ref{Exercise 4.16}은 내부 정의를 스캔해 냄으로써 메타순환 인터프리터를 수정하여 이를 달성하는 방법을 보여주었다.
컴파일러가 프로시저 본문을 컴파일하기 전에 동일한 변환을 수행하도록 수정하라.
@end quotation

@quotation
@strong{@anchor{Exercise 5.44}연습문제 5.44:} 이 절에서 우리는 어휘 주소를 생성하기 위해 컴파일 타임 환경을 사용하는 데 초점을 맞추었다.
그러나 컴파일 타임 환경에는 다른 용도도 있다.
예를 들어, @ref{Exercise 5.38}에서 우리는 원시 프로시저를 오픈 코딩함으로써 컴파일된 코드의 효율성을 높였다.
우리의 구현은 오픈 코딩된 프로시저의 이름을 예약어로 취급했다.
만약 프로그램이 그러한 이름을 다시 바인딩한다면, @ref{Exercise 5.38}에 설명된 메커니즘은 여전히 새 바인딩을 무시하고 그것을 원시로 오픈 코딩할 것이다.
예를 들어, 다음 프로시저를 고려해 보자

@example
|plus, mult, a, b, x, y| @{
    plus(mult(a, x), mult(b, y))
@}
@end example

@noindent
이것은 @code{x}와 @code{y}의 선형 결합을 계산한다.
우리는 이것을 인자 @code{+matrix}, @code{*matrix}, 그리고 네 개의 행렬로 호출할 수 있지만, 오픈 코딩 컴파일러는 여전히 @code{(+ (* a x) (* b y))}의 @code{+}와 @code{*}를 원시 @code{+}와 @code{*}로 오픈 코딩할 것이다.
원시 프로시저의 이름을 포함하는 표현식에 대해 올바른 코드를 컴파일하기 위해 컴파일 타임 환경을 참조하도록 오픈 코딩 컴파일러를 수정하라.
(이 코드는 프로그램이 이러한 이름을 @code{define}하거나 @code{set!}하지 않는 한 올바르게 작동할 것이다.)
@end quotation

@node	5.5.7, References, 5.4, 5.5
@subsection 컴파일된 코드와 평가자 인터페이스하기 (Interfacing Compiled Code to the Evaluator)

우리는 아직 컴파일된 코드를 평가자 기계에 로드하는 방법이나 실행하는 방법을 설명하지 않았다.
우리는 명시적 제어 평가자 기계가 @ref{5.4.4}에서와 같이 정의되었으며, @ref{Footnote 323}에 지정된 추가 연산이 포함되어 있다고 가정할 것이다.
우리는 Scheme 표현식을 컴파일하고, 결과 목적 코드를 평가자 기계에 로드하고, 기계가 평가자 전역 환경에서 코드를 실행하고 결과를 출력하고 평가자의 드라이버 루프에 들어가게 하는 프로시저 @code{compile_and_go}를 구현할 것이다.
우리는 또한 평가자가 해석된 표현식이 해석된 프로시저뿐만 아니라 컴파일된 프로시저도 호출할 수 있도록 수정할 것이다.
그러면 우리는 컴파일된 프로시저를 기계에 넣고 평가자를 사용하여 그것을 호출할 수 있다:

@example
// Rust에서는, 기계를 컴파일하고 실행하여 이를 수행한다:
let factorial_def = Expr::Define @{
    name: "factorial".to_string(),
    value: Box::new(Expr::Lambda @{ /* ... */ @}),
@};

// 표현식 컴파일
let seq = compile(&factorial_def, Register::Val, &Linkage::Return);
let instructions = assemble(seq.statements, &machine.register_map, &machine.operations);

// 로드 및 실행
machine.set_register("val", Value::InstructionPointer(0));
machine.set_register("flag", Value::Bool(true));
machine.start();
@i{ok}

@i{;;; EC-Eval input:}
factorial(5)

@i{;;; EC-Eval value:}
@i{120}
@end example

@noindent
평가자가 컴파일된 프로시저를 처리할 수 있게 하려면(예를 들어, 위의 @code{factorial} 호출을 평가하기 위해), 우리는 @code{apply_dispatch}(@ref{5.4.1})의 코드를 변경하여 컴파일된 프로시저를 (복합 또는 원시 프로시저와 구별하여) 인식하고 제어를 컴파일된 코드의 진입점으로 직접 전송하도록 해야 한다:@footnote{물론, 컴파일된 프로시저와 해석된 프로시저 모두 복합(비원시)이다. 명시적 제어 평가자에서 사용된 용어와의 호환성을 위해, 이 절에서 우리는 ``복합(compound)''을 (컴파일된 것과 대조적으로) 해석된 것을 의미하는 데 사용할 것이다.}

@example
// apply-dispatch
Label("apply-dispatch".into()),
match self.proc.as_ref().unwrap() @{
    Value::Primitive(_) => @{ self.current_label = Label::PrimitiveApply; @}
    Value::Procedure @{ .. @} => @{ self.current_label = Label::CompoundApply; @}
    Value::CompiledProcedure @{ .. @} => @{ self.current_label = Label::CompiledApply; @}
    _ => @{ self.current_label = Label::UnknownProcedureType; @}
@}

// compiled-apply
Label("compiled-apply".into()),
Restore(Continue),
Assign(Val, Op("compiled-procedure-entry".into(), vec![Reg(Proc)])),
Goto(Reg(Val)),
@end example

@noindent
@code{compiled_apply}에서 @code{continue}를 복원하는 것에 주목하라.
평가자는 @code{apply_dispatch}에서 연속(continuation)이 스택의 맨 위에 있도록 배열되었음을 상기하라.
반면 컴파일된 코드 진입점은 연속이 @code{continue}에 있기를 기대하므로, 컴파일된 코드가 실행되기 전에 @code{continue}가 복원되어야 한다.

우리가 평가자 기계를 시작할 때 일부 컴파일된 코드를 실행할 수 있게 하려면, 평가자 기계의 시작 부분에 @code{flag} 레지스터가 설정되어 있으면 기계가 새 진입점으로 이동하게 하는 @code{branch} 명령어를 추가한다.

@lisp
@r{;; @code{flag}가 설정되어 있으면 분기:}
(branch (label external_entry)) 
read_eval_print_loop
  (perform (op initialize_stack))
  @r{…}
@end lisp

@noindent
@code{External_entry}는 기계가 @code{val}에 결과를 놓고 @code{(goto (reg continue))}로 끝나는 명령어 시퀀스의 위치를 @code{val}에 포함한 채 시작된다고 가정한다.
이 진입점에서 시작하면 @code{val}이 지정한 위치로 점프하지만, 먼저 @code{continue}를 할당하여 실행이 @code{print_result}로 돌아오도록 한다. @code{print_result}는 @code{val}의 값을 출력한 다음 평가자의 읽기-평가-출력 루프의 시작으로 간다.

@example
// external-entry
Label("external-entry".into()),
Perform(Op("initialize-stack".into(), vec![])),
Assign(Env, Op("get-global-environment".into(), vec![])),
Assign(Continue, Label("print-result".into())),
Goto(Reg(Val)),
@end example

@noindent
이제 우리는 다음 프로시저를 사용하여 프로시저 정의를 컴파일하고, 컴파일된 코드를 실행하고, 읽기-평가-출력 루프를 실행하여 프로시저를 시도할 수 있다.
우리는 컴파일된 코드가 @code{val}에 결과를 가지고 @code{continue}의 위치로 돌아오기를 원하므로, 타겟 @code{val}과 링키지 @code{return}으로 표현식을 컴파일한다.
컴파일러가 생성한 목적 코드를 평가자 레지스터 기계를 위한 실행 가능한 명령어로 변환하기 위해, 우리는 레지스터 기계 시뮬레이터(@ref{5.2.2})의 @code{assemble} 프로시저를 사용한다.

@example
fn compile_and_go(expression: &Expr, machine: &mut EvaluatorMachine) @{
    let seq = compile(expression, Register::Val, &Linkage::Return);
    // 우리 Rust 구현에서는 ResolvedInst로 직접 컴파일한다
    let instructions = assemble(seq.statements, ...);
    
    println!("Compiled @{@} instructions", instructions.len());
@}
@end example

@noindent
만약 우리가 @ref{5.4.4}의 끝에서처럼 스택 모니터링을 설정했다면, 컴파일된 코드의 스택 사용량을 검사할 수 있다:

@example
// 팩토리얼 컴파일
let expr = Expr::Definition @{
    var: "factorial".into(),
    value: Box::new(Expr::Lambda @{ ... @})
@};
compile_and_go(&expr, &mut machine);

// (total-pushes = 0, maximum-depth = 0)

@i{;;; EC-Eval input:}
(factorial 5)
@i{(total-pushes = 31, maximum-depth = 14)}

@i{;;; EC-Eval value:}
@i{120}
@end example

@noindent
이 예제를 @ref{5.4.4}의 끝에 표시된 동일한 프로시저의 해석된 버전을 사용한 @code{(factorial 5)}의 평가와 비교해 보라.
해석된 버전은 144번의 푸시와 28의 최대 스택 깊이를 요구했다.
이것은 우리의 컴파일 전략으로 인한 최적화를 보여준다.

@subsubheading 해석과 컴파일 (Interpretation and compilation)

이 절의 프로그램들을 가지고, 우리는 이제 해석과 컴파일이라는 대안적인 실행 전략을 실험해 볼 수 있다.@footnote{우리는 컴파일된 코드가 해석된 프로시저를 호출할 수 있도록 컴파일러를 확장함으로써 더 잘할 수 있다. @ref{Exercise 5.47} 참조.}
인터프리터는 기계를 사용자 프로그램 수준으로 끌어올린다; 컴파일러는 사용자 프로그램을 기계어 수준으로 낮춘다.
우리는 Scheme 언어(또는 어떤 프로그래밍 언어든)를 기계어 위에 세워진 일관된 추상화 제품군으로 간주할 수 있다.
인터프리터는 대화형 프로그램 개발 및 디버깅에 좋은데, 왜냐하면 프로그램 실행 단계가 이러한 추상화의 관점에서 조직되어 있어 프로그래머에게 더 이해하기 쉽기 때문이다.
컴파일된 코드는 더 빠르게 실행될 수 있는데, 왜냐하면 프로그램 실행 단계가 기계어 관점에서 조직되어 있고, 컴파일러가 고수준 추상화를 가로지르는 최적화를 자유롭게 수행할 수 있기 때문이다.@footnote{실행 전략과 무관하게, 사용자 프로그램 실행 중 발생한 오류가 시스템을 죽이거나 잘못된 답을 생성하도록 허용하는 대신 감지되고 신호되도록 주장한다면 상당한 오버헤드가 발생한다. 예를 들어, 범위를 벗어난 배열 참조는 수행하기 전에 참조의 유효성을 확인함으로써 감지할 수 있다. 그러나 확인 오버헤드는 배열 참조 자체 비용의 여러 배가 될 수 있으며, 프로그래머는 그러한 확인이 바람직한지 결정할 때 속도와 안전성을 저울질해야 한다. 좋은 컴파일러는 그러한 확인이 포함된 코드를 생성할 수 있어야 하고, 중복 확인을 피해야 하며, 프로그래머가 컴파일된 코드의 오류 검사 범위와 유형을 제어할 수 있도록 해야 한다.

C와 C++ 같은 인기 있는 언어의 컴파일러는 가능한 한 빨리 실행되도록 하기 위해 실행 코드에 오류 검사 연산을 거의 넣지 않는다. 결과적으로 오류 검사를 명시적으로 제공하는 것은 프로그래머의 몫이다. 불행히도 사람들은 속도가 제약 조건이 아닌 중요한 애플리케이션에서도 종종 이를 무시한다. 그들의 프로그램은 빠르고 위험한 삶을 산다. 예를 들어, 1988년 인터넷을 마비시킨 악명 높은 ``웜(Worm)''은 finger 데몬에서 입력 버퍼가 오버플로되었는지 확인하지 않은 @abbr{UNIX}(tm) 운영 체제의 실패를 악용했다. (@ref{Spafford 1989} 참조.)}

해석과 컴파일의 대안은 또한 새로운 컴퓨터로 언어를 포팅하기 위한 다른 전략으로 이어진다. 우리가 Lisp을 새 기계에 구현하고 싶다고 가정해 보자.
한 가지 전략은 @ref{5.4}의 명시적 제어 평가자로 시작하여 그 명령어를 새 기계를 위한 명령어로 번역하는 것이다.
다른 전략은 컴파일러로 시작하여 코드 생성기를 변경하여 새 기계를 위한 코드를 생성하도록 하는 것이다.
두 번째 전략은 원래 Lisp 시스템에서 실행되는 컴파일러로 컴파일하고 컴파일된 버전의 런타임 라이브러리와 링크함으로써 어떤 Lisp 프로그램도 새 기계에서 실행할 수 있게 해준다.@footnote{물론 해석 전략이나 컴파일 전략 중 어느 것을 사용하든 우리는 새 기계를 위한 저장소 할당, 입출력, 그리고 평가자와 컴파일러에 대한 논의에서 ``원시''로 취급한 모든 다양한 연산을 구현해야 한다. 여기서 작업을 최소화하는 한 가지 전략은 이러한 연산을 가능한 한 많이 Lisp으로 작성한 다음 새 기계를 위해 컴파일하는 것이다. 궁극적으로 모든 것은 새 기계를 위해 직접 코딩된 작은 커널(가비지 컬렉션 및 실제 기계 원시를 적용하는 메커니즘과 같은)로 축소된다.}
더 좋은 방법은 컴파일러 자체를 컴파일하고, 이것을 새 기계에서 실행하여 다른 Lisp 프로그램을 컴파일하는 것이다.@footnote{이 전략은 컴파일러의 정확성에 대한 재미있는 테스트로 이어진다. 예를 들어, 컴파일된 컴파일러를 사용하여 새 기계에서 프로그램을 컴파일한 것이 원래 Lisp 시스템에서 프로그램을 컴파일한 것과 동일한지 확인하는 것이다. 차이의 원인을 추적하는 것은 재미있지만 종종 좌절감을 주는데, 결과가 아주 작은 세부 사항에도 매우 민감하기 때문이다.}
또는 @ref{4.1}의 인터프리터 중 하나를 컴파일하여 새 기계에서 실행되는 인터프리터를 생성할 수도 있다.

@quotation
@strong{@anchor{Exercise 5.45}연습문제 5.45:} 컴파일된 코드에 의해 사용된 스택 연산과 동일한 계산에 대해 평가자에 의해 사용된 스택 연산을 비교함으로써, 우리는 컴파일러가 스택 사용을 최적화하는 정도를 속도(총 스택 연산 수 감소)와 공간(최대 스택 깊이 감소) 측면에서 결정할 수 있다.
이 최적화된 스택 사용을 동일한 계산을 위한 특수 목적 기계의 성능과 비교하면 컴파일러의 품질에 대한 몇 가지 지표를 얻을 수 있다.

@enumerate a

@item
@ref{Exercise 5.27}은 위에서 주어진 재귀적 팩토리얼 프로시저를 사용하여 @math{{n!}}을 계산하기 위해 평가자가 필요로 하는 푸시 횟수와 최대 스택 깊이를 @math{n}의 함수로 결정하도록 요청했다.
@ref{Exercise 5.14}는 @ref{Figure 5.11}에 표시된 특수 목적 팩토리얼 기계에 대해 동일한 측정을 수행하도록 요청했다.
이제 컴파일된 @code{factorial} 프로시저를 사용하여 동일한 분석을 수행하라.

컴파일된 버전의 푸시 횟수 대 해석된 버전의 푸시 횟수의 비율을 구하고, 최대 스택 깊이에 대해서도 동일하게 하라.
@math{{n!}}을 계산하는 데 사용된 연산 수와 스택 깊이는 @math{n}에 선형적이므로, 이 비율들은 @math{n}이 커짐에 따라 상수에 접근해야 한다.
이 상수들은 무엇인가?
마찬가지로, 특수 목적 기계의 스택 사용량 대 해석된 버전의 사용량 비율을 구하라.

특수 목적 대 해석된 코드의 비율과 컴파일된 대 해석된 코드의 비율을 비교하라.
당신은 특수 목적 기계가 컴파일된 코드보다 훨씬 더 잘한다는 것을 발견해야 하는데, 왜냐하면 손으로 맞춘 컨트롤러 코드는 우리의 초보적인 범용 컴파일러가 생성한 것보다 훨씬 더 좋아야 하기 때문이다.

@item
컴파일러가 손으로 맞춘 버전의 성능에 더 가까운 코드를 생성하도록 도울 수 있는 개선 사항을 제안할 수 있는가?

@end enumerate
@end quotation

@quotation
@strong{@anchor{Exercise 5.46}연습문제 5.46:} @ref{Exercise 5.45}와 같은 분석을 수행하여 트리 재귀적 피보나치 프로시저

@example
fn fib(n: u64) -> u64 @{
    if n < 2 @{ n @} else @{ fib(n - 1) + fib(n - 2) @}
@}
@end example

@noindent
를 컴파일하는 것의 효과를 @ref{Figure 5.12}의 특수 목적 피보나치 기계를 사용하는 것의 효과와 비교하여 결정하라.
(해석된 성능 측정에 대해서는 @ref{Exercise 5.29}를 참조하라.)
피보나치의 경우, 사용된 시간 자원은 @math{n}에 선형적이지 않다; 따라서 스택 연산의 비율은 @math{n}과 무관한 극한값에 접근하지 않을 것이다.
@end quotation

@quotation
@strong{@anchor{Exercise 5.47}연습문제 5.47:} 이 절에서는 해석된 코드가 컴파일된 프로시저를 호출할 수 있도록 명시적 제어 평가자를 수정하는 방법을 설명했다.
컴파일된 프로시저가 원시 프로시저와 컴파일된 프로시저뿐만 아니라 해석된 프로시저도 호출할 수 있도록 컴파일러를 수정하는 방법을 보여라.
이를 위해서는 복합(해석된) 프로시저의 경우를 처리하도록 @code{compile_procedure_call}을 수정해야 한다.
@code{compile_proc_appl}에서와 같이 모든 동일한 @code{target}과 @code{linkage} 조합을 처리해야 한다.
실제 프로시저 적용을 수행하기 위해, 코드는 평가자의 @code{compound_apply} 진입점으로 점프해야 한다.
이 레이블은 목적 코드에서 직접 참조될 수 없으므로(어셈블러는 자신이 조립하는 코드가 참조하는 모든 레이블이 거기에 정의되어 있을 것을 요구하기 때문에), 우리는 평가자 기계에 이 진입점을 유지할 @code{compapp}라는 레지스터를 추가하고, 이를 초기화하는 명령어를 추가할 것이다:

@example
Assign("compapp".into(), Label("compound-apply".into())),
// flag가 설정되어 있으면 분기:
Branch("external-entry".into()),
Label("read-eval-print-loop".into()),
// ...
@end example

코드를 테스트하려면, 프로시저 @code{g}를 호출하는 프로시저 @code{f}를 정의하는 것으로 시작하라.
@code{compile_and_go}를 사용하여 @code{f}의 정의를 컴파일하고 평가자를 시작하라.
이제 평가자에서 @code{g}를 정의하고 @code{f}를 호출해 보라.
@end quotation

@quotation
@strong{@anchor{Exercise 5.48}연습문제 5.48:} 이 절에서 구현된 @code{compile_and_go} 인터페이스는 어색한데, 왜냐하면 컴파일러가 단 한 번만(평가자 기계가 시작될 때) 호출될 수 있기 때문이다.
다음과 같이 명시적 제어 평가자 내에서 호출될 수 있는 @code{compile_and_run} 원시를 제공하여 컴파일러-인터프리터 인터페이스를 증강하라:

@example
@i{;;; EC-Eval input:}
compile_and_run("
fn factorial(n) @{
    if n == 1 @{ 1 @} else @{ factorial(n - 1) * n @}
@}
")

@i{;;; EC-Eval value:}
@i{ok}

@i{;;; EC-Eval input:}
factorial(5)

@i{;;; EC-Eval value:}
@i{120}
@end example
@end quotation

@quotation
@strong{@anchor{Exercise 5.49}연습문제 5.49:} 명시적 제어 평가자의 읽기-평가-출력 루프를 사용하는 대신, 읽기-컴파일-실행-출력 루프를 수행하는 레지스터 기계를 설계하라.
즉, 기계는 표현식을 읽고, 컴파일하고, 결과 코드를 조립 및 실행하고, 결과를 출력하는 루프를 실행해야 한다.
이것은 우리의 시뮬레이션 설정에서 실행하기 쉬운데, 왜냐하면 우리는 프로시저 @code{compile}과 @code{assemble}을 ``레지스터 기계 연산''으로 호출하도록 배열할 수 있기 때문이다.
@end quotation

@quotation
@strong{@anchor{Exercise 5.50}연습문제 5.50:} 컴파일러를 사용하여 @ref{4.1}의 메타순환 평가자를 컴파일하고 이 프로그램을 레지스터 기계 시뮬레이터를 사용하여 실행하라.
(한 번에 하나 이상의 정의를 컴파일하려면 정의를 @code{begin}으로 묶을 수 있다.)
결과 인터프리터는 여러 수준의 해석 때문에 매우 느리게 실행될 것이지만, 모든 세부 사항을 작동하게 하는 것은 유익한 연습이다.
@end quotation

@quotation
@strong{@anchor{Exercise 5.51}연습문제 5.51:} @ref{5.4}의 명시적 제어 평가자를 C로 번역하여 C(또는 당신이 선택한 다른 저수준 언어)로 Scheme의 초보적인 구현을 개발하라.
이 코드를 실행하려면 적절한 저장소 할당 루틴과 기타 런타임 지원도 제공해야 할 것이다.
@end quotation

@quotation
@strong{@anchor{Exercise 5.52}연습문제 5.52:} @ref{Exercise 5.51}에 대한 대조점으로, 컴파일러를 수정하여 Scheme 프로시저를 C 명령어 시퀀스로 컴파일하도록 하라.
@ref{4.1}의 메타순환 평가자를 컴파일하여 C로 작성된 Scheme 인터프리터를 생성하라.
@end quotation

@unnumbered 참고 문헌 (References)

@anchor{Abelson et al. 1992}
Abelson, Harold, Andrew Berlin, Jacob Katzenelson, William McAllister,
Guillermo Rozas, Gerald Jay Sussman, and Jack Wisdom. 1992.  The Super@-com@-pu@-ter
Tool@-kit: A general framework for special-purpose com@-pu@-ting.
@cite{In@-ter@-na@-tio@-nal Journal of High-Speed Electronics} 3(3): 337-361.
@url{http://www.hpl.hp.com/techreports/94/HPL-94-30.html, –›}

@anchor{Allen 1978}
Allen, John.  1978.  @cite{Anatomy of Lisp}. New York: McGraw-Hill.

@anchor{ANSI 1994}
@abbr{ANSI} @abbr{X}3.226-1994. @cite{American National Standard for Information
Systems---Programming Language---Common Lisp}.

@anchor{Appel 1987}
Appel, Andrew W.  1987.  Garbage collection can be faster than stack
allocation.  @cite{Information Processing Letters} 25(4): 275-279.
@url{https://www.cs.princeton.edu/~appel/papers/45.ps, –›}

@anchor{Backus 1978}
Backus, John.  1978.  Can programming be liberated from the von Neumann style?
@cite{Communications of the @abbr{ACM}} 21(8): 613-641.
@url{http://worrydream.com/refs/Backus-CanProgrammingBeLiberated.pdf, –›}

@anchor{Baker (1978)}
Baker, Henry G., Jr.  1978.  List processing in real time on a serial computer.
@cite{Communications of the @abbr{ACM}} 21(4): 280-293.
@url{http://dspace.mit.edu/handle/1721.1/41976, –›}

@anchor{Batali et al. 1982}
Batali, John, Neil Mayle, Howard Shrobe, Gerald Jay Sussman, and Daniel Weise.
1982.  The Scheme-81 architecture---System and chip.  @cite{Proceedings of
the @abbr{MIT} Conference on Advanced Research in @abbr{VLSI}}에서, Paul Penfield, Jr. 편집. Dedham, @abbr{MA}: Artech House.

@anchor{Borning (1977)}
Borning, Alan.  1977.  ThingLab---An object-oriented system for building
simulations using constraints. @cite{Proceedings of the 5th International
Joint Conference on Artificial Intelligence}에서.
@url{http://ijcai.org/Past%20Proceedings/IJCAI-77-VOL1/PDF/085.pdf, –›}

@anchor{Borodin and Munro (1975)}
Borodin, Alan, and Ian Munro.  1975.  @cite{The Computational Complexity of
Algebraic and Numeric Problems}. New York: American Elsevier.

@anchor{Chaitin 1975}
Chaitin, Gregory J.  1975.  Randomness and mathematical proof.
@cite{Scientific American} 232(5): 47-52.
@url{http://www.owlnet.rice.edu/~km9/Randomness%20and%20Mathematical.pdf, –›}

@anchor{Church (1941)}
Church, Alonzo.  1941.  @cite{The Calculi of Lambda-Con@-ver@-sion}.  Princeton,
N.J.: Princeton University Press.

@anchor{Clark (1978)}
Clark, Keith L.  1978.  Negation as failure.  @cite{Logic and Data Bases}에서.
New York: Plenum Press, pp. 293-322.
@url{http://www.doc.ic.ac.uk/~klc/neg.html, –›}

@anchor{Clinger (1982)}
Clinger, William.  1982.  Nondeterministic call by need is neither lazy nor by
name. @cite{Proceedings of the @abbr{ACM} Symposium on Lisp and
Functional Programming}에서, pp. 226-234.

@anchor{Clinger and Rees 1991}
Clinger, William, and Jonathan Rees.  1991.  Macros that work.  @cite{Proceedings of the 1991 @abbr{ACM} Conference on Principles of
Programming Languages}에서, pp. 155-162.
@url{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.464.1336&rep=rep1&type=pdf, –›}

@anchor{Colmerauer et al. 1973}
Colmerauer A., H. Kanoui, R. Pasero, and P. Roussel.  1973.  Un syst@`eme de
communication homme-machine en fran@,{c}ais.  Technical report, Groupe
Intelligence Artificielle, Universit@'e d'Aix Marseille, Luminy.
@url{http://alain.colmerauer.free.fr/alcol/ArchivesPublications/HommeMachineFr/HoMa.pdf, –›}

@anchor{Cormen et al. 1990}
Cormen, Thomas, Charles Leiserson, and Ronald Rivest.  1990. @cite{Introduction
to Algorithms}. Cambridge, @abbr{MA}: @abbr{MIT} Press.

@anchor{Darlington et al. 1982}
Darlington, John, Peter Henderson, and David Turner.  1982.  @cite{Functional
Programming and Its Applications}. New York: Cambridge University Press.

@anchor{Dijkstra 1968a}
Dijkstra, Edsger W. 1968a.  The structure of the ``@abbr{THE}''
multiprogramming system.  @cite{Communications of the @abbr{ACM}}
11(5): 341-346.
@url{http://www.cs.utexas.edu/users/EWD/ewd01xx/EWD196.PDF, –›}

@anchor{1968b}
Dijkstra, Edsger W. 1968b.  Cooperating sequential processes.  @cite{Programming Languages}에서, F. Genuys 편집. New York: Academic Press,
pp.  43-112.
@url{http://www.cs.utexas.edu/users/EWD/ewd01xx/EWD123.PDF, –›}

@anchor{Dinesman 1968}
Dinesman, Howard P.  1968.  @cite{Superior Mathematical Puzzles}.  New York:
Simon and Schuster.

@anchor{deKleer et al. 1977}
deKleer, Johan, Jon Doyle, Guy Steele, and Gerald J. Sussman.  1977.
@abbr{AMORD}: Explicit control of reasoning.  @cite{Proceedings of the
@abbr{ACM} Symposium on Artificial Intelligence and Programming Languages}에서,
pp.  116-125.
@url{http://dspace.mit.edu/handle/1721.1/5750, –›}

@anchor{Doyle (1979)}
Doyle, Jon. 1979. A truth maintenance system. @cite{Artificial Intelligence}
12: 231-272.
@url{http://dspace.mit.edu/handle/1721.1/5733, –›}

@anchor{Feigenbaum and Shrobe 1993}
Feigenbaum, Edward, and Howard Shrobe. 1993. The Japanese National Fifth
Generation Project: Introduction, survey, and evaluation.  @cite{Future
Generation Computer Systems}에서, vol. 9, pp. 105-117.
@url{https://saltworks.stanford.edu/assets/kv359wz9060.pdf, –›}

@anchor{Feeley (1986)}
Feeley, Marc.  1986.  Deux approches @`a l'implantation du language
Scheme.  석사 학위 논문 (Masters thesis), Universit@'e de Montr@'eal.
@url{http://www.iro.umontreal.ca/~feeley/papers/FeeleyMSc.pdf, –›}

@anchor{Feeley and Lapalme 1987}
Feeley, Marc and Guy Lapalme.  1987.  Using closures for code generation.
@cite{Journal of Computer Languages} 12(1): 47-66.
@url{http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.90.6978, –›}

Feller, William.  1957.  @cite{An Introduction to Probability Theory and Its
Applications}, volume 1. New York: John Wiley & Sons.

@anchor{Fenichel and Yochelson (1969)}
Fenichel, R., and J. Yochelson.  1969.  A Lisp garbage collector for virtual
memory computer systems.  @cite{Communications of the @abbr{ACM}}
12(11): 611-612.
@url{https://www.cs.purdue.edu/homes/hosking/690M/p611-fenichel.pdf, –›}

@anchor{Floyd (1967)}
Floyd, Robert. 1967. Nondeterministic algorithms. @cite{@abbr{JACM}},
14(4): 636-644.
@url{http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.332.36, –›}

@anchor{Forbus and deKleer 1993}
Forbus, Kenneth D., and Johan deKleer.  1993. @cite{Building Problem
Solvers}. Cambridge, @abbr{MA}: @abbr{MIT} Press.

@anchor{Friedman and Wise (1976)}
Friedman, Daniel P., and David S. Wise.  1976.  @abbr{CONS} should not
evaluate its arguments. @cite{Automata, Languages, and Programming: Third
International Colloquium}에서, S. Michaelson과 R.  Milner 편집, pp. 257-284.
@url{https://www.cs.indiana.edu/cgi-bin/techreports/TRNNN.cgi?trnum=TR44, –›}

@anchor{Friedman et al. 1992}
Friedman, Daniel P., Mitchell Wand, and Christopher T. Haynes. 1992.
@cite{Essentials of Programming Languages}.  Cambridge, @abbr{MA}: @abbr{MIT}
Press/McGraw-Hill.

@anchor{Gabriel 1988}
Gabriel, Richard P. 1988.  The Why of @emph{Y}.  @cite{Lisp Pointers}
2(2): 15-25.
@url{http://www.dreamsongs.com/Files/WhyOfY.pdf, –›}

Goldberg, Adele, and David Robson.  1983.  @cite{Smalltalk-80: The Language and
Its Implementation}. Reading, @abbr{MA}: Addison-Wesley.
@url{http://stephane.ducasse.free.fr/FreeBooks/BlueBook/Bluebook.pdf, –›}

@anchor{Gordon et al. 1979}
Gordon, Michael, Robin Milner, and Christopher Wadsworth.  1979.
@cite{Edinburgh @abbr{LCF}}. Lecture Notes in Computer Science, volume 78. New York:
Springer-Verlag.

@anchor{Gray and Reuter 1993}
Gray, Jim, and Andreas Reuter. 1993. @cite{Transaction Processing: Concepts and
Models}. San Mateo, @abbr{CA}: Morgan-Kaufman.

@anchor{Green 1969}
Green, Cordell.  1969.  Application of theorem proving to problem solving.  @cite{Proceedings of the International Joint Conference on Artificial
Intelligence}에서, pp. 219-240.
@url{http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.81.9820, –›}

@anchor{Green and Raphael (1968)}
Green, Cordell, and Bertram Raphael.  1968.  The use of theorem-proving
techniques in question-answering systems.  @cite{Proceedings of the
@abbr{ACM} National Conference}에서, pp. 169-181.
@url{http://www.kestrel.edu/home/people/green/publications/green-raphael.pdf, –›}

@anchor{Griss 1981}
Griss, Martin L.  1981.  Portable Standard Lisp, a brief overview.  Utah
Symbolic Computation Group Operating Note 58, University of Utah.

@anchor{Guttag 1977}
Guttag, John V.  1977.  Abstract data types and the development of data
structures.  @cite{Communications of the @abbr{ACM}} 20(6): 396-404.
@url{http://www.unc.edu/~stotts/comp723/guttagADT77.pdf, –›}

@anchor{Hamming 1980}
Hamming, Richard W.  1980.  @cite{Coding and Information Theory}.  Englewood
Cliffs, N.J.: Prentice-Hall.

@anchor{Hanson 1990}
Hanson, Christopher P.  1990.  Efficient stack allocation for tail-recursive
languages.  @cite{Proceedings of @abbr{ACM} Conference on Lisp and
Functional Programming}에서, pp. 106-118.
@url{https://groups.csail.mit.edu/mac/ftpdir/users/cph/links.ps.gz, –›}

@anchor{Hanson 1991}
Hanson, Christopher P.  1991.  A syntactic closures macro facility.  @cite{Lisp
Pointers}, 4(3).
@url{http://groups.csail.mit.edu/mac/ftpdir/scheme-reports/synclo.ps, –›}

@anchor{Hardy 1921}
Hardy, Godfrey H.  1921.  Srinivasa Ramanujan.  @cite{Proceedings of the London
Mathematical Society} @abbr{XIX}(2).

@anchor{Hardy and Wright 1960}
Hardy, Godfrey H., and E. M. Wright.  1960.  @cite{An Introduction to the
Theory of Numbers}.  4판 (4th edition).  New York: Oxford University Press.
@url{https://archive.org/details/AnIntroductionToTheTheoryOfNumbers-4thEd-G.h.HardyE.m.Wright, –›}

@anchor{Havender (1968)}
Havender, J. 1968. Avoiding deadlocks in multi-tasking systems. @cite{IBM
Systems Journal} 7(2): 74-84.

@anchor{Hearn 1969}
Hearn, Anthony C.  1969.  Standard Lisp.  기술 보고서 (Technical report) @abbr{AIM}-90,
Artificial Intelligence Project, Stanford University.
@url{http://www.softwarepreservation.org/projects/LISP/stanford/Hearn-StandardLisp-AIM-90.pdf, –›}

@anchor{Henderson 1980}
Henderson, Peter. 1980.  @cite{Functional Programming: Application and
Implementation}. Englewood Cliffs, N.J.: Prentice-Hall.

@anchor{Henderson 1982}
Henderson. Peter. 1982. Functional Geometry. @cite{Conference Record of the
1982 @abbr{ACM} Symposium on Lisp and Functional Programming}에서, pp. 179-187.
@url{http://pmh-systems.co.uk/phAcademic/papers/funcgeo.pdf, –›},
@url{http://eprints.soton.ac.uk/257577/1/funcgeo2.pdf, 2002 version –›}

@anchor{Hewitt (1969)}
Hewitt, Carl E.  1969.  @abbr{PLANNER}: A language for proving
theorems in robots.  @cite{Proceedings of the International Joint
Conference on Artificial Intelligence}에서, pp. 295-301.
@url{http://dspace.mit.edu/handle/1721.1/6171, –›}

@anchor{Hewitt (1977)}
Hewitt, Carl E.  1977.  Viewing control structures as patterns of passing
messages.  @cite{Journal of Artificial Intelligence} 8(3): 323-364.
@url{http://dspace.mit.edu/handle/1721.1/6272, –›}

@anchor{Hoare (1972)}
Hoare, C. A. R. 1972.  Proof of correctness of data representations.
@cite{Acta Informatica} 1(1).

@anchor{Hodges 1983}
Hodges, Andrew. 1983.  @cite{Alan Turing: The Enigma}. New York: Simon and
Schuster.

@anchor{Hofstadter 1979}
Hofstadter, Douglas R.  1979.  @cite{G@"odel, Escher, Bach: An Eternal Golden
Braid}. New York: Basic Books.

@anchor{Hughes 1990}
Hughes, R. J. M.  1990.  Why functional programming matters.  @cite{Research
Topics in Functional Programming}에서, David Turner 편집.  Reading, @abbr{MA}:
Addison-Wesley, pp. 17-42.
@url{http://www.cs.kent.ac.uk/people/staff/dat/miranda/whyfp90.pdf, –›}

@anchor{IEEE 1990}
@abbr{IEEE} Std 1178-1990.  1990.  @cite{@abbr{IEEE} Standard for the
Scheme Programming Language}.

@anchor{Ingerman et al. 1960}
Ingerman, Peter, Edgar Irons, Kirk Sattley, and Wallace Feurzeig; assisted by
M. Lind, Herbert Kanner, and Robert Floyd.  1960.  @abbr{THUNKS}: A way of
compiling procedure statements, with some comments on procedure declarations.
미발행 원고 (Unpublished manuscript).  (또한, Wallace Feurzeig의 개인적 소통.)

@anchor{Kaldewaij 1990}
Kaldewaij, Anne. 1990.  @cite{Programming: The Derivation of Algorithms}. New
York: Prentice-Hall.

@anchor{Knuth (1973)}
Knuth, Donald E.  1973.  @cite{Fundamental Algorithms}. Volume 1 of @cite{The
Art of Computer Programming}.  2판 (2nd edition). Reading, @abbr{MA}: Addison-Wesley.

@anchor{Knuth 1981}
Knuth, Donald E.  1981.  @cite{Seminumerical Algorithms}. Volume 2 of @cite{The
Art of Computer Programming}.  2판 (2nd edition). Reading, @abbr{MA}: Addison-Wesley.

@anchor{Kohlbecker 1986}
Kohlbecker, Eugene Edmund, Jr. 1986.  Syntactic extensions in the programming
language Lisp.  박사 학위 논문 (Ph.D. thesis), Indiana University.
@url{http://www.ccs.neu.edu/scheme/pubs/dissertation-kohlbecker.pdf, –›}

@anchor{Konopasek and Jayaraman 1984}
Konopasek, Milos, and Sundaresan Jayaraman.  1984.  @cite{The TK!Solver Book: A
Guide to Problem-Solving in Science, Engineering, Business, and
Education}. Berkeley, @abbr{CA}: Osborne/McGraw-Hill.

@anchor{Kowalski (1973; 1979)}
Kowalski, Robert.  1973.  Predicate logic as a programming language.  기술 보고서 (Technical
report) 70, Department of Computational Logic, School of Artificial
Intelligence, University of Edinburgh.
@url{http://www.doc.ic.ac.uk/~rak/papers/IFIP%2074.pdf, –›}

Kowalski, Robert.  1979.  @cite{Logic for Problem Solving}. New York:
North-Holland.
@url{http://www.doc.ic.ac.uk/%7Erak/papers/LogicForProblemSolving.pdf, –›}

@anchor{Lamport (1978)}
Lamport, Leslie. 1978.  Time, clocks, and the ordering of events in a
distributed system.  @cite{Communications of the @abbr{ACM}} 21(7): 558-565.
@url{https://amturing.acm.org/p558-lamport.pdf, –›}

@anchor{Lampson et al. 1981}
Lampson, Butler, J. J. Horning, R.  London, J. G. Mitchell, and G. K.  Popek.
1981.  Report on the programming language Euclid.  기술 보고서 (Technical report), Computer
Systems Research Group, University of Toronto.
@url{http://www.bitsavers.org/pdf/xerox/parc/techReports/CSL-81-12_Report_On_The_Programming_Language_Euclid.pdf, –›}

@anchor{Landin (1965)}
Landin, Peter.  1965.  A correspondence between Algol 60 and Church's lambda
notation: Part I.  @cite{Communications of the @abbr{ACM}} 8(2): 89-101.

@anchor{Lieberman and Hewitt 1983}
Lieberman, Henry, and Carl E. Hewitt. 1983. A real-time garbage collector based
on the lifetimes of objects. @cite{Communications of the @abbr{ACM}}
26(6): 419-429.
@url{http://dspace.mit.edu/handle/1721.1/6335, –›}

@anchor{Liskov and Zilles (1975)}
Liskov, Barbara H., and Stephen N. Zilles.  1975.  Specification techniques for
data abstractions.  @cite{@abbr{IEEE} Transactions on Software Engineering}
1(1): 7-19.
@url{http://csg.csail.mit.edu/CSGArchives/memos/Memo-117.pdf, –›}

@anchor{McAllester (1978; 1980)}
McAllester, David Allen.  1978.  A three-valued truth-maintenance system.  Memo
473, @abbr{MIT} Artificial Intelligence Laboratory.
@url{http://dspace.mit.edu/handle/1721.1/6296, –›}

McAllester, David Allen.  1980.  An outlook on truth maintenance.  Memo 551,
@abbr{MIT} Artificial Intelligence Laboratory.
@url{http://dspace.mit.edu/handle/1721.1/6327, –›}

@anchor{McCarthy 1960}
McCarthy, John.  1960.  Recursive functions of symbolic expressions and their
computation by machine.  @cite{Communications of the @abbr{ACM}} 3(4): 184-195.
@url{http://homepages.inf.ed.ac.uk/wadler/papers/papers-we-love/mccarthy-recursive-functions.pdf, –›}

@anchor{McCarthy 1963}
McCarthy, John.  1963.  A basis for a mathematical theory of computation.  @cite{Computer Programming and Formal Systems}에서, P. Braffort와
D. Hirschberg 편집.  North-Holland.
@url{https://ropas.snu.ac.kr/~kwang/4190.310/mccarthy63basis.pdf, –›}

@anchor{McCarthy 1978}
McCarthy, John.  1978.  The history of Lisp.  @cite{Proceedings of the
@abbr{ACM} @abbr{SIGPLAN} Conference on the History of Programming
Languages}에서.
@url{http://jmc.stanford.edu/articles/lisp.html, –›}

@anchor{McCarthy et al. 1965}
McCarthy, John, P. W. Abrahams, D. J. Edwards, T. P. Hart, and M. I.  Levin.
1965.  @cite{Lisp 1.5 Programmer's Manual}.  2판 (2nd edition).  Cambridge, @abbr{MA}:
@abbr{MIT} Press.
@url{http://www.softwarepreservation.org/projects/LISP/book/LISP%201.5%20Programmers%20Manual.pdf/view, –›}

@anchor{McDermott and Sussman (1972)}
McDermott, Drew, and Gerald Jay Sussman.  1972. Conniver reference manual.
Memo 259, @abbr{MIT} Artificial Intelligence Laboratory.
@url{http://dspace.mit.edu/handle/1721.1/6203, –›}

@anchor{Miller 1976}
Miller, Gary L.  1976.  Riemann's Hypothesis and tests for primality.
@cite{Journal of Computer and System Sciences} 13(3): 300-317.
@url{http://www.cs.cmu.edu/~glmiller/Publications/b2hd-Mi76.html, –›}

@anchor{Miller and Rozas 1994}
Miller, James S., and Guillermo J. Rozas. 1994.  Garbage collection is fast,
but a stack is faster.  Memo 1462, @abbr{MIT} Artificial Intelligence
Laboratory.
@url{http://dspace.mit.edu/handle/1721.1/6622, –›}

@anchor{Moon 1978}
Moon, David.  1978.  MacLisp reference manual, Version 0.  기술 보고서 (Technical report),
@abbr{MIT} Laboratory for Computer Science.
@url{http://www.softwarepreservation.org/projects/LISP/MIT/Moon-MACLISP_Reference_Manual-Apr_08_1974.pdf/view, –›}

@anchor{Moon and Weinreb 1981}
Moon, David, and Daniel Weinreb.  1981.  Lisp machine manual.  기술 보고서 (Technical
report), @abbr{MIT} Artificial Intelligence Laboratory.
@url{http://www.unlambda.com/lmman/index.html, –›}

@anchor{Morris et al. 1980}
Morris, J. H., Eric Schmidt, and Philip Wadler.  1980.  Experience with an
applicative string processing language.  @cite{Proceedings of the 7th Annual
@abbr{ACM} @abbr{SIGACT}/@abbr{SIGPLAN} Symposium on the Principles of
Programming Languages}에서.

@anchor{Phillips 1934}
Phillips, Hubert.  1934. @cite{The Sphinx Problem Book}.  London: Faber and
Faber.

@anchor{Pitman 1983}
Pitman, Kent. 1983. The revised MacLisp Manual (Saturday evening edition).
기술 보고서 (Technical report) 295, @abbr{MIT} Laboratory for Computer Science.
@url{http://maclisp.info/pitmanual, –›}

@anchor{Rabin 1980}
Rabin, Michael O. 1980. Probabilistic algorithm for testing primality.
@cite{Journal of Number Theory} 12: 128-138.

@anchor{Raymond 1993}
Raymond, Eric.  1993. @cite{The New Hacker's Dictionary}. 2판 (2nd edition).
Cambridge, @abbr{MA}: @abbr{MIT} Press.
@url{http://www.catb.org/jargon/, –›}

Raynal, Michel. 1986. @cite{Algorithms for Mutual Exclusion}.  Cambridge, @abbr{MA}:
@abbr{MIT} Press.

@anchor{Rees and Adams 1982}
Rees, Jonathan A., and Norman I. Adams IV. 1982.  T: A dialect of Lisp or,
lambda: The ultimate software tool.  @cite{Conference Record of the 1982
@abbr{ACM} Symposium on Lisp and Functional Programming}에서, pp.  114-122.
@url{http://people.csail.mit.edu/riastradh/t/adams82t.pdf, –›}

Rees, Jonathan, and William Clinger (eds). 1991.  The revised⁴ report on the
algorithmic language Scheme.  @cite{Lisp Pointers}, 4(3).
@url{http://people.csail.mit.edu/jaffer/r4rs.pdf, –›}

@anchor{Rivest et al. (1977)}
Rivest, Ronald, Adi Shamir, and Leonard Adleman.  1977.  A method for obtaining
digital signatures and public-key cryptosystems. 기술 메모 (Technical memo) @abbr{LCS}/@abbr{TM82},
@abbr{MIT} Laboratory for Computer Science.
@url{http://people.csail.mit.edu/rivest/Rsapaper.pdf, –›}

@anchor{Robinson 1965}
Robinson, J. A. 1965.  A machine-oriented logic based on the resolution
principle.  @cite{Journal of the @abbr{ACM}} 12(1): 23.

@anchor{Robinson 1983}
Robinson, J. A. 1983.  Logic programming---Past, present, and future.
@cite{New Generation Computing} 1: 107-124.

@anchor{Spafford 1989}
Spafford, Eugene H.  1989.  The Internet Worm: Crisis and aftermath.
@cite{Communications of the @abbr{ACM}} 32(6): 678-688.
@url{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.123.8503&rep=rep1&type=pdf, –›}

@anchor{Steele 1977}
Steele, Guy Lewis, Jr.  1977.  Debunking the ``expensive procedure call'' myth.
@cite{Proceedings of the National Conference of the @abbr{ACM}}에서,
pp. 153-62.
@url{http://dspace.mit.edu/handle/1721.1/5753, –›}

@anchor{Steele 1982}
Steele, Guy Lewis, Jr.  1982.  An overview of Common Lisp.  @cite{Proceedings of the @abbr{ACM} Symposium on Lisp and Functional
Programming}에서, pp. 98-107.

@anchor{Steele 1990}
Steele, Guy Lewis, Jr.  1990.  @cite{Common Lisp: The Language}. 2판 (2nd edition).
Digital Press.
@url{http://www.cs.cmu.edu/Groups/AI/html/cltl/cltl2.html, –›}

@anchor{Steele and Sussman 1975}
Steele, Guy Lewis, Jr., and Gerald Jay Sussman.  1975.  Scheme: An interpreter
for the extended lambda calculus.  Memo 349, @abbr{MIT} Artificial
Intelligence Laboratory.
@url{http://dspace.mit.edu/handle/1721.1/5794, –›}

@anchor{Steele et al. 1983}
Steele, Guy Lewis, Jr., Donald R. Woods, Raphael A. Finkel, Mark R.  Crispin,
Richard M. Stallman, and Geoffrey S. Goodfellow.  1983.  @cite{The Hacker's
Dictionary}. New York: Harper & Row.
@url{http://www.dourish.com/goodies/jargon.html, –›}

@anchor{Stoy 1977}
Stoy, Joseph E.  1977.  @cite{Denotational Semantics}. Cambridge, @abbr{MA}:
@abbr{MIT} Press.

@anchor{Sussman and Stallman 1975}
Sussman, Gerald Jay, and Richard M. Stallman.  1975.  Heuristic techniques in
computer-aided circuit analysis.  @cite{@abbr{IEEE} Transactions on Circuits
and Systems} @abbr{CAS}-22(11): 857-865.
@url{http://dspace.mit.edu/handle/1721.1/5803, –›}

@anchor{Sussman and Steele 1980}
Sussman, Gerald Jay, and Guy Lewis Steele Jr.  1980.  Constraints---A language
for expressing almost-hierachical descriptions.  @cite{AI Journal} 14: 1-39.
@url{http://dspace.mit.edu/handle/1721.1/6312, –›}

@anchor{Sussman and Wisdom 1992}
Sussman, Gerald Jay, and Jack Wisdom.  1992. Chaotic evolution of the solar
system.  @cite{Science} 257: 256-262.
@url{http://groups.csail.mit.edu/mac/users/wisdom/ss-chaos.pdf, –›}

@anchor{Sussman et al. (1971)}
Sussman, Gerald Jay, Terry Winograd, and Eugene Charniak.  1971.  Microplanner
reference manual.  Memo 203@abbr{A}, @abbr{MIT} Artificial Intelligence Laboratory.
@url{http://dspace.mit.edu/handle/1721.1/6184, –›}

@anchor{Sutherland (1963)}
Sutherland, Ivan E.  1963.  @abbr{SKETCHPAD}: A man-machine graphical
com@-mu@-ni@-cation system.  기술 보고서 (Technical report) 296, @abbr{MIT} Lincoln Laboratory.
@url{https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-574.pdf, –›}

@anchor{Teitelman 1974}
Teitelman, Warren.  1974.  Interlisp reference manual.  기술 보고서 (Technical report), Xerox
Palo Alto Research Center.
@url{http://www.softwarepreservation.org/projects/LISP/interlisp/Interlisp-Oct_1974.pdf/view, –›}

@anchor{Thatcher et al. 1978}
Thatcher, James W., Eric G. Wagner, and Jesse B. Wright. 1978.  Data type
specification: Parameterization and the power of specification techniques. @cite{Conference Record of the Tenth Annual @abbr{ACM} Symposium on Theory
of Computing}에서, pp. 119-132.

@anchor{Turner 1981}
Turner, David.  1981.  The future of applicative languages.  @cite{Proceedings of the 3rd European Conference on Informatics}에서, Lecture Notes
in Computer Science, volume 123. New York: Springer-Verlag, pp.  334-348.

@anchor{Wand 1980}
Wand, Mitchell.  1980.  Continuation-based program transformation strategies.
@cite{Journal of the @abbr{ACM}} 27(1): 164-180.
@url{http://www.diku.dk/OLD/undervisning/2005e/224/papers/Wand80.pdf, –›}

@anchor{Waters (1979)}
Waters, Richard C.  1979.  A method for analyzing loop programs.
@cite{@abbr{IEEE} Transactions on Software Engineering} 5(3): 237-247.

Winograd, Terry.  1971.  Procedures as a representation for data in a computer
program for understanding natural language.  기술 보고서 (Technical report) @abbr{AI TR}-17,
@abbr{MIT} Artificial Intelligence Laboratory.
@url{http://dspace.mit.edu/handle/1721.1/7095, –›}

@anchor{Winston 1992}
Winston, Patrick. 1992. @cite{Artificial Intelligence}.  3판 (3rd edition).  Reading,
@abbr{MA}: Addison-Wesley.

@anchor{Zabih et al. 1987}
Zabih, Ramin, David McAllester, and David Chapman.  1987.  Non-deterministic
Lisp with dependency-directed backtracking.  @cite{@abbr{AAAI}-87}에서,
pp. 59-64.
@url{http://www.aaai.org/Papers/AAAI/1987/AAAI87-011.pdf, –›}

@anchor{Zippel (1979)}
Zippel, Richard.  1979.  Probabilistic algorithms for sparse polynomials.
박사 학위 논문 (Ph.D. dissertation), Department of Electrical Engineering and Computer Science,
@abbr{MIT}.

@anchor{Zippel 1993}
Zippel, Richard.  1993.  @cite{Effective Polynomial Computation}.  Boston, @abbr{MA}:
Kluwer Academic Publishers.

@node    Exercises, Figures, References, Top
@unnumbered 연습 문제 목록

@include exercises.texi

@node    Figures, Term Index, Exercises, Top
@unnumbered 그림 목록

@include figures.texi

@node    Term Index, Colophon, Figures, Top
@unnumbered 용어 색인

@quotation
이 색인의 부정확한 점들은 컴퓨터의 도움을 받아 작성되었다는 사실로 설명될 수 있을 것이다.

---도널드 E. 커누스, @cite{Fundamental Algorithms}@* 
(@cite{The Art of Computer Programming} 제1권) 
@end quotation

@printindex cp

@node    Colophon, , Term Index, Top
@unnumbered 제작 노트 (Colophon)

표지 그림은 아고스티노 라멜리(Agostino Ramelli)의 1588년 작 북휠(bookwheel) 메커니즘입니다. 이는 초기 하이퍼텍스트 탐색 도구로 볼 수 있습니다. 이 판화 이미지는 @url{http://newgottland.com/2012/02/09/before-the-ereader-there-was-the-wheelreader/ramelli_bookwheel_1032px/, New Gottland}의 J. E. Johnson이 제공했습니다.

본문 폰트는 Linux Libertine, 제목 폰트는 Linux Biolinum을 사용했으며, 둘 다 필립 H. 폴(Philipp H. Poll)이 제작했습니다. 타자기체는 래프 레비언(Raph Levien)이 만든 Inconsolata를 사용했으며, 디모스테니스 카포니스(Dimosthenis Kaponis)와 타카시 타니가와(Takashi Tanigawa)가 Inconsolata LGC 형태로 보완했습니다.

그래픽 디자인과 타이포그래피는 안드레스 라바(Andres Raba)가 담당했습니다. Texinfo 소스는 Texinfo 5.1 패키지의 @code{texi2any} 유틸리티의 커스터마이즈 버전을 사용하여 @abbr{HTML}로 변환되었습니다. 다이어그램은 Inkscape로 그려졌으며, 수식은 MathJax와 MathML의 도움을 받아 조판되었습니다.

@bye
