<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<!-- Created by GNU Texinfo 7.1, https://www.gnu.org/software/texinfo/ -->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>3.5 (Structure and Interpretation of Computer Programs, 2e)</title>

<meta name="description" content="3.5 (Structure and Interpretation of Computer Programs, 2e)" />
<meta name="keywords" content="3.5 (Structure and Interpretation of Computer Programs, 2e)" />
<meta name="resource-type" content="document" />
<meta name="distribution" content="global" />
<meta name="Generator" content="texi2any" />
<meta name="viewport" content="width=device-width,initial-scale=1" />

<link href="index.xhtml" rel="start" title="Top" />
<link href="Term-Index.xhtml" rel="index" title="Term Index" />
<link href="index.xhtml#SEC_Contents" rel="contents" title="Table of Contents" />
<link href="Chapter-3.xhtml" rel="up" title="Chapter 3" />
<link href="Chapter-4.xhtml" rel="next" title="Chapter 4" />
<link href="3_002e4.xhtml#g_t3_002e4_002e5" rel="prev" title="3.4.5" />
<style type="text/css">
<!--
a.copiable-link {visibility: hidden; text-decoration: none; line-height: 0em}
div.example {margin-left: 3.2em}
span.r {font-family: initial; font-weight: normal; font-style: normal}
span:hover a.copiable-link {visibility: visible}
ul.mark-bullet {list-style-type: disc}
-->
</style>
<link href="css/style.css" rel="stylesheet" type="text/css" />
<link href="css/prettify.css" rel="stylesheet" type="text/css" />
<script src="js/highlight/prettify.js" type="text/javascript"></script>
<script src="js/highlight/lang-lisp.js" type="text/javascript"></script>
<script src="js/highlight/lang-rust.js" type="text/javascript"></script>
</head>

<body lang="en">
<div class="section-level-extent" id="g_t3_002e5">
<div class="nav-panel">
<p>
Next: <a href="Chapter-4.xhtml" accesskey="n" rel="next">Metalinguistic Abstraction</a>, Previous: <a href="3_002e4.xhtml#g_t3_002e4_002e5" accesskey="p" rel="prev">Async/Await: Cooperative Concurrency</a>, Up: <a href="Chapter-3.xhtml" accesskey="u" rel="up">Modularity, Objects, and State</a> &#160; [<a href="index.xhtml#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="Term-Index.xhtml" title="Index" rel="index">Index</a>]</p>
</div>
<h3 class="section" id="Streams"><span>3.5 Streams<a class="copiable-link" href="#Streams"> &#182;</a></span></h3>

<p>We&#8217;ve gained a good understanding of assignment as a tool in modeling, as well
as an appreciation of the complex problems that assignment raises. It is time
to ask whether we could have gone about things in a different way, so as to
avoid some of these problems.  In this section, we explore an alternative
approach to modeling state, based on data structures called <a class="index-entry-id" id="index-streams-2"></a>
<em class="dfn">streams</em>.
As we shall see, streams can mitigate some of the complexity of modeling state.
</p>
<p>Let&#8217;s step back and review where this complexity comes from.  In an attempt to
model real-world phenomena, we made some apparently reasonable decisions: We
modeled real-world objects with local state by computational objects with local
variables.  We identified time variation in the real world with time variation
in the computer.  We implemented the time variation of the states of the model
objects in the computer with assignments to the local variables of the model
objects.
</p>
<p>Is there another approach?  Can we avoid identifying time in the computer with
time in the modeled world?  Must we make the model change with time in order to
model phenomena in a changing world?  Think about the issue in terms of
mathematical functions.  We can describe the time-varying behavior of a
quantity <em class="math">x</em> as a function of time <em class="math">{x(t)}</em>.  If we concentrate on <em class="math">x</em>
instant by instant, we think of it as a changing quantity.  Yet if we
concentrate on the entire time history of values, we do not emphasize
change&#8212;the function itself does not change.<a class="footnote" id="DOCF171" href="#FOOT171"><sup>171</sup></a>
</p>
<p>If time is measured in discrete steps, then we can model a time function as a
(possibly infinite) sequence.  In this section, we will see how to model change
in terms of sequences that represent the time histories of the systems being
modeled.  To accomplish this, we introduce new data structures called
<a class="index-entry-id" id="index-streams-3"></a>
<em class="dfn">streams</em>.  From an abstract point of view, a stream is simply a
sequence.  However, we will find that the straightforward implementation of
streams as lists (as in <a class="ref" href="2_002e2.xhtml#g_t2_002e2_002e1">Representing Sequences</a>) doesn&#8217;t fully reveal the power of
stream processing.  As an alternative, we introduce the technique of
<a class="index-entry-id" id="index-delayed-evaluation-1"></a>
<em class="dfn">delayed evaluation</em>, which enables us to represent very large (even
infinite) sequences as streams.
</p>
<p>Stream processing lets us model systems that have state without ever using
assignment or mutable data.  This has important implications, both theoretical
and practical, because we can build models that avoid the drawbacks inherent in
introducing assignment.  On the other hand, the stream framework raises
difficulties of its own, and the question of which modeling technique leads to
more modular and more easily maintained systems remains open.
</p>

<hr />
<div class="subsection-level-extent" id="g_t3_002e5_002e1">
<h4 class="subsection" id="Streams-Are-Delayed-Lists"><span>3.5.1 Streams Are Delayed Lists<a class="copiable-link" href="#Streams-Are-Delayed-Lists"> &#182;</a></span></h4>

<p>As we saw in <a class="ref" href="2_002e2.xhtml#g_t2_002e2_002e3">Sequences as Conventional Interfaces</a>, sequences can serve as standard interfaces
for combining program modules.  We formulated powerful abstractions for
manipulating sequences, such as <code class="code">map</code>, <code class="code">filter</code>, and
<code class="code">accumulate</code>, that capture a wide variety of operations in a manner that
is both succinct and elegant.
</p>
<p>Unfortunately, if we represent sequences as lists, this elegance is bought at
the price of severe inefficiency with respect to both the time and space
required by our computations.  When we represent manipulations on sequences as
transformations of lists, our programs must construct and copy data structures
(which may be huge) at every step of a process.
</p>
<p>To see why this is true, let us compare two programs for computing the sum of
all the prime numbers in an interval.  The first program is written in standard
iterative style:<a class="footnote" id="DOCF172" href="#FOOT172"><sup>172</sup></a>
</p>
<div class="example">
<pre class="example-preformatted">fn sum_primes(a: u64, b: u64) -&gt; u64 {
    let mut accum = 0;
    for count in a..=b {
        if is_prime(count) {
            accum += count;
        }
    }
    accum
}
</pre></div>

<p>The second program performs the same computation using the sequence operations
of <a class="ref" href="2_002e2.xhtml#g_t2_002e2_002e3">Sequences as Conventional Interfaces</a>:
</p>
<div class="example">
<pre class="example-preformatted">fn sum_primes(a: u64, b: u64) -&gt; u64 {
    (a..=b)
        .filter(|&amp;n| is_prime(n))
        .sum()
}
</pre></div>

<p>In carrying out the computation, the first program needs to store only the sum
being accumulated.  In contrast, the filter in the second program cannot do any
testing until <code class="code">enumerate-interval</code> has constructed a complete list of the
numbers in the interval.  The filter generates another list, which in turn is
passed to <code class="code">accumulate</code> before being collapsed to form a sum.  Such large
intermediate storage is not needed by the first program, which we can think of
as enumerating the interval incrementally, adding each prime to the sum as it
is generated.
</p>
<p>The inefficiency in using lists becomes painfully apparent if we use the
sequence paradigm to compute the second prime in the interval from 10,000 to
1,000,000 by evaluating the expression
</p>
<div class="example">
<pre class="example-preformatted">(10_000..=1_000_000)
    .filter(|&amp;n| is_prime(n))
    .nth(1)  // Second prime (0-indexed)
    .unwrap()
// =&gt; 10009
</pre></div>

<p>This expression does find the second prime, but the computational overhead is
outrageous.  We construct a list of almost a million integers, filter this list
by testing each element for primality, and then ignore almost all of the
result.  In a more traditional programming style, we would interleave the
enumeration and the filtering, and stop when we reached the second prime.
</p>
<p>Streams are a clever idea that allows one to use sequence manipulations without
incurring the costs of manipulating sequences as lists.  With streams we can
achieve the best of both worlds: We can formulate programs elegantly as
sequence manipulations, while attaining the efficiency of incremental
computation.  The basic idea is to arrange to construct a stream only
partially, and to pass the partial construction to the program that consumes
the stream.  If the consumer attempts to access a part of the stream that has
not yet been constructed, the stream will automatically construct just enough
more of itself to produce the required part, thus preserving the illusion that
the entire stream exists.  In other words, although we will write programs as
if we were processing complete sequences, we design our stream implementation
to automatically and transparently interleave the construction of the stream
with its use.
</p>
<p>On the surface, streams are just lists with different names for the procedures
that manipulate them.  There is a constructor, <code class="code">Stream::cons</code> (or similar constructor), and two
selectors, <code class="code">head</code> and <code class="code">tail</code>, which satisfy the
constraints
</p>
<div class="example">
<pre class="example-preformatted">// Iterator contract (Rust equivalent of stream axioms):
// iter.next()  =&gt;  Some(first_element)  // on first call
// iter.next()  =&gt;  Some(second_element) // on subsequent calls
// iter.next()  =&gt;  None                 // when exhausted
</pre></div>

<p>There is a distinguishable object, <code class="code">the-empty-stream</code>, which cannot be the
result of any <code class="code">cons-stream</code> operation, and which can be identified with
the predicate <code class="code">stream-null?</code>.<a class="footnote" id="DOCF173" href="#FOOT173"><sup>173</sup></a>  Thus we can
make and use streams, in just the same way as we can make and use lists, to
represent aggregate data arranged in a sequence.  In particular, we can build
stream analogs of the list operations from <a class="ref" href="Chapter-2.xhtml">Building Abstractions with Data</a>, such as
<code class="code">list-ref</code>, <code class="code">map</code>, and <code class="code">for-each</code>:<a class="footnote" id="DOCF174" href="#FOOT174"><sup>174</sup></a>
</p>
<div class="example">
<pre class="example-preformatted">// Rust iterators are already lazy streams!
// These operations are built into Iterator trait:

// stream-ref =&gt; Iterator::nth
fn stream_ref&lt;I: Iterator&gt;(s: I, n: usize) -&gt; Option&lt;I::Item&gt; {
    s.skip(n).next()
}

// stream-map =&gt; Iterator::map
fn stream_map&lt;I, F, B&gt;(s: I, proc: F) -&gt; impl Iterator&lt;Item = B&gt;
where
    I: Iterator,
    F: FnMut(I::Item) -&gt; B,
{
    s.map(proc)
}

// stream-for-each =&gt; Iterator::for_each
fn stream_for_each&lt;I, F&gt;(s: I, proc: F)
where
    I: Iterator,
    F: FnMut(I::Item),
{
    s.for_each(proc);
}
</pre></div>

<p><code class="code">Stream-for-each</code> is useful for viewing streams:
</p>
<div class="example">
<pre class="example-preformatted">fn display_stream&lt;I: Iterator&gt;(s: I)
where
    I::Item: std::fmt::Display,
{
    for x in s {
        println!(&quot;{}&quot;, x);
    }
}
</pre></div>

<p>To make the stream implementation automatically and transparently interleave
the construction of a stream with its use, we will arrange for the <code class="code">cdr</code>
of a stream to be evaluated when it is accessed by the <code class="code">tail</code>
procedure rather than when the stream is constructed by <code class="code">cons-stream</code>.
This implementation choice is reminiscent of our discussion of rational numbers
in <a class="ref" href="2_002e1.xhtml#g_t2_002e1_002e2">Abstraction Barriers</a>, where we saw that we can choose to implement rational
numbers so that the reduction of numerator and denominator to lowest terms is
performed either at construction time or at selection time.  The two
rational-number implementations produce the same data abstraction, but the
choice has an effect on efficiency.  There is a similar relationship between
streams and ordinary lists.  As a data abstraction, streams are the same as
lists.  The difference is the time at which the elements are evaluated.  With
ordinary lists, both the <code class="code">car</code> and the <code class="code">cdr</code> are evaluated at
construction time.  With streams, the <code class="code">cdr</code> is evaluated at selection
time.
</p>
<p>Our implementation of streams will be based on a special form called
<code class="code">delay</code>.  Evaluating <code class="code">(delay ⟨<var class="var">exp</var>⟩)</code> does not evaluate the
expression <code class="code">⟨</code><var class="var">exp</var><code class="code">⟩</code>, but rather returns a so-called 
<a class="index-entry-id" id="index-delayed-object"></a>
<em class="dfn">delayed object</em>, which we can think of as a &#8220;promise&#8221; to evaluate 
<code class="code">⟨</code><var class="var">exp</var><code class="code">⟩</code> at some
future time.  As a companion to <code class="code">delay</code>, there is a procedure called
<code class="code">force</code> that takes a delayed object as argument and performs the
evaluation&#8212;in effect, forcing the <code class="code">delay</code> to fulfill its promise.  We
will see below how <code class="code">delay</code> and <code class="code">force</code> can be implemented, but first
let us use these to construct streams.
</p>
<p><code class="code">Cons-stream</code> is a special form defined so that
</p>
<div class="example">
<pre class="example-preformatted">std::iter::once(a).chain(b)
</pre></div>

<p>is equivalent to
</p>
<div class="example">
<pre class="example-preformatted">// In Rust, iterators are lazy by default
// The &quot;tail&quot; is computed on demand when next() is called
std::iter::once(a).chain(/* b is evaluated lazily */)
</pre></div>

<p>What this means is that we will construct streams using pairs.  However, rather
than placing the value of the rest of the stream into the <code class="code">cdr</code> of the
pair we will put there a promise to compute the rest if it is ever requested.
<code class="code">Stream-car</code> and <code class="code">tail</code> can now be defined as procedures:
</p>
<div class="example">
<pre class="example-preformatted">// In Rust, Iterator::next() returns Option&lt;Item&gt;
// - Some(item) = stream-car (the first element)
// - Calling next() again = stream-cdr (rest of stream)
let mut stream = (1..=10).filter(|n| n % 2 == 0);
let first = stream.next();   // stream-car =&gt; Some(2)
let second = stream.next();  // stream-cdr then car =&gt; Some(4)
</pre></div>

<p><code class="code">Stream-car</code> selects the <code class="code">car</code> of the pair; <code class="code">tail</code> selects
the <code class="code">cdr</code> of the pair and evaluates the delayed expression found there to
obtain the rest of the stream.<a class="footnote" id="DOCF175" href="#FOOT175"><sup>175</sup></a>
</p>
<h4 class="subsubheading" id="The-stream-implementation-in-action"><span>The stream implementation in action<a class="copiable-link" href="#The-stream-implementation-in-action"> &#182;</a></span></h4>

<p>To see how this implementation behaves, let us analyze the &#8220;outrageous&#8221; prime
computation we saw above, reformulated in terms of streams:
</p>
<div class="example">
<pre class="example-preformatted">// Lazy evaluation: only computes elements as needed
(10_000..=1_000_000)
    .filter(|&amp;n| is_prime(n))
    .nth(1)  // Gets second prime without computing all
    .unwrap()
// Only tests primality until second prime is found!
</pre></div>

<p>We will see that it does indeed work efficiently.
</p>
<p>We begin by calling <code class="code">stream-enumerate-interval</code> with the arguments 10,000
and 1,000,000.  <code class="code">Stream-enumerate-interval</code> is the stream analog of
<code class="code">enumerate-interval</code> (<a class="ref" href="2_002e2.xhtml#g_t2_002e2_002e3">Sequences as Conventional Interfaces</a>):
</p>
<div class="example">
<pre class="example-preformatted">// In Rust, ranges are already lazy iterators!
fn stream_enumerate_interval(low: u64, high: u64) -&gt; impl Iterator&lt;Item = u64&gt; {
    low..=high  // RangeInclusive is lazy - no allocation
}
</pre></div>

<p>and thus the result returned by <code class="code">stream-enumerate-interval</code>, formed by the
<code class="code">cons-stream</code>, is<a class="footnote" id="DOCF176" href="#FOOT176"><sup>176</sup></a>
</p>
<div class="example">
<pre class="example-preformatted">// The Rust range iterator internally stores:
// RangeInclusive { start: 10000, end: 1000000 }
// No elements are computed until next() is called
10_000..=1_000_000
</pre></div>

<p>That is, <code class="code">stream-enumerate-interval</code> returns a stream represented as a
pair whose <code class="code">car</code> is 10,000 and whose <code class="code">cdr</code> is a promise to enumerate
more of the interval if so requested.  This stream is now filtered for primes,
using the stream analog of the <code class="code">filter</code> procedure (<a class="ref" href="2_002e2.xhtml#g_t2_002e2_002e3">Sequences as Conventional Interfaces</a>):
</p>
<div class="example">
<pre class="example-preformatted">// In Rust, Iterator::filter is already lazy
fn stream_filter&lt;I, P&gt;(stream: I, pred: P) -&gt; impl Iterator&lt;Item = I::Item&gt;
where
    I: Iterator,
    P: FnMut(&amp;I::Item) -&gt; bool,
{
    stream.filter(pred)
    // Returns a Filter adapter - no computation yet!
}
</pre></div>

<p><code class="code">Stream-filter</code> tests the <code class="code">head</code> of the stream (the <code class="code">car</code>
of the pair, which is 10,000).  Since this is not prime, <code class="code">stream-filter</code>
examines the <code class="code">tail</code> of its input stream.  The call to
<code class="code">tail</code> forces evaluation of the delayed
<code class="code">stream-enumerate-interval</code>, which now returns
</p>
<div class="example">
<pre class="example-preformatted">// After consuming 10000, the range's internal state becomes:
// RangeInclusive { start: 10001, end: 1000000 }
// Still lazy - 10001 computed only when next() called
</pre></div>

<p><code class="code">Stream-filter</code> now looks at the <code class="code">head</code> of this stream, 10,001,
sees that this is not prime either, forces another <code class="code">tail</code>, and so
on, until <code class="code">stream-enumerate-interval</code> yields the prime 10,007, whereupon
<code class="code">stream-filter</code>, according to its definition, returns
</p>
<div class="example">
<pre class="example-preformatted">// Filter yields matching element, continues lazily
// Internal state: Filter { iter: range, predicate }
// Only advances when next element requested
</pre></div>

<p>which in this case is
</p>
<div class="example">
<pre class="example-preformatted">// After finding first prime 10007:
// Filter { iter: 10008..=1000000, predicate: is_prime }
// The 10007 is yielded, rest remains unevaluated
</pre></div>

<p>This result is now passed to <code class="code">tail</code> in our original expression.
This forces the delayed <code class="code">stream-filter</code>, which in turn keeps forcing the
delayed <code class="code">stream-enumerate-interval</code> until it finds the next prime, which
is 10,009.  Finally, the result passed to <code class="code">head</code> in our original
expression is
</p>
<div class="example">
<pre class="example-preformatted">// After finding second prime 10009:
// Filter { iter: 10010..=1000000, predicate: is_prime }
// nth(1) returns 10009, computation stops here
</pre></div>

<p><code class="code">Stream-car</code> returns 10,009, and the computation is complete.  Only as
many integers were tested for primality as were necessary to find the second
prime, and the interval was enumerated only as far as was necessary to feed the
prime filter.
</p>
<p>In general, we can think of delayed evaluation as &#8220;demand-driven&#8221;
programming, whereby each stage in the stream process is activated only enough
to satisfy the next stage.  What we have done is to decouple the actual order
of events in the computation from the apparent structure of our procedures.  We
write procedures as if the streams existed &#8220;all at once&#8221; when, in reality,
the computation is performed incrementally, as in traditional programming
styles.
</p>
<h4 class="subsubheading" id="Implementing-delay-and-force"><span>Implementing <code class="code">delay</code> and <code class="code">force</code><a class="copiable-link" href="#Implementing-delay-and-force"> &#182;</a></span></h4>

<p>Although <code class="code">delay</code> and <code class="code">force</code> may seem like mysterious operations,
their implementation is really quite straightforward.  <code class="code">Delay</code> must
package an expression so that it can be evaluated later on demand, and we can
accomplish this simply by treating the expression as the body of a procedure.
<code class="code">Delay</code> can be a special form such that
</p>
<div class="example">
<pre class="example-preformatted">|| exp  // A closure captures the expression
</pre></div>

<p>is syntactic sugar for
</p>
<div class="example">
<pre class="example-preformatted">|| exp  // Equivalent: closure with no arguments
</pre></div>

<p><code class="code">Force</code> simply calls the procedure (of no arguments) produced by
<code class="code">delay</code>, so we can implement <code class="code">force</code> as a procedure:
</p>
<div class="example">
<pre class="example-preformatted">fn force&lt;T, F: FnOnce() -&gt; T&gt;(delayed_object: F) -&gt; T {
    delayed_object()  // Simply call the closure
}
</pre></div>

<p>This implementation suffices for <code class="code">delay</code> and <code class="code">force</code> to work as
advertised, but there is an important optimization that we can include.  In
many applications, we end up forcing the same delayed object many times.  This
can lead to serious inefficiency in recursive programs involving streams.  (See
<a class="ref" href="#Exercise-3_002e57">Exercise 3.57</a>.)  The solution is to build delayed objects so that the
first time they are forced, they store the value that is computed.  Subsequent
forcings will simply return the stored value without repeating the computation.
In other words, we implement <code class="code">delay</code> as a special-purpose memoized
procedure similar to the one described in <a class="ref" href="3_002e3.xhtml#Exercise-3_002e27">Exercise 3.27</a>.  One way to
accomplish this is to use the following procedure, which takes as argument a
procedure (of no arguments) and returns a memoized version of the procedure.
The first time the memoized procedure is run, it saves the computed result.  On
subsequent evaluations, it simply returns the result.
</p>
<div class="example">
<pre class="example-preformatted">use std::cell::OnceCell;

// Memoized thunk using OnceCell for single initialization
struct MemoizedThunk&lt;T, F: FnOnce() -&gt; T&gt; {
    result: OnceCell&lt;T&gt;,
    proc: Option&lt;F&gt;,  // Option allows taking ownership
}

impl&lt;T, F: FnOnce() -&gt; T&gt; MemoizedThunk&lt;T, F&gt; {
    fn new(proc: F) -&gt; Self {
        MemoizedThunk {
            result: OnceCell::new(),
            proc: Some(proc),
        }
    }

    fn force(&amp;mut self) -&gt; &amp;T {
        self.result.get_or_init(|| {
            (self.proc.take().unwrap())()
        })
    }
}
</pre></div>

<p><code class="code">Delay</code> is then defined so that <code class="code">(delay ⟨<var class="var">exp</var>⟩)</code> is equivalent
to
</p>
<div class="example">
<pre class="example-preformatted">// std::cell::Lazy provides this in Rust:
use std::cell::LazyCell;
let delayed = LazyCell::new(|| exp);
// First access computes; subsequent accesses return cached value
</pre></div>

<p>and <code class="code">force</code> is as defined previously.<a class="footnote" id="DOCF177" href="#FOOT177"><sup>177</sup></a>
</p>
<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e50"></a>Exercise 3.50:</strong> Complete the following
definition, which generalizes <code class="code">stream-map</code> to allow procedures that take
multiple arguments, analogous to <code class="code">map</code> in <a class="ref" href="2_002e2.xhtml#g_t2_002e2_002e1">Representing Sequences</a>.
</p>
<div class="example">
<pre class="example-preformatted">// Multi-iterator map using Iterator::zip
fn stream_map2&lt;A, B, R, I1, I2, F&gt;(
    mut s1: I1,
    mut s2: I2,
    mut proc: F,
) -&gt; impl Iterator&lt;Item = R&gt;
where
    I1: Iterator&lt;Item = A&gt;,
    I2: Iterator&lt;Item = B&gt;,
    F: FnMut(A, B) -&gt; R,
{
    std::iter::from_fn(move || {
        Some(proc(s1.next()?, s2.next()?))
    })
}
// Or simply: s1.zip(s2).map(|(a, b)| proc(a, b))
</pre></div>
</blockquote>

<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e51"></a>Exercise 3.51:</strong> In order to take a closer look at
delayed evaluation, we will use the following procedure, which simply returns
its argument after printing it:
</p>
<div class="example">
<pre class="example-preformatted">fn show&lt;T: std::fmt::Debug + Clone&gt;(x: T) -&gt; T {
    println!(&quot;{:?}&quot;, x);
    x
}
</pre></div>

<p>What does the interpreter print in response to evaluating each expression in
the following sequence?<a class="footnote" id="DOCF178" href="#FOOT178"><sup>178</sup></a>
</p>
<div class="example">
<pre class="example-preformatted">let x = (0..=10).map(|n| show(n));
// Iterators in Rust are consumed on use, so we need collect or clone

// With inspect for side effects:
let mut x = (0..=10).inspect(|n| println!(&quot;{}&quot;, n));
x.nth(5);  // Prints 0,1,2,3,4,5 then returns Some(5)
x.nth(1);  // Continues from 6, prints 6,7 then returns Some(7)
</pre></div>
</blockquote>

<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e52"></a>Exercise 3.52:</strong> Consider the sequence of
expressions
</p>
<div class="example">
<pre class="example-preformatted">use std::cell::Cell;

let sum = Cell::new(0_i64);

let accum = |x: i64| {
    sum.set(sum.get() + x);
    sum.get()
};

// Warning: this example shows problematic mutation with lazy eval!
// The order of forcing affects results due to shared mutable state
let seq = (1..=20).map(|x| accum(x));

let y = seq.clone().filter(|&amp;x| x % 2 == 0);
let z = seq.clone().filter(|&amp;x| x % 5 == 0);

// Results depend on evaluation order - this is the lesson:
// mixing lazy streams with mutation is confusing!
</pre></div>

<p>What is the value of <code class="code">sum</code> after each of the above expressions is
evaluated?  What is the printed response to evaluating the <code class="code">stream-ref</code>
and <code class="code">display-stream</code> expressions?  Would these responses differ if we had
implemented <code class="code">delay(⟨<var class="var">exp</var>⟩)</code> simply as <code class="code">|| ⟨<var class="var">exp</var>⟩</code>
without using the optimization provided by <code class="code">memo_proc</code>?  Explain.
</p></blockquote>

<hr />
</div>
<div class="subsection-level-extent" id="g_t3_002e5_002e2">
<h4 class="subsection" id="Infinite-Streams"><span>3.5.2 Infinite Streams<a class="copiable-link" href="#Infinite-Streams"> &#182;</a></span></h4>

<p>We have seen how to support the illusion of manipulating streams as complete
entities even though, in actuality, we compute only as much of the stream as we
need to access.  We can exploit this technique to represent sequences
efficiently as streams, even if the sequences are very long.  What is more
striking, we can use streams to represent sequences that are infinitely long.
For instance, consider the following definition of the stream of positive
integers:
</p>
<div class="example">
<pre class="example-preformatted">// Infinite stream of integers
struct IntegersFrom {
    current: i64,
}

impl IntegersFrom {
    fn new(start: i64) -&gt; Self {
        IntegersFrom { current: start }
    }
}

impl Iterator for IntegersFrom {
    type Item = i64;

    fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; {
        let value = self.current;
        self.current += 1;
        Some(value)
    }
}

// Usage: let integers = IntegersFrom::new(1);
</pre></div>

<p>This makes sense because <code class="code">integers</code> will be a pair whose <code class="code">car</code> is 1
and whose <code class="code">cdr</code> is a promise to produce the integers beginning with 2.
This is an infinitely long stream, but in any given time we can examine only a
finite portion of it.  Thus, our programs will never know that the entire
infinite stream is not there.
</p>
<p>Using <code class="code">integers</code> we can define other infinite streams, such as the stream
of integers that are not divisible by 7:
</p>
<div class="example">
<pre class="example-preformatted">fn divisible(x: i64, y: i64) -&gt; bool {
    x % y == 0
}

// Integers not divisible by 7 - lazy, infinite
let no_sevens = (1..).filter(|&amp;x| !divisible(x, 7));
</pre></div>

<p>Then we can find integers not divisible by 7 simply by accessing elements of
this stream:
</p>
<div class="example">
<pre class="example-preformatted">(1..).filter(|&amp;x| x % 7 != 0).nth(100)
// =&gt; Some(117)
</pre></div>

<p>In analogy with <code class="code">integers</code>, we can define the infinite stream of Fibonacci
numbers:
</p>
<div class="example">
<pre class="example-preformatted">// Infinite Fibonacci iterator
struct Fibonacci {
    current: u64,
    next: u64,
}

impl Iterator for Fibonacci {
    type Item = u64;
    fn next(&amp;mut self) -&gt; Option&lt;u64&gt; {
        let result = self.current;
        self.current = self.next;
        self.next = result + self.next;
        Some(result)
    }
}

let fibs = Fibonacci { current: 0, next: 1 };
// fibs.take(10).collect::&lt;Vec&lt;_&gt;&gt;()
// =&gt; [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]
</pre></div>

<p><code class="code">Fibs</code> is a pair whose <code class="code">car</code> is 0 and whose <code class="code">cdr</code> is a promise
to evaluate <code class="code">(fibgen 1 1)</code>.  When we evaluate this delayed <code class="code">(fibgen 1
1)</code>, it will produce a pair whose <code class="code">car</code> is 1 and whose <code class="code">cdr</code> is a
promise to evaluate <code class="code">(fibgen 1 2)</code>, and so on.
</p>
<p>For a look at a more exciting infinite stream, we can generalize the
<code class="code">no-sevens</code> example to construct the infinite stream of prime numbers,
using a method known as the <a class="index-entry-id" id="index-sieve-of-Eratosthenes"></a>
<em class="dfn">sieve of Eratosthenes</em>.<a class="footnote" id="DOCF179" href="#FOOT179"><sup>179</sup></a>
We start with the integers beginning with 2, which is the first prime.  To get
the rest of the primes, we start by filtering the multiples of 2 from the rest
of the integers.  This leaves a stream beginning with 3, which is the next
prime.  Now we filter the multiples of 3 from the rest of this stream.  This
leaves a stream beginning with 5, which is the next prime, and so on.  In other
words, we construct the primes by a sieving process, described as follows: To
sieve a stream <code class="code">S</code>, form a stream whose first element is the first element
of <code class="code">S</code> and the rest of which is obtained by filtering all multiples of the
first element of <code class="code">S</code> out of the rest of <code class="code">S</code> and sieving the
result. This process is readily described in terms of stream operations:
</p>
<div class="example">
<pre class="example-preformatted">// Sieve of Eratosthenes as an iterator
// Note: This functional approach creates nested filters
fn sieve(stream: impl Iterator&lt;Item = u64&gt; + 'static)
    -&gt; Box&lt;dyn Iterator&lt;Item = u64&gt;&gt;
{
    let mut iter = stream.peekable();
    if let Some(&amp;prime) = iter.peek() {
        let prime = iter.next().unwrap();
        Box::new(
            std::iter::once(prime).chain(
                sieve(iter.filter(move |&amp;x| x % prime != 0))
            )
        )
    } else {
        Box::new(std::iter::empty())
    }
}

let primes = sieve(2..);
</pre></div>

<p>Now to find a particular prime we need only ask for it:
</p>
<div class="example">
<pre class="example-preformatted">sieve(2..).nth(50)
// =&gt; Some(233)
</pre></div>

<p>It is interesting to contemplate the signal-processing system set up by
<code class="code">sieve</code>, shown in the &#8220;Henderson diagram&#8221; in 
<a class="ref" href="#Figure-3_002e31">Figure 3.31</a>.<a class="footnote" id="DOCF180" href="#FOOT180"><sup>180</sup></a>  The input stream
feeds into an &#8220;un<code class="code">cons</code>er&#8221; that separates the first element of the
stream from the rest of the stream.  The first element is used to construct a
divisibility filter, through which the rest is passed, and the output of the
filter is fed to another sieve box.  Then the original first element is
<code class="code">cons</code>ed onto the output of the internal sieve to form the output stream.
Thus, not only is the stream infinite, but the signal processor is also
infinite, because the sieve contains a sieve within it.
</p>
<div class="float">
<a class="anchor" id="Figure-3_002e31"></a><img class="image" src="fig/chap3/Fig3.31a.std.svg" alt="fig/chap3/Fig3.31a" />
<div class="caption"><p><strong class="strong">Figure 3.31:</strong> The prime sieve viewed as a signal-processing system.</p></div></div>
<h4 class="subsubheading" id="Defining-streams-implicitly"><span>Defining streams implicitly<a class="copiable-link" href="#Defining-streams-implicitly"> &#182;</a></span></h4>

<p>The <code class="code">integers</code> and <code class="code">fibs</code> streams above were defined by specifying
&#8220;generating&#8221; procedures that explicitly compute the stream elements one by
one. An alternative way to specify streams is to take advantage of delayed
evaluation to define streams implicitly.  For example, the following expression
defines the stream <code class="code">ones</code> to be an infinite stream of ones:
</p>
<div class="example">
<pre class="example-preformatted">// Infinite stream of ones
let ones = std::iter::repeat(1);
// Or: std::iter::from_fn(|| Some(1))
</pre></div>

<p>This works much like the definition of a recursive procedure: <code class="code">ones</code> is a
pair whose <code class="code">car</code> is 1 and whose <code class="code">cdr</code> is a promise to evaluate
<code class="code">ones</code>.  Evaluating the <code class="code">cdr</code> gives us again a 1 and a promise to
evaluate <code class="code">ones</code>, and so on.
</p>
<p>We can do more interesting things by manipulating streams with operations such
as <code class="code">add_streams</code>, which produces the elementwise sum of two given
streams:<a class="footnote" id="DOCF181" href="#FOOT181"><sup>181</sup></a>
</p>
<div class="example">
<pre class="example-preformatted">fn add_streams&lt;I1, I2&gt;(s1: I1, s2: I2) -&gt; impl Iterator&lt;Item = i64&gt;
where
    I1: Iterator&lt;Item = i64&gt;,
    I2: Iterator&lt;Item = i64&gt;,
{
    s1.zip(s2).map(|(a, b)| a + b)
}
</pre></div>

<p>Now we can define the integers as follows:
</p>
<div class="example">
<pre class="example-preformatted">// In Rust, the simpler approach is just using range:
let integers = 1_i64..;

// The self-referential definition requires explicit state:
let integers = std::iter::successors(Some(1_i64), |&amp;n| Some(n + 1));
</pre></div>

<p>This defines <code class="code">integers</code> to be a stream whose first element is 1 and the
rest of which is the sum of <code class="code">ones</code> and <code class="code">integers</code>.  Thus, the second
element of <code class="code">integers</code> is 1 plus the first element of <code class="code">integers</code>, or
2; the third element of <code class="code">integers</code> is 1 plus the second element of
<code class="code">integers</code>, or 3; and so on.  This definition works because, at any point,
enough of the <code class="code">integers</code> stream has been generated so that we can feed it
back into the definition to produce the next integer.
</p>
<p>We can define the Fibonacci numbers in the same style:
</p>
<div class="example">
<pre class="example-preformatted">// Self-referential Fibonacci via successors
let fibs = std::iter::successors(
    Some((0_u64, 1_u64)),
    |&amp;(a, b)| Some((b, a + b))
).map(|(a, _)| a);

// Or using unfold (nightly):
// std::iter::unfold((0, 1), |(a, b)| {
//     let next = (*a, *b);
//     *a = next.1;
//     *b = next.0 + next.1;
//     Some(next.0)
// })
</pre></div>

<p>This definition says that <code class="code">fibs</code> is a stream beginning with 0 and 1, such
that the rest of the stream can be generated by adding <code class="code">fibs</code> to itself
shifted by one place:
</p>
<div class="example">
<pre class="example-preformatted">    1 1 2 3 5  8 13 21 <span class="r">…</span> = <code class="code">(stream-cdr fibs)</code>
    0 1 1 2 3  5  8 13 <span class="r">…</span> = <code class="code">fibs</code>
0 1 1 2 3 5 8 13 21 34 <span class="r">…</span> = <code class="code">fibs</code>
</pre></div>

<p><code class="code">Scale-stream</code> is another useful procedure in formulating such stream
definitions.  This multiplies each item in a stream by a given constant:
</p>
<div class="example">
<pre class="example-preformatted">fn scale_stream&lt;I: Iterator&lt;Item = i64&gt;&gt;(
    stream: I,
    factor: i64,
) -&gt; impl Iterator&lt;Item = i64&gt; {
    stream.map(move |x| x * factor)
}
</pre></div>

<p>For example,
</p>
<div class="example">
<pre class="example-preformatted">// Powers of 2: 1, 2, 4, 8, 16, ...
let powers_of_2 = std::iter::successors(
    Some(1_i64),
    |&amp;n| Some(n * 2)
);
</pre></div>

<p>produces the stream of powers of 2: 1, 2, 4, 8, 16, 32, &#8230;.
</p>
<p>An alternate definition of the stream of primes can be given by starting with
the integers and filtering them by testing for primality.  We will need the
first prime, 2, to get started:
</p>
<div class="example">
<pre class="example-preformatted">// Primes by filtering integers
fn primes() -&gt; impl Iterator&lt;Item = u64&gt; {
    std::iter::once(2).chain(
        (3..).filter(|&amp;n| is_prime(n))
    )
}
</pre></div>

<p>This definition is not so straightforward as it appears, because we will test
whether a number <em class="math">n</em> is prime by checking whether <em class="math">n</em> is divisible by a
prime (not by just any integer) less than or equal to <em class="math">\sqrt{n}</em>:
</p>
<div class="example">
<pre class="example-preformatted">// Test primality using previously computed primes
fn is_prime_with_primes&lt;I: Iterator&lt;Item = u64&gt;&gt;(n: u64, primes: I) -&gt; bool {
    for p in primes {
        if p * p &gt; n {
            return true;
        }
        if n % p == 0 {
            return false;
        }
    }
    true
}
</pre></div>

<p>This is a recursive definition, since <code class="code">primes</code> is defined in terms of the
<code class="code">is_prime</code> predicate, which itself uses the <code class="code">primes</code> stream.  The
reason this procedure works is that, at any point, enough of the <code class="code">primes</code>
stream has been generated to test the primality of the numbers we need to check
next.  That is, for every <em class="math">n</em> we test for primality, either <em class="math">n</em> is not
prime (in which case there is a prime already generated that divides it) or
<em class="math">n</em> is prime (in which case there is a prime already generated&#8212;i.e., a
prime less than <em class="math">n</em>&#8212;that is greater than
<em class="math">\sqrt{n}</em>).<a class="footnote" id="DOCF182" href="#FOOT182"><sup>182</sup></a>
</p>
<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e53"></a>Exercise 3.53:</strong> Without running the program,
describe the elements of the stream defined by
</p>
<div class="example">
<pre class="example-preformatted">// Powers of 2: 1, 2, 4, 8, 16, ...
// Each element is double the previous: s[n] = 2 * s[n-1]
let s = std::iter::successors(Some(1_i64), |&amp;n| Some(n + n));
</pre></div>
</blockquote>

<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e54"></a>Exercise 3.54:</strong> Define a procedure
<code class="code">mul_streams</code>, analogous to <code class="code">add_streams</code>, that produces the
elementwise product of its two input streams.  Use this together with the
stream of <code class="code">integers</code> to complete the following definition of the stream
whose <em class="math">n^{\text{th}}</em> element (counting from 0) is <em class="math">{n + 1}</em> factorial:
</p>
<div class="example">
<pre class="example-preformatted">// factorials: 1!, 2!, 3!, 4!, ... = 1, 2, 6, 24, ...
fn factorials() -&gt; impl Iterator&lt;Item = u64&gt; {
    (1..).scan(1_u64, |acc, n| {
        *acc *= n;
        Some(*acc)
    })
}
// Or: std::iter::successors(Some((1u64, 1u64)), |(f, n)| Some((f * n, n + 1)))
//     .map(|(f, _)| f)
</pre></div>
</blockquote>

<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e55"></a>Exercise 3.55:</strong> Define a procedure
<code class="code">partial_sums</code> that takes as argument a stream <em class="math">S</em> and returns the
stream whose elements are <em class="math">S_0</em>, <em class="math">{S_0 + S_1}</em>, <em class="math">{S_0 + S_1} + {S_2, \dots}</em>.  
For example, <code class="code">(partial-sums integers)</code> should be the
stream 1, 3, 6, 10, 15, &#8230;.
</p></blockquote>

<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e56"></a>Exercise 3.56:</strong> A famous problem, first raised by
R. Hamming, is to enumerate, in ascending order with no repetitions, all
positive integers with no prime factors other than 2, 3, or 5.  One obvious way
to do this is to simply test each integer in turn to see whether it has any
factors other than 2, 3, and 5.  But this is very inefficient, since, as the
integers get larger, fewer and fewer of them fit the requirement.  As an
alternative, let us call the required stream of numbers <code class="code">S</code> and notice the
following facts about it.
</p>
<ul class="itemize mark-bullet">
<li><code class="code">S</code> begins with 1.

</li><li>The elements of <code class="code">scale_stream(S, 2)</code> are also
elements of <code class="code">S</code>.

</li><li>The same is true for <code class="code">scale_stream(S, 3)</code>
and <code class="code">scale_stream(S, 5)</code>.

</li><li>These are all the elements of <code class="code">S</code>.

</li></ul>

<p>Now all we have to do is combine elements from these sources.  For this we
define a procedure <code class="code">merge</code> that combines two ordered streams into one
ordered result stream, eliminating repetitions:
</p>
<div class="example">
<pre class="example-preformatted">// Merge two ordered iterators, eliminating duplicates
fn merge&lt;I1, I2&gt;(s1: I1, s2: I2) -&gt; impl Iterator&lt;Item = u64&gt;
where
    I1: Iterator&lt;Item = u64&gt;,
    I2: Iterator&lt;Item = u64&gt;,
{
    let mut p1 = s1.peekable();
    let mut p2 = s2.peekable();

    std::iter::from_fn(move || {
        match (p1.peek(), p2.peek()) {
            (Some(&amp;a), Some(&amp;b)) if a &lt; b =&gt; p1.next(),
            (Some(&amp;a), Some(&amp;b)) if a &gt; b =&gt; p2.next(),
            (Some(_), Some(_)) =&gt; {
                p2.next(); // Skip duplicate
                p1.next()
            }
            (Some(_), None) =&gt; p1.next(),
            (None, Some(_)) =&gt; p2.next(),
            (None, None) =&gt; None,
        }
    })
}
</pre></div>

<p>Then the required stream may be constructed with <code class="code">merge</code>, as follows:
</p>
<div class="example">
<pre class="example-preformatted">// Hamming numbers: 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, ...
// (numbers with only 2, 3, 5 as prime factors)
// Fill in: merge(scale(S, 2), merge(scale(S, 3), scale(S, 5)))
</pre></div>

<p>Fill in the missing expressions in the places marked <code class="code">⟨??⟩</code> above.
</p></blockquote>

<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e57"></a>Exercise 3.57:</strong> How many additions are performed
when we compute the <em class="math">n^{\text{th}}</em> Fibonacci number using the definition of
<code class="code">fibs</code> based on the <code class="code">add_streams</code> procedure?  Show that the number of
additions would be exponentially greater if we had implemented <code class="code">delay(⟨<var class="var">exp</var>⟩)</code>
simply as <code class="code">|| ⟨<var class="var">exp</var>⟩</code>, without using the
optimization provided by the <code class="code">memo_proc</code> procedure described in 
<a class="ref" href="#g_t3_002e5_002e1">Streams Are Delayed Lists</a>.<a class="footnote" id="DOCF183" href="#FOOT183"><sup>183</sup></a>
</p></blockquote>

<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e58"></a>Exercise 3.58:</strong> Give an interpretation of the
stream computed by the following procedure:
</p>
<div class="example">
<pre class="example-preformatted">// Generates decimal (or other radix) expansion of num/den
fn expand(num: i64, den: i64, radix: i64) -&gt; impl Iterator&lt;Item = i64&gt; {
    std::iter::successors(Some(num), move |&amp;n| {
        Some((n * radix) % den)
    })
    .map(move |n| (n * radix) / den)
}
// expand(1, 7, 10) =&gt; 1, 4, 2, 8, 5, 7, 1, 4, ... (1/7 = 0.142857...)
// expand(3, 8, 10) =&gt; 3, 7, 5, 0, 0, 0, ... (3/8 = 0.375)
</pre></div>

<p>(<code class="code">Quotient</code> is a primitive that returns the integer quotient of two
integers.)  What are the successive elements produced by <code class="code">(expand 1 7
10)</code>?  What is produced by <code class="code">(expand 3 8 10)</code>?
</p></blockquote>

<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e59"></a>Exercise 3.59:</strong> In <a class="ref" href="2_002e5.xhtml#g_t2_002e5_002e3">Example: Symbolic Algebra</a> we saw how
to implement a polynomial arithmetic system representing polynomials as lists
of terms.  In a similar way, we can work with <a class="index-entry-id" id="index-power-series"></a>
<em class="dfn">power series</em>, such as
\[ % :63:
\begin{eqnarray}
  e^x 	  &amp;=&amp; 1 + x + \frac{1}{2} x^2  + \frac{1}{3 \cdot 2} x^3  + \frac{1}{4 \cdot 3 \cdot 2} x^4  + \dots, \\
  \cos x  &amp;=&amp; 1 - \frac{1}{2} x^2  + \frac{1}{4 \cdot 3 \cdot 2} x^4  - \dots, \\
  \sin x  &amp;=&amp; x - \frac{1}{3 \cdot 2} x^3  + \frac{1}{5 \cdot 4 \cdot 3 \cdot 2} x^5  - \dots
\end{eqnarray}
\]
represented as infinite streams.  We will represent the series <em class="math">{a_0 +
a_1 x} + {a_2 x^2} + {a_3 x^3 + \dots}</em> as the stream whose
elements are the coefficients <em class="math">a_0</em>, <em class="math">a_1</em>, <em class="math">a_2</em>, <em class="math">a_3</em>, &#8230;.
</p>
<ol class="enumerate" type="a" start="1">
<li> The integral of the series <em class="math">{a_0 + a_1 x} + {a_2 x^2} + {a_3 x^3 + \dots}</em> is the series
\[ % :64:
  c + {a_0 x} + {\frac{1}{2} a_1 x^2} + {\frac{1}{3} a_2 x^3} + {\frac{1}{4} a_3 x^4 + \dots,}  \]
where <em class="math">c</em> is any constant.  Define a procedure <code class="code">integrate_series</code> that
takes as input a stream <em class="math">a_0</em>, <em class="math">a_1</em>, <em class="math">a_2</em>, &#8230; representing a power
series and returns the stream <em class="math">a_0</em>, <em class="math">{{1\over2}a_1}</em>, <em class="math">{{1\over3}a_2}</em>, &#8230; of
coefficients of the non-constant terms of the integral of the series.  (Since
the result has no constant term, it doesn&#8217;t represent a power series; when we
use <code class="code">integrate_series</code>, we will <code class="code">cons</code> on the appropriate constant.)

</li><li> The function <em class="math">{x \mapsto e^x}</em> is its own derivative.  This implies that
<em class="math">e^x</em> and the integral of <em class="math">e^x</em> are the same series, except for the
constant term, which is <em class="math">{e^0 = 1}</em>.  Accordingly, we can generate the series
for <em class="math">e^x</em> as

<div class="example">
<pre class="example-preformatted">// Power series for e^x: coefficients are 1/n!
fn exp_series() -&gt; impl Iterator&lt;Item = f64&gt; {
    std::iter::successors(Some((1.0_f64, 1_u64)), |(coef, n)| {
        Some((coef / (*n as f64), n + 1))
    })
    .map(|(coef, _)| coef)
}
// =&gt; 1.0, 1.0, 0.5, 0.166..., 0.0416..., ...
</pre></div>

<p>Show how to generate the series for sine and cosine, starting from the facts
that the derivative of sine is cosine and the derivative of cosine is the
negative of sine:
</p>
<div class="example">
<pre class="example-preformatted">// cos(x) = 1 - x^2/2! + x^4/4! - ...
fn cosine_series() -&gt; impl Iterator&lt;Item = f64&gt; {
    // Coefficients: 1, 0, -1/2, 0, 1/24, 0, -1/720, ...
    (0..).scan((1.0_f64, 1), |(coef, sign), n| {
        let result = if n % 2 == 0 { *coef * (*sign as f64) } else { 0.0 };
        if n % 2 == 0 {
            *coef /= ((n + 1) * (n + 2)) as f64;
            *sign *= -1;
        }
        Some(result)
    })
}

// sin(x) = x - x^3/3! + x^5/5! - ...
fn sine_series() -&gt; impl Iterator&lt;Item = f64&gt; {
    // Coefficients: 0, 1, 0, -1/6, 0, 1/120, ...
    (0..).scan((1.0_f64, 1), |(coef, sign), n| {
        let result = if n % 2 == 1 { *coef * (*sign as f64) } else { 0.0 };
        if n % 2 == 1 {
            *coef /= ((n + 1) * (n + 2)) as f64;
            *sign *= -1;
        }
        Some(result)
    })
}
</pre></div>
</li></ol>
</blockquote>

<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e60"></a>Exercise 3.60:</strong> With power series represented as
streams of coefficients as in <a class="ref" href="#Exercise-3_002e59">Exercise 3.59</a>, adding series is implemented
by <code class="code">add_streams</code>.  Complete the definition of the following procedure for
multiplying series:
</p>
<div class="example">
<pre class="example-preformatted">// Multiply two power series (Cauchy product)
// c_n = sum(a_i * b_(n-i)) for i = 0..n
fn mul_series&lt;I1, I2&gt;(s1: I1, s2: I2) -&gt; impl Iterator&lt;Item = f64&gt;
where
    I1: Iterator&lt;Item = f64&gt;,
    I2: Iterator&lt;Item = f64&gt;,
{
    let a: Vec&lt;f64&gt; = s1.collect();
    let b: Vec&lt;f64&gt; = s2.collect();
    (0..a.len().min(b.len())).map(move |n| {
        (0..=n).map(|i| a[i] * b[n - i]).sum()
    })
}
</pre></div>

<p>You can test your procedure by verifying that <em class="math">{\sin^2x + \cos^2x = 1,}</em>
using the series from <a class="ref" href="#Exercise-3_002e59">Exercise 3.59</a>.
</p></blockquote>

<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e61"></a>Exercise 3.61:</strong> Let <em class="math">S</em> be a power series
(<a class="ref" href="#Exercise-3_002e59">Exercise 3.59</a>) whose constant term is 1.  Suppose we want to find the
power series <em class="math">{1 / S}</em>, that is, the series <em class="math">X</em> such that <em class="math">{SX = 1}</em>.
Write <em class="math">{S = 1 + S_R}</em> where <em class="math">S_R</em> is the part of <em class="math">S</em> after the
constant term.  Then we can solve for <em class="math">X</em> as follows:
\[ % :65:
\begin{eqnarray}
  S \cdot X           &amp;=&amp;   1, \\
  (1 + S_R) \cdot X   &amp;=&amp;   1, \\
  X + S_R \cdot X     &amp;=&amp;   1, \\
  X                   &amp;=&amp;   1 - S_R \cdot X.
\end{eqnarray}
\]
In other words, <em class="math">X</em> is the power series whose constant term is 1 and whose
higher-order terms are given by the negative of <em class="math">S_R</em> times <em class="math">X</em>.  Use
this idea to write a procedure <code class="code">invert_unit_series</code> that computes <em class="math">{1 / S}</em>
for a power series <em class="math">S</em> with constant term 1.  You will need to use
<code class="code">mul_series</code> from <a class="ref" href="#Exercise-3_002e60">Exercise 3.60</a>.
</p></blockquote>

<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e62"></a>Exercise 3.62:</strong> Use the results of <a class="ref" href="#Exercise-3_002e60">Exercise 3.60</a> 
and <a class="ref" href="#Exercise-3_002e61">Exercise 3.61</a> to define a procedure <code class="code">div_series</code> that
divides two power series.  <code class="code">Div-series</code> should work for any two series,
provided that the denominator series begins with a nonzero constant term.  (If
the denominator has a zero constant term, then <code class="code">div_series</code> should signal
an error.)  Show how to use <code class="code">div_series</code> together with the result of
<a class="ref" href="#Exercise-3_002e59">Exercise 3.59</a> to generate the power series for tangent.
</p></blockquote>

<hr />
</div>
<div class="subsection-level-extent" id="g_t3_002e5_002e3">
<h4 class="subsection" id="Exploiting-the-Stream-Paradigm"><span>3.5.3 Exploiting the Stream Paradigm<a class="copiable-link" href="#Exploiting-the-Stream-Paradigm"> &#182;</a></span></h4>

<p>Streams with delayed evaluation can be a powerful modeling tool, providing many
of the benefits of local state and assignment.  Moreover, they avoid some of
the theoretical tangles that accompany the introduction of assignment into a
programming language.
</p>
<p>The stream approach can be illuminating because it allows us to build systems
with different module boundaries than systems organized around assignment to
state variables.  For example, we can think of an entire time series (or
signal) as a focus of interest, rather than the values of the state variables
at individual moments.  This makes it convenient to combine and compare
components of state from different moments.
</p>
<h4 class="subsubheading" id="Formulating-iterations-as-stream-processes"><span>Formulating iterations as stream processes<a class="copiable-link" href="#Formulating-iterations-as-stream-processes"> &#182;</a></span></h4>

<p>In section <a class="ref" href="1_002e2.xhtml#g_t1_002e2_002e1">Linear Recursion and Iteration</a>, we introduced iterative processes, which proceed by
updating state variables.  We know now that we can represent state as a
&#8220;timeless&#8221; stream of values rather than as a set of variables to be updated.
Let&#8217;s adopt this perspective in revisiting the square-root procedure from
<a class="ref" href="1_002e1.xhtml#g_t1_002e1_002e7">Example: Square Roots by Newton&#8217;s Method</a>.  Recall that the idea is to generate a sequence of better
and better guesses for the square root of <em class="math">x</em> by applying over and over again
the procedure that improves guesses:
</p>
<div class="example">
<pre class="example-preformatted">fn sqrt_improve(guess: f64, x: f64) -&gt; f64 {
    (guess + x / guess) / 2.0
}
</pre></div>

<p>In our original <code class="code">sqrt</code> procedure, we made these guesses be the successive
values of a state variable. Instead we can generate the infinite stream of
guesses, starting with an initial guess of 1:<a class="footnote" id="DOCF184" href="#FOOT184"><sup>184</sup></a>
</p>
<div class="example">
<pre class="example-preformatted">fn sqrt_stream(x: f64) -&gt; impl Iterator&lt;Item = f64&gt; {
    std::iter::successors(Some(1.0), move |&amp;guess| {
        Some(sqrt_improve(guess, x))
    })
}

// sqrt_stream(2.0).take(5).collect::&lt;Vec&lt;_&gt;&gt;()
// =&gt; [1.0, 1.5, 1.4166666666666665,
//     1.4142156862745097, 1.4142135623746899]
</pre></div>

<p>We can generate more and more terms of the stream to get better and better
guesses.  If we like, we can write a procedure that keeps generating terms
until the answer is good enough.  (See <a class="ref" href="#Exercise-3_002e64">Exercise 3.64</a>.)
</p>
<p>Another iteration that we can treat in the same way is to generate an
approximation to <em class="math">\pi</em>, based upon the alternating series that we saw in
<a class="ref" href="1_002e3.xhtml#g_t1_002e3_002e1">Procedures as Arguments</a>:
\[ % :66:
  {\pi\over4} \,=\, 1 - {1\over3} + {1\over5} - {1\over7} + {\dots.}  \]
We first generate the stream of summands of the series (the reciprocals of the
odd integers, with alternating signs).  Then we take the stream of sums of more
and more terms (using the <code class="code">partial_sums</code> procedure of <a class="ref" href="#Exercise-3_002e55">Exercise 3.55</a>)
and scale the result by 4:
</p>
<div class="example">
<pre class="example-preformatted">// Leibniz series: pi/4 = 1 - 1/3 + 1/5 - 1/7 + ...
fn pi_summands() -&gt; impl Iterator&lt;Item = f64&gt; {
    (0..).map(|n| {
        let sign = if n % 2 == 0 { 1.0 } else { -1.0 };
        sign / (2 * n + 1) as f64
    })
}

fn pi_stream() -&gt; impl Iterator&lt;Item = f64&gt; {
    pi_summands().scan(0.0, |acc, x| {
        *acc += x;
        Some(*acc * 4.0)
    })
}

// pi_stream().take(8).collect::&lt;Vec&lt;_&gt;&gt;()
// =&gt; [4.0, 2.666..., 3.466..., 2.895...,
//     3.339..., 2.976..., 3.283..., 3.017...]
</pre></div>

<p>This gives us a stream of better and better approximations to <em class="math">\pi</em>,
although the approximations converge rather slowly.  Eight terms of the
sequence bound the value of <em class="math">\pi</em> between 3.284 and 3.017.
</p>
<p>So far, our use of the stream of states approach is not much different from
updating state variables.  But streams give us an opportunity to do some
interesting tricks.  For example, we can transform a stream with a
<a class="index-entry-id" id="index-sequence-accelerator"></a>
<em class="dfn">sequence accelerator</em> that converts a sequence of approximations to a
new sequence that converges to the same value as the original, only faster.
</p>
<p>One such accelerator, due to the eighteenth-century Swiss mathematician
Leonhard Euler, works well with sequences that are partial sums of alternating
series (series of terms with alternating signs).  In Euler&#8217;s technique, if
<em class="math">S_n</em> is the <em class="math">n^{\text{th}}</em> term of the original sum sequence, then the
accelerated sequence has terms
\[ % :67:
  S_{n+1} - {{(S_{n+1} - S_n)^2 \over S_{n-1} - 2S_n + S_{n+1}}.}  \]
Thus, if the original sequence is represented as a stream of values, the
transformed sequence is given by
</p>
<div class="example">
<pre class="example-preformatted">// Euler's sequence accelerator for alternating series
fn euler_transform&lt;I: Iterator&lt;Item = f64&gt;&gt;(s: I) -&gt; impl Iterator&lt;Item = f64&gt; {
    let items: Vec&lt;f64&gt; = s.collect();
    (0..items.len().saturating_sub(2)).map(move |i| {
        let s0 = items[i];
        let s1 = items[i + 1];
        let s2 = items[i + 2];
        let denom = s0 - 2.0 * s1 + s2;
        if denom.abs() &lt; 1e-15 {
            s2
        } else {
            s2 - (s2 - s1).powi(2) / denom
        }
    })
}
</pre></div>

<p>We can demonstrate Euler acceleration with our sequence of approximations to
<em class="math">\pi</em>:
</p>
<div class="example">
<pre class="example-preformatted">// euler_transform(pi_stream().take(20)).take(8)
// =&gt; [3.166..., 3.133..., 3.145..., 3.139...,
//     3.142..., 3.140..., 3.142..., 3.141...]
// Converges much faster than the original series
</pre></div>

<p>Even better, we can accelerate the accelerated sequence, and recursively
accelerate that, and so on.  Namely, we create a stream of streams (a structure
we&#8217;ll call a <a class="index-entry-id" id="index-tableau"></a>
<em class="dfn">tableau</em>) in which each stream is the transform of the
preceding one:
</p>
<div class="example">
<pre class="example-preformatted">// Create tableau: stream of successively transformed streams
fn make_tableau&lt;F&gt;(transform: F, initial: Vec&lt;f64&gt;) -&gt; Vec&lt;Vec&lt;f64&gt;&gt;
where
    F: Fn(Vec&lt;f64&gt;) -&gt; Vec&lt;f64&gt;,
{
    std::iter::successors(Some(initial), |s| {
        let next = transform(s.clone());
        if next.is_empty() { None } else { Some(next) }
    })
    .collect()
}
</pre></div>

<p>The tableau has the form
\[ % :68:

\begin{array}{cccccc}
 s_{00} 	&amp;   s_{01}  	&amp;   s_{02}  	&amp;   s_{03}  	&amp;   s_{04}  	&amp;   \dots  \\
		&amp;   s_{10}  	&amp;   s_{11}  	&amp;   s_{12}  	&amp;   s_{13}  	&amp;   \dots  \\
		&amp; 		&amp;   s_{20}  	&amp;   s_{21}  	&amp;   s_{22}  	&amp;   \dots  \\
		&amp; 		&amp; 		&amp;   \dots  	&amp; 		&amp;   
\end{array}
\]
Finally, we form a sequence by taking the first term in each row of the
tableau:
</p>
<div class="example">
<pre class="example-preformatted">// Take first element from each row of tableau
fn accelerated_sequence&lt;F&gt;(transform: F, s: Vec&lt;f64&gt;) -&gt; Vec&lt;f64&gt;
where
    F: Fn(Vec&lt;f64&gt;) -&gt; Vec&lt;f64&gt;,
{
    make_tableau(transform, s)
        .into_iter()
        .filter_map(|row| row.first().copied())
        .collect()
}
</pre></div>

<p>We can demonstrate this kind of &#8220;super-acceleration&#8221; of the <em class="math">\pi</em>
sequence:
</p>
<div class="example">
<pre class="example-preformatted">// Super-acceleration: rapidly converges to pi
// accelerated_sequence(euler_vec_transform, pi_stream().take(30).collect())
// =&gt; [4.0, 3.166..., 3.142105..., 3.141599...,
//     3.14159271..., 3.14159265397..., 3.14159265359...]
// 8 terms yield 14 decimal places of pi!
</pre></div>

<p>The result is impressive.  Taking eight terms of the sequence yields the
correct value of <em class="math">\pi</em> to 14 decimal places.  If we had used only the
original <em class="math">\pi</em> sequence, we would need to compute on the order of <em class="math">10^{13}</em>
terms (i.e., expanding the series far enough so that the individual terms are
less than <em class="math">10^{-13}</em>) to get that much accuracy!
</p>
<p>We could have implemented these acceleration techniques without using streams.
But the stream formulation is particularly elegant and convenient because the
entire sequence of states is available to us as a data structure that can be
manipulated with a uniform set of operations.
</p>
<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e63"></a>Exercise 3.63:</strong> Louis Reasoner asks why the
<code class="code">sqrt_stream</code> procedure was not written in the following more
straightforward way, without the local variable <code class="code">guesses</code>:
</p>
<div class="example">
<pre class="example-preformatted">// Inefficient version: creates new iterator on each step
fn sqrt_stream_inefficient(x: f64) -&gt; Box&lt;dyn Iterator&lt;Item = f64&gt;&gt; {
    Box::new(std::iter::once(1.0).chain(
        sqrt_stream_inefficient(x).map(move |guess| sqrt_improve(guess, x))
    ))
}
// Without memoization, this recomputes all previous values!
</pre></div>

<p>Alyssa P. Hacker replies that this version of the procedure is considerably
less efficient because it performs redundant computation.  Explain Alyssa&#8217;s
answer.  Would the two versions still differ in efficiency if our
implementation of <code class="code">delay</code> used only <code class="code">|| ⟨<var class="var">exp</var>⟩</code> without
using the optimization provided by <code class="code">memo_proc</code> (<a class="ref" href="#g_t3_002e5_002e1">Streams Are Delayed Lists</a>)?
</p></blockquote>

<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e64"></a>Exercise 3.64:</strong> Write a procedure
<code class="code">stream_limit</code> that takes as arguments a stream and a number (the
tolerance).  It should examine the stream until it finds two successive
elements that differ in absolute value by less than the tolerance, and return
the second of the two elements.  Using this, we could compute square roots up
to a given tolerance by
</p>
<div class="example">
<pre class="example-preformatted">fn sqrt(x: f64, tolerance: f64) -&gt; f64 {
    sqrt_stream(x)
        .tuple_windows()  // requires itertools
        .find(|(a, b)| (a - b).abs() &lt; tolerance)
        .map(|(_, b)| b)
        .unwrap()
}
// Or with manual window:
fn stream_limit&lt;I: Iterator&lt;Item = f64&gt;&gt;(stream: I, tolerance: f64) -&gt; f64 {
    let mut prev = None;
    for curr in stream {
        if let Some(p) = prev {
            if (curr - p).abs() &lt; tolerance {
                return curr;
            }
        }
        prev = Some(curr);
    }
    prev.unwrap()
}
</pre></div>
</blockquote>

<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e65"></a>Exercise 3.65:</strong> Use the series
\[ % :69:
  \ln 2 \,=\, 1 - {1\over2} + {1\over3} - {1\over4} + \dots  \]
to compute three sequences of approximations to the natural logarithm of 2, in
the same way we did above for <em class="math">\pi</em>.  How rapidly do these sequences
converge?
</p></blockquote>

<h4 class="subsubheading" id="Infinite-streams-of-pairs"><span>Infinite streams of pairs<a class="copiable-link" href="#Infinite-streams-of-pairs"> &#182;</a></span></h4>

<p>In <a class="ref" href="2_002e2.xhtml#g_t2_002e2_002e3">Sequences as Conventional Interfaces</a>, we saw how the sequence paradigm handles traditional
nested loops as processes defined on sequences of pairs.  If we generalize this
technique to infinite streams, then we can write programs that are not easily
represented as loops, because the &#8220;looping&#8221; must range over an infinite set.
</p>
<p>For example, suppose we want to generalize the <code class="code">prime-sum-pairs</code> procedure
of <a class="ref" href="2_002e2.xhtml#g_t2_002e2_002e3">Sequences as Conventional Interfaces</a> to produce the stream of pairs of <em class="emph">all</em> integers
<em class="math">{(i, j)}</em> with <em class="math">{i \le j}</em> such that <em class="math">{i + j}</em> is prime.  If
<code class="code">int_pairs</code> is the sequence of all pairs of integers <em class="math">{(i, j)}</em> with
<em class="math">{i \le j}</em>, then our required stream is simply<a class="footnote" id="DOCF185" href="#FOOT185"><sup>185</sup></a>
</p>
<div class="example">
<pre class="example-preformatted">// Filter integer pairs (i, j) where i &lt;= j and i + j is prime
fn prime_sum_pairs() -&gt; impl Iterator&lt;Item = (u64, u64)&gt; {
    (1..).flat_map(|j| (1..=j).map(move |i| (i, j)))
        .filter(|&amp;(i, j)| is_prime(i + j))
}
// =&gt; (1,1), (1,2), (1,4), (2,3), (1,6), (2,5), (3,4), ...
</pre></div>

<p>Our problem, then, is to produce the stream <code class="code">int_pairs</code>.  More generally,
suppose we have two streams <em class="math">{S = (S_i)}</em> and <em class="math">{T = (T_j)}</em>,
and imagine the infinite rectangular array
\[ % :70:

\begin{array}{cccc}
	 (S_0, T_0)  &amp;  (S_0, T_1)  &amp;  (S_0, T_2)  &amp;  \dots  \\
	 (S_1, T_0)  &amp;  (S_1, T_1)  &amp;  (S_1, T_2)  &amp;  \dots  \\
	 (S_2, T_0)  &amp;  (S_2, T_1)  &amp;  (S_2, T_2)  &amp;  \dots  \\
	 \dots  &amp; &amp; &amp; 
\end{array}
\]
We wish to generate a stream that contains all the pairs in the array that lie
on or above the diagonal, i.e., the pairs
\[ % :71:

\begin{array}{cccc}
 (S_0, T_0)  	&amp;  (S_0, T_1)  	&amp;  (S_0, T_2)  	&amp;  \dots  \\
		&amp;  (S_1, T_1)  	&amp;  (S_1, T_2)  	&amp;  \dots  \\
		&amp; 		&amp;  (S_2, T_2)  	&amp;  \dots  \\
		&amp; 		&amp; 		&amp;  \dots 
\end{array}
\]
(If we take both <em class="math">S</em> and <em class="math">T</em> to be the stream of integers, then this will
be our desired stream <code class="code">int_pairs</code>.)
</p>
<p>Call the general stream of pairs <code class="code">(pairs S T)</code>, and consider it to be
composed of three parts: the pair <em class="math">{(S_0, T_0)}</em>, the rest of the pairs in
the first row, and the remaining pairs:<a class="footnote" id="DOCF186" href="#FOOT186"><sup>186</sup></a>
\[ % :72:

\begin{array}{c|ccc}
 (S_0, T_0)  	&amp;  (S_0, T_1)  	&amp;  (S_0, T_2)  	&amp;  \dots  \\
\hline
		&amp;  (S_1, T_1)  	&amp;  (S_1, T_2)  	&amp;  \dots  \\
		&amp; 		&amp;  (S_2, T_2)  	&amp;  \dots  \\
		&amp; 		&amp; 		&amp;  \dots  
\end{array}
\]
Observe that the third piece in this decomposition (pairs that are not in the
first row) is (recursively) the pairs formed from <code class="code">(stream-cdr S)</code> and
<code class="code">(stream-cdr T)</code>.  Also note that the second piece (the rest of the first
row) is
</p>
<div class="example">
<pre class="example-preformatted">// Rest of first row: pair s0 with each element of t[1..]
t.skip(1).map(move |x| (s0.clone(), x))
</pre></div>

<p>Thus we can form our stream of pairs as follows:
</p>
<div class="example">
<pre class="example-preformatted">// Generate pairs (s_i, t_j) where i &lt;= j
// Structure: first element + first row + recursive remainder
fn pairs&lt;S, T&gt;(s: S, t: T) -&gt; impl Iterator&lt;Item = (i64, i64)&gt;
where
    S: Iterator&lt;Item = i64&gt;,
    T: Iterator&lt;Item = i64&gt;,
{
    // First element: (s_0, t_0)
    // First row rest: (s_0, t_1), (s_0, t_2), ...
    // Recursive: pairs(s[1..], t[1..])
    // Combine first_row_rest and recursive with some_combiner
    todo!(&quot;Need interleave to handle infinite streams&quot;)
}
</pre></div>

<p>In order to complete the procedure, we must choose some way to combine the two
inner streams.  One idea is to use the stream analog of the <code class="code">append</code>
procedure from <a class="ref" href="2_002e2.xhtml#g_t2_002e2_002e1">Representing Sequences</a>:
</p>
<div class="example">
<pre class="example-preformatted">// Stream append - unsuitable for infinite s1!
fn stream_append&lt;I1, I2, T&gt;(s1: I1, s2: I2) -&gt; impl Iterator&lt;Item = T&gt;
where
    I1: Iterator&lt;Item = T&gt;,
    I2: Iterator&lt;Item = T&gt;,
{
    s1.chain(s2)  // Exhausts s1 before yielding s2
}
</pre></div>

<p>This is unsuitable for infinite streams, however, because it takes all the
elements from the first stream before incorporating the second stream.  In
particular, if we try to generate all pairs of positive integers using
</p>
<div class="example">
<pre class="example-preformatted">// pairs((1..), (1..)) would get stuck on first row forever
// with chain/append - need interleaving
</pre></div>

<p>our stream of results will first try to run through all pairs with the first
integer equal to 1, and hence will never produce pairs with any other value of
the first integer.
</p>
<p>To handle infinite streams, we need to devise an order of combination that
ensures that every element will eventually be reached if we let our program run
long enough.  An elegant way to accomplish this is with the following
<code class="code">interleave</code> procedure:<a class="footnote" id="DOCF187" href="#FOOT187"><sup>187</sup></a>
</p>
<div class="example">
<pre class="example-preformatted">// Interleave two streams: take alternating elements
fn interleave&lt;I1, I2, T&gt;(s1: I1, s2: I2) -&gt; impl Iterator&lt;Item = T&gt;
where
    I1: Iterator&lt;Item = T&gt;,
    I2: Iterator&lt;Item = T&gt;,
{
    let mut it1 = s1.peekable();
    let mut it2 = s2.peekable();
    let mut take_first = true;

    std::iter::from_fn(move || {
        if take_first {
            take_first = false;
            it1.next().or_else(|| it2.next())
        } else {
            take_first = true;
            it2.next().or_else(|| it1.next())
        }
    })
}
</pre></div>

<p>Since <code class="code">interleave</code> takes elements alternately from the two streams, every
element of the second stream will eventually find its way into the interleaved
stream, even if the first stream is infinite.
</p>
<p>We can thus generate the required stream of pairs as
</p>
<div class="example">
<pre class="example-preformatted">// Generate all pairs (i, j) where i &lt;= j
fn int_pairs() -&gt; impl Iterator&lt;Item = (u64, u64)&gt; {
    // Use diagonal enumeration to ensure all pairs are reached
    (1_u64..).flat_map(|sum| {
        (1..sum).map(move |i| (i, sum - i))
    })
    .filter(|&amp;(i, j)| i &lt;= j)
}
// Or with explicit interleaving of rows
</pre></div>

<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e66"></a>Exercise 3.66:</strong> Examine the stream <code class="code">(pairs
integers integers)</code>. Can you make any general comments about the order in which
the pairs are placed into the stream? For example, approximately how many pairs precede
the pair (1, 100)?  the pair (99, 100)? the pair (100, 100)? (If you can make
precise mathematical statements here, all the better. But feel free to give
more qualitative answers if you find yourself getting bogged down.)
</p></blockquote>

<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e67"></a>Exercise 3.67:</strong> Modify the <code class="code">pairs</code> procedure
so that <code class="code">(pairs integers integers)</code> will produce the stream of <em class="emph">all</em>
pairs of integers <em class="math">{(i, j)}</em> (without the condition <em class="math">{i \le j}</em>).  Hint:
You will need to mix in an additional stream.
</p></blockquote>

<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e68"></a>Exercise 3.68:</strong> Louis Reasoner thinks that
building a stream of pairs from three parts is unnecessarily complicated.
Instead of separating the pair <em class="math">{(S_0, T_0)}</em> from the rest of the pairs in
the first row, he proposes to work with the whole first row, as follows:
</p>
<div class="example">
<pre class="example-preformatted">// Louis's broken pairs - infinite recursion!
fn pairs&lt;I1, I2, T&gt;(s: I1, t: I2) -&gt; impl Iterator&lt;Item = (T, T)&gt;
where
    I1: Iterator&lt;Item = T&gt;,
    I2: Iterator&lt;Item = T&gt; + Clone,
{
    // BUG: pairs() is called before interleave() can consume
    // any elements from the first iterator, causing infinite
    // recursion during construction (not lazy enough)
    interleave(
        t.clone().map(|x| (s.next()?, x)),  // First row
        pairs(s.skip(1), t.skip(1)),         // Recursive call
    )
}
// This fails because Rust iterators are eager at construction
// time - we'd need true lazy evaluation (thunks) to make this
// pattern work. The correct approach uses explicit laziness.
</pre></div>

<p>Does this work?  Consider what happens if we evaluate <code class="code">(pairs integers
integers)</code> using Louis&#8217;s definition of <code class="code">pairs</code>.
</p></blockquote>

<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e69"></a>Exercise 3.69:</strong> Write a procedure <code class="code">triples</code>
that takes three infinite streams, <em class="math">S</em>, <em class="math">T</em>, and <em class="math">U</em>, and produces the
stream of triples <em class="math">{(S_i, T_j, U_k)}</em> such that <em class="math">{i \le j \le k}</em>.  
Use <code class="code">triples</code> to generate the stream of all Pythagorean
triples of positive integers, i.e., the triples <em class="math">{(i, j, k)}</em> such that
<em class="math">{i \le j}</em> and <em class="math">{i^2 + j^2 = k^2}</em>.
</p></blockquote>

<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e70"></a>Exercise 3.70:</strong> It would be nice to be able to
generate streams in which the pairs appear in some useful order, rather than in
the order that results from an <em class="emph">ad hoc</em> interleaving process.  We can use
a technique similar to the <code class="code">merge</code> procedure of <a class="ref" href="#Exercise-3_002e56">Exercise 3.56</a>, if we
define a way to say that one pair of integers is &#8220;less than&#8221; another.  One
way to do this is to define a &#8220;weighting function&#8221; <em class="math">{W(i, j)}</em> and
stipulate that <em class="math">{(i_1, j_1)}</em> is less than <em class="math">{(i_2, j_2)}</em> if
<em class="math">{W(i_1, j_1) &lt;} {W(i_2, j_2)}</em>.  Write a procedure
<code class="code">merge_weighted</code> that is like <code class="code">merge</code>, except that
<code class="code">merge_weighted</code> takes an additional argument <code class="code">weight</code>, which is a
procedure that computes the weight of a pair, and is used to determine the
order in which elements should appear in the resulting merged
stream.<a class="footnote" id="DOCF188" href="#FOOT188"><sup>188</sup></a>  Using this, generalize <code class="code">pairs</code> to a procedure
<code class="code">weighted_pairs</code> that takes two streams, together with a procedure that
computes a weighting function, and generates the stream of pairs, ordered
according to weight.  Use your procedure to generate
</p>
<ol class="enumerate" type="a" start="1">
<li> the stream of all pairs of positive integers <em class="math">{(i, j)}</em> with <em class="math">{i \le j}</em>
ordered according to the sum <em class="math">{i + j}</em>,

</li><li> the stream of all pairs of positive integers <em class="math">{(i, j)}</em> with <em class="math">{i \le j}</em>,
where neither <em class="math">i</em> nor <em class="math">j</em> is divisible by 2, 3, or 5, and the pairs are
ordered according to the sum <em class="math">{2i + 3j + 5ij}</em>.

</li></ol>
</blockquote>

<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e71"></a>Exercise 3.71:</strong> Numbers that can be expressed as
the sum of two cubes in more than one way are sometimes called
<a class="index-entry-id" id="index-Ramanujan-numbers"></a>
<em class="dfn">Ramanujan numbers</em>, in honor of the mathematician Srinivasa
Ramanujan.<a class="footnote" id="DOCF189" href="#FOOT189"><sup>189</sup></a> Ordered streams of pairs provide an elegant
solution to the problem of computing these numbers.  To find a number that can
be written as the sum of two cubes in two different ways, we need only generate
the stream of pairs of integers <em class="math">{(i, j)}</em> weighted according to the sum
<em class="math">{i^3 + j^3}</em> (see <a class="ref" href="#Exercise-3_002e70">Exercise 3.70</a>), then search the stream for two
consecutive pairs with the same weight.  Write a procedure to generate the
Ramanujan numbers.  The first such number is 1,729.  What are the next five?
</p></blockquote>

<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e72"></a>Exercise 3.72:</strong> In a similar way to <a class="ref" href="#Exercise-3_002e71">Exercise 3.71</a> 
generate a stream of all numbers that can be written as the sum of two
squares in three different ways (showing how they can be so written).
</p></blockquote>

<h4 class="subsubheading" id="Streams-as-signals"><span>Streams as signals<a class="copiable-link" href="#Streams-as-signals"> &#182;</a></span></h4>

<p>We began our discussion of streams by describing them as computational analogs
of the &#8220;signals&#8221; in signal-processing systems.  In fact, we can use streams
to model signal-processing systems in a very direct way, representing the
values of a signal at successive time intervals as consecutive elements of a
stream.  For instance, we can implement an <a class="index-entry-id" id="index-integrator"></a>
<em class="dfn">integrator</em> or
<a class="index-entry-id" id="index-summer"></a>
<em class="dfn">summer</em> that, for an input stream <em class="math">{x = (x_i)}</em>, an initial
value <em class="math">C</em>, and a small increment <em class="math">{dt}</em>, accumulates the sum
\[ % :73:
  S_i \,=\, C + {\sum_{j=1}^i x_j \, dt}  \]
and returns the stream of values <em class="math">{S = (S_i)}</em>.  The following
<code class="code">integral</code> procedure is reminiscent of the &#8220;implicit style&#8221; definition
of the stream of integers (<a class="ref" href="#g_t3_002e5_002e2">Infinite Streams</a>):
</p>
<div class="example">
<pre class="example-preformatted">fn integral(
    integrand: impl Iterator&lt;Item = f64&gt;,
    initial_value: f64,
    dt: f64,
) -&gt; impl Iterator&lt;Item = f64&gt; {
    // Use scan to accumulate the running sum
    std::iter::once(initial_value).chain(
        integrand.scan(initial_value, move |acc, x| {
            *acc += x * dt;
            Some(*acc)
        })
    )
}
</pre></div>

<p><a class="ref" href="#Figure-3_002e32">Figure 3.32</a> is a picture of a signal-processing system that corresponds
to the <code class="code">integral</code> procedure.  The input stream is scaled by <em class="math">{dt}</em> and
passed through an adder, whose output is passed back through the same adder.
The self-reference in the definition of <code class="code">int</code> is reflected in the figure
by the feedback loop that connects the output of the adder to one of the
inputs.
</p>
<div class="float">
<a class="anchor" id="Figure-3_002e32"></a><img class="image" src="fig/chap3/Fig3.32a.std.svg" alt="fig/chap3/Fig3.32a" />
<div class="caption"><p><strong class="strong">Figure 3.32:</strong> The <code class="code">integral</code> procedure viewed as a signal-processing system.</p></div></div>
<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e73"></a>Exercise 3.73:</strong> We can model electrical circuits
using streams to represent the values of currents or voltages at a sequence of
times.  For instance, suppose we have an <a class="index-entry-id" id="index-RC-circuit"></a>
<em class="dfn">RC circuit</em> consisting of a
resistor of resistance <em class="math">R</em> and a capacitor of capacitance <em class="math">C</em> in series.
The voltage response <em class="math">v</em> of the circuit to an injected current <em class="math">i</em> is
determined by the formula in <a class="ref" href="#Figure-3_002e33">Figure 3.33</a>, whose structure is shown by the
accompanying signal-flow diagram.
</p>
<div class="float">
<a class="anchor" id="Figure-3_002e33"></a><img class="image" src="fig/chap3/Fig3.33a.std.svg" alt="fig/chap3/Fig3.33a" />
<div class="caption"><p><strong class="strong">Figure 3.33:</strong> An RC circuit and the associated signal-flow diagram.</p></div></div>
<p>Write a procedure <code class="code">RC</code> that models this circuit.  <code class="code">RC</code> should take as
inputs the values of <em class="math">R</em>, <em class="math">C</em>, and <em class="math">{dt}</em> and should return a procedure
that takes as inputs a stream representing the current <em class="math">i</em> and an initial
value for the capacitor voltage <em class="math">v_0</em> and produces as output the stream of
voltages <em class="math">v</em>.  For example, you should be able to use <code class="code">RC</code> to model an
RC circuit with <em class="math">R</em> = 5 ohms, <em class="math">C</em> = 1 farad, and a 0.5-second time step by
evaluating <code class="code">let rc1 = rc(5.0, 1.0, 0.5);</code>.  This defines <code class="code">rc1</code> as a
procedure that takes a stream representing the time sequence of currents and an
initial capacitor voltage and produces the output stream of voltages.
</p></blockquote>

<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e74"></a>Exercise 3.74:</strong> Alyssa P. Hacker is designing a
system to process signals coming from physical sensors.  One important feature
she wishes to produce is a signal that describes the <a class="index-entry-id" id="index-zero-crossings"></a>
<em class="dfn">zero crossings</em>
of the input signal.  That is, the resulting signal should be <em class="math">{+1}</em> whenever the
input signal changes from negative to positive, <em class="math">{-1}</em> whenever the input signal
changes from positive to negative, and <em class="math">0</em> otherwise.  (Assume that the sign of a
<em class="math">0</em> input is positive.)  For example, a typical input signal with its associated
zero-crossing signal would be
</p>
<div class="example">
<pre class="example-preformatted">// Input signal and zero-crossing detection:
// ... 1.0  2.0  1.5  1.0  0.5 -0.1 -2.0 -3.0 -2.0 -0.5  0.2  3.0  4.0 ...
// ...   0    0    0    0    0   -1    0    0    0    0    1    0    0 ...
</pre></div>

<p>In Alyssa&#8217;s system, the signal from the sensor is represented as a stream
<code class="code">sense-data</code> and the stream <code class="code">zero-crossings</code> is the corresponding
stream of zero crossings.  Alyssa first writes a procedure
<code class="code">sign_change_detector</code> that takes two values as arguments and compares the
signs of the values to produce an appropriate <em class="math">0</em>, <em class="math">1</em>, or <em class="math">{-1}</em>.  She then
constructs her zero-crossing stream as follows:
</p>
<div class="example">
<pre class="example-preformatted">fn sign_change_detector(current: f64, last: f64) -&gt; i32 {
    match (last &lt; 0.0, current &gt;= 0.0) {
        (true, true) =&gt; 1,    // Negative to positive
        (false, false) if last &gt;= 0.0 &amp;&amp; current &lt; 0.0 =&gt; -1,
        _ =&gt; 0,
    }
}

fn make_zero_crossings(
    input: impl Iterator&lt;Item = f64&gt;,
) -&gt; impl Iterator&lt;Item = i32&gt; {
    input.scan(0.0_f64, |last, current| {
        let crossing = sign_change_detector(current, *last);
        *last = current;
        Some(crossing)
    })
}

let zero_crossings = make_zero_crossings(sense_data);
</pre></div>

<p>Alyssa&#8217;s boss, Eva Lu Ator, walks by and suggests that this program is
approximately equivalent to the following one, which uses the generalized
version of <code class="code">stream-map</code> from <a class="ref" href="#Exercise-3_002e50">Exercise 3.50</a>:
</p>
<div class="example">
<pre class="example-preformatted">// Using zip to pair current with previous values
let zero_crossings = sense_data.clone()
    .zip(std::iter::once(0.0).chain(sense_data))
    .map(|(current, last)| sign_change_detector(current, last));
// The missing expression: prepend 0.0 to create the &quot;last value&quot; stream
</pre></div>

<p>Complete the program by supplying the indicated <code class="code">⟨</code><var class="var">expression</var><code class="code">⟩</code>.
</p></blockquote>

<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e75"></a>Exercise 3.75:</strong> Unfortunately, Alyssa&#8217;s
zero-crossing detector in <a class="ref" href="#Exercise-3_002e74">Exercise 3.74</a> proves to be insufficient,
because the noisy signal from the sensor leads to spurious zero crossings.  Lem
E.  Tweakit, a hardware specialist, suggests that Alyssa smooth the signal to
filter out the noise before extracting the zero crossings.  Alyssa takes his
advice and decides to extract the zero crossings from the signal constructed by
averaging each value of the sense data with the previous value.  She explains
the problem to her assistant, Louis Reasoner, who attempts to implement the
idea, altering Alyssa&#8217;s program as follows:
</p>
<div class="example">
<pre class="example-preformatted">// Louis's buggy version - compares smoothed to previous raw value
fn make_zero_crossings_buggy(
    input: impl Iterator&lt;Item = f64&gt;,
) -&gt; impl Iterator&lt;Item = i32&gt; {
    input.scan(0.0_f64, |last_value, current| {
        let avpt = (current + *last_value) / 2.0;
        // BUG: should compare avpt to *previous* avpt, not last_value
        let crossing = sign_change_detector(avpt, *last_value);
        *last_value = avpt;  // This compounds the error
        Some(crossing)
    })
}
// Fix: track both last_value AND last_avpt separately
</pre></div>

<p>This does not correctly implement Alyssa&#8217;s plan.  Find the bug that Louis has
installed and fix it without changing the structure of the program.  (Hint: You
will need to increase the number of arguments to <code class="code">make_zero_crossings</code>.)
</p></blockquote>

<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e76"></a>Exercise 3.76:</strong> Eva Lu Ator has a criticism of
Louis&#8217;s approach in <a class="ref" href="#Exercise-3_002e75">Exercise 3.75</a>.  The program he wrote is not modular,
because it intermixes the operation of smoothing with the zero-crossing
extraction.  For example, the extractor should not have to be changed if Alyssa
finds a better way to condition her input signal.  Help Louis by writing a
procedure <code class="code">smooth</code> that takes a stream as input and produces a stream in
which each element is the average of two successive input stream elements.
Then use <code class="code">smooth</code> as a component to implement the zero-crossing detector
in a more modular style.
</p></blockquote>

<hr />
</div>
<div class="subsection-level-extent" id="g_t3_002e5_002e4">
<h4 class="subsection" id="Streams-and-Delayed-Evaluation"><span>3.5.4 Streams and Delayed Evaluation<a class="copiable-link" href="#Streams-and-Delayed-Evaluation"> &#182;</a></span></h4>

<p>The <code class="code">integral</code> procedure at the end of the preceding section shows how we
can use streams to model signal-processing systems that contain feedback loops.
The feedback loop for the adder shown in <a class="ref" href="#Figure-3_002e32">Figure 3.32</a> is modeled by the
fact that <code class="code">integral</code>&#8217;s internal stream <code class="code">int</code> is defined in terms of
itself:
</p>
<div class="example">
<pre class="example-preformatted">// Self-referential stream definition (implicit style)
// In Rust, we use scan for the accumulating pattern:
let int = std::iter::once(initial_value).chain(
    integrand.scan(initial_value, move |acc, x| {
        *acc += x * dt;
        Some(*acc)
    })
);
</pre></div>

<p>The interpreter&#8217;s ability to deal with such an implicit definition depends on
the <code class="code">delay</code> that is incorporated into <code class="code">cons-stream</code>.  Without this
<code class="code">delay</code>, the interpreter could not construct <code class="code">int</code> before evaluating
both arguments to <code class="code">cons-stream</code>, which would require that <code class="code">int</code>
already be defined.  In general, <code class="code">delay</code> is crucial for using streams to
model signal-processing systems that contain loops.  Without <code class="code">delay</code>, our
models would have to be formulated so that the inputs to any signal-processing
component would be fully evaluated before the output could be produced.  This
would outlaw loops.
</p>
<p>Unfortunately, stream models of systems with loops may require uses of
<code class="code">delay</code> beyond the &#8220;hidden&#8221; <code class="code">delay</code> supplied by <code class="code">cons-stream</code>.
For instance, <a class="ref" href="#Figure-3_002e34">Figure 3.34</a> shows a signal-processing system for solving
the differential equation <em class="math">{dy / dt = f(y)}</em> where <em class="math">f</em> is a given
function.  The figure shows a mapping component, which applies <em class="math">f</em> to its
input signal, linked in a feedback loop to an integrator in a manner very
similar to that of the analog computer circuits that are actually used to solve
such equations.
</p>
<div class="float">
<a class="anchor" id="Figure-3_002e34"></a><img class="image" src="fig/chap3/Fig3.34.std.svg" alt="fig/chap3/Fig3.34" />
<div class="caption"><p><strong class="strong">Figure 3.34:</strong> An &#8220;analog computer circuit&#8221; that solves the equation <em class="math">{dy / dt = f(y)}</em>.</p></div></div>
<p>Assuming we are given an initial value <em class="math">y_0</em> for <em class="math">y</em>, we could try to model
this system using the procedure
</p>
<div class="example">
<pre class="example-preformatted">// This naive approach won't work - dy isn't defined yet!
fn solve_broken&lt;F&gt;(f: F, y0: f64, dt: f64) -&gt; impl Iterator&lt;Item = f64&gt;
where F: Fn(f64) -&gt; f64
{
    let y = integral(dy, y0, dt);   // Error: dy not defined
    let dy = y.clone().map(f);      // Can't use y before it exists
    y
}
</pre></div>

<p>This procedure does not work, because in the first line of <code class="code">solve</code> the
call to <code class="code">integral</code> requires that the input <code class="code">dy</code> be defined, which
does not happen until the second line of <code class="code">solve</code>.
</p>
<p>On the other hand, the intent of our definition does make sense, because we
can, in principle, begin to generate the <code class="code">y</code> stream without knowing
<code class="code">dy</code>.  Indeed, <code class="code">integral</code> and many other stream operations have
properties similar to those of <code class="code">cons-stream</code>, in that we can generate part
of the answer given only partial information about the arguments.  For
<code class="code">integral</code>, the first element of the output stream is the specified
<code class="code">initial-value</code>.  Thus, we can generate the first element of the output
stream without evaluating the integrand <code class="code">dy</code>.  Once we know the first
element of <code class="code">y</code>, the <code class="code">stream-map</code> in the second line of <code class="code">solve</code>
can begin working to generate the first element of <code class="code">dy</code>, which will
produce the next element of <code class="code">y</code>, and so on.
</p>
<p>To take advantage of this idea, we will redefine <code class="code">integral</code> to expect the
integrand stream to be a <a class="index-entry-id" id="index-delayed-argument"></a>
<em class="dfn">delayed argument</em>.  <code class="code">Integral</code> will
<code class="code">force</code> the integrand to be evaluated only when it is required to generate
more than the first element of the output stream:
</p>
<div class="example">
<pre class="example-preformatted">// In Rust, we use successors with a lazy closure for the integrand
fn integral_delayed&lt;F&gt;(
    delayed_integrand: F,
    initial_value: f64,
    dt: f64,
) -&gt; impl Iterator&lt;Item = f64&gt;
where
    F: FnOnce() -&gt; Box&lt;dyn Iterator&lt;Item = f64&gt;&gt;,
{
    let integrand = std::cell::OnceCell::new();
    std::iter::successors(
        Some((initial_value, 0_usize)),
        move |(acc, idx)| {
            let stream = integrand.get_or_init(delayed_integrand);
            // Force evaluation only when needed
            stream.nth(*idx).map(|x| (*acc + x * dt, idx + 1))
        }
    ).map(|(val, _)| val)
}
</pre></div>

<p>Now we can implement our <code class="code">solve</code> procedure by delaying the evaluation of
<code class="code">dy</code> in the definition of <code class="code">y</code>:<a class="footnote" id="DOCF190" href="#FOOT190"><sup>190</sup></a>
</p>
<div class="example">
<pre class="example-preformatted">// Solving dy/dt = f(y) using successors for self-reference
fn solve&lt;F&gt;(f: F, y0: f64, dt: f64) -&gt; impl Iterator&lt;Item = f64&gt;
where
    F: Fn(f64) -&gt; f64,
{
    std::iter::successors(Some(y0), move |&amp;y| {
        // dy = f(y), then integrate: y_new = y + dy * dt
        Some(y + f(y) * dt)
    })
}
</pre></div>

<p>In general, every caller of <code class="code">integral</code> must now <code class="code">delay</code> the integrand
argument.  We can demonstrate that the <code class="code">solve</code> procedure works by
approximating <em class="math">{e \approx 2.718}</em> by computing the value at <em class="math">{y = 1}</em> of the
solution to the differential equation <em class="math">{dy / dt = y}</em> with initial
condition <em class="math">{y(0) = 1}</em>:
</p>
<div class="example">
<pre class="example-preformatted">// Approximate e by solving dy/dt = y with y(0) = 1
let result = solve(|y| y, 1.0, 0.001).nth(1000).unwrap();
// =&gt; 2.716924 (approximates e ~ 2.71828...)
</pre></div>

<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e77"></a>Exercise 3.77:</strong> The <code class="code">integral</code> procedure
used above was analogous to the &#8220;implicit&#8221; definition of the infinite stream
of integers in <a class="ref" href="#g_t3_002e5_002e2">Infinite Streams</a>.  Alternatively, we can give a definition of
<code class="code">integral</code> that is more like <code class="code">integers-starting-from</code> (also in
<a class="ref" href="#g_t3_002e5_002e2">Infinite Streams</a>):
</p>
<div class="example">
<pre class="example-preformatted">// Explicit recursive style integral
fn integral_explicit(
    mut integrand: impl Iterator&lt;Item = f64&gt;,
    initial_value: f64,
    dt: f64,
) -&gt; impl Iterator&lt;Item = f64&gt; {
    std::iter::once(initial_value).chain(
        std::iter::from_fn(move || {
            integrand.next().map(|x| initial_value + x * dt)
        })
    )
}
// Note: This version also needs delayed integrand for loops
</pre></div>

<p>When used in systems with loops, this procedure has the same problem as does
our original version of <code class="code">integral</code>.  Modify the procedure so that it
expects the <code class="code">integrand</code> as a delayed argument and hence can be used in the
<code class="code">solve</code> procedure shown above.
</p></blockquote>

<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e78"></a>Exercise 3.78:</strong> Consider the problem of designing
a signal-processing system to study the homogeneous second-order linear
differential equation
\[ % :74:
  \frac{d^2 y}{dt^2} - {a \frac{dy}{dt}} - {by} \,=\, {0.}  \]
The output stream, modeling <em class="math">y</em>, is generated by a network that contains a
loop. This is because the value of <em class="math">{d^2 y / dt^2}</em> depends upon the
values of <em class="math">y</em> and <em class="math">{dy / dt}</em> and both of these are determined by
integrating <em class="math">{d^2 y / dt^2}</em>.  The diagram we would like to encode is
shown in <a class="ref" href="#Figure-3_002e35">Figure 3.35</a>.  Write a procedure <code class="code">solve-2nd</code> that takes as
arguments the constants <em class="math">a</em>, <em class="math">b</em>, and <em class="math">{dt}</em> and the initial values
<em class="math">y_0</em> and <em class="math">{dy_0}</em> for <em class="math">y</em> and <em class="math">{dy / dt}</em> and generates the
stream of successive values of <em class="math">y</em>.
</p></blockquote>

<div class="float">
<a class="anchor" id="Figure-3_002e35"></a><img class="image" src="fig/chap3/Fig3.35b.std.svg" alt="fig/chap3/Fig3.35b" />
<div class="caption"><p><strong class="strong">Figure 3.35:</strong> Signal-flow diagram for the solution to a second-order linear differential equation.</p></div></div>
<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e79"></a>Exercise 3.79:</strong> Generalize the <code class="code">solve-2nd</code>
procedure of <a class="ref" href="#Exercise-3_002e78">Exercise 3.78</a> so that it can be used to solve general
second-order differential equations <em class="math">{d^2 y / dt^2} =
{f(dy / dt, y)}</em>.
</p></blockquote>

<div class="float">
<a class="anchor" id="Figure-3_002e36"></a><img class="image" src="fig/chap3/Fig3.36.std.svg" alt="fig/chap3/Fig3.36" />
<div class="caption"><p><strong class="strong">Figure 3.36:</strong> A series RLC circuit.</p></div></div>
<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e80"></a>Exercise 3.80:</strong> A <a class="index-entry-id" id="index-series-RLC-circuit"></a>
<em class="dfn">series RLC circuit</em>
consists of a resistor, a capacitor, and an inductor connected in series, as
shown in <a class="ref" href="#Figure-3_002e36">Figure 3.36</a>.  If <em class="math">R</em>, <em class="math">L</em>, and <em class="math">C</em> are the resistance,
inductance, and capacitance, then the relations between voltage <em class="math">{(v)}</em> and
current <em class="math">{(i)}</em> for the three components are described by the equations
\[ % :75:
\begin{eqnarray}
  v_R 	&amp;=&amp;   i_R R, \\
  v_L 	&amp;=&amp;   L\,{di_L \over dt}, \\
  i_C 	&amp;=&amp;   C\,{dv_C \over dt},
\end{eqnarray}
\]
and the circuit connections dictate the relations
\[ % :76:
\begin{eqnarray}
  i_R 	&amp;=&amp;   i_L = -i_C, \\
  v_C 	&amp;=&amp;   v_L + v_R.
\end{eqnarray}
\]
Combining these equations shows that the state of the circuit (summarized by
<em class="math">v_C</em>, the voltage across the capacitor, and <em class="math">i_L</em>, the current in
the inductor) is described by the pair of differential equations
\[ % :77:
\begin{eqnarray}
  {dv_C \over dt}   &amp;=&amp;   -{i_L \over C}\,, \\
  {di_L \over dt}   &amp;=&amp;    {1 \over L}\, v_C - {R \over L}\, i_L.
\end{eqnarray}
\]
The signal-flow diagram representing this system of differential equations is
shown in <a class="ref" href="#Figure-3_002e37">Figure 3.37</a>.
</p></blockquote>

<div class="float">
<a class="anchor" id="Figure-3_002e37"></a><img class="image" src="fig/chap3/Fig3.37.std.svg" alt="fig/chap3/Fig3.37" />
<div class="caption"><p><strong class="strong">Figure 3.37:</strong> A signal-flow diagram for the solution to a series RLC circuit.</p></div></div>
<blockquote class="quotation">
<p>Write a procedure <code class="code">RLC</code> that takes as arguments the parameters <em class="math">R</em>,
<em class="math">L</em>, and <em class="math">C</em> of the circuit and the time increment <em class="math">{dt}</em>.  In a manner
similar to that of the <code class="code">RC</code> procedure of <a class="ref" href="#Exercise-3_002e73">Exercise 3.73</a>, <code class="code">RLC</code>
should produce a procedure that takes the initial values of the state
variables, <em class="math">v_{C_0}</em> and <em class="math">i_{L_0}</em>, and produces a pair (using
<code class="code">cons</code>) of the streams of states <em class="math">v_C</em> and <em class="math">i_L</em>.  Using
<code class="code">RLC</code>, generate the pair of streams that models the behavior of a series
RLC circuit with <em class="math">R</em> = 1 ohm, <em class="math">C</em> = 0.2 farad, <em class="math">L</em> = 1 henry, <em class="math">{dt}</em>
= 0.1 second, and initial values <em class="math">i_{L_0}</em> = 0 amps and <em class="math">v_{C_0}</em> =
10 volts.
</p></blockquote>

<h4 class="subsubheading" id="Normal_002dorder-evaluation"><span>Normal-order evaluation<a class="copiable-link" href="#Normal_002dorder-evaluation"> &#182;</a></span></h4>

<p>The examples in this section illustrate how the explicit use of <code class="code">delay</code>
and <code class="code">force</code> provides great programming flexibility, but the same examples
also show how this can make our programs more complex.  Our new <code class="code">integral</code>
procedure, for instance, gives us the power to model systems with loops, but we
must now remember that <code class="code">integral</code> should be called with a delayed
integrand, and every procedure that uses <code class="code">integral</code> must be aware of this.
In effect, we have created two classes of procedures: ordinary procedures and
procedures that take delayed arguments.  In general, creating separate classes
of procedures forces us to create separate classes of higher-order procedures
as well.<a class="footnote" id="DOCF191" href="#FOOT191"><sup>191</sup></a>
</p>
<p>One way to avoid the need for two different classes of procedures is to make
all procedures take delayed arguments.  We could adopt a model of evaluation in
which all arguments to procedures are automatically delayed and arguments are
forced only when they are actually needed (for example, when they are required
by a primitive operation).  This would transform our language to use
normal-order evaluation, which we first described when we introduced the
substitution model for evaluation in <a class="ref" href="1_002e1.xhtml#g_t1_002e1_002e5">The Substitution Model for Procedure Application</a>.  Converting to
normal-order evaluation provides a uniform and elegant way to simplify the use
of delayed evaluation, and this would be a natural strategy to adopt if we were
concerned only with stream processing.  In <a class="ref" href="4_002e2.xhtml#g_t4_002e2">Variations on a Scheme &#8212; Lazy Evaluation</a>, after we have
studied the evaluator, we will see how to transform our language in just this
way.  Unfortunately, including delays in procedure calls wreaks havoc with our
ability to design programs that depend on the order of events, such as programs
that use assignment, mutate data, or perform input or output.  Even the single
<code class="code">delay</code> in <code class="code">cons-stream</code> can cause great confusion, as illustrated by
<a class="ref" href="#Exercise-3_002e51">Exercise 3.51</a> and <a class="ref" href="#Exercise-3_002e52">Exercise 3.52</a>.  As far as anyone knows,
mutability and delayed evaluation do not mix well in programming languages, and
devising ways to deal with both of these at once is an active area of research.
</p>
<hr />
</div>
<div class="subsection-level-extent" id="g_t3_002e5_002e4a">
<h4 class="subsection" id="Lock_002dFree-Data-Structures"><span>3.5.5 Lock-Free Data Structures<a class="copiable-link" href="#Lock_002dFree-Data-Structures"> &#182;</a></span></h4>
<a class="index-entry-id" id="index-lock_002dfree-data-structures"></a>
<a class="index-entry-id" id="index-atomics"></a>
<a class="index-entry-id" id="index-compare_002dand_002dswap"></a>
<a class="index-entry-id" id="index-memory-ordering"></a>

<p>In <a class="ref" href="3_002e4.xhtml#g_t3_002e4">Concurrency: Time Is of the Essence</a>, we explored concurrent programming with streams and saw how
shared mutable state can lead to race conditions. Our solution involved using
locks (<code class="code">Mutex</code> and <code class="code">RwLock</code>) to ensure exclusive access to shared
data. While locks provide straightforward correctness guarantees, they come
with significant costs: threads waiting for locks cannot make progress,
<em class="dfn">priority inversion</em> can occur, and lock contention can devastate
performance on multi-core systems.
</p>
<p>Lock-free data structures offer an alternative approach: they use atomic
operations and <em class="dfn">compare-and-swap</em> primitives to coordinate concurrent
access without ever blocking a thread. This section explores the foundations
of lock-free programming in Rust, revealing both its power and its subtlety.
</p>
<h4 class="subsubheading" id="The-Cost-of-Locks"><span>The Cost of Locks<a class="copiable-link" href="#The-Cost-of-Locks"> &#182;</a></span></h4>

<p>Consider a simple counter shared between threads. With locks, the
implementation is straightforward:
</p>
<div class="example">
<pre class="example-preformatted">use std::sync::{Arc, Mutex};
use std::thread;

let counter = Arc::new(Mutex::new(0_u64));
let mut handles = vec![];

for _ in 0..8 {
    let counter = Arc::clone(&amp;counter);
    let handle = thread::spawn(move || {
        for _ in 0..1_000_000 {
            *counter.lock().unwrap() += 1;
        }
    });
    handles.push(handle);
}

for handle in handles {
    handle.join().unwrap();
}

assert_eq!(*counter.lock().unwrap(), 8_000_000);
</pre></div>

<p>This works correctly, but each increment requires acquiring and releasing the
lock&#8212;a heavyweight operation involving system calls and cache coherence
protocols. Under contention, threads spend more time waiting than computing.
</p>
<h4 class="subsubheading" id="Atomic-Types_003a-The-Foundation"><span>Atomic Types: The Foundation<a class="copiable-link" href="#Atomic-Types_003a-The-Foundation"> &#182;</a></span></h4>

<p>Rust provides <em class="dfn">atomic types</em> that support operations guaranteed to execute
without interruption. These types live in <code class="code">std::sync::atomic</code> and include
<code class="code">AtomicBool</code>, <code class="code">AtomicUsize</code>, <code class="code">AtomicIsize</code>, and
<code class="code">AtomicPtr&lt;T&gt;</code>.
</p>
<a class="index-entry-id" id="index-AtomicUsize"></a>
<a class="index-entry-id" id="index-fetch_005fadd"></a>

<p>Here is our counter rewritten with atomics:
</p>
<div class="example">
<pre class="example-preformatted">use std::sync::Arc;
use std::sync::atomic::{AtomicU64, Ordering};
use std::thread;

let counter = Arc::new(AtomicU64::new(0));
let mut handles = vec![];

for _ in 0..8 {
    let counter = Arc::clone(&amp;counter);
    let handle = thread::spawn(move || {
        for _ in 0..1_000_000 {
            counter.fetch_add(1, Ordering::Relaxed);
        }
    });
    handles.push(handle);
}

for handle in handles {
    handle.join().unwrap();
}

assert_eq!(counter.load(Ordering::Relaxed), 8_000_000);
</pre></div>

<p>The <code class="code">fetch_add</code> method atomically reads the current value, adds 1, and
stores the result&#8212;all as a single, indivisible operation. No locks, no
blocking, no context switches. On modern hardware, this compiles to a single
<code class="code">LOCK ADD</code> instruction on x86 or <code class="code">LDADD</code> on ARM.
</p>
<h4 class="subsubheading" id="Memory-Ordering_003a-The-Subtlety"><span>Memory Ordering: The Subtlety<a class="copiable-link" href="#Memory-Ordering_003a-The-Subtlety"> &#182;</a></span></h4>

<a class="index-entry-id" id="index-memory-ordering-1"></a>
<a class="index-entry-id" id="index-Ordering_003a_003aRelaxed"></a>
<a class="index-entry-id" id="index-Ordering_003a_003aAcquire"></a>
<a class="index-entry-id" id="index-Ordering_003a_003aRelease"></a>
<a class="index-entry-id" id="index-Ordering_003a_003aSeqCst"></a>

<p>The <code class="code">Ordering</code> parameter in atomic operations controls how memory
operations are reordered by the compiler and CPU. Understanding memory ordering
is crucial for correctness in lock-free programming.
</p>
<p>Modern processors execute instructions out of order for performance. Two
threads might observe memory operations in different orders unless we impose
constraints. Rust provides four ordering guarantees:
</p>
<ul class="itemize mark-bullet">
<li><code class="code">Relaxed</code>: No ordering constraints. Only the atomicity of the
operation itself is guaranteed. Use for counters where order doesn&#8217;t matter.

</li><li><code class="code">Acquire</code>: When loading, all subsequent memory operations cannot be
reordered before this load. Used when acquiring a lock or reading a flag that
guards other data.

</li><li><code class="code">Release</code>: When storing, all previous memory operations cannot be
reordered after this store. Used when releasing a lock or publishing data.

</li><li><code class="code">SeqCst</code> (Sequentially Consistent): The strongest guarantee&#8212;all threads
observe all operations in the same order. Easiest to reason about but most
expensive.
</li></ul>

<p>The key insight is the <em class="dfn">happens-before</em> relationship: if operation A has
Release ordering and operation B has Acquire ordering, and B reads the value
written by A, then everything before A <em class="dfn">happens-before</em> everything after B.
</p>
<a class="index-entry-id" id="index-synchronizes_002dwith"></a>

<p>Here is a classic example using <code class="code">Acquire</code> and <code class="code">Release</code> to publish
data safely:
</p>
<div class="example">
<pre class="example-preformatted">use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::Arc;
use std::thread;

let data = Arc::new(AtomicUsize::new(0));
let ready = Arc::new(AtomicBool::new(false));

let data_clone = Arc::clone(&amp;data);
let ready_clone = Arc::clone(&amp;ready);

let writer = thread::spawn(move || {
    // Write data first
    data_clone.store(42, Ordering::Relaxed);
    // Signal that data is ready (Release ordering)
    ready_clone.store(true, Ordering::Release);
});

let reader = thread::spawn(move || {
    // Wait until data is ready (Acquire ordering)
    while !ready.load(Ordering::Acquire) {
        std::hint::spin_loop();
    }
    // Now safe to read data
    assert_eq!(data.load(Ordering::Relaxed), 42);
});

writer.join().unwrap();
reader.join().unwrap();
</pre></div>

<p>The <code class="code">Release</code> store in the writer and <code class="code">Acquire</code> load in the reader
create a <em class="dfn">synchronizes-with</em> relationship, ensuring the reader sees the
data written before the flag was set.
</p>
<h4 class="subsubheading" id="Compare_002dand_002dSwap_003a-The-Fundamental-Primitive"><span>Compare-and-Swap: The Fundamental Primitive<a class="copiable-link" href="#Compare_002dand_002dSwap_003a-The-Fundamental-Primitive"> &#182;</a></span></h4>

<a class="index-entry-id" id="index-compare_005fexchange"></a>
<a class="index-entry-id" id="index-CAS-operation"></a>

<p>The most powerful atomic operation is <em class="dfn">compare-and-swap</em> (CAS), exposed
in Rust as <code class="code">compare_exchange</code>. This operation atomically:
</p>
<ol class="enumerate">
<li> Reads the current value from memory
</li><li> Compares it to an expected value
</li><li> If equal, stores a new value and returns success
</li><li> If not equal, returns failure with the actual current value
</li></ol>

<p>CAS is the foundation of lock-free algorithms. Here is its signature:
</p>
<div class="example">
<pre class="example-preformatted">pub fn compare_exchange(
    &amp;self,
    current: T,
    new: T,
    success: Ordering,
    failure: Ordering,
) -&gt; Result&lt;T, T&gt;
</pre></div>

<p>The operation succeeds if the current value matches <code class="code">current</code>, updating
it to <code class="code">new</code>. Otherwise, it returns the actual value. Crucially, both the
read and conditional write happen atomically.
</p>
<p>Let&#8217;s implement a simple spinlock using CAS:
</p>
<div class="example">
<pre class="example-preformatted">use std::sync::atomic::{AtomicBool, Ordering};
use std::cell::UnsafeCell;

pub struct SpinLock&lt;T&gt; {
    locked: AtomicBool,
    data: UnsafeCell&lt;T&gt;,
}

unsafe impl&lt;T: Send&gt; Sync for SpinLock&lt;T&gt; {}

impl&lt;T&gt; SpinLock&lt;T&gt; {
    pub fn new(data: T) -&gt; Self {
        SpinLock {
            locked: AtomicBool::new(false),
            data: UnsafeCell::new(data),
        }
    }

    pub fn lock(&amp;self) -&gt; SpinLockGuard&lt;T&gt; {
        // Spin until we acquire the lock
        while self.locked.compare_exchange(
            false,                   // Expected: unlocked
            true,                    // New: locked
            Ordering::Acquire,       // Success: acquire semantics
            Ordering::Relaxed,       // Failure: retry with relaxed
        ).is_err() {
            // Hint to CPU that we're spinning
            std::hint::spin_loop();
        }
        SpinLockGuard { lock: self }
    }
}

pub struct SpinLockGuard&lt;'a, T&gt; {
    lock: &amp;'a SpinLock&lt;T&gt;,
}

impl&lt;'a, T&gt; std::ops::Deref for SpinLockGuard&lt;'a, T&gt; {
    type Target = T;
    fn deref(&amp;self) -&gt; &amp;T {
        unsafe { &amp;*self.lock.data.get() }
    }
}

impl&lt;'a, T&gt; Drop for SpinLockGuard&lt;'a, T&gt; {
    fn drop(&amp;mut self) {
        self.lock.locked.store(false, Ordering::Release);
    }
}
</pre></div>

<p>The CAS loop spins until it successfully changes <code class="code">locked</code> from
<code class="code">false</code> to <code class="code">true</code>. The <code class="code">Acquire</code> ordering ensures that any
subsequent access to <code class="code">data</code> happens after the lock is acquired.
</p>
<h4 class="subsubheading" id="A-Lock_002dFree-Stack"><span>A Lock-Free Stack<a class="copiable-link" href="#A-Lock_002dFree-Stack"> &#182;</a></span></h4>

<a class="index-entry-id" id="index-lock_002dfree-stack"></a>
<a class="index-entry-id" id="index-Treiber-stack"></a>

<p>Now let&#8217;s build a more sophisticated structure: a lock-free stack (also called
a <em class="dfn">Treiber stack</em>). The core idea is to represent the stack as a linked
list with an atomic pointer to the head node.
</p>
<div class="example">
<pre class="example-preformatted">use std::sync::atomic::{AtomicPtr, Ordering};
use std::ptr;

struct Node&lt;T&gt; {
    data: T,
    next: *mut Node&lt;T&gt;,
}

pub struct LockFreeStack&lt;T&gt; {
    head: AtomicPtr&lt;Node&lt;T&gt;&gt;,
}

impl&lt;T&gt; LockFreeStack&lt;T&gt; {
    pub fn new() -&gt; Self {
        LockFreeStack {
            head: AtomicPtr::new(ptr::null_mut()),
        }
    }

    pub fn push(&amp;self, data: T) {
        let new_node = Box::into_raw(Box::new(Node {
            data,
            next: ptr::null_mut(),
        }));

        loop {
            // Read current head
            let old_head = self.head.load(Ordering::Relaxed);

            // Link new node to current head
            unsafe { (*new_node).next = old_head; }

            // Try to install new node as head
            match self.head.compare_exchange(
                old_head,
                new_node,
                Ordering::Release,  // Success: publish the new node
                Ordering::Relaxed,  // Failure: retry
            ) {
                Ok(_) =&gt; return,  // Success!
                Err(_) =&gt; {
                    // Another thread modified head; retry
                    continue;
                }
            }
        }
    }

    pub fn pop(&amp;self) -&gt; Option&lt;T&gt; {
        loop {
            let old_head = self.head.load(Ordering::Acquire);

            if old_head.is_null() {
                return None;  // Stack is empty
            }

            // Read next pointer from head node
            let next = unsafe { (*old_head).next };

            // Try to install next as new head
            match self.head.compare_exchange(
                old_head,
                next,
                Ordering::Release,  // Success: publish new head
                Ordering::Acquire,  // Failure: retry with acquire
            ) {
                Ok(_) =&gt; {
                    // Successfully removed head
                    let result = unsafe {
                        Box::from_raw(old_head).data
                    };
                    return Some(result);
                }
                Err(_) =&gt; {
                    // Another thread modified head; retry
                    continue;
                }
            }
        }
    }
}
</pre></div>

<p>Both <code class="code">push</code> and <code class="code">pop</code> follow the same pattern: read the current
state, compute the new state, and use CAS to atomically update if nothing
changed. If another thread modified the head in the meantime, CAS fails and we
retry with the new value.
</p>
<p>This is <em class="dfn">optimistic concurrency</em>: we assume success and retry on conflict,
rather than pessimistically blocking with locks.
</p>
<h4 class="subsubheading" id="The-ABA-Problem"><span>The ABA Problem<a class="copiable-link" href="#The-ABA-Problem"> &#182;</a></span></h4>

<a class="index-entry-id" id="index-ABA-problem"></a>
<a class="index-entry-id" id="index-tagged-pointers"></a>

<p>Our stack has a subtle bug. Consider this scenario:
</p>
<ol class="enumerate">
<li> Thread 1 reads head pointer (pointing to node A)
</li><li> Thread 2 pops A, then pops B, then pushes A back
</li><li> Thread 1&#8217;s CAS succeeds because head points to A again
</li><li> But A&#8217;s <code class="code">next</code> pointer might now be corrupted!
</li></ol>

<p>This is the infamous <em class="dfn">ABA problem</em>: the value went from A to B and back to
A, but the CAS cannot detect that the pointer has been reused. The solution is
to tag pointers with a version counter:
</p>
<div class="example">
<pre class="example-preformatted">use std::sync::atomic::{AtomicU64, Ordering};

#[repr(C)]
struct TaggedPtr&lt;T&gt; {
    ptr: *mut T,
    tag: u64,
}

// Pack pointer and tag into a single 128-bit value
// Requires platform support for 128-bit CAS
pub struct VersionedStack&lt;T&gt; {
    head: AtomicU128,  // Conceptual; requires platform support
}
</pre></div>

<p>On x86-64, we can use the <code class="code">CMPXCHG16B</code> instruction to atomically swap 128
bits, encoding both pointer and version. Alternatively, we can steal bits from
the pointer itself (pointers are typically aligned, leaving low bits unused).
</p>
<p>In practice, <strong class="strong">most programmers should not write their own lock-free
structures</strong>. The subtleties are profound, and bugs can be nearly impossible to
reproduce or debug. Instead, use battle-tested libraries like <code class="code">crossbeam</code>.
</p>
<h4 class="subsubheading" id="Production-Lock_002dFree_003a-The-Crossbeam-Crate"><span>Production Lock-Free: The Crossbeam Crate<a class="copiable-link" href="#Production-Lock_002dFree_003a-The-Crossbeam-Crate"> &#182;</a></span></h4>

<a class="index-entry-id" id="index-crossbeam"></a>
<a class="index-entry-id" id="index-epoch_002dbased-reclamation"></a>

<p>The <code class="code">crossbeam</code> crate provides production-quality lock-free structures:
</p>
<ul class="itemize mark-bullet">
<li><code class="code">crossbeam::queue::SegQueue</code>: Lock-free multi-producer, multi-consumer
queue

</li><li><code class="code">crossbeam::deque::Worker/Stealer</code>: Work-stealing deque (used by
<code class="code">rayon</code>)

</li><li><code class="code">crossbeam::channel</code>: Lock-free channels with select support

</li><li><code class="code">crossbeam::epoch</code>: Safe memory reclamation for lock-free structures
</li></ul>

<a class="index-entry-id" id="index-memory-reclamation"></a>

<p>The hardest problem in lock-free programming is <em class="dfn">safe memory reclamation</em>:
when can we safely deallocate a node that other threads might still be
accessing? Crossbeam solves this with <em class="dfn">epoch-based reclamation</em>:
</p>
<div class="example">
<pre class="example-preformatted">use crossbeam::epoch::{self, Atomic, Owned};
use std::sync::atomic::Ordering;

pub struct CrossbeamStack&lt;T&gt; {
    head: Atomic&lt;Node&lt;T&gt;&gt;,
}

impl&lt;T&gt; CrossbeamStack&lt;T&gt; {
    pub fn push(&amp;self, data: T) {
        let new = Owned::new(Node {
            data,
            next: Atomic::null(),
        });

        let guard = epoch::pin();  // Enter epoch

        loop {
            let head = self.head.load(Ordering::Acquire, &amp;guard);
            new.next.store(head, Ordering::Relaxed);

            match self.head.compare_exchange(
                head,
                new,
                Ordering::Release,
                Ordering::Acquire,
                &amp;guard,
            ) {
                Ok(_) =&gt; return,
                Err(e) =&gt; new = e.new,
            }
        }
    }
}
</pre></div>

<p>The <code class="code">guard</code> ensures that any pointer we read remains valid until we drop
the guard. Crossbeam tracks epochs globally, deferring deallocation until all
guards from that epoch are dropped. This is analogous to read-copy-update (RCU)
in the Linux kernel.
</p>
<h4 class="subsubheading" id="When-to-Use-Lock_002dFree"><span>When to Use Lock-Free<a class="copiable-link" href="#When-to-Use-Lock_002dFree"> &#182;</a></span></h4>

<a class="index-entry-id" id="index-when-to-use-lock_002dfree"></a>

<p>Lock-free programming is not a silver bullet. Use lock-free structures when:
</p>
<ul class="itemize mark-bullet">
<li>Contention is high and lock overhead dominates
</li><li>You need guaranteed progress (no deadlocks or priority inversion)
</li><li>The structure is simple (queues, stacks, counters)
</li><li>You can use a proven library like <code class="code">crossbeam</code>
</li></ul>

<p>Use locks when:
</p>
<ul class="itemize mark-bullet">
<li>Contention is low
</li><li>The critical section is complex (multiple operations, conditionals)
</li><li>Correctness is paramount and lock-free subtleties are risky
</li><li>You need reader-writer patterns (<code class="code">RwLock</code> can be very efficient)
</li></ul>

<p><strong class="strong">Default to locks</strong>. Reach for lock-free only when profiling shows lock
contention is a bottleneck, and use existing libraries rather than rolling
your own.
</p>
<h4 class="subsubheading" id="Progress-Guarantees"><span>Progress Guarantees<a class="copiable-link" href="#Progress-Guarantees"> &#182;</a></span></h4>

<a class="index-entry-id" id="index-wait_002dfree"></a>
<a class="index-entry-id" id="index-lock_002dfree"></a>
<a class="index-entry-id" id="index-obstruction_002dfree"></a>

<p>Lock-free algorithms provide different <em class="dfn">progress guarantees</em>:
</p>
<ul class="itemize mark-bullet">
<li><strong class="strong">Wait-free</strong>: Every thread completes its operation in a bounded number
of steps, regardless of other threads&#8217; behavior. Strongest guarantee but
hardest to achieve.

</li><li><strong class="strong">Lock-free</strong>: At least one thread makes progress in a bounded number of
steps. Our stack is lock-free: even if some threads retry CAS loops, at least
one thread succeeds.

</li><li><strong class="strong">Obstruction-free</strong>: A thread makes progress if it runs in isolation.
Weakest guarantee: progress stalls only under contention.
</li></ul>

<p>Most practical lock-free structures are lock-free but not wait-free. Wait-free
algorithms typically require per-thread helping mechanisms, adding complexity.
</p>
<h4 class="subsubheading" id="Connection-to-Streams"><span>Connection to Streams<a class="copiable-link" href="#Connection-to-Streams"> &#182;</a></span></h4>

<p>Recall the stream-based concurrent systems from <a class="ref" href="#g_t3_002e5_002e3">Exploiting the Stream Paradigm</a>. Lock-free
structures shine in producer-consumer scenarios:
</p>
<div class="example">
<pre class="example-preformatted">use crossbeam::channel::unbounded;
use std::thread;

let (sender, receiver) = unbounded();

// Producer threads (lock-free push)
for i in 0..4 {
    let sender = sender.clone();
    thread::spawn(move || {
        for j in 0..1000 {
            sender.send((i, j)).unwrap();
        }
    });
}
drop(sender);  // Close channel when producers finish

// Consumer thread (lock-free pop)
let consumer = thread::spawn(move || {
    let mut count = 0;
    while let Ok(_) = receiver.recv() {
        count += 1;
    }
    count
});

assert_eq!(consumer.join().unwrap(), 4000);
</pre></div>

<p>The <code class="code">crossbeam::channel</code> uses lock-free algorithms internally, providing
high throughput under contention. This pattern&#8212;streams of data flowing
through lock-free queues&#8212;is the foundation of modern concurrent systems like
Tokio&#8217;s task scheduler and Rayon&#8217;s work-stealing.
</p>
<p>Lock-free programming embodies SICP&#8217;s theme of <em class="dfn">managing state through
time</em>. Instead of freezing time with locks, we embrace concurrent modification
and use atomic operations to mediate conflicts. The result is systems that
scale gracefully to many cores, sacrificing simplicity for performance when
the application demands it.
</p>
<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e81a"></a>Exercise 3.81a:</strong> Implement a lock-free
<code class="code">fetch_min</code> operation for <code class="code">AtomicUsize</code> that atomically updates the
value to the minimum of the current value and a given value. Your
implementation should use <code class="code">compare_exchange</code> in a loop and return the
previous value. Then write a test demonstrating that concurrent calls correctly
compute the global minimum.
</p>
<div class="example">
<pre class="example-preformatted">impl AtomicMinimum {
    pub fn fetch_min(&amp;self, val: usize) -&gt; usize {
        // Your implementation here
    }
}
</pre></div>
</blockquote>

<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e82a"></a>Exercise 3.82a:</strong> The ABA problem can be
demonstrated with careful thread scheduling. Write a test for the naive
<code class="code">LockFreeStack</code> (without version tagging) that exposes the ABA bug. You
will need to use synchronization primitives like <code class="code">std::sync::Barrier</code> to
orchestrate the precise timing of three threads: one that pops A, one that pops
B and pushes A, and one that attempts a CAS on the original A.
</p>
<p>Hint: Insert delays or print statements to observe the pointer reuse.
</p></blockquote>

<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e83a"></a>Exercise 3.83a:</strong> Design a lock-free queue using
two atomic pointers: <code class="code">head</code> (for dequeue) and <code class="code">tail</code> (for enqueue).
Compare the properties of your design to a lock-free stack:
</p>
<ul class="itemize mark-bullet">
<li>Can both <code class="code">enqueue</code> and <code class="code">dequeue</code> proceed concurrently without
interfering?

</li><li>What happens when the queue is empty? How do you handle the case where
<code class="code">head == tail</code>?

</li><li>Do you need a dummy node to distinguish empty from single-element queues?

</li><li>What memory ordering do you need for the CAS operations and why?
</li></ul>

<p>You need not implement the full queue, but provide a detailed design with
pseudocode explaining how you handle edge cases and ensure correctness.
</p></blockquote>

<hr />
</div>
<div class="subsection-level-extent" id="g_t3_002e5_002e5">
<h4 class="subsection" id="Modularity-of-Functional-Programs-and-Modularity-of-Objects"><span>3.5.6 Modularity of Functional Programs and Modularity of Objects<a class="copiable-link" href="#Modularity-of-Functional-Programs-and-Modularity-of-Objects"> &#182;</a></span></h4>

<p>As we saw in <a class="ref" href="3_002e1.xhtml#g_t3_002e1_002e2">The Benefits of Introducing Assignment</a>, one of the major benefits of introducing
assignment is that we can increase the modularity of our systems by
encapsulating, or &#8220;hiding,&#8221; parts of the state of a large system within local
variables.  Stream models can provide an equivalent modularity without the use
of assignment.  As an illustration, we can reimplement the Monte Carlo
estimation of <em class="math">\pi</em>, which we examined in <a class="ref" href="3_002e1.xhtml#g_t3_002e1_002e2">The Benefits of Introducing Assignment</a>, from a
stream-processing point of view.
</p>
<p>The key modularity issue was that we wished to hide the internal state of a
random-number generator from programs that used random numbers.  We began with
a procedure <code class="code">rand-update</code>, whose successive values furnished our supply of
random numbers, and used this to produce a random-number generator:
</p>
<div class="example">
<pre class="example-preformatted">// Stateful random number generator using Cell
fn make_rand(random_init: u64) -&gt; impl FnMut() -&gt; u64 {
    let x = std::cell::Cell::new(random_init);
    move || {
        let next = rand_update(x.get());
        x.set(next);
        next
    }
}
</pre></div>

<p>In the stream formulation there is no random-number generator <em class="emph">per se</em>,
just a stream of random numbers produced by successive calls to
<code class="code">rand-update</code>:
</p>
<div class="example">
<pre class="example-preformatted">// Stream of random numbers using successors
fn random_numbers(random_init: u64) -&gt; impl Iterator&lt;Item = u64&gt; {
    std::iter::successors(Some(random_init), |&amp;x| Some(rand_update(x)))
}
</pre></div>

<p>We use this to construct the stream of outcomes of the Ces&#224;ro experiment
performed on consecutive pairs in the <code class="code">random-numbers</code> stream:
</p>
<div class="example">
<pre class="example-preformatted">fn gcd(a: u64, b: u64) -&gt; u64 {
    if b == 0 { a } else { gcd(b, a % b) }
}

// Map over successive pairs from a stream
fn map_successive_pairs&lt;T, U, I, F&gt;(mut stream: I, f: F) -&gt; impl Iterator&lt;Item = U&gt;
where
    I: Iterator&lt;Item = T&gt;,
    F: Fn(T, T) -&gt; U,
{
    std::iter::from_fn(move || {
        let r1 = stream.next()?;
        let r2 = stream.next()?;
        Some(f(r1, r2))
    })
}

let cesaro_stream = map_successive_pairs(
    random_numbers(random_init),
    |r1, r2| gcd(r1, r2) == 1
);
</pre></div>

<p>The <code class="code">cesaro-stream</code> is now fed to a <code class="code">monte-carlo</code> procedure, which
produces a stream of estimates of probabilities.  The results are then
converted into a stream of estimates of <em class="math">\pi</em>.  This version of the program
doesn&#8217;t need a parameter telling how many trials to perform.  Better estimates
of <em class="math">\pi</em> (from performing more experiments) are obtained by looking farther
into the <code class="code">pi</code> stream:
</p>
<div class="example">
<pre class="example-preformatted">// Monte Carlo as a running probability stream
fn monte_carlo(
    experiment_stream: impl Iterator&lt;Item = bool&gt;,
) -&gt; impl Iterator&lt;Item = f64&gt; {
    experiment_stream.scan((0_u64, 0_u64), |(passed, failed), result| {
        if result {
            *passed += 1;
        } else {
            *failed += 1;
        }
        Some(*passed as f64 / (*passed + *failed) as f64)
    })
}

// Stream of pi estimates
let pi_stream = monte_carlo(cesaro_stream)
    .map(|p| (6.0 / p).sqrt());
</pre></div>

<p>There is considerable modularity in this approach, because we still can
formulate a general <code class="code">monte-carlo</code> procedure that can deal with arbitrary
experiments.  Yet there is no assignment or local state.
</p>
<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e81"></a>Exercise 3.81:</strong> <a class="ref" href="3_002e1.xhtml#Exercise-3_002e6">Exercise 3.6</a> discussed
generalizing the random-number generator to allow one to reset the
random-number sequence so as to produce repeatable sequences of &#8220;random&#8221;
numbers.  Produce a stream formulation of this same generator that operates on
an input stream of requests to <code class="code">generate</code> a new random number or to
<code class="code">reset</code> the sequence to a specified value and that produces the desired
stream of random numbers.  Don&#8217;t use assignment in your solution.
</p></blockquote>

<blockquote class="quotation">
<p><strong class="strong"><a class="anchor" id="Exercise-3_002e82"></a>Exercise 3.82:</strong> Redo <a class="ref" href="3_002e1.xhtml#Exercise-3_002e5">Exercise 3.5</a> on Monte
Carlo integration in terms of streams.  The stream version of
<code class="code">estimate-integral</code> will not have an argument telling how many trials to
perform.  Instead, it will produce a stream of estimates based on successively
more trials.
</p></blockquote>

<h4 class="subsubheading" id="A-functional_002dprogramming-view-of-time"><span>A functional-programming view of time<a class="copiable-link" href="#A-functional_002dprogramming-view-of-time"> &#182;</a></span></h4>

<p>Let us now return to the issues of objects and state that were raised at the
beginning of this chapter and examine them in a new light.  We introduced
assignment and mutable objects to provide a mechanism for modular construction
of programs that model systems with state.  We constructed computational
objects with local state variables and used assignment to modify these
variables.  We modeled the temporal behavior of the objects in the world by the
temporal behavior of the corresponding computational objects.
</p>
<p>Now we have seen that streams provide an alternative way to model objects with
local state.  We can model a changing quantity, such as the local state of some
object, using a stream that represents the time history of successive states.
In essence, we represent time explicitly, using streams, so that we decouple
time in our simulated world from the sequence of events that take place during
evaluation.  Indeed, because of the presence of <code class="code">delay</code> there may be
little relation between simulated time in the model and the order of events
during the evaluation.
</p>
<p>In order to contrast these two approaches to modeling, let us reconsider the
implementation of a &#8220;withdrawal processor&#8221; that monitors the balance in a
bank account.  In <a class="ref" href="3_002e1.xhtml#g_t3_002e1_002e3">The Costs of Introducing Assignment</a> we implemented a simplified version of
such a processor:
</p>
<div class="example">
<pre class="example-preformatted">// Stateful withdrawal using Cell for interior mutability
fn make_simplified_withdraw(initial_balance: i64) -&gt; impl FnMut(i64) -&gt; i64 {
    let balance = std::cell::Cell::new(initial_balance);
    move |amount| {
        balance.set(balance.get() - amount);
        balance.get()
    }
}
</pre></div>

<p>Calls to <code class="code">make-simplified-withdraw</code> produce computational objects, each
with a local state variable <code class="code">balance</code> that is decremented by successive
calls to the object.  The object takes an <code class="code">amount</code> as an argument and
returns the new balance.  We can imagine the user of a bank account typing a
sequence of inputs to such an object and observing the sequence of returned
values shown on a display screen.
</p>
<p>Alternatively, we can model a withdrawal processor as a procedure that takes as
input a balance and a stream of amounts to withdraw and produces the stream of
successive balances in the account:
</p>
<div class="example">
<pre class="example-preformatted">// Functional stream-based withdrawal - no mutation!
fn stream_withdraw(
    initial_balance: i64,
    amount_stream: impl Iterator&lt;Item = i64&gt;,
) -&gt; impl Iterator&lt;Item = i64&gt; {
    std::iter::once(initial_balance).chain(
        amount_stream.scan(initial_balance, |balance, amount| {
            *balance -= amount;
            Some(*balance)
        })
    )
}
// Each balance is fully determined by inputs - pure function!
</pre></div>

<p><code class="code">Stream-withdraw</code> implements a well-defined mathematical function whose
output is fully determined by its input.  Suppose, however, that the input
<code class="code">amount-stream</code> is the stream of successive values typed by the user and
that the resulting stream of balances is displayed.  Then, from the perspective
of the user who is typing values and watching results, the stream process has
the same behavior as the object created by <code class="code">make-simplified-withdraw</code>.
However, with the stream version, there is no assignment, no local state
variable, and consequently none of the theoretical difficulties that we
encountered in <a class="ref" href="3_002e1.xhtml#g_t3_002e1_002e3">The Costs of Introducing Assignment</a>.  Yet the system has state!
</p>
<p>This is really remarkable.  Even though <code class="code">stream-withdraw</code> implements a
well-defined mathematical function whose behavior does not change, the user&#8217;s
perception here is one of interacting with a system that has a changing state.
One way to resolve this paradox is to realize that it is the user&#8217;s temporal
existence that imposes state on the system.  If the user could step back from
the interaction and think in terms of streams of balances rather than
individual transactions, the system would appear stateless.<a class="footnote" id="DOCF192" href="#FOOT192"><sup>192</sup></a>
</p>
<p>From the point of view of one part of a complex process, the other parts appear
to change with time.  They have hidden time-varying local state.  If we wish to
write programs that model this kind of natural decomposition in our world (as
we see it from our viewpoint as a part of that world) with structures in our
computer, we make computational objects that are not functional&#8212;they must
change with time.  We model state with local state variables, and we model the
changes of state with assignments to those variables.  By doing this we make
the time of execution of a computation model time in the world that we are part
of, and thus we get &#8220;objects&#8221; in our computer.
</p>
<p>Modeling with objects is powerful and intuitive, largely because this matches
the perception of interacting with a world of which we are part.  However, as
we&#8217;ve seen repeatedly throughout this chapter, these models raise thorny
problems of constraining the order of events and of synchronizing multiple
processes.  The possibility of avoiding these problems has stimulated the
development of <a class="index-entry-id" id="index-functional-programming-languages"></a>
<em class="dfn">functional programming languages</em>, which do not include
any provision for assignment or mutable data.  In such a language, all
procedures implement well-defined mathematical functions of their arguments,
whose behavior does not change.  The functional approach is extremely
attractive for dealing with concurrent systems.<a class="footnote" id="DOCF193" href="#FOOT193"><sup>193</sup></a>
</p>
<p>On the other hand, if we look closely, we can see time-related problems
creeping into functional models as well.  One particularly troublesome area
arises when we wish to design interactive systems, especially ones that model
interactions between independent entities.  For instance, consider once more
the implementation of a banking system that permits joint bank accounts.  In a
conventional system using assignment and objects, we would model the fact that
Peter and Paul share an account by having both Peter and Paul send their
transaction requests to the same bank-account object, as we saw in 
<a class="ref" href="3_002e1.xhtml#g_t3_002e1_002e3">The Costs of Introducing Assignment</a>.  From the stream point of view, where there are no &#8220;objects&#8221;
<em class="emph">per se</em>, we have already indicated that a bank account can be modeled as
a process that operates on a stream of transaction requests to produce a stream
of responses.  Accordingly, we could model the fact that Peter and Paul have a
joint bank account by merging Peter&#8217;s stream of transaction requests with
Paul&#8217;s stream of requests and feeding the result to the bank-account stream
process, as shown in <a class="ref" href="#Figure-3_002e38">Figure 3.38</a>.
</p>
<div class="float">
<a class="anchor" id="Figure-3_002e38"></a><img class="image" src="fig/chap3/Fig3.38a.std.svg" alt="fig/chap3/Fig3.38a" />
<div class="caption"><p><strong class="strong">Figure 3.38:</strong> A joint bank account, modeled by merging two streams of transaction requests.</p></div></div>
<p>The trouble with this formulation is in the notion of <a class="index-entry-id" id="index-merge"></a>
<em class="dfn">merge</em>.  It will
not do to merge the two streams by simply taking alternately one request from
Peter and one request from Paul. Suppose Paul accesses the account only very
rarely.  We could hardly force Peter to wait for Paul to access the account
before he could issue a second transaction.  However such a merge is
implemented, it must interleave the two transaction streams in some way that is
constrained by &#8220;real time&#8221; as perceived by Peter and Paul, in the sense that,
if Peter and Paul meet, they can agree that certain transactions were processed
before the meeting, and other transactions were processed after the
meeting.<a class="footnote" id="DOCF194" href="#FOOT194"><sup>194</sup></a> This
is precisely the same constraint that we had to deal with in 
<a class="ref" href="3_002e4.xhtml#g_t3_002e4_002e1">The Nature of Time in Concurrent Systems</a>, where we found the need to introduce explicit synchronization to
ensure a &#8220;correct&#8221; order of events in concurrent processing of objects with
state.  Thus, in an attempt to support the functional style, the need to merge
inputs from different agents reintroduces the same problems that the functional
style was meant to eliminate.
</p>
<p>We began this chapter with the goal of building computational models whose
structure matches our perception of the real world we are trying to model.  We
can model the world as a collection of separate, time-bound, interacting
objects with state, or we can model the world as a single, timeless, stateless
unity.  Each view has powerful advantages, but neither view alone is completely
satisfactory.  A grand unification has yet to emerge.<a class="footnote" id="DOCF195" href="#FOOT195"><sup>195</sup></a>
</p>
</div>
</div>
<div class="footnotes-segment">
<hr />
<h4 class="footnotes-heading">Footnotes</h4>

<h5 class="footnote-body-heading"><a id="FOOT171" href="#DOCF171">(171)</a></h5>
<p>Physicists sometimes
adopt this view by introducing the &#8220;world lines&#8221; of particles as a device for
reasoning about motion.  We&#8217;ve also already mentioned (<a class="ref" href="2_002e2.xhtml#g_t2_002e2_002e3">Sequences as Conventional Interfaces</a>)
that this is the natural way to think about signal-processing systems.  We will
explore applications of streams to signal processing in <a class="ref" href="#g_t3_002e5_002e3">Exploiting the Stream Paradigm</a>.</p>
<h5 class="footnote-body-heading"><a id="FOOT172" href="#DOCF172">(172)</a></h5>
<p>Assume that we have a predicate <code class="code">is_prime</code> (e.g.,
as in <a class="ref" href="1_002e2.xhtml#g_t1_002e2_002e6">Example: Testing for Primality</a>) that tests for primality.</p>
<h5 class="footnote-body-heading"><a id="FOOT173" href="#DOCF173">(173)</a></h5>
<p>In the <abbr class="abbr">MIT</abbr>
implementation, <code class="code">the-empty-stream</code> is the same as the empty list
<code class="code">'()</code>, and <code class="code">stream-null?</code> is the same as <code class="code">null?</code>.</p>
<h5 class="footnote-body-heading"><a id="FOOT174" href="#DOCF174">(174)</a></h5>
<p>This should bother
you.  The fact that we are defining such similar procedures for streams and
lists indicates that we are missing some underlying abstraction.
Unfortunately, in order to exploit this abstraction, we will need to exert
finer control over the process of evaluation than we can at present.  We will
discuss this point further at the end of <a class="ref" href="#g_t3_002e5_002e4">Streams and Delayed Evaluation</a>.  In 
<a class="ref" href="4_002e2.xhtml#g_t4_002e2">Variations on a Scheme &#8212; Lazy Evaluation</a>, we&#8217;ll develop a framework that unifies lists and streams.</p>
<h5 class="footnote-body-heading"><a id="FOOT175" href="#DOCF175">(175)</a></h5>
<p>Although <code class="code">head</code> and
<code class="code">tail</code> can be defined as procedures, <code class="code">cons-stream</code> must be a
special form.  If <code class="code">cons-stream</code> were a procedure, then, according to our
model of evaluation, evaluating <code class="code">(cons-stream ⟨<var class="var">a</var>⟩ ⟨<var class="var">b</var>⟩)</code> would
automatically cause <code class="code">⟨</code><var class="var">b</var><code class="code">⟩</code> to be evaluated, which is precisely what we do
not want to happen.  For the same reason, <code class="code">delay</code> must be a special form,
though <code class="code">force</code> can be an ordinary procedure.</p>
<h5 class="footnote-body-heading"><a id="FOOT176" href="#DOCF176">(176)</a></h5>
<p>The numbers shown here do not really appear in
the delayed expression.  What actually appears is the original expression, in
an environment in which the variables are bound to the appropriate numbers.
For example, <code class="code">(+ low 1)</code> with <code class="code">low</code> bound to 10,000 actually appears
where <code class="code">10001</code> is shown.</p>
<h5 class="footnote-body-heading"><a id="FOOT177" href="#DOCF177">(177)</a></h5>
<p>There are many possible
implementations of streams other than the one described in this section.
Delayed evaluation, which is the key to making streams practical, was inherent
in Algol 60&#8217;s <a class="index-entry-id" id="index-call_002dby_002dname"></a>
<em class="dfn">call-by-name</em> parameter-passing method.  The use of this
mechanism to implement streams was first described by <a class="ref" href="References.xhtml#Landin-_00281965_0029">Landin (1965)</a>.  Delayed
evaluation for streams was introduced into Lisp by <a class="ref" href="References.xhtml#Friedman-and-Wise-_00281976_0029">Friedman and Wise (1976)</a>. In
their implementation, <code class="code">cons</code> always delays evaluating its arguments, so
that lists automatically behave as streams.  The memoizing optimization is also
known as <a class="index-entry-id" id="index-call_002dby_002dneed"></a>
<em class="dfn">call-by-need</em>.  The Algol community would refer to our
original delayed objects as <a class="index-entry-id" id="index-call_002dby_002dname-thunks"></a>
<em class="dfn">call-by-name thunks</em> and to the optimized
versions as <a class="index-entry-id" id="index-call_002dby_002dneed-thunks"></a>
<em class="dfn">call-by-need thunks</em>.</p>
<h5 class="footnote-body-heading"><a id="FOOT178" href="#DOCF178">(178)</a></h5>
<p>Exercises such as <a class="ref" href="#Exercise-3_002e51">Exercise 3.51</a> and
<a class="ref" href="#Exercise-3_002e52">Exercise 3.52</a> are valuable for testing our understanding of how
<code class="code">delay</code> works.  On the other hand, intermixing delayed evaluation with
printing&#8212;and, even worse, with assignment&#8212;is extremely confusing, and
instructors of courses on computer languages have traditionally tormented their
students with examination questions such as the ones in this section.  Needless
to say, writing programs that depend on such subtleties is odious programming
style.  Part of the power of stream processing is that it lets us ignore the
order in which events actually happen in our programs.  Unfortunately, this is
precisely what we cannot afford to do in the presence of assignment, which
forces us to be concerned with time and change.</p>
<h5 class="footnote-body-heading"><a id="FOOT179" href="#DOCF179">(179)</a></h5>
<p>Eratosthenes, a third-century <abbr class="abbr">B.C.</abbr>
Alexandrian Greek philosopher, is famous for giving the first accurate estimate
of the circumference of the Earth, which he computed by observing shadows cast
at noon on the day of the summer solstice.  Eratosthenes&#8217;s sieve method,
although ancient, has formed the basis for special-purpose hardware &#8220;sieves&#8221;
that, until recently, were the most powerful tools in existence for locating
large primes.  Since the 70s, however, these methods have been superseded by
outgrowths of the probabilistic techniques discussed in <a class="ref" href="1_002e2.xhtml#g_t1_002e2_002e6">Example: Testing for Primality</a>.</p>
<h5 class="footnote-body-heading"><a id="FOOT180" href="#DOCF180">(180)</a></h5>
<p>We have named these figures after Peter Henderson, who was the
first person to show us diagrams of this sort as a way of thinking about stream
processing.  Each solid line represents a stream of values being transmitted.
The dashed line from the <code class="code">car</code> to the <code class="code">cons</code> and the <code class="code">filter</code>
indicates that this is a single value rather than a stream.</p>
<h5 class="footnote-body-heading"><a id="FOOT181" href="#DOCF181">(181)</a></h5>
<p>This uses the generalized version of <code class="code">stream-map</code> from
<a class="ref" href="#Exercise-3_002e50">Exercise 3.50</a>.</p>
<h5 class="footnote-body-heading"><a id="FOOT182" href="#DOCF182">(182)</a></h5>
<p>This last point is very subtle and relies on
the fact that <em class="math">{p_{n+1} \le p_n^2}.</em>  (Here, <em class="math">p_k</em> denotes the
<em class="math">k^{\text{th}}</em> prime.)  Estimates such as these are very difficult to establish.  The
ancient proof by Euclid that there are an infinite number of primes shows that
<em class="math">p_{n+1} \le {p_1 p_2 \cdots p_n + 1}</em>, and no substantially
better result was proved until 1851, when the Russian mathematician
P. L. Chebyshev established that <em class="math">p_{n+1} \le 2p_n</em> for all <em class="math">n</em>.
This result, originally conjectured in 1845, is known as <a class="index-entry-id" id="index-Bertrand_0027s-hypothesis"></a>
<em class="dfn">Bertrand&#8217;s hypothesis</em>.  
A proof can be found in section 22.3 of <a class="ref" href="References.xhtml#Hardy-and-Wright-1960">Hardy and Wright 1960</a>.</p>
<h5 class="footnote-body-heading"><a id="FOOT183" href="#DOCF183">(183)</a></h5>
<p>This exercise shows how call-by-need is closely related
to ordinary memoization as described in <a class="ref" href="3_002e3.xhtml#Exercise-3_002e27">Exercise 3.27</a>.  In that exercise,
we used assignment to explicitly construct a local table.  Our call-by-need
stream optimization effectively constructs such a table automatically, storing
values in the previously forced parts of the stream.</p>
<h5 class="footnote-body-heading"><a id="FOOT184" href="#DOCF184">(184)</a></h5>
<p>We can&#8217;t use <code class="code">let</code>
to bind the local variable <code class="code">guesses</code>, because the value of <code class="code">guesses</code>
depends on <code class="code">guesses</code> itself.  <a class="ref" href="#Exercise-3_002e63">Exercise 3.63</a> addresses why we want a
local variable here.</p>
<h5 class="footnote-body-heading"><a id="FOOT185" href="#DOCF185">(185)</a></h5>
<p>As in 
<a class="ref" href="2_002e2.xhtml#g_t2_002e2_002e3">Sequences as Conventional Interfaces</a>, we represent a pair of integers as a list rather than a Lisp
pair.</p>
<h5 class="footnote-body-heading"><a id="FOOT186" href="#DOCF186">(186)</a></h5>
<p>See <a class="ref" href="#Exercise-3_002e68">Exercise 3.68</a> for
some insight into why we chose this decomposition.</p>
<h5 class="footnote-body-heading"><a id="FOOT187" href="#DOCF187">(187)</a></h5>
<p>The precise statement of the required
property on the order of combination is as follows: There should be a function
<em class="math">f</em> of two arguments such that the pair corresponding to element <em class="math">i</em> of the
first stream and element <em class="math">j</em> of the second stream will appear as element
number <em class="math">{f(i, j)}</em> of the output stream.  The trick of using
<code class="code">interleave</code> to accomplish this was shown to us by David Turner, who
employed it in the language KRC (<a class="ref" href="References.xhtml#Turner-1981">Turner 1981</a>).</p>
<h5 class="footnote-body-heading"><a id="FOOT188" href="#DOCF188">(188)</a></h5>
<p>We will require that the weighting function be such that the
weight of a pair increases as we move out along a row or down along a column of
the array of pairs.</p>
<h5 class="footnote-body-heading"><a id="FOOT189" href="#DOCF189">(189)</a></h5>
<p>To quote from G. H. Hardy&#8217;s obituary of Ramanujan (<a class="ref" href="References.xhtml#Hardy-1921">Hardy 1921</a>): 
&#8220;It was Mr. Littlewood (I believe) who remarked that &#8216;every positive
integer was one of his friends.&#8217;  I remember once going to see him when he was
lying ill at Putney.  I had ridden in taxi-cab No. 1729, and remarked that the
number seemed to me a rather dull one, and that I hoped it was not an
unfavorable omen.  &#8216;No,&#8217; he replied, &#8216;it is a very interesting number; it is
the smallest number expressible as the sum of two cubes in two different ways.&#8217;
&#8221; The trick of using weighted pairs to generate the Ramanujan numbers was
shown to us by Charles Leiserson.</p>
<h5 class="footnote-body-heading"><a id="FOOT190" href="#DOCF190">(190)</a></h5>
<p>This procedure is not
guaranteed to work in all Scheme implementations, although for any
implementation there is a simple variation that will work.  The problem has to
do with subtle differences in the ways that Scheme implementations handle
internal definitions.  (See <a class="ref" href="4_002e1.xhtml#g_t4_002e1_002e6">Internal Definitions</a>.)</p>
<h5 class="footnote-body-heading"><a id="FOOT191" href="#DOCF191">(191)</a></h5>
<p>This is a small reflection, in Lisp, of the difficulties that
conventional strongly typed languages such as Pascal have in coping with
higher-order procedures.  In such languages, the programmer must specify the
data types of the arguments and the result of each procedure: number, logical
value, sequence, and so on.  Consequently, we could not express an abstraction
such as &#8220;map a given procedure <code class="code">proc</code> over all the elements in a
sequence&#8221; by a single higher-order procedure such as <code class="code">stream-map</code>.
Rather, we would need a different mapping procedure for each different
combination of argument and result data types that might be specified for a
<code class="code">proc</code>.  Maintaining a practical notion of &#8220;data type&#8221; in the presence
of higher-order procedures raises many difficult issues.  One way of dealing
with this problem is illustrated by the language ML (<a class="ref" href="References.xhtml#Gordon-et-al_002e-1979">Gordon et al. 1979</a>), 
whose &#8220;polymorphic data types&#8221; include templates for
higher-order transformations between data types.  Moreover, data types for most
procedures in ML are never explicitly declared by the programmer.  Instead, ML
includes a <a class="index-entry-id" id="index-type_002dinferencing"></a>
<em class="dfn">type-inferencing</em> mechanism that uses information in the
environment to deduce the data types for newly defined procedures.</p>
<h5 class="footnote-body-heading"><a id="FOOT192" href="#DOCF192">(192)</a></h5>
<p>Similarly
in physics, when we observe a moving particle, we say that the position (state)
of the particle is changing.  However, from the perspective of the particle&#8217;s
world line in space-time there is no change involved.</p>
<h5 class="footnote-body-heading"><a id="FOOT193" href="#DOCF193">(193)</a></h5>
<p>John Backus, the
inventor of Fortran, gave high visibility to functional programming when he was
awarded the <abbr class="abbr">ACM</abbr> Turing award in 1978.  His acceptance speech 
(<a class="ref" href="References.xhtml#Backus-1978">Backus 1978</a>) strongly advocated the functional approach.  A good overview of
functional programming is given in <a class="ref" href="References.xhtml#Henderson-1980">Henderson 1980</a> and in 
<a class="ref" href="References.xhtml#Darlington-et-al_002e-1982">Darlington et al. 1982</a>.</p>
<h5 class="footnote-body-heading"><a id="FOOT194" href="#DOCF194">(194)</a></h5>
<p>Observe that, for any two streams, there is in general more
than one acceptable order of interleaving.  Thus, technically, &#8220;merge&#8221; is a
relation rather than a function&#8212;the answer is not a deterministic function of
the inputs.  We already mentioned (<a class="ref" href="3_002e4.xhtml#Footnote-167">Footnote 167</a>) that nondeterminism is
essential when dealing with concurrency.  The merge relation illustrates the
same essential nondeterminism, from the functional perspective.  In 
<a class="ref" href="4_002e3.xhtml#g_t4_002e3">Variations on a Scheme &#8212; Nondeterministic Computing</a>, we will look at nondeterminism from yet another point of view.</p>
<h5 class="footnote-body-heading"><a id="FOOT195" href="#DOCF195">(195)</a></h5>
<p>The object model
approximates the world by dividing it into separate pieces.  The functional
model does not modularize along object boundaries.  The object model is useful
when the unshared state of the &#8220;objects&#8221; is much larger than the state that
they share.  An example of a place where the object viewpoint fails is quantum
mechanics, where thinking of things as individual particles leads to paradoxes
and confusions.  Unifying the object view with the functional view may have
little to do with programming, but rather with fundamental epistemological
issues.</p>
</div>
<hr />
<div class="nav-panel">
<p>
Next: <a href="Chapter-4.xhtml" accesskey="n" rel="next">Metalinguistic Abstraction</a>, Previous: <a href="3_002e4.xhtml#g_t3_002e4_002e5" accesskey="p" rel="prev">Async/Await: Cooperative Concurrency</a>, Up: <a href="Chapter-3.xhtml" accesskey="u" rel="up">Modularity, Objects, and State</a> &#160; [<a href="index.xhtml#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="Term-Index.xhtml" title="Index" rel="index">Index</a>]</p>
</div>



</body>
</html>
